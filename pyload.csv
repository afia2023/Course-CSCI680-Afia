Project Name,File Name,Method Name,Start Line,End Line,Method Code,Documentation,Code With Doc,TokenID
pyload,setup.py,initialize_options,37,38,def initialize_options(self):        pass,,def initialize_options(self):        pass,406546fa-71b4-4668-953e-d0489cbaa052
pyload,setup.py,finalize_options,40,56,"def finalize_options(self):        jinja2_version = pkg_resources.get_distribution(""jinja2"").version        if pkg_resources.parse_version(jinja2_version) < pkg_resources.parse_version(            ""3.0.0""        ):            mapping_file_version = 2        else:            mapping_file_version = 3        mapping_file = f""babel_v{mapping_file_version}.cfg""        with open(mapping_file, ""r"", encoding=""utf-8-sig"") as fp:            mapping = fp.read()        input_dirs = self.distribution.get_option_dict(""extract_messages"")[            ""input_dirs""        ][1]        self.distribution.message_extractors = {input_dirs: mapping}",,"def finalize_options(self):        jinja2_version = pkg_resources.get_distribution(""jinja2"").version        if pkg_resources.parse_version(jinja2_version) < pkg_resources.parse_version(            ""3.0.0""        ):            mapping_file_version = 2        else:            mapping_file_version = 3        mapping_file = f""babel_v{mapping_file_version}.cfg""        with open(mapping_file, ""r"", encoding=""utf-8-sig"") as fp:            mapping = fp.read()        input_dirs = self.distribution.get_option_dict(""extract_messages"")[            ""input_dirs""        ][1]        self.distribution.message_extractors = {input_dirs: mapping}",cfc0840d-4d4e-4e66-bc20-83275d9f8aa6
pyload,setup.py,_execute,58,61,"def _execute(self, func_name, cmd_list):        execute = getattr(self, func_name)        for cmd_name in cmd_list:            execute(cmd_name)",,"def _execute(self, func_name, cmd_list):        execute = getattr(self, func_name)        for cmd_name in cmd_list:            execute(cmd_name)",1a01b6da-0115-48c8-b6e4-81d62f6c0639
pyload,setup.py,run,63,74,"def run(self):        # TODO: add ""download_catalog""        commands = [""extract_messages"", ""init_catalog"", ""compile_catalog""]        if self.dry_run:            self._execute(""get_command_name"", commands)        else:            dirname = os.path.join(os.path.dirname(__file__), ""src"", ""pyload"", ""locale"")            self.mkpath(                dirname            )  # NOTE: do we have to pass dry_run value explicitly here?            self._execute(""run_command"", commands)",,"def run(self):        # TODO: add ""download_catalog""        commands = [""extract_messages"", ""init_catalog"", ""compile_catalog""]        if self.dry_run:            self._execute(""get_command_name"", commands)        else:            dirname = os.path.join(os.path.dirname(__file__), ""src"", ""pyload"", ""locale"")            self.mkpath(                dirname            )  # NOTE: do we have to pass dry_run value explicitly here?            self._execute(""run_command"", commands)",07689c7d-539b-4618-a35a-60f972fae18b
pyload,setup.py,retrieve_version,77,87,"def retrieve_version():    version = None    build = (        int(os.environ[""PYLOAD_BUILD""].strip()) if ""PYLOAD_BUILD"" in os.environ else 0    )    filename = os.path.join(os.path.dirname(__file__), ""VERSION"")    with open(filename) as fp:        version = os.environ.get(""PYLOAD_VERSION"", fp.read()).strip()    return f""{version}.dev{build}"" if build else version",,"def retrieve_version():    version = None    build = (        int(os.environ[""PYLOAD_BUILD""].strip()) if ""PYLOAD_BUILD"" in os.environ else 0    )    filename = os.path.join(os.path.dirname(__file__), ""VERSION"")    with open(filename) as fp:        version = os.environ.get(""PYLOAD_VERSION"", fp.read()).strip()    return f""{version}.dev{build}"" if build else version",1423dfae-0f3d-45c3-be6e-48fb166a56fb
pyload,__init__.py,excepthook,47,53,"def excepthook(exc_type, exc_value, exc_traceback):    if issubclass(exc_type, KeyboardInterrupt):        sys.__excepthook__(exc_type, exc_value, exc_traceback)        return    msg_list = traceback.format_exception_only(exc_type, exc_value)    exc_info = (exc_type, exc_value, exc_traceback)    exc_logger.exception(msg_list[-1], exc_info=exc_info)",,"def excepthook(exc_type, exc_value, exc_traceback):    if issubclass(exc_type, KeyboardInterrupt):        sys.__excepthook__(exc_type, exc_value, exc_traceback)        return    msg_list = traceback.format_exception_only(exc_type, exc_value)    exc_info = (exc_type, exc_value, exc_traceback)    exc_logger.exception(msg_list[-1], exc_info=exc_info)",92508ccd-aafb-40ec-805f-67b98a7a4ed7
pyload,__main__.py,_daemon,28,68,"def _daemon(core_args, pid_file=""""):    try:        pid = os.fork()        if pid > 0:            sys.exit()    except OSError as exc:        sys.stderr.write(f""fork #1 failed: {exc.errno} ({exc.strerror})\n"")        sys.exit(os.EX_OSERR)    # decouple from parent environment    os.setsid()    os.umask(0)    # do second fork    try:        pid = os.fork()        if pid > 0:            # exit from second parent, print(eventual PID before)            print(f""Daemon PID {pid}"")            sys.exit()    except OSError as exc:        sys.stderr.write(f""fork #2 failed: {exc.errno} ({exc.strerror})\n"")        sys.exit(os.EX_OSERR)    # Iterate through and close some file descriptors.    for fd in range(3):        try:            os.close(fd)        except OSError:  #: ERROR as fd wasn't open to begin with (ignored)            pass    os.open(os.devnull, os.O_RDWR)  #: standard input (0)    os.dup2(0, 1)  #: standard output (1)    os.dup2(0, 2)    if pid_file:        write_pid_file(pid_file)        atexit.register(partial(delete_pid_file, pid_file))    pyload_core = Core(*core_args)    pyload_core.start()",,"def _daemon(core_args, pid_file=""""):    try:        pid = os.fork()        if pid > 0:            sys.exit()    except OSError as exc:        sys.stderr.write(f""fork #1 failed: {exc.errno} ({exc.strerror})\n"")        sys.exit(os.EX_OSERR)    # decouple from parent environment    os.setsid()    os.umask(0)    # do second fork    try:        pid = os.fork()        if pid > 0:            # exit from second parent, print(eventual PID before)            print(f""Daemon PID {pid}"")            sys.exit()    except OSError as exc:        sys.stderr.write(f""fork #2 failed: {exc.errno} ({exc.strerror})\n"")        sys.exit(os.EX_OSERR)    # Iterate through and close some file descriptors.    for fd in range(3):        try:            os.close(fd)        except OSError:  #: ERROR as fd wasn't open to begin with (ignored)            pass    os.open(os.devnull, os.O_RDWR)  #: standard input (0)    os.dup2(0, 1)  #: standard output (1)    os.dup2(0, 2)    if pid_file:        write_pid_file(pid_file)        atexit.register(partial(delete_pid_file, pid_file))    pyload_core = Core(*core_args)    pyload_core.start()",7a98689e-e86f-4962-b46e-7d7759abd687
pyload,__main__.py,write_pid_file,71,76,"def write_pid_file(pid_file):    delete_pid_file(pid_file)    pid = os.getpid()    os.makedirs(os.path.dirname(pid_file), exist_ok=True)    with open(pid_file, ""w"") as fp:        fp.write(str(pid))",,"def write_pid_file(pid_file):    delete_pid_file(pid_file)    pid = os.getpid()    os.makedirs(os.path.dirname(pid_file), exist_ok=True)    with open(pid_file, ""w"") as fp:        fp.write(str(pid))",e4e24aaf-4201-4d51-8ce0-2a14a177d0e7
pyload,__main__.py,delete_pid_file,79,81,def delete_pid_file(pid_file):    if os.path.isfile(pid_file):        os.remove(pid_file),,def delete_pid_file(pid_file):    if os.path.isfile(pid_file):        os.remove(pid_file),0f1352aa-82b2-4ad1-acd0-cfba6b56e459
pyload,__main__.py,read_pid_file,84,95,"def read_pid_file(pid_file):        if os.path.isfile(pid_file):        with open(pid_file, ""r"") as fp:            pid = fp.read().strip()        if pid:            pid = int(pid)            return pid    else:        return 0",return pid as int or 0,"def read_pid_file(pid_file):    """""" return pid as int or 0""""""    if os.path.isfile(pid_file):        with open(pid_file, ""r"") as fp:            pid = fp.read().strip()        if pid:            pid = int(pid)            return pid    else:        return 0

return pid as int or 0",21c2db71-bc8b-4e10-9143-28aae68aa85f
pyload,__main__.py,is_already_running,98,152,"def is_already_running(pid_file):    pid = read_pid_file(pid_file)    if not pid:        return 0    if os.name == ""nt"":        ret = 0        import ctypes        import ctypes.wintypes        TH32CS_SNAPPROCESS = 2        INVALID_HANDLE_VALUE = -1        class PROCESSENTRY32(ctypes.Structure):            _fields_ = [('dwSize', ctypes.wintypes.DWORD),                        ('cntUsage', ctypes.wintypes.DWORD),                        ('th32ProcessID', ctypes.wintypes.DWORD),                        ('th32DefaultHeapID', ctypes.wintypes.LPVOID),                        ('th32ModuleID', ctypes.wintypes.DWORD),                        ('cntThreads', ctypes.wintypes.DWORD),                        ('th32ParentProcessID', ctypes.wintypes.DWORD),                        ('pcPriClassBase', ctypes.wintypes.LONG),                        ('dwFlags', ctypes.wintypes.DWORD),                        ('szExeFile', ctypes.c_char * 260)]        kernel32 = ctypes.windll.kernel32        process_info = PROCESSENTRY32()        process_info.dwSize = ctypes.sizeof(PROCESSENTRY32)        hProcessSnapshot = kernel32.CreateToolhelp32Snapshot(TH32CS_SNAPPROCESS, 0)        if hProcessSnapshot != INVALID_HANDLE_VALUE:            found = False            status = kernel32.Process32First(hProcessSnapshot , ctypes.pointer(process_info))            while status:                if process_info.th32ProcessID == pid:                    found = True                    break                status = kernel32.Process32Next(hProcessSnapshot, ctypes.pointer(process_info))            kernel32.CloseHandle(hProcessSnapshot)            if found and process_info.szExeFile.decode().lower() in (""python.exe"", ""pythonw.exe""):                ret = pid        else:            sys.stderr.write(""Unhandled error in CreateToolhelp32Snapshot: {}\n"".format(kernel32.GetLastError()))        return ret    else:        try:            os.kill(pid, 0)  # 0 - default signal (does nothing)        except Exception:            return 0        return pid",,"def is_already_running(pid_file):    pid = read_pid_file(pid_file)    if not pid:        return 0    if os.name == ""nt"":        ret = 0        import ctypes        import ctypes.wintypes        TH32CS_SNAPPROCESS = 2        INVALID_HANDLE_VALUE = -1        class PROCESSENTRY32(ctypes.Structure):            _fields_ = [('dwSize', ctypes.wintypes.DWORD),                        ('cntUsage', ctypes.wintypes.DWORD),                        ('th32ProcessID', ctypes.wintypes.DWORD),                        ('th32DefaultHeapID', ctypes.wintypes.LPVOID),                        ('th32ModuleID', ctypes.wintypes.DWORD),                        ('cntThreads', ctypes.wintypes.DWORD),                        ('th32ParentProcessID', ctypes.wintypes.DWORD),                        ('pcPriClassBase', ctypes.wintypes.LONG),                        ('dwFlags', ctypes.wintypes.DWORD),                        ('szExeFile', ctypes.c_char * 260)]        kernel32 = ctypes.windll.kernel32        process_info = PROCESSENTRY32()        process_info.dwSize = ctypes.sizeof(PROCESSENTRY32)        hProcessSnapshot = kernel32.CreateToolhelp32Snapshot(TH32CS_SNAPPROCESS, 0)        if hProcessSnapshot != INVALID_HANDLE_VALUE:            found = False            status = kernel32.Process32First(hProcessSnapshot , ctypes.pointer(process_info))            while status:                if process_info.th32ProcessID == pid:                    found = True                    break                status = kernel32.Process32Next(hProcessSnapshot, ctypes.pointer(process_info))            kernel32.CloseHandle(hProcessSnapshot)            if found and process_info.szExeFile.decode().lower() in (""python.exe"", ""pythonw.exe""):                ret = pid        else:            sys.stderr.write(""Unhandled error in CreateToolhelp32Snapshot: {}\n"".format(kernel32.GetLastError()))        return ret    else:        try:            os.kill(pid, 0)  # 0 - default signal (does nothing)        except Exception:            return 0        return pid",c73931aa-a7fb-48cc-9fc3-f7f57265d084
pyload,__main__.py,_parse_args,155,206,"def _parse_args(cmd_args):        parser = argparse.ArgumentParser(        description=DESCRIPTION, formatter_class=argparse.RawDescriptionHelpFormatter,    )    group = parser.add_mutually_exclusive_group()    parser.add_argument(        ""-d"", ""--debug"", action=""store_true"", help=""enable debug mode"", default=None    )    parser.add_argument(        ""-r"",        ""--reset"",        action=""store_true"",        help=""reset default username/password"",        default=None,    )    parser.add_argument(        ""--storagedir"",        help=""use this location to save downloads"",        default=None,    )    parser.add_argument(        ""--userdir"",        help=""use this location to store user data files"",        default=Core.DEFAULT_DATADIR,    )    parser.add_argument(        ""--tempdir"",        help=""use this location to store temporary files"",        default=Core.DEFAULT_TMPDIR,    )    parser.add_argument(        ""--pidfile"",        help=""set the full path to the pidfile"",        default=os.path.join(Core.DEFAULT_TMPDIR, ""pyload.pid""),    )    parser.add_argument(""--dry-run"", action=""store_true"", help=""test start-up and exit"", default=False)    parser.add_argument(""--daemon"", action=""store_true"", help=""run as daemon"")    parser.add_argument(""--quit"", action=""store_true"", help=""quit running pyLoad instance"", default=False)    parser.add_argument(""--status"", action=""store_true"", help=""display pid if running or 0"", default=False)    group.add_argument(""--version"", action=""version"", version=f""pyLoad {__version__}"")    return parser.parse_args(cmd_args)","Parse command line parameters.

Args:
  cmd_args ([str]): command line parameters as list of strings

Returns:
  :obj:`argparse.Namespace`: command line parameters namespace","def _parse_args(cmd_args):    """"""    Parse command line parameters.    Args:      cmd_args ([str]): command line parameters as list of strings    Returns:      :obj:`argparse.Namespace`: command line parameters namespace    """"""    parser = argparse.ArgumentParser(        description=DESCRIPTION, formatter_class=argparse.RawDescriptionHelpFormatter,    )    group = parser.add_mutually_exclusive_group()    parser.add_argument(        ""-d"", ""--debug"", action=""store_true"", help=""enable debug mode"", default=None    )    parser.add_argument(        ""-r"",        ""--reset"",        action=""store_true"",        help=""reset default username/password"",        default=None,    )    parser.add_argument(        ""--storagedir"",        help=""use this location to save downloads"",        default=None,    )    parser.add_argument(        ""--userdir"",        help=""use this location to store user data files"",        default=Core.DEFAULT_DATADIR,    )    parser.add_argument(        ""--tempdir"",        help=""use this location to store temporary files"",        default=Core.DEFAULT_TMPDIR,    )    parser.add_argument(        ""--pidfile"",        help=""set the full path to the pidfile"",        default=os.path.join(Core.DEFAULT_TMPDIR, ""pyload.pid""),    )    parser.add_argument(""--dry-run"", action=""store_true"", help=""test start-up and exit"", default=False)    parser.add_argument(""--daemon"", action=""store_true"", help=""run as daemon"")    parser.add_argument(""--quit"", action=""store_true"", help=""quit running pyLoad instance"", default=False)    parser.add_argument(""--status"", action=""store_true"", help=""display pid if running or 0"", default=False)    group.add_argument(""--version"", action=""version"", version=f""pyLoad {__version__}"")    return parser.parse_args(cmd_args)

Parse command line parameters.

Args:
  cmd_args ([str]): command line parameters as list of strings

Returns:
  :obj:`argparse.Namespace`: command line parameters namespace",b7f9ae06-6b09-4ff9-934f-ece0c5a30b79
pyload,__main__.py,run,209,244,"def run(core_args, daemon=False, pid_file=""""):    # change name to 'pyLoad'    # from .lib.rename_process import rename_process    # rename_process('pyLoad')    if pid_file:        pid = is_already_running(pid_file)        if pid:            sys.stderr.write(f""pyLoad already running with pid {pid}\n"")            if os.name == ""nt"":                sys.exit(70)            else:                sys.exit(os.EX_SOFTWARE)    if daemon:        if os.name == ""nt"":            sys.stderr.write(""Daemon is not supported under windows\n"")            sys.exit(70)  #: EX_SOFTWARE        else:            return _daemon(core_args, pid_file=pid_file)    else:        if pid_file:            write_pid_file(pid_file)            atexit.register(partial(delete_pid_file, pid_file))    pyload_core = Core(*core_args)    try:        pyload_core.start()    except KeyboardInterrupt:        pyload_core.log.info(pyload_core._(""Killed from terminal""))        pyload_core.terminate()        if os.name == ""nt"":            sys.exit(75)        else:            sys.exit(os.EX_TEMPFAIL)",,"def run(core_args, daemon=False, pid_file=""""):    # change name to 'pyLoad'    # from .lib.rename_process import rename_process    # rename_process('pyLoad')    if pid_file:        pid = is_already_running(pid_file)        if pid:            sys.stderr.write(f""pyLoad already running with pid {pid}\n"")            if os.name == ""nt"":                sys.exit(70)            else:                sys.exit(os.EX_SOFTWARE)    if daemon:        if os.name == ""nt"":            sys.stderr.write(""Daemon is not supported under windows\n"")            sys.exit(70)  #: EX_SOFTWARE        else:            return _daemon(core_args, pid_file=pid_file)    else:        if pid_file:            write_pid_file(pid_file)            atexit.register(partial(delete_pid_file, pid_file))    pyload_core = Core(*core_args)    try:        pyload_core.start()    except KeyboardInterrupt:        pyload_core.log.info(pyload_core._(""Killed from terminal""))        pyload_core.terminate()        if os.name == ""nt"":            sys.exit(75)        else:            sys.exit(os.EX_TEMPFAIL)",14bcce4b-d10a-4d1d-a9d2-82a85e8623fc
pyload,__main__.py,quit_instance,247,279,"def quit_instance(pid_file):    if not pid_file:        sys.stderr.write(""Cannot quit without pidfile.\n"")        return    if os.name == ""nt"":        sys.stderr.write(""Not supported on windows.\n"")        return    pid = is_already_running(pid_file)    if not pid:        sys.stderr.write(""No pyLoad running.\n"")        return    try:        os.kill(pid, 3)  #: SIGQUIT        t = time.time()        sys.stdout.write(""waiting for pyLoad to quit\n"")        while os.path.exists(pid_file) and t + 10 > time.time():            time.sleep(0.25)        if not os.path.exists(pid_file):            sys.stdout.write(""pyLoad successfully stopped\n"")        else:            os.kill(pid, 9)  #: SIGKILL            sys.stderr.write(""pyLoad did not respond\n"")            sys.stderr.write(f""Kill signal was send to process with id {pid}\n"")    except Exception as exc:        sys.stderr.write(""Error quitting pyLoad\n"")",,"def quit_instance(pid_file):    if not pid_file:        sys.stderr.write(""Cannot quit without pidfile.\n"")        return    if os.name == ""nt"":        sys.stderr.write(""Not supported on windows.\n"")        return    pid = is_already_running(pid_file)    if not pid:        sys.stderr.write(""No pyLoad running.\n"")        return    try:        os.kill(pid, 3)  #: SIGQUIT        t = time.time()        sys.stdout.write(""waiting for pyLoad to quit\n"")        while os.path.exists(pid_file) and t + 10 > time.time():            time.sleep(0.25)        if not os.path.exists(pid_file):            sys.stdout.write(""pyLoad successfully stopped\n"")        else:            os.kill(pid, 9)  #: SIGKILL            sys.stderr.write(""pyLoad did not respond\n"")            sys.stderr.write(f""Kill signal was send to process with id {pid}\n"")    except Exception as exc:        sys.stderr.write(""Error quitting pyLoad\n"")",5ae91c1c-eae5-4d3a-8a7c-c7d1616f8a78
pyload,__main__.py,main,282,292,"def main(cmd_args=sys.argv[1:]):        args = _parse_args(cmd_args)    core_args = (args.userdir, args.tempdir, args.storagedir, args.debug, args.reset, args.dry_run)    if args.quit:        quit_instance(args.pidfile)    else:        run(core_args, args.daemon, args.pidfile)",Entry point for console_scripts.,"def main(cmd_args=sys.argv[1:]):    """"""    Entry point for console_scripts.    """"""    args = _parse_args(cmd_args)    core_args = (args.userdir, args.tempdir, args.storagedir, args.debug, args.reset, args.dry_run)    if args.quit:        quit_instance(args.pidfile)    else:        run(core_args, args.daemon, args.pidfile)

Entry point for console_scripts.",276d6e31-bc00-4cec-9764-d1a57e436af2
core,log_factory.py,__init__,44,47,"def __init__(self, core):        self.pyload = core        self._ = core._        self.loggers = {}",,"def __init__(self, core):        self.pyload = core        self._ = core._        self.loggers = {}",7886dfee-2c72-4715-b341-2509d2b9571b
core,log_factory.py,init_logger,49,53,"def init_logger(self, name):        logger = logging.getLogger(name)        self.loggers[name] = logger        self._init_logger(logger)        return logger",,"def init_logger(self, name):        logger = logging.getLogger(name)        self.loggers[name] = logger        self._init_logger(logger)        return logger",1cd7ab02-4b5e-4af2-ab79-d58699176438
core,log_factory.py,_init_logger,55,68,"def _init_logger(self, logger):        console = self.pyload.config.get(""log"", ""console"")        syslog = self.pyload.config.get(""log"", ""syslog"")        filelog = self.pyload.config.get(""log"", ""filelog"")        level = logging.DEBUG if self.pyload.debug else logging.INFO        logger.setLevel(level)        if console:            self._init_console_handler(logger)        if syslog:            self._init_syslog_handler(logger)        if filelog:            self._init_filelog_handler(logger)",,"def _init_logger(self, logger):        console = self.pyload.config.get(""log"", ""console"")        syslog = self.pyload.config.get(""log"", ""syslog"")        filelog = self.pyload.config.get(""log"", ""filelog"")        level = logging.DEBUG if self.pyload.debug else logging.INFO        logger.setLevel(level)        if console:            self._init_console_handler(logger)        if syslog:            self._init_syslog_handler(logger)        if filelog:            self._init_filelog_handler(logger)",bd945e3f-ac2b-4c92-b52c-08b6183a5b23
core,log_factory.py,get_logger,70,71,"def get_logger(self, name):        return self.loggers.get(name, self.init_logger(name))",,"def get_logger(self, name):        return self.loggers.get(name, self.init_logger(name))",d36c5107-2721-4c6f-af88-1e973a80def9
core,log_factory.py,remove_logger,73,77,"def remove_logger(self, name):        logger = self.loggers.pop(name)        if not logger:            return        self._removeHandlers(logger)",,"def remove_logger(self, name):        logger = self.loggers.pop(name)        if not logger:            return        self._removeHandlers(logger)",c0f5e234-5377-462e-bc08-9394a3d851b8
core,log_factory.py,reset_logger,79,83,"def reset_logger(self, name):        logger = self.loggers.get(name)        if not logger:            return        self._init_logger(logger)",,"def reset_logger(self, name):        logger = self.loggers.get(name)        if not logger:            return        self._init_logger(logger)",a2f6d002-645e-46a0-aaf0-116c3e5964f5
core,log_factory.py,_removeHandlers,85,88,"def _removeHandlers(self, logger):        for handler in logger.handlers:            with closing(handler) as hdlr:                logger.removeHandler(hdlr)",,"def _removeHandlers(self, logger):        for handler in logger.handlers:            with closing(handler) as hdlr:                logger.removeHandler(hdlr)",f440c809-aa19-4c74-a78f-db74eff5868c
core,log_factory.py,shutdown,90,93,def shutdown(self):        for logger in self.loggers.values():            self._removeHandlers(logger)        self.loggers.clear(),,def shutdown(self):        for logger in self.loggers.values():            self._removeHandlers(logger)        self.loggers.clear(),79651fc4-f8fd-4e13-aec3-3dc982adeffd
core,log_factory.py,_init_console_handler,95,114,"def _init_console_handler(self, logger):        color = self.pyload.config.get(""log"", ""console_color"") and colorlog        if color:            consoleform = colorlog.ColoredFormatter(                self.LINEFORMAT_COLORED,                datefmt=self.DATEFORMAT,                log_colors=self.PRIMARY_COLORS,                secondary_log_colors=self.SECONDARY_COLORS,                style=self.LINESTYLE,            )        else:            consoleform = logging.Formatter(                self.LINEFORMAT, self.DATEFORMAT, self.LINESTYLE            )        consolehdlr = logging.StreamHandler(sys.stdout)        consolehdlr.setFormatter(consoleform)        logger.addHandler(consolehdlr)",,"def _init_console_handler(self, logger):        color = self.pyload.config.get(""log"", ""console_color"") and colorlog        if color:            consoleform = colorlog.ColoredFormatter(                self.LINEFORMAT_COLORED,                datefmt=self.DATEFORMAT,                log_colors=self.PRIMARY_COLORS,                secondary_log_colors=self.SECONDARY_COLORS,                style=self.LINESTYLE,            )        else:            consoleform = logging.Formatter(                self.LINEFORMAT, self.DATEFORMAT, self.LINESTYLE            )        consolehdlr = logging.StreamHandler(sys.stdout)        consolehdlr.setFormatter(consoleform)        logger.addHandler(consolehdlr)",4e1d2aa1-1fcb-4639-847c-572fde9ebd44
core,log_factory.py,_init_syslog_handler,116,145,"def _init_syslog_handler(self, logger):        # try to mimic to normal syslog messages        fmt = ""{asctime} {name}: {message}""        datefmt = ""%b %e %H:%M:%S""        syslog_form = logging.Formatter(fmt, datefmt, self.LINESTYLE)        syslog_addr = None        location = self.pyload.config.get(""log"", ""syslog_location"")        if location == ""remote"":            host = self.pyload.config.get(""log"", ""syslog_host"")            port = self.pyload.config.get(""log"", ""syslog_port"")            syslog_addr = (host, port)        else:            folder = self.pyload.config.get(""log"", ""syslog_folder"")            if folder:                syslog_addr = folder            elif sys.platform == ""darwin"":                syslog_addr = ""/var/run/syslog""            elif os.name == ""nt"":                # TODO: Recheck                syslog_addr = os.path.join(self.pyload.userdir, ""logs"", ""syslog"")            else:                syslog_addr = ""/dev/log""            os.makedirs(syslog_addr, exist_ok=True)        sysloghdlr = logging.handlers.SysLogHandler(syslog_addr)        sysloghdlr.setFormatter(syslog_form)        logger.addHandler(sysloghdlr)",,"def _init_syslog_handler(self, logger):        # try to mimic to normal syslog messages        fmt = ""{asctime} {name}: {message}""        datefmt = ""%b %e %H:%M:%S""        syslog_form = logging.Formatter(fmt, datefmt, self.LINESTYLE)        syslog_addr = None        location = self.pyload.config.get(""log"", ""syslog_location"")        if location == ""remote"":            host = self.pyload.config.get(""log"", ""syslog_host"")            port = self.pyload.config.get(""log"", ""syslog_port"")            syslog_addr = (host, port)        else:            folder = self.pyload.config.get(""log"", ""syslog_folder"")            if folder:                syslog_addr = folder            elif sys.platform == ""darwin"":                syslog_addr = ""/var/run/syslog""            elif os.name == ""nt"":                # TODO: Recheck                syslog_addr = os.path.join(self.pyload.userdir, ""logs"", ""syslog"")            else:                syslog_addr = ""/dev/log""            os.makedirs(syslog_addr, exist_ok=True)        sysloghdlr = logging.handlers.SysLogHandler(syslog_addr)        sysloghdlr.setFormatter(syslog_form)        logger.addHandler(sysloghdlr)",250c87ea-3d6e-4560-9c64-996417ba6640
core,log_factory.py,_init_filelog_handler,147,177,"def _init_filelog_handler(self, logger):        filename = logger.name + self.FILE_EXTENSION        filelog_folder = self.pyload.config.get(""log"", ""filelog_folder"")        if not filelog_folder:            filelog_folder = os.path.join(self.pyload.userdir, ""logs"")        os.makedirs(filelog_folder, exist_ok=True)        filelog_form = logging.Formatter(            self.LINEFORMAT, self.DATEFORMAT, self.LINESTYLE        )        filelog_path = os.path.join(filelog_folder, filename)        encoding = locale.getpreferredencoding(do_setlocale=False)        if self.pyload.config.get(""log"", ""filelog_rotate""):            max_size = self.pyload.config.get(""log"", ""filelog_size"") << 10            max_entries = self.pyload.config.get(""log"", ""filelog_entries"")            filehdlr = logging.handlers.RotatingFileHandler(                filelog_path,                maxBytes=max_size,                backupCount=max_entries,                encoding=encoding,            )        else:            filehdlr = logging.FileHandler(filelog_path, encoding=encoding)        filehdlr.setFormatter(filelog_form)        logger.addHandler(filehdlr)",,"def _init_filelog_handler(self, logger):        filename = logger.name + self.FILE_EXTENSION        filelog_folder = self.pyload.config.get(""log"", ""filelog_folder"")        if not filelog_folder:            filelog_folder = os.path.join(self.pyload.userdir, ""logs"")        os.makedirs(filelog_folder, exist_ok=True)        filelog_form = logging.Formatter(            self.LINEFORMAT, self.DATEFORMAT, self.LINESTYLE        )        filelog_path = os.path.join(filelog_folder, filename)        encoding = locale.getpreferredencoding(do_setlocale=False)        if self.pyload.config.get(""log"", ""filelog_rotate""):            max_size = self.pyload.config.get(""log"", ""filelog_size"") << 10            max_entries = self.pyload.config.get(""log"", ""filelog_entries"")            filehdlr = logging.handlers.RotatingFileHandler(                filelog_path,                maxBytes=max_size,                backupCount=max_entries,                encoding=encoding,            )        else:            filehdlr = logging.FileHandler(filelog_path, encoding=encoding)        filehdlr.setFormatter(filelog_form)        logger.addHandler(filehdlr)",a03fdb46-76ef-4ae5-899f-b318d6f203c3
core,scheduler.py,__init__,17,19,def __init__(self):        self.call = []        self.result = (),,def __init__(self):        self.call = []        self.result = (),a422e8ab-628f-4288-9165-fc2d6882dd3b
core,scheduler.py,add_callback,21,22,"def add_callback(self, f, *cargs, **ckwargs):        self.call.append((f, cargs, ckwargs))",,"def add_callback(self, f, *cargs, **ckwargs):        self.call.append((f, cargs, ckwargs))",9e1856b5-42da-455c-aa3c-36f5c6498b41
core,scheduler.py,callback,24,31,"def callback(self, *args, **kwargs):        if self.result:            raise AlreadyCalled        self.result = (args, kwargs)        for f, cargs, ckwargs in self.call:            args += tuple(cargs)            kwargs.update(ckwargs)            f(*args ** kwargs)",,"def callback(self, *args, **kwargs):        if self.result:            raise AlreadyCalled        self.result = (args, kwargs)        for f, cargs, ckwargs in self.call:            args += tuple(cargs)            kwargs.update(ckwargs)            f(*args ** kwargs)",19adc244-a445-4231-a7c5-eefe773cdcd7
core,scheduler.py,__init__,35,38,"def __init__(self, core):        self.pyload = core        self._ = core._        self.queue = PriorityQueue()",,"def __init__(self, core):        self.pyload = core        self._ = core._        self.queue = PriorityQueue()",447e6e56-61cf-4b18-950a-28080e39cdf8
core,scheduler.py,add_job,40,45,"def add_job(self, t, call, args=[], kwargs={}, threaded=True):        d = Deferred()        t += time.time()        j = Job(t, call, args, kwargs, d, threaded)        self.queue.put((t, j))        return d",,"def add_job(self, t, call, args=[], kwargs={}, threaded=True):        d = Deferred()        t += time.time()        j = Job(t, call, args, kwargs, d, threaded)        self.queue.put((t, j))        return d",a7fb4ba4-24ea-440a-8281-ad6865114f7b
core,scheduler.py,remove_job,47,62,"def remove_job(self, d):                index = -1        for i, j in enumerate(self.queue):            if j[1].deferred == d:                index = i        if index >= 0:            del self.queue[index]            return True        return False",":param d: deferred object
:return: if job was deleted","def remove_job(self, d):        """"""        :param d: deferred object        :return: if job was deleted        """"""        index = -1        for i, j in enumerate(self.queue):            if j[1].deferred == d:                index = i        if index >= 0:            del self.queue[index]            return True        return False

:param d: deferred object
:return: if job was deleted",61679f99-6d8a-4f99-b140-546903ae593c
core,scheduler.py,run,64,74,"def run(self):        while True:            t, j = self.queue.get()            if not j:                break            else:                if t <= time.time():                    j.start()                else:                    self.queue.put((t, j))                    break",,"def run(self):        while True:            t, j = self.queue.get()            if not j:                break            else:                if t <= time.time():                    j.start()                else:                    self.queue.put((t, j))                    break",15fcb0a0-135d-4c36-8c48-f0f2eabc697f
core,scheduler.py,__init__,78,84,"def __init__(self, time, call, args=[], kwargs={}, deferred=None, threaded=True):        self.time = float(time)        self.call = call        self.args = args        self.kwargs = kwargs        self.deferred = deferred        self.threaded = threaded",,"def __init__(self, time, call, args=[], kwargs={}, deferred=None, threaded=True):        self.time = float(time)        self.call = call        self.args = args        self.kwargs = kwargs        self.deferred = deferred        self.threaded = threaded",7531c1b6-b701-43e1-86d5-9bda0bdfab63
core,scheduler.py,__lt__,86,87,"def __lt__(self, other):        return id(self) < id(other)",,"def __lt__(self, other):        return id(self) < id(other)",54a2a84c-d4a1-4109-8f2a-2ca5e98ff8b1
core,scheduler.py,run,89,94,"def run(self):        ret = self.call(*self.args, **self.kwargs)        if self.deferred is None:            return        else:            self.deferred.callback(ret)",,"def run(self):        ret = self.call(*self.args, **self.kwargs)        if self.deferred is None:            return        else:            self.deferred.callback(ret)",4369f9cf-acc2-4016-bab7-6556a771b6dd
core,scheduler.py,start,96,100,"def start(self):        if self.threaded:            start_new_thread(self.run, ())        else:            self.run()",,"def start(self):        if self.threaded:            start_new_thread(self.run, ())        else:            self.run()",09bb6383-0641-4851-a9c1-da6a3f4756c1
core,scheduler.py,__init__,108,110,def __init__(self):        self.queue = []        self.lock = Lock(),,def __init__(self):        self.queue = []        self.lock = Lock(),3ce77d17-d7fe-4e4a-8a3e-462370991053
core,scheduler.py,__iter__,112,113,def __iter__(self):        return iter(self.queue),,def __iter__(self):        return iter(self.queue),675357fd-4416-43eb-ba3d-5d028921ab96
core,scheduler.py,__delitem__,115,116,"def __delitem__(self, key):        del self.queue[key]",,"def __delitem__(self, key):        del self.queue[key]",0e419922-d5f2-4cc3-9fd6-8d33191319b4
core,scheduler.py,put,119,120,"def put(self, element):        heappush(self.queue, element)",,"def put(self, element):        heappush(self.queue, element)",f88c1df5-6eb5-4b9e-b82d-52ba197a92b5
core,scheduler.py,get,123,131,"def get(self):                try:            el = heappop(self.queue)            return el        except IndexError:            return None, None",return element or None.,"def get(self):        """"""        return element or None.        """"""        try:            el = heappop(self.queue)            return el        except IndexError:            return None, None

return element or None.",eeed1056-2ebc-48da-96fd-023f6642a713
core,__init__.py,version,59,60,def version(self):        return PYLOAD_VERSION,,def version(self):        return PYLOAD_VERSION,9345ff8b-09bd-4c3a-bb32-365557956341
core,__init__.py,version_info,63,64,def version_info(self):        return PYLOAD_VERSION_INFO,,def version_info(self):        return PYLOAD_VERSION_INFO,60bf26d6-4793-47c2-91d3-8fb066aa5cb8
core,__init__.py,running,67,68,def running(self):        return self._running.is_set(),,def running(self):        return self._running.is_set(),2a5800e7-1a53-4d31-8e0a-2a2126c1a81f
core,__init__.py,exiting,72,73,def exiting(self):        return self._exiting,,def exiting(self):        return self._exiting,222f7c4c-1c29-44a9-98f2-136552bd0213
core,__init__.py,debug,76,77,def debug(self):        return self._debug,,def debug(self):        return self._debug,e57933e6-adc4-4460-8ae0-46298446ca3a
core,__init__.py,__init__,80,112,"def __init__(self, userdir, tempdir, storagedir, debug=None, reset=False, dry=False):        self._running = Event()        self._exiting = False        self._do_restart = False        self._do_exit = False        self._ = lambda x: x        self._debug = 0        self._dry_run = dry        # if self.tmpdir not in sys.path:        # sys.path.append(self.tmpdir)        # if refresh:        # cleanpy(PACKDIR)        datadir = os.path.join(os.path.realpath(userdir), ""data"")        os.makedirs(datadir, exist_ok=True)        os.chdir(datadir)        self._init_config(userdir, tempdir, storagedir, debug)        self._init_log()        if storagedir is not None:            self.log.warning(""Download folder was specified from the commandline"")        self._init_database(reset and not dry)        self._init_network()        self._init_api()        self._init_managers()        self._init_webserver()        atexit.register(self.terminate)        # TODO: Remove...        self.last_client_connected = 0",,"def __init__(self, userdir, tempdir, storagedir, debug=None, reset=False, dry=False):        self._running = Event()        self._exiting = False        self._do_restart = False        self._do_exit = False        self._ = lambda x: x        self._debug = 0        self._dry_run = dry        # if self.tmpdir not in sys.path:        # sys.path.append(self.tmpdir)        # if refresh:        # cleanpy(PACKDIR)        datadir = os.path.join(os.path.realpath(userdir), ""data"")        os.makedirs(datadir, exist_ok=True)        os.chdir(datadir)        self._init_config(userdir, tempdir, storagedir, debug)        self._init_log()        if storagedir is not None:            self.log.warning(""Download folder was specified from the commandline"")        self._init_database(reset and not dry)        self._init_network()        self._init_api()        self._init_managers()        self._init_webserver()        atexit.register(self.terminate)        # TODO: Remove...        self.last_client_connected = 0",72ed6170-1c6e-4d36-a004-ad7d60717ec0
core,__init__.py,_init_config,114,144,"def _init_config(self, userdir, tempdir, storagedir, debug):        from .config.parser import ConfigParser        self.userdir = os.path.realpath(userdir)        self.tempdir = os.path.realpath(tempdir)        os.makedirs(self.userdir, exist_ok=True)        os.makedirs(self.tempdir, exist_ok=True)        self.config = ConfigParser(self.userdir)        if debug is None:            if self.config.get(""general"", ""debug_mode""):                debug_level = self.config.get(""general"", ""debug_level"")                self._debug = self.DEBUG_LEVEL_MAP[debug_level]        else:            self._debug = max(0, int(debug))        # If no argument set, read storage dir from config file,        # otherwise save setting to config dir        if storagedir is None:            storagedir = self.config.get(""general"", ""storage_folder"")            # Make sure storage_folder is not empty            if not storagedir:                self.config.set(""general"", ""storage_folder"", ""~/Downloads/pyLoad"")                storagedir = self.config.get(""general"", ""storage_folder"")        else:            self.config.set(""general"", ""storage_folder"", storagedir)        os.makedirs(storagedir, exist_ok=True)        if not self._dry_run:            self.config.save()",,"def _init_config(self, userdir, tempdir, storagedir, debug):        from .config.parser import ConfigParser        self.userdir = os.path.realpath(userdir)        self.tempdir = os.path.realpath(tempdir)        os.makedirs(self.userdir, exist_ok=True)        os.makedirs(self.tempdir, exist_ok=True)        self.config = ConfigParser(self.userdir)        if debug is None:            if self.config.get(""general"", ""debug_mode""):                debug_level = self.config.get(""general"", ""debug_level"")                self._debug = self.DEBUG_LEVEL_MAP[debug_level]        else:            self._debug = max(0, int(debug))        # If no argument set, read storage dir from config file,        # otherwise save setting to config dir        if storagedir is None:            storagedir = self.config.get(""general"", ""storage_folder"")            # Make sure storage_folder is not empty            if not storagedir:                self.config.set(""general"", ""storage_folder"", ""~/Downloads/pyLoad"")                storagedir = self.config.get(""general"", ""storage_folder"")        else:            self.config.set(""general"", ""storage_folder"", storagedir)        os.makedirs(storagedir, exist_ok=True)        if not self._dry_run:            self.config.save()",78234c79-b97e-4efe-b6ea-d7937d942799
core,__init__.py,_init_log,146,156,"def _init_log(self):        from .log_factory import LogFactory        self.logfactory = LogFactory(self)        self.log = self.logfactory.get_logger(            ""pyload""        )  # NOTE: forced debug mode from console is not working actually        self.log.info(f""*** Welcome to pyLoad {self.version} ***"")        if self._dry_run:            self.log.info(""*** TEST RUN ***"")",,"def _init_log(self):        from .log_factory import LogFactory        self.logfactory = LogFactory(self)        self.log = self.logfactory.get_logger(            ""pyload""        )  # NOTE: forced debug mode from console is not working actually        self.log.info(f""*** Welcome to pyLoad {self.version} ***"")        if self._dry_run:            self.log.info(""*** TEST RUN ***"")",e5e620c9-18ed-4590-8add-c126ce1d5fa6
core,__init__.py,_init_network,158,162,def _init_network(self):        from .network import request_factory        from .network.request_factory import RequestFactory        self.req = self.request_factory = RequestFactory(self),,def _init_network(self):        from .network import request_factory        from .network.request_factory import RequestFactory        self.req = self.request_factory = RequestFactory(self),b663aec9-6725-4195-89ba-0466a777fc31
core,__init__.py,_init_api,164,167,def _init_api(self):        from .api import Api        self.api = Api(self),,def _init_api(self):        from .api import Api        self.api = Api(self),b951c19b-e639-47bb-99d6-d0ac7b72ee41
core,__init__.py,_init_webserver,169,172,def _init_webserver(self):        from pyload.webui.webserver_thread import WebServerThread        self.webserver = WebServerThread(self),,def _init_webserver(self):        from pyload.webui.webserver_thread import WebServerThread        self.webserver = WebServerThread(self),1b0cabfd-c0a0-4011-ae3a-84f4ab86b5e6
core,__init__.py,_init_database,174,193,"def _init_database(self, reset):        from .threads.database_thread import DatabaseThread        db_path = os.path.join(self.userdir, ""data"", DatabaseThread.DB_FILENAME)        newdb = not os.path.isfile(db_path)        self.db = DatabaseThread(self)        self.db.setup()        userpw = (self.DEFAULT_USERNAME, self.DEFAULT_PASSWORD)        # nousers = bool(self.db.list_users())        if reset or newdb:            self.db.add_user(*userpw, reset=True)        if reset:            self.log.info(                self._(                    ""Successfully reset default login credentials `{}|{}`""                ).format(*userpw)            )",,"def _init_database(self, reset):        from .threads.database_thread import DatabaseThread        db_path = os.path.join(self.userdir, ""data"", DatabaseThread.DB_FILENAME)        newdb = not os.path.isfile(db_path)        self.db = DatabaseThread(self)        self.db.setup()        userpw = (self.DEFAULT_USERNAME, self.DEFAULT_PASSWORD)        # nousers = bool(self.db.list_users())        if reset or newdb:            self.db.add_user(*userpw, reset=True)        if reset:            self.log.info(                self._(                    ""Successfully reset default login credentials `{}|{}`""                ).format(*userpw)            )",cbe47b8f-4c7a-42c6-bb22-5fdd008fdf76
core,__init__.py,_init_managers,195,213,def _init_managers(self):        from .managers.account_manager import AccountManager        from .managers.addon_manager import AddonManager        from .managers.captcha_manager import CaptchaManager        from .managers.event_manager import EventManager        from .managers.file_manager import FileManager        from .managers.plugin_manager import PluginManager        from .managers.thread_manager import ThreadManager        from .scheduler import Scheduler        self.files = self.file_manager = FileManager(self)        self.scheduler = Scheduler(self)        self.pgm = self.plugin_manager = PluginManager(self)        self.evm = self.event_manager = EventManager(self)        self.acm = self.account_manager = AccountManager(self)        self.thm = self.thread_manager = ThreadManager(self)        self.cpm = self.captcha_manager = CaptchaManager(self)        self.adm = self.addon_manager = AddonManager(self),,def _init_managers(self):        from .managers.account_manager import AccountManager        from .managers.addon_manager import AddonManager        from .managers.captcha_manager import CaptchaManager        from .managers.event_manager import EventManager        from .managers.file_manager import FileManager        from .managers.plugin_manager import PluginManager        from .managers.thread_manager import ThreadManager        from .scheduler import Scheduler        self.files = self.file_manager = FileManager(self)        self.scheduler = Scheduler(self)        self.pgm = self.plugin_manager = PluginManager(self)        self.evm = self.event_manager = EventManager(self)        self.acm = self.account_manager = AccountManager(self)        self.thm = self.thread_manager = ThreadManager(self)        self.cpm = self.captcha_manager = CaptchaManager(self)        self.adm = self.addon_manager = AddonManager(self),dd8777f0-b9bd-4977-b8ab-7c858a1ada6f
core,__init__.py,_setup_permissions,215,248,"def _setup_permissions(self):        self.log.debug(""Setup permissions..."")        if os.name == ""nt"":            return        change_group = self.config.get(""permission"", ""change_group"")        change_user = self.config.get(""permission"", ""change_user"")        if change_group:            try:                from grp import getgrnam                group = getgrnam(self.config.get(""permission"", ""group""))                os.setgid(group[2])            except Exception:                self.log.warning(                    self._(""Unable to change gid""),                    exc_info=self.debug > 1,                    stack_info=self.debug > 2,                )        if change_user:            try:                from pwd import getpwnam                user = getpwnam(self.config.get(""permission"", ""user""))                os.setuid(user[2])            except Exception:                self.log.warning(                    self._(""Unable to change uid""),                    exc_info=self.debug > 1,                    stack_info=self.debug > 2,                )",,"def _setup_permissions(self):        self.log.debug(""Setup permissions..."")        if os.name == ""nt"":            return        change_group = self.config.get(""permission"", ""change_group"")        change_user = self.config.get(""permission"", ""change_user"")        if change_group:            try:                from grp import getgrnam                group = getgrnam(self.config.get(""permission"", ""group""))                os.setgid(group[2])            except Exception:                self.log.warning(                    self._(""Unable to change gid""),                    exc_info=self.debug > 1,                    stack_info=self.debug > 2,                )        if change_user:            try:                from pwd import getpwnam                user = getpwnam(self.config.get(""permission"", ""user""))                os.setuid(user[2])            except Exception:                self.log.warning(                    self._(""Unable to change uid""),                    exc_info=self.debug > 1,                    stack_info=self.debug > 2,                )",e14e8ade-9ddb-4061-8eda-2b041062e281
core,__init__.py,set_language,250,253,"def set_language(self, lang):        localedir = os.path.join(PKGDIR, ""locale"")        languages = (locale.locale_alias[lang.lower()].split(""_"", 1)[0],)        self._set_language(self.LOCALE_DOMAIN, localedir, languages)",,"def set_language(self, lang):        localedir = os.path.join(PKGDIR, ""locale"")        languages = (locale.locale_alias[lang.lower()].split(""_"", 1)[0],)        self._set_language(self.LOCALE_DOMAIN, localedir, languages)",58d613d7-9695-4abc-b97f-aeeac72adc24
core,__init__.py,_set_language,255,260,"def _set_language(self, *args, **kwargs):        trans = gettext.translation(*args, **kwargs)        try:            self._ = trans.ugettext        except AttributeError:            self._ = trans.gettext",,"def _set_language(self, *args, **kwargs):        trans = gettext.translation(*args, **kwargs)        try:            self._ = trans.ugettext        except AttributeError:            self._ = trans.gettext",c3c56eea-51c5-47b0-b7c5-022142fd0c3b
core,__init__.py,_setup_language,262,275,"def _setup_language(self):        self.log.debug(""Setup language..."")        lang = self.config.get(""general"", ""language"")        if not lang:            lc = locale.getlocale()[0] or locale.getdefaultlocale()[0]            lang = lc.split(""_"", 1)[0] if lc else ""en""        try:            self.set_language(lang)        except IOError as exc:            if lang != ""en"":                self.log.warning(exc, exc_info=self.debug > 1, stack_info=self.debug > 2)            self._set_language(self.LOCALE_DOMAIN, fallback=True)",,"def _setup_language(self):        self.log.debug(""Setup language..."")        lang = self.config.get(""general"", ""language"")        if not lang:            lc = locale.getlocale()[0] or locale.getdefaultlocale()[0]            lang = lc.split(""_"", 1)[0] if lc else ""en""        try:            self.set_language(lang)        except IOError as exc:            if lang != ""en"":                self.log.warning(exc, exc_info=self.debug > 1, stack_info=self.debug > 2)            self._set_language(self.LOCALE_DOMAIN, fallback=True)",e2d7cb7a-c0d5-4d8e-9510-2d4c437c9808
core,__init__.py,_setup_network,283,292,"def _setup_network(self):        self.log.debug(""Setup network..."")        # TODO: Move to AccountManager        self.log.info(self._(""Activating accounts...""))        self.acm.get_account_infos()        # self.scheduler.add_job(0, self.acm.get_account_infos)        self.log.info(self._(""Activating plugins...""))        self.adm.core_ready()",,"def _setup_network(self):        self.log.debug(""Setup network..."")        # TODO: Move to AccountManager        self.log.info(self._(""Activating accounts...""))        self.acm.get_account_infos()        # self.scheduler.add_job(0, self.acm.get_account_infos)        self.log.info(self._(""Activating plugins...""))        self.adm.core_ready()",ea71fbcf-f220-46d8-beef-24ffa9a6f915
core,__init__.py,_start_webserver,294,297,"def _start_webserver(self):        if not self.config.get(""webui"", ""enabled""):            return        self.webserver.start()",,"def _start_webserver(self):        if not self.config.get(""webui"", ""enabled""):            return        self.webserver.start()",f3ee159d-b8c9-43d2-8e95-a58d0cadd74a
core,__init__.py,_stop_webserver,299,302,"def _stop_webserver(self):        if not self.config.get(""webui"", ""enabled""):            return        self.webserver.stop()",,"def _stop_webserver(self):        if not self.config.get(""webui"", ""enabled""):            return        self.webserver.stop()",cb5924c3-9526-482b-8a63-270d98da74b0
core,__init__.py,_get_args_for_reloading,304,358,"def _get_args_for_reloading(self):                rv = [sys.executable]        py_script = sys.argv[0]        args = sys.argv[1:]        # Need to look at main module to determine how it was executed.        __main__ = sys.modules[""__main__""]        # The value of __package__ indicates how Python was called. It may        # not exist if a setuptools script is installed as an egg. It may be        # set incorrectly for entry points created with pip on Windows.        if getattr(__main__, ""__package__"", None) is None or (            os.name == ""nt""            and __main__.__package__ == """"            and not os.path.exists(py_script)            and os.path.exists(f""{py_script}.exe"")        ):            # Executed a file, like ""python app.py"".            py_script = os.path.abspath(py_script)            if os.name == ""nt"":                # Windows entry points have "".exe"" extension and should be                # called directly.                if not os.path.exists(py_script) and os.path.exists(f""{py_script}.exe""):                    py_script += "".exe""                if (                    os.path.splitext(sys.executable)[1] == "".exe""                    and os.path.splitext(py_script)[1] == "".exe""                ):                    rv.pop(0)            rv.append(py_script)        else:            # Executed a module, like ""python -m module"".            if sys.argv[0] == ""-m"":                args = sys.argv            else:                if os.path.isfile(py_script):                    # Rewritten by Python from ""-m script"" to ""/path/to/script.py"".                    py_module = __main__.__package__                    name = os.path.splitext(os.path.basename(py_script))[0]                    if name != ""__main__"":                        py_module += f"".{name}""                else:                    # Incorrectly rewritten by pydevd debugger from ""-m script"" to ""script"".                    py_module = py_script                rv.extend((""-m"", py_module.lstrip(""."")))        rv.extend(args)        return rv","Determine how the script was executed, and return the args needed
to execute it again in a new process.","def _get_args_for_reloading(self):        """"""Determine how the script was executed, and return the args needed        to execute it again in a new process.        """"""        rv = [sys.executable]        py_script = sys.argv[0]        args = sys.argv[1:]        # Need to look at main module to determine how it was executed.        __main__ = sys.modules[""__main__""]        # The value of __package__ indicates how Python was called. It may        # not exist if a setuptools script is installed as an egg. It may be        # set incorrectly for entry points created with pip on Windows.        if getattr(__main__, ""__package__"", None) is None or (            os.name == ""nt""            and __main__.__package__ == """"            and not os.path.exists(py_script)            and os.path.exists(f""{py_script}.exe"")        ):            # Executed a file, like ""python app.py"".            py_script = os.path.abspath(py_script)            if os.name == ""nt"":                # Windows entry points have "".exe"" extension and should be                # called directly.                if not os.path.exists(py_script) and os.path.exists(f""{py_script}.exe""):                    py_script += "".exe""                if (                    os.path.splitext(sys.executable)[1] == "".exe""                    and os.path.splitext(py_script)[1] == "".exe""                ):                    rv.pop(0)            rv.append(py_script)        else:            # Executed a module, like ""python -m module"".            if sys.argv[0] == ""-m"":                args = sys.argv            else:                if os.path.isfile(py_script):                    # Rewritten by Python from ""-m script"" to ""/path/to/script.py"".                    py_module = __main__.__package__                    name = os.path.splitext(os.path.basename(py_script))[0]                    if name != ""__main__"":                        py_module += f"".{name}""                else:                    # Incorrectly rewritten by pydevd debugger from ""-m script"" to ""script"".                    py_module = py_script                rv.extend((""-m"", py_module.lstrip(""."")))        rv.extend(args)        return rv

Determine how the script was executed, and return the args needed
to execute it again in a new process.",0394a5d7-2611-4b4a-be00-a717a232d558
core,__init__.py,start,360,435,"def start(self):        try:            try:                signal.signal(signal.SIGQUIT, self.sigquit)                signal.signal(signal.SIGTERM, self.sigterm)            except Exception:                pass            self.log.debug(""Starting core..."")            if self.debug:                debug_level = reversemap(self.DEBUG_LEVEL_MAP)[self.debug].upper()                self.log.debug(f""Debug level: {debug_level}"")            # self.evm.fire('pyload:starting')            self._running.set()            self._setup_language()            self._setup_permissions()            self.log.info(self._(""User directory: {}"").format(self.userdir))            self.log.info(self._(""Cache directory: {}"").format(self.tempdir))            storage_folder = self.config.get(""general"", ""storage_folder"")            self.log.info(self._(""Storage directory: {}"").format(storage_folder))            avail_space = format.size(fs.free_space(storage_folder))            self.log.info(self._(""Storage free space: {}"").format(avail_space))            self._setup_network()            # self._setup_niceness()            # # some memory stats            # from guppy import hpy            # hp=hpy()            # print(hp.heap())            # import objgraph            # objgraph.show_most_common_types(limit=30)            # import memdebug            # memdebug.start(8002)            # from meliae import scanner            # scanner.dump_all_objects(os.path.join(PACKDIR, 'objs.json'))            self._start_webserver()            self.log.debug(""*** pyLoad is up and running ***"")            # self.evm.fire('pyload:started')            self.thm.pause = False  # NOTE: Recheck...            if self._dry_run:                raise Exit            while True:                self._running.wait()                self.thread_manager.run()                if self._do_restart:                    raise Restart                if self._do_exit:                    raise Exit                self.scheduler.run()                time.sleep(1)        except Restart:            self.restart()        except (Exit, KeyboardInterrupt, SystemExit):            self.terminate()        except Exception as exc:            self.log.critical(exc, exc_info=True, stack_info=self.debug > 2)            self.terminate()            if os.name == ""nt"":                sys.exit(70)            else:                sys.exit(os.EX_SOFTWARE)",,"def start(self):        try:            try:                signal.signal(signal.SIGQUIT, self.sigquit)                signal.signal(signal.SIGTERM, self.sigterm)            except Exception:                pass            self.log.debug(""Starting core..."")            if self.debug:                debug_level = reversemap(self.DEBUG_LEVEL_MAP)[self.debug].upper()                self.log.debug(f""Debug level: {debug_level}"")            # self.evm.fire('pyload:starting')            self._running.set()            self._setup_language()            self._setup_permissions()            self.log.info(self._(""User directory: {}"").format(self.userdir))            self.log.info(self._(""Cache directory: {}"").format(self.tempdir))            storage_folder = self.config.get(""general"", ""storage_folder"")            self.log.info(self._(""Storage directory: {}"").format(storage_folder))            avail_space = format.size(fs.free_space(storage_folder))            self.log.info(self._(""Storage free space: {}"").format(avail_space))            self._setup_network()            # self._setup_niceness()            # # some memory stats            # from guppy import hpy            # hp=hpy()            # print(hp.heap())            # import objgraph            # objgraph.show_most_common_types(limit=30)            # import memdebug            # memdebug.start(8002)            # from meliae import scanner            # scanner.dump_all_objects(os.path.join(PACKDIR, 'objs.json'))            self._start_webserver()            self.log.debug(""*** pyLoad is up and running ***"")            # self.evm.fire('pyload:started')            self.thm.pause = False  # NOTE: Recheck...            if self._dry_run:                raise Exit            while True:                self._running.wait()                self.thread_manager.run()                if self._do_restart:                    raise Restart                if self._do_exit:                    raise Exit                self.scheduler.run()                time.sleep(1)        except Restart:            self.restart()        except (Exit, KeyboardInterrupt, SystemExit):            self.terminate()        except Exception as exc:            self.log.critical(exc, exc_info=True, stack_info=self.debug > 2)            self.terminate()            if os.name == ""nt"":                sys.exit(70)            else:                sys.exit(os.EX_SOFTWARE)",8714abf9-0536-4945-9706-8751184678f7
core,__init__.py,is_client_connected,437,438,def is_client_connected(self):        return (self.last_client_connected + 30) > time.time(),,def is_client_connected(self):        return (self.last_client_connected + 30) > time.time(),d51c2c65-e19c-41df-9681-fb23f711d0a6
core,__init__.py,restart,440,451,"def restart(self):        self.log.info(self._(""pyLoad is restarting...""))        # self.evm.fire('pyload:restarting')        self.terminate()        if sys.path[0]:            os.chdir(sys.path[0])        args = self._get_args_for_reloading()        subprocess.Popen(args, close_fds=True)        sys.exit()",,"def restart(self):        self.log.info(self._(""pyLoad is restarting...""))        # self.evm.fire('pyload:restarting')        self.terminate()        if sys.path[0]:            os.chdir(sys.path[0])        args = self._get_args_for_reloading()        subprocess.Popen(args, close_fds=True)        sys.exit()",31fe887c-fb04-44b8-970d-d70a874364cc
core,__init__.py,sigquit,453,456,"def sigquit(self, a, b):        self.log.info(self._(""Received Quit signal""))        self.terminate()        sys.exit()",,"def sigquit(self, a, b):        self.log.info(self._(""Received Quit signal""))        self.terminate()        sys.exit()",59cc729f-0121-4c52-9729-2c15408004a8
core,__init__.py,sigterm,458,461,"def sigterm(self, a, b):        self.log.info(self._(""Received Terminate signal""))        self.terminate()        sys.exit()",,"def sigterm(self, a, b):        self.log.info(self._(""Received Terminate signal""))        self.terminate()        sys.exit()",b9a77d9e-e9d3-40e1-9d96-3342e63bf33e
core,__init__.py,terminate,463,469,"def terminate(self):        if self.running:            self.stop()            self.log.info(self._(""Exiting core...""))            # self.tsm.exit()            # self.db.exit()  # NOTE: Why here?            self.logfactory.shutdown()",,"def terminate(self):        if self.running:            self.stop()            self.log.info(self._(""Exiting core...""))            # self.tsm.exit()            # self.db.exit()  # NOTE: Why here?            self.logfactory.shutdown()",b9fbec21-eb58-4622-8ea2-19cb296146cd
core,__init__.py,stop,474,490,"def stop(self):        try:            self.log.debug(""Stopping core..."")            # self.evm.fire('pyload:stopping')            for thread in self.thread_manager.threads:                thread.put(""quit"")            for pyfile in list(self.files.cache.values()):                pyfile.abort_download()            self._exiting = True            self.addon_manager.core_exiting()        finally:            self.files.sync_save()            self._running.clear()",,"def stop(self):        try:            self.log.debug(""Stopping core..."")            # self.evm.fire('pyload:stopping')            for thread in self.thread_manager.threads:                thread.put(""quit"")            for pyfile in list(self.files.cache.values()):                pyfile.abort_download()            self._exiting = True            self.addon_manager.core_exiting()        finally:            self.files.sync_save()            self._running.clear()",ecd7fafc-f918-4273-8461-ed15585dc7f3
api,__init__.py,permission,35,41,"def permission(bits):    class Wrapper:        def __new__(cls, func, *args, **kwargs):            perm_map[func.__name__] = bits            return func    return Wrapper",,"def permission(bits):    class Wrapper:        def __new__(cls, func, *args, **kwargs):            perm_map[func.__name__] = bits            return func    return Wrapper",0b0a877e-8dc8-4b72-a67e-572a3fe9de7f
api,__init__.py,legacy,44,50,"def legacy(legacy_name):    class Wrapper:        def __new__(cls, func, *args, **kwargs):            legacy_map[func.__name__] = legacy_name            return func    return Wrapper",,"def legacy(legacy_name):    class Wrapper:        def __new__(cls, func, *args, **kwargs):            legacy_map[func.__name__] = legacy_name            return func    return Wrapper",96e5ba80-3a56-402d-bcc9-dc2a9174061c
api,__init__.py,has_permission,77,79,"def has_permission(userperms, perms):    # bitwise or perms before if needed    return perms == (userperms & perms)",,"def has_permission(userperms, perms):    # bitwise or perms before if needed    return perms == (userperms & perms)",e7e87294-a194-4111-83aa-294ce2207519
api,__init__.py,__new__,100,113,"def __new__(cls, core):        obj = super(Api, cls).__new__(cls)        # add methods specified by the @legacy decorator        # also set legacy method permissions according to the @permissions decorator        for func_name, legacy_name in legacy_map.items():            func = getattr(obj, func_name)            setattr(obj, legacy_name, func)            permissions = perm_map.get(func_name)            if permissions is not None:                perm_map[legacy_name] = permissions        return obj",,"def __new__(cls, core):        obj = super(Api, cls).__new__(cls)        # add methods specified by the @legacy decorator        # also set legacy method permissions according to the @permissions decorator        for func_name, legacy_name in legacy_map.items():            func = getattr(obj, func_name)            setattr(obj, legacy_name, func)            permissions = perm_map.get(func_name)            if permissions is not None:                perm_map[legacy_name] = permissions        return obj",75ca0065-ffeb-4dae-841b-0f1a9da0da7b
api,__init__.py,__init__,115,117,"def __init__(self, core):        self.pyload = core        self._ = core._",,"def __init__(self, core):        self.pyload = core        self._ = core._",4f9f2535-07e9-45a3-9683-21fe4a08075a
api,__init__.py,_convert_py_file,119,133,"def _convert_py_file(self, p):        f = FileData(            p[""id""],            p[""url""],            p[""name""],            p[""plugin""],            p[""size""],            p[""format_size""],            p[""status""],            p[""statusmsg""],            p[""package""],            p[""error""],            p[""order""],        )        return f",,"def _convert_py_file(self, p):        f = FileData(            p[""id""],            p[""url""],            p[""name""],            p[""plugin""],            p[""size""],            p[""format_size""],            p[""status""],            p[""statusmsg""],            p[""package""],            p[""error""],            p[""order""],        )        return f",4cf97f91-273b-42dc-b812-382848225fde
api,__init__.py,_convert_config_format,135,153,"def _convert_config_format(self, c):        sections = {}        for section_name, sub in c.items():            section = ConfigSection(section_name, sub[""desc""])            items = []            for key, data in sub.items():                if key in (""desc"", ""outline""):                    continue                item = ConfigItem()                item.name = key                item.description = data[""desc""]                item.value = str(data[""value""])                item.type = data[""type""]                items.append(item)            section.items = items            sections[section_name] = section            if ""outline"" in sub:                section.outline = sub[""outline""]        return sections",,"def _convert_config_format(self, c):        sections = {}        for section_name, sub in c.items():            section = ConfigSection(section_name, sub[""desc""])            items = []            for key, data in sub.items():                if key in (""desc"", ""outline""):                    continue                item = ConfigItem()                item.name = key                item.description = data[""desc""]                item.value = str(data[""value""])                item.type = data[""type""]                items.append(item)            section.items = items            sections[section_name] = section            if ""outline"" in sub:                section.outline = sub[""outline""]        return sections",bc6ac85e-7de0-40b4-800b-7a584f8cc4ef
api,__init__.py,get_config_value,157,170,"def get_config_value(self, category, option, section=""core""):                if section == ""core"":            value = self.pyload.config[category][option]        else:            value = self.pyload.config.get_plugin(category, option)        return value","Retrieve config value.

:param category: name of category, or plugin
:param option: config option
:param section: 'plugin' or 'core'
:return: config value","def get_config_value(self, category, option, section=""core""):        """"""        Retrieve config value.        :param category: name of category, or plugin        :param option: config option        :param section: 'plugin' or 'core'        :return: config value        """"""        if section == ""core"":            value = self.pyload.config[category][option]        else:            value = self.pyload.config.get_plugin(category, option)        return value

Retrieve config value.

:param category: name of category, or plugin
:param option: config option
:param section: 'plugin' or 'core'
:return: config value",1fbad892-10e2-4826-a690-bd4a8702d45c
api,__init__.py,set_config_value,174,197,"def set_config_value(self, category, option, value, section=""core""):                self.pyload.addon_manager.dispatch_event(            ""config_changed"", category, option, value, section        )        if section == ""core"":            self.pyload.config[category][option] = value            if option in (                ""limit_speed"",                ""max_speed"",            ):  #: not so nice to update the limit                self.pyload.request_factory.update_bucket()        elif section == ""plugin"":            self.pyload.config.set_plugin(category, option, value)","Set new config value.

:param category:
:param option:
:param value: new config value
:param section: 'plugin' or 'core","def set_config_value(self, category, option, value, section=""core""):        """"""        Set new config value.        :param category:        :param option:        :param value: new config value        :param section: 'plugin' or 'core        """"""        self.pyload.addon_manager.dispatch_event(            ""config_changed"", category, option, value, section        )        if section == ""core"":            self.pyload.config[category][option] = value            if option in (                ""limit_speed"",                ""max_speed"",            ):  #: not so nice to update the limit                self.pyload.request_factory.update_bucket()        elif section == ""plugin"":            self.pyload.config.set_plugin(category, option, value)

Set new config value.

:param category:
:param option:
:param value: new config value
:param section: 'plugin' or 'core",7c7e0554-4f27-4fc8-8585-387bbbacca78
api,__init__.py,get_config,201,207,def get_config(self):                return self._convert_config_format(self.pyload.config.config),"Retrieves complete config of core.

:return: list of `ConfigSection`","def get_config(self):        """"""        Retrieves complete config of core.        :return: list of `ConfigSection`        """"""        return self._convert_config_format(self.pyload.config.config)

Retrieves complete config of core.

:return: list of `ConfigSection`",7151fa4f-cf32-44bb-97a3-b5f2b0f48dbf
api,__init__.py,get_config_dict,210,216,def get_config_dict(self):                return self.pyload.config.config,"Retrieves complete config in dict format, not for RPC.

:return: dict","def get_config_dict(self):        """"""        Retrieves complete config in dict format, not for RPC.        :return: dict        """"""        return self.pyload.config.config

Retrieves complete config in dict format, not for RPC.

:return: dict",949549ff-154d-4050-92bc-94201ba227e2
api,__init__.py,get_plugin_config,220,226,def get_plugin_config(self):                return self._convert_config_format(self.pyload.config.plugin),"Retrieves complete config for all plugins.

:return: list of `ConfigSection`","def get_plugin_config(self):        """"""        Retrieves complete config for all plugins.        :return: list of `ConfigSection`        """"""        return self._convert_config_format(self.pyload.config.plugin)

Retrieves complete config for all plugins.

:return: list of `ConfigSection`",b04dcb6d-bc84-4eaa-937c-a901daa04b68
api,__init__.py,get_plugin_config_dict,229,235,def get_plugin_config_dict(self):                return self.pyload.config.plugin,"Plugin config as dict, not for RPC.

:return: dict","def get_plugin_config_dict(self):        """"""        Plugin config as dict, not for RPC.        :return: dict        """"""        return self.pyload.config.plugin

Plugin config as dict, not for RPC.

:return: dict",e927bdaa-3503-44d5-ac8a-cbbb70381a7b
api,__init__.py,pause_server,239,243,def pause_server(self):                self.pyload.thread_manager.pause = True,"Pause server: It won't start any new downloads, but nothing gets aborted.","def pause_server(self):        """"""        Pause server: It won't start any new downloads, but nothing gets aborted.        """"""        self.pyload.thread_manager.pause = True

Pause server: It won't start any new downloads, but nothing gets aborted.",42e5abf1-61d2-4d95-a8c9-8b249923c7e6
api,__init__.py,unpause_server,247,251,def unpause_server(self):                self.pyload.thread_manager.pause = False,Unpause server: New Downloads will be started.,"def unpause_server(self):        """"""        Unpause server: New Downloads will be started.        """"""        self.pyload.thread_manager.pause = False

Unpause server: New Downloads will be started.",66d3158d-755f-41f2-80df-99bd77a24b49
api,__init__.py,toggle_pause,255,262,def toggle_pause(self):                self.pyload.thread_manager.pause ^= True        return self.pyload.thread_manager.pause,"Toggle pause state.

:return: new pause state","def toggle_pause(self):        """"""        Toggle pause state.        :return: new pause state        """"""        self.pyload.thread_manager.pause ^= True        return self.pyload.thread_manager.pause

Toggle pause state.

:return: new pause state",3a2a3869-9874-4d84-a2e6-0aab95fc7a95
api,__init__.py,toggle_reconnect,266,273,"def toggle_reconnect(self):                self.pyload.config.toggle(""reconnect"", ""enabled"")        return self.pyload.config.get(""reconnect"", ""enabled"")","Toggle reconnect activation.

:return: new reconnect state","def toggle_reconnect(self):        """"""        Toggle reconnect activation.        :return: new reconnect state        """"""        self.pyload.config.toggle(""reconnect"", ""enabled"")        return self.pyload.config.get(""reconnect"", ""enabled"")

Toggle reconnect activation.

:return: new reconnect state",14d8a902-97f5-4c17-8565-2e0f108fa862
api,__init__.py,status_server,277,301,"def status_server(self):                server_status = ServerStatus(            self.pyload.thread_manager.pause,            len(self.pyload.thread_manager.processing_ids()),            self.pyload.files.get_queue_count(),            self.pyload.files.get_file_count(),            0,            not self.pyload.thread_manager.pause and self.is_time_download(),            self.pyload.config.get(""reconnect"", ""enabled"") and self.is_time_reconnect(),            self.is_captcha_waiting(),        )        for pyfile in [            x.active            for x in self.pyload.thread_manager.threads            if x.active and isinstance(x.active, PyFile)        ]:            server_status.speed += pyfile.get_speed()  #: bytes/s        return server_status","Some general information about the current status of pyLoad.

:return: `ServerStatus`","def status_server(self):        """"""        Some general information about the current status of pyLoad.        :return: `ServerStatus`        """"""        server_status = ServerStatus(            self.pyload.thread_manager.pause,            len(self.pyload.thread_manager.processing_ids()),            self.pyload.files.get_queue_count(),            self.pyload.files.get_file_count(),            0,            not self.pyload.thread_manager.pause and self.is_time_download(),            self.pyload.config.get(""reconnect"", ""enabled"") and self.is_time_reconnect(),            self.is_captcha_waiting(),        )        for pyfile in [            x.active            for x in self.pyload.thread_manager.threads            if x.active and isinstance(x.active, PyFile)        ]:            server_status.speed += pyfile.get_speed()  #: bytes/s        return server_status

Some general information about the current status of pyLoad.

:return: `ServerStatus`",35bb1d39-34c6-4167-b62e-98ea8953c2b8
api,__init__.py,free_space,305,309,"def free_space(self):                return fs.free_space(self.pyload.config.get(""general"", ""storage_folder""))",Available free space at download directory in bytes.,"def free_space(self):        """"""        Available free space at download directory in bytes.        """"""        return fs.free_space(self.pyload.config.get(""general"", ""storage_folder""))

Available free space at download directory in bytes.",d75577f6-7139-4a37-9a0c-aa944b68b069
api,__init__.py,get_server_version,313,317,def get_server_version(self):                return self.pyload.version,pyLoad Core version.,"def get_server_version(self):        """"""        pyLoad Core version.        """"""        return self.pyload.version

pyLoad Core version.",5f00abd5-7ad8-4e78-a5c9-61163f2e20a5
api,__init__.py,kill,319,323,def kill(self):                self.pyload._do_exit = True,Clean way to quit pyLoad.,"def kill(self):        """"""        Clean way to quit pyLoad.        """"""        self.pyload._do_exit = True

Clean way to quit pyLoad.",29ddb9cf-423f-4364-a71a-176b40bc2473
api,__init__.py,restart,325,329,def restart(self):                self.pyload._do_restart = True,Restart pyload core.,"def restart(self):        """"""        Restart pyload core.        """"""        self.pyload._do_restart = True

Restart pyload core.",566dc229-ee31-45a4-900c-fa7a9853a7ee
api,__init__.py,get_log,333,352,"def get_log(self, offset=0):                filelog_folder = self.pyload.config.get(""log"", ""filelog_folder"")        if not filelog_folder:            filelog_folder = os.path.join(self.pyload.userdir, ""logs"")        path = os.path.join(filelog_folder, ""pyload"" + LogFactory.FILE_EXTENSION)        try:            with open(path) as fh:                lines = fh.readlines()            if offset >= len(lines):                return []            return lines[offset:]        except Exception:            return [""No log available""]","Returns most recent log entries.

:param offset: line offset
:return: List of log entries","def get_log(self, offset=0):        """"""        Returns most recent log entries.        :param offset: line offset        :return: List of log entries        """"""        filelog_folder = self.pyload.config.get(""log"", ""filelog_folder"")        if not filelog_folder:            filelog_folder = os.path.join(self.pyload.userdir, ""logs"")        path = os.path.join(filelog_folder, ""pyload"" + LogFactory.FILE_EXTENSION)        try:            with open(path) as fh:                lines = fh.readlines()            if offset >= len(lines):                return []            return lines[offset:]        except Exception:            return [""No log available""]

Returns most recent log entries.

:param offset: line offset
:return: List of log entries",3c9ad9ad-24b4-4f92-abda-c4cc958ea678
api,__init__.py,is_time_download,356,364,"def is_time_download(self):                start = self.pyload.config.get(""download"", ""start_time"").split("":"")        end = self.pyload.config.get(""download"", ""end_time"").split("":"")        return seconds.compare(start, end)","Checks if pyload will start new downloads according to time in config.

:return: bool","def is_time_download(self):        """"""        Checks if pyload will start new downloads according to time in config.        :return: bool        """"""        start = self.pyload.config.get(""download"", ""start_time"").split("":"")        end = self.pyload.config.get(""download"", ""end_time"").split("":"")        return seconds.compare(start, end)

Checks if pyload will start new downloads according to time in config.

:return: bool",71a86f38-140e-4c3c-8b0f-53eb521f18e3
api,__init__.py,is_time_reconnect,368,378,"def is_time_reconnect(self):                start = self.pyload.config.get(""reconnect"", ""start_time"").split("":"")        end = self.pyload.config.get(""reconnect"", ""end_time"").split("":"")        return seconds.compare(start, end) and self.pyload.config.get(            ""reconnect"", ""enabled""        )","Checks if pyload will try to make a reconnect.

:return: bool","def is_time_reconnect(self):        """"""        Checks if pyload will try to make a reconnect.        :return: bool        """"""        start = self.pyload.config.get(""reconnect"", ""start_time"").split("":"")        end = self.pyload.config.get(""reconnect"", ""end_time"").split("":"")        return seconds.compare(start, end) and self.pyload.config.get(            ""reconnect"", ""enabled""        )

Checks if pyload will try to make a reconnect.

:return: bool",05f9ab6d-5b43-41dc-9268-b05697f0fae0
api,__init__.py,status_downloads,382,414,"def status_downloads(self):                data = []        for pyfile in self.pyload.thread_manager.get_active_files():            if not isinstance(pyfile, PyFile):                continue            data.append(                DownloadInfo(                    pyfile.id,                    pyfile.name,                    pyfile.get_speed(),                    pyfile.get_eta(),                    pyfile.format_eta(),                    pyfile.get_bytes_left(),                    pyfile.get_size(),                    pyfile.format_size(),                    pyfile.get_percent(),                    pyfile.status,                    pyfile.get_status_name(),                    pyfile.format_wait(),                    pyfile.wait_until,                    pyfile.packageid,                    pyfile.package().name,                    pyfile.pluginname,                )            )        return data","Status off all currently running downloads.

:return: list of `DownloadStatus`","def status_downloads(self):        """"""        Status off all currently running downloads.        :return: list of `DownloadStatus`        """"""        data = []        for pyfile in self.pyload.thread_manager.get_active_files():            if not isinstance(pyfile, PyFile):                continue            data.append(                DownloadInfo(                    pyfile.id,                    pyfile.name,                    pyfile.get_speed(),                    pyfile.get_eta(),                    pyfile.format_eta(),                    pyfile.get_bytes_left(),                    pyfile.get_size(),                    pyfile.format_size(),                    pyfile.get_percent(),                    pyfile.status,                    pyfile.get_status_name(),                    pyfile.format_wait(),                    pyfile.wait_until,                    pyfile.packageid,                    pyfile.package().name,                    pyfile.pluginname,                )            )        return data

Status off all currently running downloads.

:return: list of `DownloadStatus`",78c1f7cb-afa7-4723-80c1-aba9c0fdfd30
api,__init__.py,add_package,418,454,"def add_package(self, name, links, dest=Destination.QUEUE):                if self.pyload.config.get(""general"", ""folder_per_package""):            folder = name        else:            folder = """"        folder = (            folder.replace(""http://"", """")            .replace(""https://"", """")            .replace(""../"", ""_"")            .replace(""..\\"", ""_"")            .replace("":"", """")            .replace(""/"", ""_"")            .replace(""\\"", ""_"")        )        package_id = self.pyload.files.add_package(name, folder, Destination(dest))        self.pyload.files.add_links(links, package_id)        self.pyload.log.info(            self._(""Added package {name} containing {count:d} links"").format(                name=name, count=len(links)            )        )        self.pyload.files.save()        return package_id","Adds a package, with links to desired destination.

:param name: name of the new package
:param links: list of urls
:param dest: `Destination`
:return: package id of the new package","def add_package(self, name, links, dest=Destination.QUEUE):        """"""        Adds a package, with links to desired destination.        :param name: name of the new package        :param links: list of urls        :param dest: `Destination`        :return: package id of the new package        """"""        if self.pyload.config.get(""general"", ""folder_per_package""):            folder = name        else:            folder = """"        folder = (            folder.replace(""http://"", """")            .replace(""https://"", """")            .replace(""../"", ""_"")            .replace(""..\\"", ""_"")            .replace("":"", """")            .replace(""/"", ""_"")            .replace(""\\"", ""_"")        )        package_id = self.pyload.files.add_package(name, folder, Destination(dest))        self.pyload.files.add_links(links, package_id)        self.pyload.log.info(            self._(""Added package {name} containing {count:d} links"").format(                name=name, count=len(links)            )        )        self.pyload.files.save()        return package_id

Adds a package, with links to desired destination.

:param name: name of the new package
:param links: list of urls
:param dest: `Destination`
:return: package id of the new package",a7713932-80fc-470c-99a6-dc4131da654a
api,__init__.py,parse_urls,458,477,"def parse_urls(self, html=None, url=None):                urls = []        if html:            urls += urlmatcher.findall(html)        if url:            page = get_url(url)            urls += urlmatcher.findall(page)        # remove duplicates        return self.check_urls(set(urls))","Parses html content or any arbitrary text for links and returns result of
`check_urls`

:param html: html source
:param url: url to load html source from
:return:","def parse_urls(self, html=None, url=None):        """"""        Parses html content or any arbitrary text for links and returns result of        `check_urls`        :param html: html source        :param url: url to load html source from        :return:        """"""        urls = []        if html:            urls += urlmatcher.findall(html)        if url:            page = get_url(url)            urls += urlmatcher.findall(page)        # remove duplicates        return self.check_urls(set(urls))

Parses html content or any arbitrary text for links and returns result of
`check_urls`

:param html: html source
:param url: url to load html source from
:return:",831c0826-4ce9-446f-b23a-db666503667e
api,__init__.py,check_urls,481,497,"def check_urls(self, urls):                data = self.pyload.plugin_manager.parse_urls(urls)        plugins = {}        for url, plugin in data:            if plugin in plugins:                plugins[plugin].append(url)            else:                plugins[plugin] = [url]        return plugins","Gets urls and returns pluginname mapped to list of matches urls.

:param urls:
:return: {plugin: urls}","def check_urls(self, urls):        """"""        Gets urls and returns pluginname mapped to list of matches urls.        :param urls:        :return: {plugin: urls}        """"""        data = self.pyload.plugin_manager.parse_urls(urls)        plugins = {}        for url, plugin in data:            if plugin in plugins:                plugins[plugin].append(url)            else:                plugins[plugin] = [url]        return plugins

Gets urls and returns pluginname mapped to list of matches urls.

:param urls:
:return: {plugin: urls}",111feb1e-7414-40b7-83d1-1b14c6c05f9c
api,__init__.py,check_online_status,501,524,"def check_online_status(self, urls):                data = self.pyload.plugin_manager.parse_urls(urls)        rid = self.pyload.thread_manager.create_result_thread(data, False)        tmp = [            (url, (url, OnlineStatus(url, pluginname, ""unknown"", 3, 0)))            for url, pluginname in data        ]        data = parse_names(tmp)        result = {}        for k, v in data.items():            for url, status in v:                status.packagename = k                result[url] = status        return OnlineCheck(rid, result)","initiates online status check.

:param urls:
:return: initial set of data as `OnlineCheck` instance containing the result id","def check_online_status(self, urls):        """"""        initiates online status check.        :param urls:        :return: initial set of data as `OnlineCheck` instance containing the result id        """"""        data = self.pyload.plugin_manager.parse_urls(urls)        rid = self.pyload.thread_manager.create_result_thread(data, False)        tmp = [            (url, (url, OnlineStatus(url, pluginname, ""unknown"", 3, 0)))            for url, pluginname in data        ]        data = parse_names(tmp)        result = {}        for k, v in data.items():            for url, status in v:                status.packagename = k                result[url] = status        return OnlineCheck(rid, result)

initiates online status check.

:param urls:
:return: initial set of data as `OnlineCheck` instance containing the result id",a1a095e4-6719-4fd6-b096-79f0f33376af
api,__init__.py,check_online_status_container,528,545,"def check_online_status_container(self, urls, container, data):                with open(            os.path.join(                self.pyload.config.get(""general"", ""storage_folder""), ""tmp_"" + container            ),            ""wb"",        ) as th:            th.write(data)        return self.check_online_status(urls + [th.name])","checks online status of urls and a submitted container file.

:param urls: list of urls
:param container: container file name
:param data: file content
:return: online check","def check_online_status_container(self, urls, container, data):        """"""        checks online status of urls and a submitted container file.        :param urls: list of urls        :param container: container file name        :param data: file content        :return: online check        """"""        with open(            os.path.join(                self.pyload.config.get(""general"", ""storage_folder""), ""tmp_"" + container            ),            ""wb"",        ) as th:            th.write(data)        return self.check_online_status(urls + [th.name])

checks online status of urls and a submitted container file.

:param urls: list of urls
:param container: container file name
:param data: file content
:return: online check",c7816ac5-e788-48e8-a623-d89cf06f851e
api,__init__.py,poll_results,549,562,"def poll_results(self, rid):                result = self.pyload.thread_manager.get_info_result(rid)        if ""ALL_INFO_FETCHED"" in result:            del result[""ALL_INFO_FETCHED""]            return OnlineCheck(-1, result)        else:            return OnlineCheck(rid, result)","Polls the result available for ResultID.

:param rid: `ResultID`
:return: `OnlineCheck`, if rid is -1 then no more data available","def poll_results(self, rid):        """"""        Polls the result available for ResultID.        :param rid: `ResultID`        :return: `OnlineCheck`, if rid is -1 then no more data available        """"""        result = self.pyload.thread_manager.get_info_result(rid)        if ""ALL_INFO_FETCHED"" in result:            del result[""ALL_INFO_FETCHED""]            return OnlineCheck(-1, result)        else:            return OnlineCheck(rid, result)

Polls the result available for ResultID.

:param rid: `ResultID`
:return: `OnlineCheck`, if rid is -1 then no more data available",2588a4ab-5eec-4968-82c0-724fa286e536
api,__init__.py,generate_packages,566,574,"def generate_packages(self, links):                result = parse_names((x, x) for x in links)        return result","Parses links, generates packages names from urls.

:param links: list of urls
:return: package names mapped to urls","def generate_packages(self, links):        """"""        Parses links, generates packages names from urls.        :param links: list of urls        :return: package names mapped to urls        """"""        result = parse_names((x, x) for x in links)        return result

Parses links, generates packages names from urls.

:param links: list of urls
:return: package names mapped to urls",7e12c31b-430a-4b11-a153-452777cefa15
api,__init__.py,generate_and_add_packages,578,589,"def generate_and_add_packages(self, links, dest=Destination.COLLECTOR):                return [            self.add_package(name, urls, dest)            for name, urls in self.generate_packages(links).items()        ]","Generates and add packages.

:param links: list of urls
:param dest: `Destination`
:return: list of package ids","def generate_and_add_packages(self, links, dest=Destination.COLLECTOR):        """"""        Generates and add packages.        :param links: list of urls        :param dest: `Destination`        :return: list of package ids        """"""        return [            self.add_package(name, urls, dest)            for name, urls in self.generate_packages(links).items()        ]

Generates and add packages.

:param links: list of urls
:param dest: `Destination`
:return: list of package ids",7faf32bc-f471-462c-b907-876a9bdb41eb
api,__init__.py,check_and_add_packages,593,603,"def check_and_add_packages(self, links, dest=Destination.COLLECTOR):                data = self.pyload.plugin_manager.parse_urls(links)        self.pyload.thread_manager.create_result_thread(data, True)","Checks online status, retrieves names, and will add packages.
Because of these packages are not added immediately, only for internal use.

:param links: list of urls
:param dest: `Destination`
:return: None","def check_and_add_packages(self, links, dest=Destination.COLLECTOR):        """"""        Checks online status, retrieves names, and will add packages.        Because of these packages are not added immediately, only for internal use.        :param links: list of urls        :param dest: `Destination`        :return: None        """"""        data = self.pyload.plugin_manager.parse_urls(links)        self.pyload.thread_manager.create_result_thread(data, True)

Checks online status, retrieves names, and will add packages.
Because of these packages are not added immediately, only for internal use.

:param links: list of urls
:param dest: `Destination`
:return: None",04e4832d-a56a-4440-91c6-3db38d33aca3
api,__init__.py,get_package_data,607,630,"def get_package_data(self, package_id):                data = self.pyload.files.get_package_data(int(package_id))        if not data:            raise PackageDoesNotExists(package_id)        pdata = PackageData(            data[""id""],            data[""name""],            data[""folder""],            data[""site""],            data[""password""],            data[""queue""],            data[""order""],            links=[self._convert_py_file(x) for x in data[""links""].values()],        )        return pdata","Returns complete information about package, and included files.

:param package_id: package id
:return: `PackageData` with .links attribute","def get_package_data(self, package_id):        """"""        Returns complete information about package, and included files.        :param package_id: package id        :return: `PackageData` with .links attribute        """"""        data = self.pyload.files.get_package_data(int(package_id))        if not data:            raise PackageDoesNotExists(package_id)        pdata = PackageData(            data[""id""],            data[""name""],            data[""folder""],            data[""site""],            data[""password""],            data[""queue""],            data[""order""],            links=[self._convert_py_file(x) for x in data[""links""].values()],        )        return pdata

Returns complete information about package, and included files.

:param package_id: package id
:return: `PackageData` with .links attribute",2a2beac5-0b71-49d1-b305-9322970c8b4c
api,__init__.py,get_package_info,634,658,"def get_package_info(self, package_id):                data = self.pyload.files.get_package_data(int(package_id))        if not data:            raise PackageDoesNotExists(package_id)        pdata = PackageData(            data[""id""],            data[""name""],            data[""folder""],            data[""site""],            data[""password""],            data[""queue""],            data[""order""],            fids=[int(x) for x in data[""links""]],        )        return pdata","Returns information about package, without detailed information about containing
files.

:param package_id: package id
:return: `PackageData` with .fid attribute","def get_package_info(self, package_id):        """"""        Returns information about package, without detailed information about containing        files.        :param package_id: package id        :return: `PackageData` with .fid attribute        """"""        data = self.pyload.files.get_package_data(int(package_id))        if not data:            raise PackageDoesNotExists(package_id)        pdata = PackageData(            data[""id""],            data[""name""],            data[""folder""],            data[""site""],            data[""password""],            data[""queue""],            data[""order""],            fids=[int(x) for x in data[""links""]],        )        return pdata

Returns information about package, without detailed information about containing
files.

:param package_id: package id
:return: `PackageData` with .fid attribute",81351f61-b1c6-42e6-914f-e5d54b4ae157
api,__init__.py,get_file_data,662,675,"def get_file_data(self, file_id):                info = self.pyload.files.get_file_data(int(file_id))        if not info:            raise FileDoesNotExists(file_id)        fileinfo = list(info.values())[0]        fdata = self._convert_py_file(fileinfo)        return fdata","Get complete information about a specific file.

:param file_id: file id
:return: `FileData`","def get_file_data(self, file_id):        """"""        Get complete information about a specific file.        :param file_id: file id        :return: `FileData`        """"""        info = self.pyload.files.get_file_data(int(file_id))        if not info:            raise FileDoesNotExists(file_id)        fileinfo = list(info.values())[0]        fdata = self._convert_py_file(fileinfo)        return fdata

Get complete information about a specific file.

:param file_id: file id
:return: `FileData`",3b7ce99a-2df6-4c5f-b3f3-80a7d1477bf0
api,__init__.py,delete_files,679,688,"def delete_files(self, file_ids):                for id in file_ids:            self.pyload.files.delete_link(int(id))        self.pyload.files.save()","Deletes several file entries from pyload.

:param file_ids: list of file ids","def delete_files(self, file_ids):        """"""        Deletes several file entries from pyload.        :param file_ids: list of file ids        """"""        for id in file_ids:            self.pyload.files.delete_link(int(id))        self.pyload.files.save()

Deletes several file entries from pyload.

:param file_ids: list of file ids",a25662ec-665a-4b43-8907-cce47824dcef
api,__init__.py,delete_packages,692,701,"def delete_packages(self, package_ids):                for id in package_ids:            self.pyload.files.delete_package(int(id))        self.pyload.files.save()","Deletes packages and containing links.

:param package_ids: list of package ids","def delete_packages(self, package_ids):        """"""        Deletes packages and containing links.        :param package_ids: list of package ids        """"""        for id in package_ids:            self.pyload.files.delete_package(int(id))        self.pyload.files.save()

Deletes packages and containing links.

:param package_ids: list of package ids",7fa54671-1fd4-4431-a32f-5ae69f275763
api,__init__.py,get_queue,705,727,"def get_queue(self):                return [            PackageData(                pack[""id""],                pack[""name""],                pack[""folder""],                pack[""site""],                pack[""password""],                pack[""queue""],                pack[""order""],                pack[""linksdone""],                pack[""sizedone""],                pack[""sizetotal""],                pack[""linkstotal""],            )            for pack in self.pyload.files.get_info_data(Destination.QUEUE).values()        ]","Returns info about queue and packages, **not** about files, see `get_queue_data`         or `get_package_data` instead.

:return: list of `PackageInfo`","def get_queue(self):        """"""        Returns info about queue and packages, **not** about files, see `get_queue_data` \        or `get_package_data` instead.        :return: list of `PackageInfo`        """"""        return [            PackageData(                pack[""id""],                pack[""name""],                pack[""folder""],                pack[""site""],                pack[""password""],                pack[""queue""],                pack[""order""],                pack[""linksdone""],                pack[""sizedone""],                pack[""sizetotal""],                pack[""linkstotal""],            )            for pack in self.pyload.files.get_info_data(Destination.QUEUE).values()        ]

Returns info about queue and packages, **not** about files, see `get_queue_data`         or `get_package_data` instead.

:return: list of `PackageInfo`",782e8369-26b8-46d3-a503-d764364b3a58
api,__init__.py,get_queue_data,731,754,"def get_queue_data(self):                return [            PackageData(                pack[""id""],                pack[""name""],                pack[""folder""],                pack[""site""],                pack[""password""],                pack[""queue""],                pack[""order""],                pack[""linksdone""],                pack[""sizedone""],                pack[""sizetotal""],                links=[self._convert_py_file(x) for x in pack[""links""].values()],            )            for pack in self.pyload.files.get_complete_data(Destination.QUEUE).values()        ]","Return complete data about everything in queue, this is very expensive use it
sparely.
See `get_queue` for alternative.

:return: list of `PackageData`","def get_queue_data(self):        """"""        Return complete data about everything in queue, this is very expensive use it        sparely.        See `get_queue` for alternative.        :return: list of `PackageData`        """"""        return [            PackageData(                pack[""id""],                pack[""name""],                pack[""folder""],                pack[""site""],                pack[""password""],                pack[""queue""],                pack[""order""],                pack[""linksdone""],                pack[""sizedone""],                pack[""sizetotal""],                links=[self._convert_py_file(x) for x in pack[""links""].values()],            )            for pack in self.pyload.files.get_complete_data(Destination.QUEUE).values()        ]

Return complete data about everything in queue, this is very expensive use it
sparely.
See `get_queue` for alternative.

:return: list of `PackageData`",7250247e-a3d7-4eaa-afae-ad77150614b2
api,__init__.py,get_collector,758,779,"def get_collector(self):                return [            PackageData(                pack[""id""],                pack[""name""],                pack[""folder""],                pack[""site""],                pack[""password""],                pack[""queue""],                pack[""order""],                pack[""linksdone""],                pack[""sizedone""],                pack[""sizetotal""],                pack[""linkstotal""],            )            for pack in self.pyload.files.get_info_data(Destination.COLLECTOR).values()        ]","same as `get_queue` for collector.

:return: list of `PackageInfo`","def get_collector(self):        """"""        same as `get_queue` for collector.        :return: list of `PackageInfo`        """"""        return [            PackageData(                pack[""id""],                pack[""name""],                pack[""folder""],                pack[""site""],                pack[""password""],                pack[""queue""],                pack[""order""],                pack[""linksdone""],                pack[""sizedone""],                pack[""sizetotal""],                pack[""linkstotal""],            )            for pack in self.pyload.files.get_info_data(Destination.COLLECTOR).values()        ]

same as `get_queue` for collector.

:return: list of `PackageInfo`",1da53147-6934-4b29-b8ce-f3056d47fb9e
api,__init__.py,get_collector_data,783,806,"def get_collector_data(self):                return [            PackageData(                pack[""id""],                pack[""name""],                pack[""folder""],                pack[""site""],                pack[""password""],                pack[""queue""],                pack[""order""],                pack[""linksdone""],                pack[""sizedone""],                pack[""sizetotal""],                links=[self._convert_py_file(x) for x in pack[""links""].values()],            )            for pack in self.pyload.files.get_complete_data(                Destination.COLLECTOR            ).values()        ]","same as `get_queue_data` for collector.

:return: list of `PackageInfo`","def get_collector_data(self):        """"""        same as `get_queue_data` for collector.        :return: list of `PackageInfo`        """"""        return [            PackageData(                pack[""id""],                pack[""name""],                pack[""folder""],                pack[""site""],                pack[""password""],                pack[""queue""],                pack[""order""],                pack[""linksdone""],                pack[""sizedone""],                pack[""sizetotal""],                links=[self._convert_py_file(x) for x in pack[""links""].values()],            )            for pack in self.pyload.files.get_complete_data(                Destination.COLLECTOR            ).values()        ]

same as `get_queue_data` for collector.

:return: list of `PackageInfo`",dfcbf151-678c-484f-bd16-e0613137562c
api,__init__.py,add_files,810,824,"def add_files(self, package_id, links):                self.pyload.files.add_links(links, int(package_id))        self.pyload.log.info(            self._(""Added {count:d} links to package #{package:d} "").format(                count=len(links), package=package_id            )        )        self.pyload.files.save()","Adds files to specific package.

:param package_id: package id
:param links: list of urls","def add_files(self, package_id, links):        """"""        Adds files to specific package.        :param package_id: package id        :param links: list of urls        """"""        self.pyload.files.add_links(links, int(package_id))        self.pyload.log.info(            self._(""Added {count:d} links to package #{package:d} "").format(                count=len(links), package=package_id            )        )        self.pyload.files.save()

Adds files to specific package.

:param package_id: package id
:param links: list of urls",80d1ad0d-5b30-4a03-8392-d098d44a5f89
api,__init__.py,push_to_queue,828,834,"def push_to_queue(self, package_id):                self.pyload.files.set_package_location(package_id, Destination.QUEUE)","Moves package from Collector to Queue.

:param package_id: package id","def push_to_queue(self, package_id):        """"""        Moves package from Collector to Queue.        :param package_id: package id        """"""        self.pyload.files.set_package_location(package_id, Destination.QUEUE)

Moves package from Collector to Queue.

:param package_id: package id",554c7e5f-e423-4a96-bb39-0e1a2bb1fd4a
api,__init__.py,pull_from_queue,838,844,"def pull_from_queue(self, package_id):                self.pyload.files.set_package_location(package_id, Destination.COLLECTOR)","Moves package from Queue to Collector.

:param package_id: package id","def pull_from_queue(self, package_id):        """"""        Moves package from Queue to Collector.        :param package_id: package id        """"""        self.pyload.files.set_package_location(package_id, Destination.COLLECTOR)

Moves package from Queue to Collector.

:param package_id: package id",ecd01da9-22a9-4826-b62e-679ebab88599
api,__init__.py,restart_package,848,854,"def restart_package(self, package_id):                self.pyload.files.restart_package(int(package_id))","Restarts a package, resets every containing files.

:param package_id: package id","def restart_package(self, package_id):        """"""        Restarts a package, resets every containing files.        :param package_id: package id        """"""        self.pyload.files.restart_package(int(package_id))

Restarts a package, resets every containing files.

:param package_id: package id",01667fd8-eefd-4706-b989-14ad582f1d25
api,__init__.py,restart_file,858,864,"def restart_file(self, file_id):                self.pyload.files.restart_file(int(file_id))","Resets file status, so it will be downloaded again.

:param file_id:  file id","def restart_file(self, file_id):        """"""        Resets file status, so it will be downloaded again.        :param file_id:  file id        """"""        self.pyload.files.restart_file(int(file_id))

Resets file status, so it will be downloaded again.

:param file_id:  file id",44dfda18-7e62-4fc9-9b3c-9485713aed46
api,__init__.py,recheck_package,868,876,"def recheck_package(self, package_id):                self.pyload.files.recheck_package(int(package_id))","Probes online status of all files in a package, also a default action when
package is added.

:param package_id:
:return:","def recheck_package(self, package_id):        """"""        Probes online status of all files in a package, also a default action when        package is added.        :param package_id:        :return:        """"""        self.pyload.files.recheck_package(int(package_id))

Probes online status of all files in a package, also a default action when
package is added.

:param package_id:
:return:",b19a1ae1-757d-43fd-a892-c0492df9c2c6
api,__init__.py,stop_all_downloads,880,886,def stop_all_downloads(self):                pyfiles = list(self.pyload.files.cache.values())        for pyfile in pyfiles:            pyfile.abort_download(),Aborts all running downloads.,"def stop_all_downloads(self):        """"""        Aborts all running downloads.        """"""        pyfiles = list(self.pyload.files.cache.values())        for pyfile in pyfiles:            pyfile.abort_download()

Aborts all running downloads.",33e4b60b-45b4-4dfc-8527-ff3ae45e683c
api,__init__.py,stop_downloads,890,900,"def stop_downloads(self, file_ids):                pyfiles = list(self.pyload.files.cache.values())        for pyfile in pyfiles:            if pyfile.id in file_ids:                pyfile.abort_download()","Aborts specific downloads.

:param file_ids: list of file ids
:return:","def stop_downloads(self, file_ids):        """"""        Aborts specific downloads.        :param file_ids: list of file ids        :return:        """"""        pyfiles = list(self.pyload.files.cache.values())        for pyfile in pyfiles:            if pyfile.id in file_ids:                pyfile.abort_download()

Aborts specific downloads.

:param file_ids: list of file ids
:return:",8cea0948-175e-430c-b9ee-3a8741dcfb2e
api,__init__.py,set_package_name,904,913,"def set_package_name(self, package_id, name):                pack = self.pyload.files.get_package(package_id)        pack.name = name        pack.sync()","Renames a package.

:param package_id: package id
:param name: new package name","def set_package_name(self, package_id, name):        """"""        Renames a package.        :param package_id: package id        :param name: new package name        """"""        pack = self.pyload.files.get_package(package_id)        pack.name = name        pack.sync()

Renames a package.

:param package_id: package id
:param name: new package name",38419ea5-bbd2-4331-afbf-8a2365c8ad80
api,__init__.py,move_package,917,929,"def move_package(self, destination, package_id):                try:            dest = Destination(destination)        except ValueError:            pass        else:            self.pyload.files.set_package_location(package_id, dest)","Set a new package location.

:param destination: `Destination`
:param package_id: package id","def move_package(self, destination, package_id):        """"""        Set a new package location.        :param destination: `Destination`        :param package_id: package id        """"""        try:            dest = Destination(destination)        except ValueError:            pass        else:            self.pyload.files.set_package_location(package_id, dest)

Set a new package location.

:param destination: `Destination`
:param package_id: package id",4de5e06a-838a-4bf6-a43d-c7c4649a10d6
api,__init__.py,move_files,933,942,"def move_files(self, file_ids, package_id):                # TODO: implement        pass","Move multiple files to another package.

:param file_ids: list of file ids
:param package_id: destination package
:return:","def move_files(self, file_ids, package_id):        """"""        Move multiple files to another package.        :param file_ids: list of file ids        :param package_id: destination package        :return:        """"""        # TODO: implement        pass

Move multiple files to another package.

:param file_ids: list of file ids
:param package_id: destination package
:return:",46680cc4-9c6c-4a6d-9b32-00ed0898bd67
api,__init__.py,upload_container,946,961,"def upload_container(self, filename, data):                with open(            os.path.join(                self.pyload.config.get(""general"", ""storage_folder""), ""tmp_"" + filename            ),            ""wb"",        ) as th:            th.write(data)        self.add_package(th.name, [th.name], Destination.COLLECTOR)","Uploads and adds a container file to pyLoad.

:param filename: file name - extension is important, so it can correctly decrypt
:param data: file content","def upload_container(self, filename, data):        """"""        Uploads and adds a container file to pyLoad.        :param filename: file name - extension is important, so it can correctly decrypt        :param data: file content        """"""        with open(            os.path.join(                self.pyload.config.get(""general"", ""storage_folder""), ""tmp_"" + filename            ),            ""wb"",        ) as th:            th.write(data)        self.add_package(th.name, [th.name], Destination.COLLECTOR)

Uploads and adds a container file to pyLoad.

:param filename: file name - extension is important, so it can correctly decrypt
:param data: file content",4a62fdb8-c84c-4a52-a95d-673c975e3d26
api,__init__.py,order_package,965,972,"def order_package(self, package_id, position):                self.pyload.files.reorder_package(package_id, position)","Gives a package a new position.

:param package_id: package id
:param position:","def order_package(self, package_id, position):        """"""        Gives a package a new position.        :param package_id: package id        :param position:        """"""        self.pyload.files.reorder_package(package_id, position)

Gives a package a new position.

:param package_id: package id
:param position:",443dd39c-ac39-44ad-adcf-1917f1e61984
api,__init__.py,order_file,976,983,"def order_file(self, file_id, position):                self.pyload.files.reorder_file(file_id, position)","Gives a new position to a file within its package.

:param file_id: file id
:param position:","def order_file(self, file_id, position):        """"""        Gives a new position to a file within its package.        :param file_id: file id        :param position:        """"""        self.pyload.files.reorder_file(file_id, position)

Gives a new position to a file within its package.

:param file_id: file id
:param position:",11f62741-b634-46af-ba58-edf9df656532
api,__init__.py,set_package_data,987,1004,"def set_package_data(self, package_id, data):                p = self.pyload.files.get_package(package_id)        if not p:            raise PackageDoesNotExists(package_id)        for key, value in data.items():            if key == ""id"":                continue            setattr(p, key, value)        p.sync()        self.pyload.files.save()","Allows to modify several package attributes.

:param package_id: package id
:param data: dict that maps attribute to desired value","def set_package_data(self, package_id, data):        """"""        Allows to modify several package attributes.        :param package_id: package id        :param data: dict that maps attribute to desired value        """"""        p = self.pyload.files.get_package(package_id)        if not p:            raise PackageDoesNotExists(package_id)        for key, value in data.items():            if key == ""id"":                continue            setattr(p, key, value)        p.sync()        self.pyload.files.save()

Allows to modify several package attributes.

:param package_id: package id
:param data: dict that maps attribute to desired value",c487d1f6-9f07-4baa-8b8d-695a4cc7b779
api,__init__.py,delete_finished,1008,1014,def delete_finished(self):                return self.pyload.files.delete_finished_links(),"Deletes all finished files and completely finished packages.

:return: list of deleted package ids","def delete_finished(self):        """"""        Deletes all finished files and completely finished packages.        :return: list of deleted package ids        """"""        return self.pyload.files.delete_finished_links()

Deletes all finished files and completely finished packages.

:return: list of deleted package ids",11b35fe9-65a7-4dbf-862f-15d86f6fcce7
api,__init__.py,restart_failed,1018,1022,def restart_failed(self):                self.pyload.files.restart_failed(),Restarts all failed failes.,"def restart_failed(self):        """"""        Restarts all failed failes.        """"""        self.pyload.files.restart_failed()

Restarts all failed failes.",13f5aaf8-2c5d-4791-bfd0-a40998313693
api,__init__.py,get_package_order,1026,1041,"def get_package_order(self, destination):                packages = self.pyload.files.get_info_data(Destination(destination))        order = {}        for package_id in packages:            pack = self.pyload.files.get_package_data(int(package_id))            while pack[""order""] in order.keys():  #: just in case                pack[""order""] += 1            order[pack[""order""]] = pack[""id""]        return order","Returns information about package order.

:param destination: `Destination`
:return: dict mapping order to package id","def get_package_order(self, destination):        """"""        Returns information about package order.        :param destination: `Destination`        :return: dict mapping order to package id        """"""        packages = self.pyload.files.get_info_data(Destination(destination))        order = {}        for package_id in packages:            pack = self.pyload.files.get_package_data(int(package_id))            while pack[""order""] in order.keys():  #: just in case                pack[""order""] += 1            order[pack[""order""]] = pack[""id""]        return order

Returns information about package order.

:param destination: `Destination`
:return: dict mapping order to package id",19091434-b6b2-4166-92ed-cfb6f8689c66
api,__init__.py,get_file_order,1045,1058,"def get_file_order(self, package_id):                raw_data = self.pyload.files.get_package_data(int(package_id))        order = {}        for id, pyfile in raw_data[""links""].items():            while pyfile[""order""] in order.keys():  #: just in case                pyfile[""order""] += 1            order[pyfile[""order""]] = pyfile[""id""]        return order","Information about file order within package.

:param package_id:
:return: dict mapping order to file id","def get_file_order(self, package_id):        """"""        Information about file order within package.        :param package_id:        :return: dict mapping order to file id        """"""        raw_data = self.pyload.files.get_package_data(int(package_id))        order = {}        for id, pyfile in raw_data[""links""].items():            while pyfile[""order""] in order.keys():  #: just in case                pyfile[""order""] += 1            order[pyfile[""order""]] = pyfile[""id""]        return order

Information about file order within package.

:param package_id:
:return: dict mapping order to file id",506cee46-ed5d-41cc-9c3c-b685b1b9a8cc
api,__init__.py,is_captcha_waiting,1062,1070,def is_captcha_waiting(self):                self.pyload.last_client_connected = time.time()        task = self.pyload.captcha_manager.get_task()        return task is not None,"Indicates wether a captcha task is available.

:return: bool","def is_captcha_waiting(self):        """"""        Indicates wether a captcha task is available.        :return: bool        """"""        self.pyload.last_client_connected = time.time()        task = self.pyload.captcha_manager.get_task()        return task is not None

Indicates wether a captcha task is available.

:return: bool",52a2da68-0783-4ac4-8c19-2fe651c17496
api,__init__.py,get_captcha_task,1074,1089,"def get_captcha_task(self, exclusive=False):                self.pyload.last_client_connected = time.time()        task = self.pyload.captcha_manager.get_task()        if task:            task.set_waiting_for_user(exclusive=exclusive)            data, type, result = task.get_captcha()            t = CaptchaTask(int(task.id), json.dumps(data), type, result)            return t        else:            return CaptchaTask(-1)","Returns a captcha task.

:param exclusive: unused
:return: `CaptchaTask`","def get_captcha_task(self, exclusive=False):        """"""        Returns a captcha task.        :param exclusive: unused        :return: `CaptchaTask`        """"""        self.pyload.last_client_connected = time.time()        task = self.pyload.captcha_manager.get_task()        if task:            task.set_waiting_for_user(exclusive=exclusive)            data, type, result = task.get_captcha()            t = CaptchaTask(int(task.id), json.dumps(data), type, result)            return t        else:            return CaptchaTask(-1)

Returns a captcha task.

:param exclusive: unused
:return: `CaptchaTask`",8883ca30-1274-40ef-b3d7-25a1fd11616b
api,__init__.py,get_captcha_task_status,1093,1102,"def get_captcha_task_status(self, tid):                self.pyload.last_client_connected = time.time()        t = self.pyload.captcha_manager.get_task_by_id(tid)        return t.get_status() if t else """"","Get information about captcha task.

:param tid: task id
:return: string","def get_captcha_task_status(self, tid):        """"""        Get information about captcha task.        :param tid: task id        :return: string        """"""        self.pyload.last_client_connected = time.time()        t = self.pyload.captcha_manager.get_task_by_id(tid)        return t.get_status() if t else """"

Get information about captcha task.

:param tid: task id
:return: string",e2d0841b-0e39-4ea0-943f-c3ff4330c36e
api,__init__.py,set_captcha_result,1106,1117,"def set_captcha_result(self, tid, result):                self.pyload.last_client_connected = time.time()        task = self.pyload.captcha_manager.get_task_by_id(tid)        if task:            task.set_result(result)            self.pyload.captcha_manager.remove_task(task)","Set result for a captcha task.

:param tid: task id
:param result: captcha result","def set_captcha_result(self, tid, result):        """"""        Set result for a captcha task.        :param tid: task id        :param result: captcha result        """"""        self.pyload.last_client_connected = time.time()        task = self.pyload.captcha_manager.get_task_by_id(tid)        if task:            task.set_result(result)            self.pyload.captcha_manager.remove_task(task)

Set result for a captcha task.

:param tid: task id
:param result: captcha result",9fb0ed76-c1d3-45cb-8a8a-1bfd2948a81c
api,__init__.py,get_events,1121,1153,"def get_events(self, uuid):                events = self.pyload.event_manager.get_events(uuid)        new_events = []        def conv_dest(d):            return (Destination.QUEUE if d == ""queue"" else Destination.COLLECTOR).value        for e in events:            event = EventInfo()            event.eventname = e[0]            if e[0] in (""update"", ""remove"", ""insert""):                event.id = e[3]                event.type = (                    ElementType.PACKAGE if e[2] == ""pack"" else ElementType.FILE                ).value                event.destination = conv_dest(e[1])            elif e[0] == ""order"":                if e[1]:                    event.id = e[1]                    event.type = (                        ElementType.PACKAGE if e[2] == ""pack"" else ElementType.FILE                    )                    event.destination = conv_dest(e[3])            elif e[0] == ""reload"":                event.destination = conv_dest(e[1])            new_events.append(event)        return new_events","Lists occurred events, may be affected to changes in the future.

:param uuid:
:return: list of `Events`","def get_events(self, uuid):        """"""        Lists occurred events, may be affected to changes in the future.        :param uuid:        :return: list of `Events`        """"""        events = self.pyload.event_manager.get_events(uuid)        new_events = []        def conv_dest(d):            return (Destination.QUEUE if d == ""queue"" else Destination.COLLECTOR).value        for e in events:            event = EventInfo()            event.eventname = e[0]            if e[0] in (""update"", ""remove"", ""insert""):                event.id = e[3]                event.type = (                    ElementType.PACKAGE if e[2] == ""pack"" else ElementType.FILE                ).value                event.destination = conv_dest(e[1])            elif e[0] == ""order"":                if e[1]:                    event.id = e[1]                    event.type = (                        ElementType.PACKAGE if e[2] == ""pack"" else ElementType.FILE                    )                    event.destination = conv_dest(e[3])            elif e[0] == ""reload"":                event.destination = conv_dest(e[1])            new_events.append(event)        return new_events

Lists occurred events, may be affected to changes in the future.

:param uuid:
:return: list of `Events`",086852fd-da52-4c03-8b1c-eda967d0821a
api,__init__.py,get_accounts,1157,1181,"def get_accounts(self, refresh):                accs = self.pyload.account_manager.get_account_infos(False, refresh)        accounts = []        for group in accs.values():            accounts.extend(                [                    AccountInfo(                        acc[""validuntil""],                        acc[""login""],                        acc[""options""],                        acc[""valid""],                        acc[""trafficleft""],                        acc[""premium""],                        acc[""type""],                    )                    for acc in group                ]            )        return accounts","Get information about all entered accounts.

:param refresh: reload account info
:return: list of `AccountInfo`","def get_accounts(self, refresh):        """"""        Get information about all entered accounts.        :param refresh: reload account info        :return: list of `AccountInfo`        """"""        accs = self.pyload.account_manager.get_account_infos(False, refresh)        accounts = []        for group in accs.values():            accounts.extend(                [                    AccountInfo(                        acc[""validuntil""],                        acc[""login""],                        acc[""options""],                        acc[""valid""],                        acc[""trafficleft""],                        acc[""premium""],                        acc[""type""],                    )                    for acc in group                ]            )        return accounts

Get information about all entered accounts.

:param refresh: reload account info
:return: list of `AccountInfo`",3ebf2883-4873-4b08-b659-072a7b1315c9
api,__init__.py,get_account_types,1185,1191,def get_account_types(self):                return list(self.pyload.account_manager.accounts.keys()),"All available account types.

:return: list","def get_account_types(self):        """"""        All available account types.        :return: list        """"""        return list(self.pyload.account_manager.accounts.keys())

All available account types.

:return: list",b5e96acc-eb1e-45e3-9670-08d131055212
api,__init__.py,update_account,1195,1199,"def update_account(self, plugin, account, password=None, options={}):                self.pyload.account_manager.update_account(plugin, account, password, options)",Changes pw/options for specific account.,"def update_account(self, plugin, account, password=None, options={}):        """"""        Changes pw/options for specific account.        """"""        self.pyload.account_manager.update_account(plugin, account, password, options)

Changes pw/options for specific account.",5e5d6ef2-4887-4f33-a2a4-b9a8381c349a
api,__init__.py,remove_account,1203,1210,"def remove_account(self, plugin, account):                self.pyload.account_manager.remove_account(plugin, account)","Remove account from pyload.

:param plugin: pluginname
:param account: accountname","def remove_account(self, plugin, account):        """"""        Remove account from pyload.        :param plugin: pluginname        :param account: accountname        """"""        self.pyload.account_manager.remove_account(plugin, account)

Remove account from pyload.

:param plugin: pluginname
:param account: accountname",fa1ca7ed-7ca9-41a9-8bdb-9436aa95b54d
api,__init__.py,login,1213,1222,"def login(self, username, password):                return True if self.check_auth(username, password) else False","Login into pyLoad, this **must** be called when using rpc before any methods can
be used.

:param username:
:param password:
:return: bool indicating login was successful","def login(self, username, password):        """"""        Login into pyLoad, this **must** be called when using rpc before any methods can        be used.        :param username:        :param password:        :return: bool indicating login was successful        """"""        return True if self.check_auth(username, password) else False

Login into pyLoad, this **must** be called when using rpc before any methods can
be used.

:param username:
:param password:
:return: bool indicating login was successful",cd7deb37-b294-4c10-8200-851c8d732ec4
api,__init__.py,check_auth,1225,1233,"def check_auth(self, username, password):                return self.pyload.db.check_auth(username, password)","Check authentication and returns details.

:param username:
:param password:
:return: dict with info, empty when login is incorrect","def check_auth(self, username, password):        """"""        Check authentication and returns details.        :param username:        :param password:        :return: dict with info, empty when login is incorrect        """"""        return self.pyload.db.check_auth(username, password)

Check authentication and returns details.

:param username:
:param password:
:return: dict with info, empty when login is incorrect",1137336e-5e7f-4306-9513-43068808ded2
api,__init__.py,user_exists,1235,1242,"def user_exists(self, username):                return self.pyload.db.user_exists(username)","Check if a user actually exists in the database.

:param username:
:return: boolean","def user_exists(self, username):        """"""        Check if a user actually exists in the database.        :param username:        :return: boolean        """"""        return self.pyload.db.user_exists(username)

Check if a user actually exists in the database.

:param username:
:return: boolean",d17f8081-c185-4331-b7ed-a458e3a40891
api,__init__.py,is_authorized,1245,1260,"def is_authorized(self, func, userdata):                if userdata[""role""] == Role.ADMIN:            return True        elif func in perm_map and has_permission(            userdata[""permission""], perm_map[func]        ):            return True        else:            return False","checks if the user is authorized for specific method.

:param func: function name
:param userdata: dictionary of user data
:return: boolean","def is_authorized(self, func, userdata):        """"""        checks if the user is authorized for specific method.        :param func: function name        :param userdata: dictionary of user data        :return: boolean        """"""        if userdata[""role""] == Role.ADMIN:            return True        elif func in perm_map and has_permission(            userdata[""permission""], perm_map[func]        ):            return True        else:            return False

checks if the user is authorized for specific method.

:param func: function name
:param userdata: dictionary of user data
:return: boolean",73a59c35-d9bd-40d7-87a3-7be3d44bb769
api,__init__.py,get_userdir,1263,1264,def get_userdir(self):        return os.path.realpath(self.pyload.userdir),,def get_userdir(self):        return os.path.realpath(self.pyload.userdir),324a6efb-e935-4694-877d-57514d23fbb6
api,__init__.py,get_cachedir,1267,1268,def get_cachedir(self):        return os.path.realpath(self.pyload.tempdir),,def get_cachedir(self):        return os.path.realpath(self.pyload.tempdir),3ec8b1f2-c715-4ab2-b9c6-d22bd651444c
api,__init__.py,getUserData,1272,1286,"def getUserData(self, username, password):                user = self.check_auth(username, password)        if user:            return OldUserData(                user[""name""],                user[""email""],                user[""role""],                user[""permission""],                user[""template""],            )        else:            return OldUserData()",similar to `check_auth` but returns UserData thrift type.,"def getUserData(self, username, password):        """"""        similar to `check_auth` but returns UserData thrift type.        """"""        user = self.check_auth(username, password)        if user:            return OldUserData(                user[""name""],                user[""email""],                user[""role""],                user[""permission""],                user[""template""],            )        else:            return OldUserData()

similar to `check_auth` but returns UserData thrift type.",a18792bc-b28a-4819-b18e-69c4c7148182
api,__init__.py,get_userdata,1289,1304,"def get_userdata(self, username, password):                user = self.check_auth(username, password)        if user:            return UserData(                user[""id""],                user[""name""],                user[""email""],                user[""role""],                user[""permission""],                user[""template""],            )        else:            return UserData()",similar to `check_auth` but returns UserData thrift type.,"def get_userdata(self, username, password):        """"""        similar to `check_auth` but returns UserData thrift type.        """"""        user = self.check_auth(username, password)        if user:            return UserData(                user[""id""],                user[""name""],                user[""email""],                user[""role""],                user[""permission""],                user[""template""],            )        else:            return UserData()

similar to `check_auth` but returns UserData thrift type.",a20b7dc9-2f4b-4a21-8992-b4c613bb15e8
api,__init__.py,getAllUserData,1307,1321,"def getAllUserData(self):                res = {}        for id, data in self.pyload.db.get_all_user_data().items():            res[data[""name""]] = OldUserData(                data[""name""],                data[""email""],                data[""role""],                data[""permission""],                data[""template""],            )        return res",returns all known user and info.,"def getAllUserData(self):        """"""        returns all known user and info.        """"""        res = {}        for id, data in self.pyload.db.get_all_user_data().items():            res[data[""name""]] = OldUserData(                data[""name""],                data[""email""],                data[""role""],                data[""permission""],                data[""template""],            )        return res

returns all known user and info.",a1e33397-fe92-476c-86f6-fbd90a10cee9
api,__init__.py,get_all_userdata,1323,1337,"def get_all_userdata(self):                res = {}        for id, data in self.pyload.db.get_all_user_data().items():            res[id] = UserData(                id,                data[""name""],                data[""email""],                data[""role""],                data[""permission""],                data[""template""],            )        return res",returns all known user and info.,"def get_all_userdata(self):        """"""        returns all known user and info.        """"""        res = {}        for id, data in self.pyload.db.get_all_user_data().items():            res[id] = UserData(                id,                data[""name""],                data[""email""],                data[""role""],                data[""permission""],                data[""template""],            )        return res

returns all known user and info.",fadcd6b5-31b6-41d2-8447-09ae06ced820
api,__init__.py,get_services,1341,1351,"def get_services(self):                data = {}        for plugin, funcs in self.pyload.addon_manager.methods.items():            data[plugin] = funcs        return data","A dict of available services, these can be defined by addon plugins.

:return: dict with this style: {""plugin"": {""method"": ""description""}}","def get_services(self):        """"""        A dict of available services, these can be defined by addon plugins.        :return: dict with this style: {""plugin"": {""method"": ""description""}}        """"""        data = {}        for plugin, funcs in self.pyload.addon_manager.methods.items():            data[plugin] = funcs        return data

A dict of available services, these can be defined by addon plugins.

:return: dict with this style: {""plugin"": {""method"": ""description""}}",7bd2d2c6-abd2-41e7-b92b-7374c6810551
api,__init__.py,has_service,1355,1364,"def has_service(self, plugin, func):                cont = self.pyload.addon_manager.methods        return plugin in cont and func in cont[plugin]","Checks whether a service is available.

:param plugin:
:param func:
:return: bool","def has_service(self, plugin, func):        """"""        Checks whether a service is available.        :param plugin:        :param func:        :return: bool        """"""        cont = self.pyload.addon_manager.methods        return plugin in cont and func in cont[plugin]

Checks whether a service is available.

:param plugin:
:param func:
:return: bool",33cebbca-c68f-49cb-9e53-cd55fdebcc13
api,__init__.py,call,1367,1388,"def call(self, info):                plugin = info.plugin        func = info.func        args = info.arguments        parse = info.parse_arguments        if not self.has_service(plugin, func):            raise ServiceDoesNotExists(plugin, func)        try:            ret = self.pyload.addon_manager.call_rpc(plugin, func, args, parse)            return str(ret)        except Exception as exc:            raise ServiceException(exc)","Calls a service (a method in addon plugin).

:param info: `ServiceCall`
:return: result
:raises: ServiceDoesNotExists, when it's not available
:raises: ServiceException, when an exception was raised","def call(self, info):        """"""        Calls a service (a method in addon plugin).        :param info: `ServiceCall`        :return: result        :raises: ServiceDoesNotExists, when it's not available        :raises: ServiceException, when an exception was raised        """"""        plugin = info.plugin        func = info.func        args = info.arguments        parse = info.parse_arguments        if not self.has_service(plugin, func):            raise ServiceDoesNotExists(plugin, func)        try:            ret = self.pyload.addon_manager.call_rpc(plugin, func, args, parse)            return str(ret)        except Exception as exc:            raise ServiceException(exc)

Calls a service (a method in addon plugin).

:param info: `ServiceCall`
:return: result
:raises: ServiceDoesNotExists, when it's not available
:raises: ServiceException, when an exception was raised",dbc78aef-e0e0-4a94-bb57-8129703edeb0
api,__init__.py,get_all_info,1392,1398,def get_all_info(self):                return self.pyload.addon_manager.get_all_info(),"Returns all information stored by addon plugins. Values are always strings.

:return: {""plugin"": {""name"": value } }","def get_all_info(self):        """"""        Returns all information stored by addon plugins. Values are always strings.        :return: {""plugin"": {""name"": value } }        """"""        return self.pyload.addon_manager.get_all_info()

Returns all information stored by addon plugins. Values are always strings.

:return: {""plugin"": {""name"": value } }",52a867ee-e6c9-401d-9c76-b2ec9a9eac04
api,__init__.py,get_info_by_plugin,1402,1409,"def get_info_by_plugin(self, plugin):                return self.pyload.addon_manager.get_info(plugin)","Returns information stored by a specific plugin.

:param plugin: pluginname
:return: dict of attr names mapped to value {""name"": value}","def get_info_by_plugin(self, plugin):        """"""        Returns information stored by a specific plugin.        :param plugin: pluginname        :return: dict of attr names mapped to value {""name"": value}        """"""        return self.pyload.addon_manager.get_info(plugin)

Returns information stored by a specific plugin.

:param plugin: pluginname
:return: dict of attr names mapped to value {""name"": value}",c7566d5e-71b8-46ae-8c59-5a0044a6f6de
api,__init__.py,add_user,1411,1415,"def add_user(self, user, newpw, role=0, perms=0):                return self.pyload.db.add_user(user, newpw, role, perms)",creates new user login.,"def add_user(self, user, newpw, role=0, perms=0):        """"""        creates new user login.        """"""        return self.pyload.db.add_user(user, newpw, role, perms)

creates new user login.",67b82b2e-937c-4973-930b-508ac591150e
api,__init__.py,remove_user,1417,1421,"def remove_user(self, user):                return self.pyload.db.remove_user(user)",deletes a user login.,"def remove_user(self, user):        """"""        deletes a user login.        """"""        return self.pyload.db.remove_user(user)

deletes a user login.",ce1bf2a2-e69d-4994-a028-7f527b8fb61a
api,__init__.py,change_password,1424,1428,"def change_password(self, user, oldpw, newpw):                return self.pyload.db.change_password(user, oldpw, newpw)",changes password for specific user.,"def change_password(self, user, oldpw, newpw):        """"""        changes password for specific user.        """"""        return self.pyload.db.change_password(user, oldpw, newpw)

changes password for specific user.",1b4f0112-3ba7-4dea-bb29-9a41e896a096
api,__init__.py,set_user_permission,1431,1433,"def set_user_permission(self, user, permission, role):        self.pyload.db.set_permission(user, permission)        self.pyload.db.set_role(user, role)",,"def set_user_permission(self, user, permission, role):        self.pyload.db.set_permission(user, permission)        self.pyload.db.set_role(user, role)",2235d8e9-4c79-478b-99b0-30a89eabdf94
config,parser.py,__init__,41,59,"def __init__(self, userdir):                self.config = {}  #: the config values        self.plugin = {}  #: the config for plugins        # TODO: Recheck        configdir = os.path.join(userdir, ""settings"")        os.makedirs(configdir, exist_ok=True)        self.configpath = os.path.join(configdir, ""pyload.cfg"")        self.pluginpath = os.path.join(configdir, ""plugins.cfg"")        self.plugin_cb = None  #: callback when plugin config value is changed        self.check_version()        self.read_default_config()",Constructor.,"def __init__(self, userdir):        """"""        Constructor.        """"""        self.config = {}  #: the config values        self.plugin = {}  #: the config for plugins        # TODO: Recheck        configdir = os.path.join(userdir, ""settings"")        os.makedirs(configdir, exist_ok=True)        self.configpath = os.path.join(configdir, ""pyload.cfg"")        self.pluginpath = os.path.join(configdir, ""plugins.cfg"")        self.plugin_cb = None  #: callback when plugin config value is changed        self.check_version()        self.read_default_config()

Constructor.",8e2c6a7d-c137-4185-9f4d-4202034c06e4
config,parser.py,check_version,61,106,"def check_version(self, n=0):                try:            if not os.path.exists(self.configpath):                os.makedirs(os.path.dirname(self.configpath), exist_ok=True)                shutil.copy(                    os.path.join(PKGDIR, ""core"", ""config"", ""default.cfg""),                    self.configpath,                )                os.chmod(self.configpath, 0o600)            if not os.path.exists(self.pluginpath):                os.makedirs(os.path.dirname(self.pluginpath), exist_ok=True)                with open(self.pluginpath, mode=""w"") as fp:                    fp.write(f""version: {__version__}"")                os.chmod(self.pluginpath, 0o600)            with open(self.configpath) as fp:                content = fp.read()            m_ver = self._VERSION.search(content)            if m_ver is None or int(m_ver.group(1)) < __version__:                shutil.copy(                    os.path.join(PKGDIR, ""core"", ""config"", ""default.cfg""),                    self.configpath,                )                print(""Old version of config was replaced"")            with open(self.pluginpath) as fp:                content = fp.read()            m_ver = self._VERSION.search(content)            if m_ver is None or int(m_ver.group(1)) < __version__:                with open(self.pluginpath, mode=""w"") as fp:                    fp.write(f""version: {__version__}"")                print(""Old version of plugin-config replaced"")        except Exception:            if n < 3:                time.sleep(1)                self.check_version(n + 1)            else:                raise",determines if config need to be copied.,"def check_version(self, n=0):        """"""        determines if config need to be copied.        """"""        try:            if not os.path.exists(self.configpath):                os.makedirs(os.path.dirname(self.configpath), exist_ok=True)                shutil.copy(                    os.path.join(PKGDIR, ""core"", ""config"", ""default.cfg""),                    self.configpath,                )                os.chmod(self.configpath, 0o600)            if not os.path.exists(self.pluginpath):                os.makedirs(os.path.dirname(self.pluginpath), exist_ok=True)                with open(self.pluginpath, mode=""w"") as fp:                    fp.write(f""version: {__version__}"")                os.chmod(self.pluginpath, 0o600)            with open(self.configpath) as fp:                content = fp.read()            m_ver = self._VERSION.search(content)            if m_ver is None or int(m_ver.group(1)) < __version__:                shutil.copy(                    os.path.join(PKGDIR, ""core"", ""config"", ""default.cfg""),                    self.configpath,                )                print(""Old version of config was replaced"")            with open(self.pluginpath) as fp:                content = fp.read()            m_ver = self._VERSION.search(content)            if m_ver is None or int(m_ver.group(1)) < __version__:                with open(self.pluginpath, mode=""w"") as fp:                    fp.write(f""version: {__version__}"")                print(""Old version of plugin-config replaced"")        except Exception:            if n < 3:                time.sleep(1)                self.check_version(n + 1)            else:                raise

determines if config need to be copied.",1be847ae-16c6-4be7-8bd9-f04c75635d33
config,parser.py,read_default_config,108,122,"def read_default_config(self):                self.config = self.parse_config(            os.path.join(PKGDIR, ""core"", ""config"", ""default.cfg"")        )        self.plugin = self.parse_config(self.pluginpath)        try:            homeconf = self.parse_config(self.configpath)            self.update_values(homeconf, self.config)        except Exception as exc:            exc_logger.exception(exc)",reads the config file.,"def read_default_config(self):        """"""        reads the config file.        """"""        self.config = self.parse_config(            os.path.join(PKGDIR, ""core"", ""config"", ""default.cfg"")        )        self.plugin = self.parse_config(self.pluginpath)        try:            homeconf = self.parse_config(self.configpath)            self.update_values(homeconf, self.config)        except Exception as exc:            exc_logger.exception(exc)

reads the config file.",461a9350-c55c-4cff-93d9-55230aee585e
config,parser.py,parse_config,124,212,"def parse_config(self, config_file):                with open(config_file) as fp:            config = fp.read()            config = config.splitlines()[1:]            conf = {}            section, option, value, typ, desc = """", """", """", """", """"            listmode = False            for line in config:                comment = line.rfind(""#"")                if (                    line.find("":"", comment) < 0 > line.find(""="", comment)                    and comment > 0                    and line[comment - 1].isspace()                ):                    line = line.rpartition(""#"")  #: removes comments                    if line[1]:                        line = line[0]                    else:                        line = line[2]                line = line.strip()                try:                    if line == """":                        continue                    m = self._SECTLINE.match(line)                    if m is not None:                        section, desc = m.groups()                        conf[section] = {""desc"": desc}                    else:                        if listmode:                            if line.endswith(""]""):                                listmode = False                                line = line.replace(""]"", """")                            value += [                                self.cast(typ, x.strip()) for x in line.split("","") if x                            ]                            if not listmode:                                conf[section][option] = {                                    ""desc"": desc,                                    ""type"": typ,                                    ""value"": value,                                }                        else:                            m = self._CONFLINE.search(line)                            typ = m.group(""T"")                            option = m.group(""N"")                            desc = m.group(""D"").strip()                            value = m.group(""V"").strip()                            if value.startswith(""[""):                                if value.endswith(""]""):                                    listmode = False                                    value = value[:-1]                                else:                                    listmode = True                                value = [                                    self.cast(typ, x.strip())                                    for x in value[1:].split("","")                                    if x                                ]                            else:                                value = self.cast(typ, value)                            if not listmode:                                conf[section][option] = {                                    ""desc"": desc,                                    ""type"": typ,                                    ""value"": value,                                }                except Exception as exc:                    exc_logger.exception(exc)        return conf",parses a given configfile.,"def parse_config(self, config_file):        """"""        parses a given configfile.        """"""        with open(config_file) as fp:            config = fp.read()            config = config.splitlines()[1:]            conf = {}            section, option, value, typ, desc = """", """", """", """", """"            listmode = False            for line in config:                comment = line.rfind(""#"")                if (                    line.find("":"", comment) < 0 > line.find(""="", comment)                    and comment > 0                    and line[comment - 1].isspace()                ):                    line = line.rpartition(""#"")  #: removes comments                    if line[1]:                        line = line[0]                    else:                        line = line[2]                line = line.strip()                try:                    if line == """":                        continue                    m = self._SECTLINE.match(line)                    if m is not None:                        section, desc = m.groups()                        conf[section] = {""desc"": desc}                    else:                        if listmode:                            if line.endswith(""]""):                                listmode = False                                line = line.replace(""]"", """")                            value += [                                self.cast(typ, x.strip()) for x in line.split("","") if x                            ]                            if not listmode:                                conf[section][option] = {                                    ""desc"": desc,                                    ""type"": typ,                                    ""value"": value,                                }                        else:                            m = self._CONFLINE.search(line)                            typ = m.group(""T"")                            option = m.group(""N"")                            desc = m.group(""D"").strip()                            value = m.group(""V"").strip()                            if value.startswith(""[""):                                if value.endswith(""]""):                                    listmode = False                                    value = value[:-1]                                else:                                    listmode = True                                value = [                                    self.cast(typ, x.strip())                                    for x in value[1:].split("","")                                    if x                                ]                            else:                                value = self.cast(typ, value)                            if not listmode:                                conf[section][option] = {                                    ""desc"": desc,                                    ""type"": typ,                                    ""value"": value,                                }                except Exception as exc:                    exc_logger.exception(exc)        return conf

parses a given configfile.",6ffb2d8a-1465-4fa9-b1ed-673fa79d2436
config,parser.py,update_values,214,227,"def update_values(self, config, dest):                for section in config.keys():            if section in dest:                for option in config[section].keys():                    if option in (""desc"", ""outline""):                        continue                    if option in dest[section]:                        dest[section][option][""value""] = config[section][option][                            ""value""                        ]",sets the config values from a parsed config file to values in destination.,"def update_values(self, config, dest):        """"""        sets the config values from a parsed config file to values in destination.        """"""        for section in config.keys():            if section in dest:                for option in config[section].keys():                    if option in (""desc"", ""outline""):                        continue                    if option in dest[section]:                        dest[section][option][""value""] = config[section][option][                            ""value""                        ]

sets the config values from a parsed config file to values in destination.",029f6aec-53e6-44e3-9b08-889d5d86969c
config,parser.py,save_config,235,259,"def save_config(self, config, filename):                with open(filename, mode=""w"") as fp:            os.chmod(filename, 0o600)            fp.write(f""version: {__version__} \n"")            for section in sorted(config.keys()):                fp.write(f'\n{section} - ""{config[section][""desc""]}"":\n')                for option, data in sorted(                    config[section].items(), key=lambda _x: _x[0]                ):                    if option in (""desc"", ""outline""):                        continue                    if isinstance(data[""value""], list):                        value = ""[ \n""                        for x in data[""value""]:                            value += f""\t\t{x},\n""                        value += ""\t\t]\n""                    else:                        value = str(data[""value""]) + ""\n""                    fp.write(f'\t{data[""type""]} {option} : ""{data[""desc""]}"" = {value}')",saves config to filename.,"def save_config(self, config, filename):        """"""        saves config to filename.        """"""        with open(filename, mode=""w"") as fp:            os.chmod(filename, 0o600)            fp.write(f""version: {__version__} \n"")            for section in sorted(config.keys()):                fp.write(f'\n{section} - ""{config[section][""desc""]}"":\n')                for option, data in sorted(                    config[section].items(), key=lambda _x: _x[0]                ):                    if option in (""desc"", ""outline""):                        continue                    if isinstance(data[""value""], list):                        value = ""[ \n""                        for x in data[""value""]:                            value += f""\t\t{x},\n""                        value += ""\t\t]\n""                    else:                        value = str(data[""value""]) + ""\n""                    fp.write(f'\t{data[""type""]} {option} : ""{data[""desc""]}"" = {value}')

saves config to filename.",6fff2f68-20a5-473a-aa1f-d4a7400f98a2
config,parser.py,cast,261,310,"def cast(self, typ, value):                if typ == ""int"":            return int(value)        elif typ == ""float"":            return float(value)        elif typ == ""str"":            return """" if value is None else str(value)        elif typ == ""bytes"":            return b"""" if value is None else bytes(value)        elif typ == ""bool"":            value = """" if value is None else str(value)            return value.lower() in (""1"", ""true"", ""on"", ""yes"", ""y"")        elif typ == ""time"":            default_value = ""0:00""            value = """" if value is None else str(value)            if not value:                value = default_value            elif "":"" not in value:                value += "":00""            hours, seconds = value.split("":"", 1)            if (                hours.isnumeric()                and seconds.isnumeric()                and 0 <= int(hours) <= 23                and 0 <= int(seconds) <= 59            ):                pass            else:                value = default_value            return value        elif typ in (""file"", ""folder""):            return (                """"                if value in (None, """")                else os.path.realpath(os.path.expanduser(os.fsdecode(value)))            )        else:            return value",cast value to given format.,"def cast(self, typ, value):        """"""        cast value to given format.        """"""        if typ == ""int"":            return int(value)        elif typ == ""float"":            return float(value)        elif typ == ""str"":            return """" if value is None else str(value)        elif typ == ""bytes"":            return b"""" if value is None else bytes(value)        elif typ == ""bool"":            value = """" if value is None else str(value)            return value.lower() in (""1"", ""true"", ""on"", ""yes"", ""y"")        elif typ == ""time"":            default_value = ""0:00""            value = """" if value is None else str(value)            if not value:                value = default_value            elif "":"" not in value:                value += "":00""            hours, seconds = value.split("":"", 1)            if (                hours.isnumeric()                and seconds.isnumeric()                and 0 <= int(hours) <= 23                and 0 <= int(seconds) <= 59            ):                pass            else:                value = default_value            return value        elif typ in (""file"", ""folder""):            return (                """"                if value in (None, """")                else os.path.realpath(os.path.expanduser(os.fsdecode(value)))            )        else:            return value

cast value to given format.",280a2528-dc13-4203-97af-d3a606987a2b
config,parser.py,save,312,317,"def save(self):                self.save_config(self.config, self.configpath)        self.save_config(self.plugin, self.pluginpath)",saves the configs to disk.,"def save(self):        """"""        saves the configs to disk.        """"""        self.save_config(self.config, self.configpath)        self.save_config(self.plugin, self.pluginpath)

saves the configs to disk.",b93c831d-d9b1-4c96-9b43-524cde822d15
config,parser.py,__getitem__,319,323,"def __getitem__(self, section):                return Section(self, section)",provides dictonary like access: c['section']['option'],"def __getitem__(self, section):        """"""        provides dictonary like access: c['section']['option']        """"""        return Section(self, section)

provides dictonary like access: c['section']['option']",9d13b229-6295-4a44-970b-872b962cdb25
config,parser.py,get,325,329,"def get(self, section, option):                return self.config[section][option][""value""]",get value.,"def get(self, section, option):        """"""        get value.        """"""        return self.config[section][option][""value""]

get value.",8302bf17-32a3-4366-809b-9f8cbdf17613
config,parser.py,set,331,338,"def set(self, section, option, value):                value = self.cast(self.config[section][option][""type""], value)        self.config[section][option][""value""] = value        self.save()",set value.,"def set(self, section, option, value):        """"""        set value.        """"""        value = self.cast(self.config[section][option][""type""], value)        self.config[section][option][""value""] = value        self.save()

set value.",d473cb01-1dad-4559-a09d-adaad242ad92
config,parser.py,toggle,340,341,"def toggle(self, section, option):        self.set(section, option, self.get(section, option) ^ True)",,"def toggle(self, section, option):        self.set(section, option, self.get(section, option) ^ True)",9206993c-bfe9-4349-9b69-f4a43986146f
config,parser.py,get_plugin,343,347,"def get_plugin(self, plugin, option):                return self.plugin[plugin][option][""value""]",gets a value for a plugin.,"def get_plugin(self, plugin, option):        """"""        gets a value for a plugin.        """"""        return self.plugin[plugin][option][""value""]

gets a value for a plugin.",6d11f3ca-957b-4821-a554-cabccf75aa64
config,parser.py,set_plugin,349,360,"def set_plugin(self, plugin, option, value):                value = self.cast(self.plugin[plugin][option][""type""], value)        # TODO: check if callable        if self.plugin_cb:            self.plugin_cb(plugin, option, value)        self.plugin[plugin][option][""value""] = value        self.save()",sets a value for a plugin.,"def set_plugin(self, plugin, option, value):        """"""        sets a value for a plugin.        """"""        value = self.cast(self.plugin[plugin][option][""type""], value)        # TODO: check if callable        if self.plugin_cb:            self.plugin_cb(plugin, option, value)        self.plugin[plugin][option][""value""] = value        self.save()

sets a value for a plugin.",70134acc-60f7-4a8c-b61e-459537a65ab6
config,parser.py,get_meta_data,362,366,"def get_meta_data(self, section, option):                return self.config[section][option]",get all config data for an option.,"def get_meta_data(self, section, option):        """"""        get all config data for an option.        """"""        return self.config[section][option]

get all config data for an option.",d22be72a-f481-424f-a7ee-02f06859012b
config,parser.py,add_plugin_config,368,387,"def add_plugin_config(self, name, config, outline=""""):                conf = self.plugin.get(name, {""desc"": name})        conf[""outline""] = outline        for item in config:            if item[0] in conf and item[1] == conf[item[0]][""type""]:                conf[item[0]][""desc""] = item[2]            else:                conf[item[0]] = {                    ""desc"": item[2],                    ""type"": item[1],                    ""value"": self.cast(item[1], item[3]),                }        values = [x[0] for x in config] + [""desc"", ""outline""]        # delete old values        self.plugin[name] = {k: v for k, v in conf.items() if k in values}","adds config options with tuples (name, type, desc, default)","def add_plugin_config(self, name, config, outline=""""):        """"""        adds config options with tuples (name, type, desc, default)        """"""        conf = self.plugin.get(name, {""desc"": name})        conf[""outline""] = outline        for item in config:            if item[0] in conf and item[1] == conf[item[0]][""type""]:                conf[item[0]][""desc""] = item[2]            else:                conf[item[0]] = {                    ""desc"": item[2],                    ""type"": item[1],                    ""value"": self.cast(item[1], item[3]),                }        values = [x[0] for x in config] + [""desc"", ""outline""]        # delete old values        self.plugin[name] = {k: v for k, v in conf.items() if k in values}

adds config options with tuples (name, type, desc, default)",e1d6662c-7a9e-4ec8-b3ed-f06bc0df00f0
config,parser.py,delete_config,389,394,"def delete_config(self, name):                if name in self.plugin:            del self.plugin[name]",Removes a plugin config.,"def delete_config(self, name):        """"""        Removes a plugin config.        """"""        if name in self.plugin:            del self.plugin[name]

Removes a plugin config.",cab583e2-3483-4c09-83f7-ca28a288e3f8
config,parser.py,__init__,402,407,"def __init__(self, parser, section):                self.parser = parser        self.section = section",Constructor.,"def __init__(self, parser, section):        """"""        Constructor.        """"""        self.parser = parser        self.section = section

Constructor.",77f58b46-2fd4-4efe-8b36-ffbb0ae8228d
config,parser.py,__getitem__,409,413,"def __getitem__(self, item):                return self.parser.get(self.section, item)",getitem.,"def __getitem__(self, item):        """"""        getitem.        """"""        return self.parser.get(self.section, item)

getitem.",9b154b70-98fe-42a9-8ef9-6ceb00cdc44c
config,parser.py,__setitem__,415,419,"def __setitem__(self, item, value):                self.parser.set(self.section, item, value)",setitem.,"def __setitem__(self, item, value):        """"""        setitem.        """"""        self.parser.set(self.section, item, value)

setitem.",936a6e13-c8b0-4944-a170-2b700f290d89
database,file_database.py,filecount,12,20,"def filecount(self, queue):                self.c.execute(            ""SELECT COUNT(*) FROM links as l INNER JOIN packages as p ON l.package=p.id WHERE p.queue=?"",            (queue,),        )        return self.c.fetchone()[0]",returns number of files in queue.,"def filecount(self, queue):        """"""        returns number of files in queue.        """"""        self.c.execute(            ""SELECT COUNT(*) FROM links as l INNER JOIN packages as p ON l.package=p.id WHERE p.queue=?"",            (queue,),        )        return self.c.fetchone()[0]

returns number of files in queue.",e734b133-3f33-4bc4-86b2-8efb24c7e59b
database,file_database.py,queuecount,23,31,"def queuecount(self, queue):                self.c.execute(            ""SELECT COUNT(*) FROM links as l INNER JOIN packages as p ON l.package=p.id WHERE p.queue=? AND l.status NOT IN (0,4)"",            (queue,),        )        return self.c.fetchone()[0]",number of files in queue not finished yet.,"def queuecount(self, queue):        """"""        number of files in queue not finished yet.        """"""        self.c.execute(            ""SELECT COUNT(*) FROM links as l INNER JOIN packages as p ON l.package=p.id WHERE p.queue=? AND l.status NOT IN (0,4)"",            (queue,),        )        return self.c.fetchone()[0]

number of files in queue not finished yet.",07fd5d48-6718-4ca2-8770-9908465210a6
database,file_database.py,processcount,34,42,"def processcount(self, queue, fid):                self.c.execute(            ""SELECT COUNT(*) FROM links as l INNER JOIN packages as p ON l.package=p.id WHERE p.queue=? AND l.status IN (2,3,5,7,12) AND l.id != ?"",            (queue, str(fid)),        )        return self.c.fetchone()[0]",number of files which have to be processed.,"def processcount(self, queue, fid):        """"""        number of files which have to be processed.        """"""        self.c.execute(            ""SELECT COUNT(*) FROM links as l INNER JOIN packages as p ON l.package=p.id WHERE p.queue=? AND l.status IN (2,3,5,7,12) AND l.id != ?"",            (queue, str(fid)),        )        return self.c.fetchone()[0]

number of files which have to be processed.",50cf34af-0b3e-48d9-b0f2-dfa6c967b0be
database,file_database.py,_next_package_order,45,51,"def _next_package_order(self, queue=0):        self.c.execute(""SELECT MAX(packageorder) FROM packages WHERE queue=?"", (queue,))        max_order = self.c.fetchone()[0]        if max_order is not None:            return max_order + 1        else:            return 0",,"def _next_package_order(self, queue=0):        self.c.execute(""SELECT MAX(packageorder) FROM packages WHERE queue=?"", (queue,))        max_order = self.c.fetchone()[0]        if max_order is not None:            return max_order + 1        else:            return 0",66be8cbb-7892-46d3-9288-a4bc5de69aba
database,file_database.py,_next_file_order,54,60,"def _next_file_order(self, package):        self.c.execute(""SELECT MAX(linkorder) FROM links WHERE package=?"", (package,))        max_order = self.c.fetchone()[0]        if max_order is not None:            return max_order + 1        else:            return 0",,"def _next_file_order(self, package):        self.c.execute(""SELECT MAX(linkorder) FROM links WHERE package=?"", (package,))        max_order = self.c.fetchone()[0]        if max_order is not None:            return max_order + 1        else:            return 0",be7c2b08-140f-4af3-a356-468601cb7926
database,file_database.py,add_link,63,69,"def add_link(self, url, name, plugin, package):        order = self._next_file_order(package)        self.c.execute(            ""INSERT INTO links(url, name, plugin, package, linkorder) VALUES(?,?,?,?,?)"",            (url, name, plugin, package, order),        )        return self.c.lastrowid",,"def add_link(self, url, name, plugin, package):        order = self._next_file_order(package)        self.c.execute(            ""INSERT INTO links(url, name, plugin, package, linkorder) VALUES(?,?,?,?,?)"",            (url, name, plugin, package, order),        )        return self.c.lastrowid",83ac004d-1f3c-40be-a29a-8011dda6b155
database,file_database.py,add_links,72,82,"def add_links(self, links, package):                order = self._next_file_order(package)        orders = [order + x for x in range(len(links))]        links = [(x[0], parse.name(x[0]), x[1], package, o) for x, o in zip(links, orders)]        self.c.executemany(            ""INSERT INTO links(url, name, plugin, package, linkorder) VALUES(?,?,?,?,?)"",            links,        )","links is a list of tuples (url,plugin)","def add_links(self, links, package):        """"""        links is a list of tuples (url,plugin)        """"""        order = self._next_file_order(package)        orders = [order + x for x in range(len(links))]        links = [(x[0], parse.name(x[0]), x[1], package, o) for x, o in zip(links, orders)]        self.c.executemany(            ""INSERT INTO links(url, name, plugin, package, linkorder) VALUES(?,?,?,?,?)"",            links,        )

links is a list of tuples (url,plugin)",dd9d271f-84c7-469c-b33e-4d16d68039d9
database,file_database.py,add_package,85,91,"def add_package(self, name, folder, queue):        order = self._next_package_order(queue)        self.c.execute(            ""INSERT INTO packages(name, folder, queue, packageorder) VALUES(?,?,?,?)"",            (name, folder, queue, order),        )        return self.c.lastrowid",,"def add_package(self, name, folder, queue):        order = self._next_package_order(queue)        self.c.execute(            ""INSERT INTO packages(name, folder, queue, packageorder) VALUES(?,?,?,?)"",            (name, folder, queue, order),        )        return self.c.lastrowid",4ba68a14-8a25-491b-8fb5-1327c5806cf3
database,file_database.py,delete_package,94,100,"def delete_package(self, p):        self.c.execute(""DELETE FROM links WHERE package=?"", (str(p.id),))        self.c.execute(""DELETE FROM packages WHERE id=?"", (str(p.id),))        self.c.execute(            ""UPDATE packages SET packageorder=packageorder-1 WHERE packageorder > ? AND queue=?"",            (p.order, p.queue),        )",,"def delete_package(self, p):        self.c.execute(""DELETE FROM links WHERE package=?"", (str(p.id),))        self.c.execute(""DELETE FROM packages WHERE id=?"", (str(p.id),))        self.c.execute(            ""UPDATE packages SET packageorder=packageorder-1 WHERE packageorder > ? AND queue=?"",            (p.order, p.queue),        )",e3b8eb88-cc3a-47e8-9dc4-e7fcd625467a
database,file_database.py,delete_link,103,108,"def delete_link(self, f):        self.c.execute(""DELETE FROM links WHERE id=?"", (str(f.id),))        self.c.execute(            ""UPDATE links SET linkorder=linkorder-1 WHERE linkorder > ? AND package=?"",            (f.order, str(f.packageid)),        )",,"def delete_link(self, f):        self.c.execute(""DELETE FROM links WHERE id=?"", (str(f.id),))        self.c.execute(            ""UPDATE links SET linkorder=linkorder-1 WHERE linkorder > ? AND package=?"",            (f.order, str(f.packageid)),        )",8d03c211-7383-48ca-aa46-d9ff446eb467
database,file_database.py,get_all_links,111,144,"def get_all_links(self, q):                self.c.execute(            ""SELECT l.id,l.url,l.name,l.size,l.status,l.error,l.plugin,l.package,l.linkorder FROM links as l INNER JOIN packages as p ON l.package=p.id WHERE p.queue=? ORDER BY l.linkorder"",            (q,),        )        data = {}        for r in self.c:            data[r[0]] = {                ""id"": r[0],                ""url"": r[1],                ""name"": r[2],                ""size"": r[3],                ""format_size"": format.size(r[3]),                ""status"": r[4],                ""statusmsg"": self.pyload.files.status_msg[r[4]],                ""error"": r[5],                ""plugin"": r[6],                ""package"": r[7],                ""order"": r[8],            }        return data","return information about all links in queue q.

q0 queue
q1 collector

format:

{
    id: {'name': name, ... 'package': id }, ...
}","def get_all_links(self, q):        """"""        return information about all links in queue q.        q0 queue        q1 collector        format:        {            id: {'name': name, ... 'package': id }, ...        }        """"""        self.c.execute(            ""SELECT l.id,l.url,l.name,l.size,l.status,l.error,l.plugin,l.package,l.linkorder FROM links as l INNER JOIN packages as p ON l.package=p.id WHERE p.queue=? ORDER BY l.linkorder"",            (q,),        )        data = {}        for r in self.c:            data[r[0]] = {                ""id"": r[0],                ""url"": r[1],                ""name"": r[2],                ""size"": r[3],                ""format_size"": format.size(r[3]),                ""status"": r[4],                ""statusmsg"": self.pyload.files.status_msg[r[4]],                ""error"": r[5],                ""plugin"": r[6],                ""package"": r[7],                ""order"": r[8],            }        return data

return information about all links in queue q.

q0 queue
q1 collector

format:

{
    id: {'name': name, ... 'package': id }, ...
}",14106510-2766-4761-9c94-f54941315e01
database,file_database.py,get_all_packages,147,185,"def get_all_packages(self, q):                self.c.execute(            ""SELECT p.id, p.name, p.folder, p.site, p.password, p.queue, p.packageorder, s.sizetotal, s.sizedone, s.linksdone, s.linkstotal \            FROM packages p JOIN pstats s ON p.id = s.id \            WHERE p.queue=? ORDER BY p.packageorder"",            str(q),        )        data = {}        for r in self.c:            data[r[0]] = {                ""id"": r[0],                ""name"": r[1],                ""folder"": r[2],                ""site"": r[3],                ""password"": r[4],                ""queue"": r[5],                ""order"": r[6],                ""sizetotal"": int(r[7]),                ""sizedone"": r[8] if r[8] else 0,  #: these can be None                ""linksdone"": r[9] if r[9] else 0,                ""linkstotal"": r[10],                ""links"": {},            }        return data","return information about packages in queue q (only useful in get all data)

q:
  0: queue
  1: packages

format:

{
    id: {'name': name ... 'links': {} }, ...
}","def get_all_packages(self, q):        """"""        return information about packages in queue q (only useful in get all data)        q:          0: queue          1: packages        format:        {            id: {'name': name ... 'links': {} }, ...        }        """"""        self.c.execute(            ""SELECT p.id, p.name, p.folder, p.site, p.password, p.queue, p.packageorder, s.sizetotal, s.sizedone, s.linksdone, s.linkstotal \            FROM packages p JOIN pstats s ON p.id = s.id \            WHERE p.queue=? ORDER BY p.packageorder"",            str(q),        )        data = {}        for r in self.c:            data[r[0]] = {                ""id"": r[0],                ""name"": r[1],                ""folder"": r[2],                ""site"": r[3],                ""password"": r[4],                ""queue"": r[5],                ""order"": r[6],                ""sizetotal"": int(r[7]),                ""sizedone"": r[8] if r[8] else 0,  #: these can be None                ""linksdone"": r[9] if r[9] else 0,                ""linkstotal"": r[10],                ""links"": {},            }        return data

return information about packages in queue q (only useful in get all data)

q:
  0: queue
  1: packages

format:

{
    id: {'name': name ... 'links': {} }, ...
}",93c1b69b-a0b7-41a1-8560-acb48f6c17bb
database,file_database.py,get_link_data,188,216,"def get_link_data(self, id):                self.c.execute(            ""SELECT id,url,name,size,status,error,plugin,package,linkorder FROM links WHERE id=?"",            (str(id),),        )        r = self.c.fetchone()        if not r:            return None        data = {            r[0]: {                ""id"": r[0],                ""url"": r[1],                ""name"": r[2],                ""size"": r[3],                ""format_size"": format.size(r[3]),                ""status"": r[4],                ""statusmsg"": self.pyload.files.status_msg[r[4]],                ""error"": r[5],                ""plugin"": r[6],                ""package"": r[7],                ""order"": r[8],            }        }        return data",get link information as dict.,"def get_link_data(self, id):        """"""        get link information as dict.        """"""        self.c.execute(            ""SELECT id,url,name,size,status,error,plugin,package,linkorder FROM links WHERE id=?"",            (str(id),),        )        r = self.c.fetchone()        if not r:            return None        data = {            r[0]: {                ""id"": r[0],                ""url"": r[1],                ""name"": r[2],                ""size"": r[3],                ""format_size"": format.size(r[3]),                ""status"": r[4],                ""statusmsg"": self.pyload.files.status_msg[r[4]],                ""error"": r[5],                ""plugin"": r[6],                ""package"": r[7],                ""order"": r[8],            }        }        return data

get link information as dict.",87859c54-78dc-4c3d-b6c5-8ac979e06c1f
database,file_database.py,get_package_data,219,244,"def get_package_data(self, id):                self.c.execute(            ""SELECT id,url,name,size,status,error,plugin,package,linkorder FROM links WHERE package=? ORDER BY linkorder"",            (str(id),),        )        data = {}        for r in self.c:            data[r[0]] = {                ""id"": r[0],                ""url"": r[1],                ""name"": r[2],                ""size"": r[3],                ""format_size"": format.size(r[3]),                ""status"": r[4],                ""statusmsg"": self.pyload.files.status_msg[r[4]],                ""error"": r[5],                ""plugin"": r[6],                ""package"": r[7],                ""order"": r[8],            }        return data",get data about links for a package.,"def get_package_data(self, id):        """"""        get data about links for a package.        """"""        self.c.execute(            ""SELECT id,url,name,size,status,error,plugin,package,linkorder FROM links WHERE package=? ORDER BY linkorder"",            (str(id),),        )        data = {}        for r in self.c:            data[r[0]] = {                ""id"": r[0],                ""url"": r[1],                ""name"": r[2],                ""size"": r[3],                ""format_size"": format.size(r[3]),                ""status"": r[4],                ""statusmsg"": self.pyload.files.status_msg[r[4]],                ""error"": r[5],                ""plugin"": r[6],                ""package"": r[7],                ""order"": r[8],            }        return data

get data about links for a package.",ccb18fba-3398-4ebb-935d-80b5affbefab
database,file_database.py,update_link,247,251,"def update_link(self, f):        self.c.execute(            ""UPDATE links SET url=?,name=?,size=?,status=?,error=?,package=? WHERE id=?"",            (f.url, f.name, f.size, f.status, f.error, str(f.packageid), str(f.id)),        )",,"def update_link(self, f):        self.c.execute(            ""UPDATE links SET url=?,name=?,size=?,status=?,error=?,package=? WHERE id=?"",            (f.url, f.name, f.size, f.status, f.error, str(f.packageid), str(f.id)),        )",8809aa96-0a2a-4ff6-a4d6-8a003b69f4d0
database,file_database.py,update_package,254,258,"def update_package(self, p):        self.c.execute(            ""UPDATE packages SET name=?,folder=?,site=?,password=?,queue=? WHERE id=?"",            (p.name, p.folder, p.site, p.password, p.queue, str(p.id)),        )",,"def update_package(self, p):        self.c.execute(            ""UPDATE packages SET name=?,folder=?,site=?,password=?,queue=? WHERE id=?"",            (p.name, p.folder, p.site, p.password, p.queue, str(p.id)),        )",d221e849-83b7-4fd5-93bd-ad450ce0c189
database,file_database.py,update_link_info,261,274,"def update_link_info(self, data):                self.c.executemany(            ""UPDATE links SET name=?, size=?, status=? WHERE url=? AND status IN (1,2,3,14)"",            data,        )        ids = []        statuses = ""','"".join(x[3] for x in data)        self.c.execute(f""SELECT id FROM links WHERE url IN ('{statuses}')"")        for r in self.c:            ids.append(int(r[0]))        return ids","data is list of tuples (name, size, status, url)","def update_link_info(self, data):        """"""        data is list of tuples (name, size, status, url)        """"""        self.c.executemany(            ""UPDATE links SET name=?, size=?, status=? WHERE url=? AND status IN (1,2,3,14)"",            data,        )        ids = []        statuses = ""','"".join(x[3] for x in data)        self.c.execute(f""SELECT id FROM links WHERE url IN ('{statuses}')"")        for r in self.c:            ids.append(int(r[0]))        return ids

data is list of tuples (name, size, status, url)",3f90a875-660a-41c5-b504-09a246b22a57
database,file_database.py,reorder_package,277,294,"def reorder_package(self, p, position, no_move=False):        if position == -1:            position = self._next_package_order(p.queue)        if not no_move:            if p.order > position:                self.c.execute(                    ""UPDATE packages SET packageorder=packageorder+1 WHERE packageorder >= ? AND packageorder < ? AND queue=? AND packageorder >= 0"",                    (position, p.order, p.queue),                )            elif p.order < position:                self.c.execute(                    ""UPDATE packages SET packageorder=packageorder-1 WHERE packageorder <= ? AND packageorder > ? AND queue=? AND packageorder >= 0"",                    (position, p.order, p.queue),                )        self.c.execute(            ""UPDATE packages SET packageorder=? WHERE id=?"", (position, str(p.id))        )",,"def reorder_package(self, p, position, no_move=False):        if position == -1:            position = self._next_package_order(p.queue)        if not no_move:            if p.order > position:                self.c.execute(                    ""UPDATE packages SET packageorder=packageorder+1 WHERE packageorder >= ? AND packageorder < ? AND queue=? AND packageorder >= 0"",                    (position, p.order, p.queue),                )            elif p.order < position:                self.c.execute(                    ""UPDATE packages SET packageorder=packageorder-1 WHERE packageorder <= ? AND packageorder > ? AND queue=? AND packageorder >= 0"",                    (position, p.order, p.queue),                )        self.c.execute(            ""UPDATE packages SET packageorder=? WHERE id=?"", (position, str(p.id))        )",c9a4f79f-6ca3-42fd-b7da-cf7df553e49e
database,file_database.py,reorder_link,297,312,"def reorder_link(self, f, position):                if f[""order""] > position:            self.c.execute(                ""UPDATE links SET linkorder=linkorder+1 WHERE linkorder >= ? AND linkorder < ? AND package=?"",                (position, f[""order""], f[""package""]),            )        elif f[""order""] < position:            self.c.execute(                ""UPDATE links SET linkorder=linkorder-1 WHERE linkorder <= ? AND linkorder > ? AND package=?"",                (position, f[""order""], f[""package""]),            )        self.c.execute(""UPDATE links SET linkorder=? WHERE id=?"", (position, f[""id""]))",reorder link with f as dict for pyfile.,"def reorder_link(self, f, position):        """"""        reorder link with f as dict for pyfile.        """"""        if f[""order""] > position:            self.c.execute(                ""UPDATE links SET linkorder=linkorder+1 WHERE linkorder >= ? AND linkorder < ? AND package=?"",                (position, f[""order""], f[""package""]),            )        elif f[""order""] < position:            self.c.execute(                ""UPDATE links SET linkorder=linkorder-1 WHERE linkorder <= ? AND linkorder > ? AND package=?"",                (position, f[""order""], f[""package""]),            )        self.c.execute(""UPDATE links SET linkorder=? WHERE id=?"", (position, f[""id""]))

reorder link with f as dict for pyfile.",3d1f2986-6886-410a-96e2-b04740285363
database,file_database.py,clear_package_order,315,320,"def clear_package_order(self, p):        self.c.execute(""UPDATE packages SET packageorder=? WHERE id=?"", (-1, str(p.id)))        self.c.execute(            ""UPDATE packages SET packageorder=packageorder-1 WHERE packageorder > ? AND queue=? AND id != ?"",            (p.order, p.queue, str(p.id)),        )",,"def clear_package_order(self, p):        self.c.execute(""UPDATE packages SET packageorder=? WHERE id=?"", (-1, str(p.id)))        self.c.execute(            ""UPDATE packages SET packageorder=packageorder-1 WHERE packageorder > ? AND queue=? AND id != ?"",            (p.order, p.queue, str(p.id)),        )",b5727e38-ac5a-4255-bca0-45fc094d466d
database,file_database.py,restart_file,323,324,"def restart_file(self, id):        self.c.execute('UPDATE links SET status=3,error="""" WHERE id=?', (str(id),))",,"def restart_file(self, id):        self.c.execute('UPDATE links SET status=3,error="""" WHERE id=?', (str(id),))",aea84dff-debe-44cf-be20-b18b072c358b
database,file_database.py,restart_package,327,328,"def restart_package(self, id):        self.c.execute(""UPDATE links SET status=3 WHERE package=?"", (str(id),))",,"def restart_package(self, id):        self.c.execute(""UPDATE links SET status=3 WHERE package=?"", (str(id),))",664ef353-7409-484f-8ad0-af765946a767
database,file_database.py,get_package,331,342,"def get_package(self, id):                self.c.execute(            ""SELECT name,folder,site,password,queue,packageorder FROM packages WHERE id=?"",            (str(id),),        )        r = self.c.fetchone()        if not r:            return None        return PyPackage(self.pyload.files, id, *r)",return package instance from id.,"def get_package(self, id):        """"""        return package instance from id.        """"""        self.c.execute(            ""SELECT name,folder,site,password,queue,packageorder FROM packages WHERE id=?"",            (str(id),),        )        r = self.c.fetchone()        if not r:            return None        return PyPackage(self.pyload.files, id, *r)

return package instance from id.",3e795521-7629-4792-b666-ac282443c8fd
database,file_database.py,get_file,346,357,"def get_file(self, id):                self.c.execute(            ""SELECT url, name, size, status, error, plugin, package, linkorder FROM links WHERE id=?"",            (str(id),),        )        r = self.c.fetchone()        if not r:            return None        return PyFile(self.pyload.files, id, *r)",return link instance from id.,"def get_file(self, id):        """"""        return link instance from id.        """"""        self.c.execute(            ""SELECT url, name, size, status, error, plugin, package, linkorder FROM links WHERE id=?"",            (str(id),),        )        r = self.c.fetchone()        if not r:            return None        return PyFile(self.pyload.files, id, *r)

return link instance from id.",2cc5f471-1b05-46f9-8a5d-eff449eed5cf
database,file_database.py,get_job,360,380,"def get_job(self, occupied):                # TODO: improve this hardcoded method        # plugins which are processed in collector        pre = (""DLC"", ""TXT"", ""CCF"", ""RSDF"")        self.c.execute(            f,            occupied + pre,        )        return [x[0] for x in self.c]","return pyfile ids, which are suitable for download and don't use an occupied
plugin.","def get_job(self, occupied):        """"""        return pyfile ids, which are suitable for download and don't use an occupied        plugin.        """"""        # TODO: improve this hardcoded method        # plugins which are processed in collector        pre = (""DLC"", ""TXT"", ""CCF"", ""RSDF"")        self.c.execute(            f""""""            SELECT l.id FROM links as l            INNER JOIN packages as p ON l.package=p.id            WHERE ((p.queue=1 AND l.plugin NOT IN ({"","".join(""?"" * len(occupied))})) OR l.plugin IN ({"","".join(""?"" * len(pre))})) AND l.status IN (2,3,14)            ORDER BY p.packageorder ASC, l.linkorder ASC            LIMIT 5            """""",            occupied + pre,        )        return [x[0] for x in self.c]

return pyfile ids, which are suitable for download and don't use an occupied
plugin.",0170a85a-784d-434f-b0b1-c91db524936a
database,file_database.py,get_plugin_job,383,397,"def get_plugin_job(self, plugins):                self.c.execute(            f,            plugins,        )        return [x[0] for x in self.c]",returns pyfile ids with suited plugins.,"def get_plugin_job(self, plugins):        """"""        returns pyfile ids with suited plugins.        """"""        self.c.execute(            f""""""            SELECT l.id FROM links as l            INNER JOIN packages as p ON l.package=p.id            WHERE l.plugin IN ({"","".join(""?"" * len(plugins))}) AND l.status IN (2,3,14)            ORDER BY p.packageorder ASC, l.linkorder ASC LIMIT 5            """""",            plugins,        )        return [x[0] for x in self.c]

returns pyfile ids with suited plugins.",e28f18a8-4300-4947-bf0b-007daa66f4a3
database,file_database.py,get_unfinished,400,409,"def get_unfinished(self, pid):                self.c.execute(            ""SELECT id FROM links WHERE package=? AND status NOT IN (0, 4, 13) LIMIT 3"",            (str(pid),),        )        return [r[0] for r in self.c]","return list of max length 3 ids with pyfiles in package not finished or
processed.","def get_unfinished(self, pid):        """"""        return list of max length 3 ids with pyfiles in package not finished or        processed.        """"""        self.c.execute(            ""SELECT id FROM links WHERE package=? AND status NOT IN (0, 4, 13) LIMIT 3"",            (str(pid),),        )        return [r[0] for r in self.c]

return list of max length 3 ids with pyfiles in package not finished or
processed.",d3daff37-6f45-402a-b48d-45f5125e5e80
database,file_database.py,delete_finished,412,416,"def delete_finished(self):        self.c.execute(""DELETE FROM links WHERE status IN (0,4)"")        self.c.execute(            ""DELETE FROM packages WHERE NOT EXISTS(SELECT 1 FROM links WHERE packages.id=links.package)""        )",,"def delete_finished(self):        self.c.execute(""DELETE FROM links WHERE status IN (0,4)"")        self.c.execute(            ""DELETE FROM packages WHERE NOT EXISTS(SELECT 1 FROM links WHERE packages.id=links.package)""        )",b14d623c-738b-496f-98af-9e61da73f3eb
database,file_database.py,restart_failed,419,420,"def restart_failed(self):        self.c.execute(""UPDATE links SET status=3,error='' WHERE status IN (6, 8, 9)"")",,"def restart_failed(self):        self.c.execute(""UPDATE links SET status=3,error='' WHERE status IN (6, 8, 9)"")",796ead45-5bab-4c9f-9b35-4123c584a95f
database,file_database.py,find_duplicates,423,431,"def find_duplicates(self, id, folder, filename):                self.c.execute(            ""SELECT l.plugin FROM links as l INNER JOIN packages as p ON l.package=p.id AND p.folder=? WHERE l.id!=? AND l.status=0 AND l.name=?"",            (folder, id, filename),        )        return self.c.fetchone()",checks if filename exists with different id and same package.,"def find_duplicates(self, id, folder, filename):        """"""        checks if filename exists with different id and same package.        """"""        self.c.execute(            ""SELECT l.plugin FROM links as l INNER JOIN packages as p ON l.package=p.id AND p.folder=? WHERE l.id!=? AND l.status=0 AND l.name=?"",            (folder, id, filename),        )        return self.c.fetchone()

checks if filename exists with different id and same package.",7a64e44e-3760-45a0-9879-c742bb5ae168
database,file_database.py,purge_links,434,436,"def purge_links(self):        self.c.execute(""DELETE FROM links;"")        self.c.execute(""DELETE FROM packages;"")",,"def purge_links(self):        self.c.execute(""DELETE FROM links;"")        self.c.execute(""DELETE FROM packages;"")",2aceee4a-fd4b-48c8-9009-26e36c4651a9
database,storage_database.py,set_storage,8,21,"def set_storage(self, identifier, key, value):        self.c.execute(            ""SELECT id FROM storage WHERE identifier=? AND key=?"", (identifier, key)        )        if self.c.fetchone() is not None:            self.c.execute(                ""UPDATE storage SET value=? WHERE identifier=? AND key=?"",                (value, identifier, key),            )        else:            self.c.execute(                ""INSERT INTO storage (identifier, key, value) VALUES (?, ?, ?)"",                (identifier, key, value),            )",,"def set_storage(self, identifier, key, value):        self.c.execute(            ""SELECT id FROM storage WHERE identifier=? AND key=?"", (identifier, key)        )        if self.c.fetchone() is not None:            self.c.execute(                ""UPDATE storage SET value=? WHERE identifier=? AND key=?"",                (value, identifier, key),            )        else:            self.c.execute(                ""INSERT INTO storage (identifier, key, value) VALUES (?, ?, ?)"",                (identifier, key, value),            )",dcd11baf-bbd9-46ec-ae16-a6fa2f609a47
database,storage_database.py,get_storage,24,40,"def get_storage(self, identifier, key=None):        if key is not None:            self.c.execute(                ""SELECT value FROM storage WHERE identifier=? AND key=?"",                (identifier, key),            )            row = self.c.fetchone()            if row is not None:                return row[0]        else:            self.c.execute(                ""SELECT key, value FROM storage WHERE identifier=?"", (identifier,)            )            d = {}            for row in self.c:                d[row[0]] = row[1]            return d",,"def get_storage(self, identifier, key=None):        if key is not None:            self.c.execute(                ""SELECT value FROM storage WHERE identifier=? AND key=?"",                (identifier, key),            )            row = self.c.fetchone()            if row is not None:                return row[0]        else:            self.c.execute(                ""SELECT key, value FROM storage WHERE identifier=?"", (identifier,)            )            d = {}            for row in self.c:                d[row[0]] = row[1]            return d",26c19671-0cb3-4909-ad04-d02c8d4b9280
database,storage_database.py,del_storage,43,46,"def del_storage(self, identifier, key):        self.c.execute(            ""DELETE FROM storage WHERE identifier=? AND key=?"", (identifier, key)        )",,"def del_storage(self, identifier, key):        self.c.execute(            ""DELETE FROM storage WHERE identifier=? AND key=?"", (identifier, key)        )",eca31113-2652-4312-91ef-a5aae297e68d
database,user_database.py,_salted_password,10,12,"def _salted_password(password, salt):    dk = hashlib.pbkdf2_hmac(""sha256"", password.encode(), bytes.fromhex(salt), 100000)    return salt + dk.hex()",,"def _salted_password(password, salt):    dk = hashlib.pbkdf2_hmac(""sha256"", password.encode(), bytes.fromhex(salt), 100000)    return salt + dk.hex()",18c0482d-55d6-4b77-9501-fde53a4f2f14
database,user_database.py,_gensalt,15,16,def _gensalt():    return os.urandom(16).hex(),,def _gensalt():    return os.urandom(16).hex(),d92e0c76-3ea0-4483-89be-8d6b4e2a468f
database,user_database.py,_check_password,19,23,"def _check_password(hashed, clear):    salt = hashed[:32]    to_compare = _salted_password(clear, salt)    return hashed == to_compare",,"def _check_password(hashed, clear):    salt = hashed[:32]    to_compare = _salted_password(clear, salt)    return hashed == to_compare",2939aa58-ef0c-4c36-9245-283f1ce44b9c
database,user_database.py,check_auth,28,48,"def check_auth(self, user, password):        self.c.execute(            ""SELECT id, name, password, role, permission, template, email FROM users WHERE name=?"",            (user,),        )        r = self.c.fetchone()        if not r:            return {}        stored_password = r[2]        if not _check_password(stored_password, password):            return {}        return {            ""id"": r[0],            ""name"": r[1],            ""role"": r[3],            ""permission"": r[4],            ""template"": r[5],            ""email"": r[6],        }",,"def check_auth(self, user, password):        self.c.execute(            ""SELECT id, name, password, role, permission, template, email FROM users WHERE name=?"",            (user,),        )        r = self.c.fetchone()        if not r:            return {}        stored_password = r[2]        if not _check_password(stored_password, password):            return {}        return {            ""id"": r[0],            ""name"": r[1],            ""role"": r[3],            ""permission"": r[4],            ""template"": r[5],            ""email"": r[6],        }",5fc2021f-0486-44be-8dec-7a1f4b4f3382
database,user_database.py,add_user,51,69,"def add_user(self, user, password, role=0, perms=0, reset=False):        salt_pw = _salted_password(password, _gensalt())        self.c.execute(""SELECT name FROM users WHERE name=?"", (user,))        if self.c.fetchone() is not None:            if reset:                self.c.execute(                    ""UPDATE users SET password=?, role=?, permission=? WHERE name=?"",                    (salt_pw, role, perms, user),                )                return True            else:                return False        else:            self.c.execute(                ""INSERT INTO users (name, password, role, permission) VALUES (?, ?, ?, ?)"",                (user, salt_pw, role, perms),            )            return True",,"def add_user(self, user, password, role=0, perms=0, reset=False):        salt_pw = _salted_password(password, _gensalt())        self.c.execute(""SELECT name FROM users WHERE name=?"", (user,))        if self.c.fetchone() is not None:            if reset:                self.c.execute(                    ""UPDATE users SET password=?, role=?, permission=? WHERE name=?"",                    (salt_pw, role, perms, user),                )                return True            else:                return False        else:            self.c.execute(                ""INSERT INTO users (name, password, role, permission) VALUES (?, ?, ?, ?)"",                (user, salt_pw, role, perms),            )            return True",20c91911-b8f8-4948-9e57-802455743a28
database,user_database.py,change_password,72,85,"def change_password(self, user, old_password, new_password):        self.c.execute(""SELECT id, name, password FROM users WHERE name=?"", (user,))        r = self.c.fetchone()        if not r:            return False        stored_password = r[2]        if not _check_password(stored_password, old_password):            return False        newpw = _salted_password(new_password, _gensalt())        self.c.execute(""UPDATE users SET password=? WHERE name=?"", (newpw, user))        return True",,"def change_password(self, user, old_password, new_password):        self.c.execute(""SELECT id, name, password FROM users WHERE name=?"", (user,))        r = self.c.fetchone()        if not r:            return False        stored_password = r[2]        if not _check_password(stored_password, old_password):            return False        newpw = _salted_password(new_password, _gensalt())        self.c.execute(""UPDATE users SET password=? WHERE name=?"", (newpw, user))        return True",9a89d60a-7ef5-4cd9-924a-734073b48775
database,user_database.py,set_permission,88,89,"def set_permission(self, user, perms):        self.c.execute(""UPDATE users SET permission=? WHERE name=?"", (perms, user))",,"def set_permission(self, user, perms):        self.c.execute(""UPDATE users SET permission=? WHERE name=?"", (perms, user))",8ffc1d58-e800-4bc0-a3bb-eec61ddf10c1
database,user_database.py,set_role,92,93,"def set_role(self, user, role):        self.c.execute(""UPDATE users SET role=? WHERE name=?"", (role, user))",,"def set_role(self, user, role):        self.c.execute(""UPDATE users SET role=? WHERE name=?"", (role, user))",2c5d6307-92f1-420c-83ab-dac4ded6b5e7
database,user_database.py,user_exists,96,98,"def user_exists(self, user):        self.c.execute(""SELECT name FROM users WHERE name=?"", (user,))        return self.c.fetchone() is not None",,"def user_exists(self, user):        self.c.execute(""SELECT name FROM users WHERE name=?"", (user,))        return self.c.fetchone() is not None",235108ad-f699-42e1-8857-e83130f2947c
database,user_database.py,list_users,101,106,"def list_users(self):        self.c.execute(""SELECT name FROM users"")        users = []        for row in self.c:            users.append(row[0])        return users",,"def list_users(self):        self.c.execute(""SELECT name FROM users"")        users = []        for row in self.c:            users.append(row[0])        return users",b117670b-a7e3-479e-944f-f82e96d431e2
database,user_database.py,get_all_user_data,109,121,"def get_all_user_data(self):        self.c.execute(""SELECT id, name, permission, role, template, email FROM users"")        user = {}        for r in self.c:            user[r[0]] = {                ""name"": r[1],                ""permission"": r[2],                ""role"": r[3],                ""template"": r[4],                ""email"": r[5],            }        return user",,"def get_all_user_data(self):        self.c.execute(""SELECT id, name, permission, role, template, email FROM users"")        user = {}        for r in self.c:            user[r[0]] = {                ""name"": r[1],                ""permission"": r[2],                ""role"": r[3],                ""template"": r[4],                ""email"": r[5],            }        return user",d0caf1f8-cb9a-4784-8cd0-5ad08fb25c49
database,user_database.py,remove_user,124,125,"def remove_user(self, user):        self.c.execute(""DELETE FROM users WHERE name=?"", (user,))",,"def remove_user(self, user):        self.c.execute(""DELETE FROM users WHERE name=?"", (user,))",3d13b595-c30d-4a1e-afb2-a956bffbe404
datatypes,data.py,__getitem__,9,10,"def __getitem__(self, name):        return getattr(self, name)",,"def __getitem__(self, name):        return getattr(self, name)",9d0dfafc-5f7a-435e-821a-3283f52125a3
datatypes,data.py,__setitem__,12,13,"def __setitem__(self, name, value):        return setattr(self, name, value)",,"def __setitem__(self, name, value):        return setattr(self, name, value)",780d3b71-bfc0-41ce-aa64-458960ad09fc
datatypes,data.py,__iter__,15,17,def __iter__(self):        for attr in self.__slots__:            yield attr,,def __iter__(self):        for attr in self.__slots__:            yield attr,a22afea9-7f50-4051-a508-df5dc861baf3
datatypes,data.py,__len__,19,20,def __len__(self):        return len(self.__slots__),,def __len__(self):        return len(self.__slots__),4811ddb2-edc5-4c5b-9751-68d6a018aef0
datatypes,data.py,__init__,34,50,"def __init__(        self,        validuntil=None,        login=None,        options=None,        valid=None,        trafficleft=None,        premium=None,        type=None,    ):        self.validuntil = validuntil        self.login = login        self.options = options        self.valid = valid        self.trafficleft = trafficleft        self.premium = premium        self.type = type",,"def __init__(        self,        validuntil=None,        login=None,        options=None,        valid=None,        trafficleft=None,        premium=None,        type=None,    ):        self.validuntil = validuntil        self.login = login        self.options = options        self.valid = valid        self.trafficleft = trafficleft        self.premium = premium        self.type = type",42d517ce-731d-4da8-89c9-ce08afd6358b
datatypes,data.py,__init__,56,60,"def __init__(self, tid=None, data=None, type=None, result_type=None):        self.tid = tid        self.data = data        self.type = type        self.result_type = result_type",,"def __init__(self, tid=None, data=None, type=None, result_type=None):        self.tid = tid        self.data = data        self.type = type        self.result_type = result_type",f98be1dc-253f-44e3-a84a-cdc1fc3b2ec0
datatypes,data.py,__init__,66,70,"def __init__(self, name=None, description=None, value=None, type=None):        self.name = name        self.description = description        self.value = value        self.type = type",,"def __init__(self, name=None, description=None, value=None, type=None):        self.name = name        self.description = description        self.value = value        self.type = type",2f3b70b2-0c4f-4920-a2c3-0b90c5a3b4bc
datatypes,data.py,__init__,76,80,"def __init__(self, name=None, description=None, items=None, outline=None):        self.name = name        self.description = description        self.items = items        self.outline = outline",,"def __init__(self, name=None, description=None, items=None, outline=None):        self.name = name        self.description = description        self.items = items        self.outline = outline",708364a8-e4d2-480a-a5ac-4c6eafa4ab0e
datatypes,data.py,__init__,104,140,"def __init__(        self,        fid=None,        name=None,        speed=None,        eta=None,        format_eta=None,        bleft=None,        size=None,        format_size=None,        percent=None,        status=None,        statusmsg=None,        format_wait=None,        wait_until=None,        package_id=None,        package_name=None,        plugin=None,        info=None,    ):        self.fid = fid        self.name = name        self.speed = speed        self.eta = eta        self.format_eta = format_eta        self.bleft = bleft        self.size = size        self.format_size = format_size        self.percent = percent        self.status = status        self.statusmsg = statusmsg        self.format_wait = format_wait        self.wait_until = wait_until        self.package_id = package_id        self.package_name = package_name        self.plugin = plugin        self.info = info",,"def __init__(        self,        fid=None,        name=None,        speed=None,        eta=None,        format_eta=None,        bleft=None,        size=None,        format_size=None,        percent=None,        status=None,        statusmsg=None,        format_wait=None,        wait_until=None,        package_id=None,        package_name=None,        plugin=None,        info=None,    ):        self.fid = fid        self.name = name        self.speed = speed        self.eta = eta        self.format_eta = format_eta        self.bleft = bleft        self.size = size        self.format_size = format_size        self.percent = percent        self.status = status        self.statusmsg = statusmsg        self.format_wait = format_wait        self.wait_until = wait_until        self.package_id = package_id        self.package_name = package_name        self.plugin = plugin        self.info = info",3331106f-1a67-465a-9dd5-4b2bb368cdd8
datatypes,data.py,__init__,146,150,"def __init__(self, eventname=None, id=None, type=None, destination=None):        self.eventname = eventname        self.id = id        self.type = type        self.destination = destination",,"def __init__(self, eventname=None, id=None, type=None, destination=None):        self.eventname = eventname        self.id = id        self.type = type        self.destination = destination",40605e82-0a19-4062-84f1-e492e6551a1b
datatypes,data.py,__init__,168,192,"def __init__(        self,        fid=None,        url=None,        name=None,        plugin=None,        size=None,        format_size=None,        status=None,        statusmsg=None,        package_id=None,        error=None,        order=None,    ):        self.fid = fid        self.url = url        self.name = name        self.plugin = plugin        self.size = size        self.format_size = format_size        self.status = status        self.statusmsg = statusmsg        self.package_id = package_id        self.error = error        self.order = order",,"def __init__(        self,        fid=None,        url=None,        name=None,        plugin=None,        size=None,        format_size=None,        status=None,        statusmsg=None,        package_id=None,        error=None,        order=None,    ):        self.fid = fid        self.url = url        self.name = name        self.plugin = plugin        self.size = size        self.format_size = format_size        self.status = status        self.statusmsg = statusmsg        self.package_id = package_id        self.error = error        self.order = order",7d472dfd-2204-4320-8594-399446ceddaf
datatypes,data.py,__init__,208,228,"def __init__(        self,        iid=None,        input=None,        structure=None,        preset=None,        output=None,        data=None,        title=None,        description=None,        plugin=None,    ):        self.iid = iid        self.input = input        self.structure = structure        self.preset = preset        self.output = output        self.data = data        self.title = title        self.description = description        self.plugin = plugin",,"def __init__(        self,        iid=None,        input=None,        structure=None,        preset=None,        output=None,        data=None,        title=None,        description=None,        plugin=None,    ):        self.iid = iid        self.input = input        self.structure = structure        self.preset = preset        self.output = output        self.data = data        self.title = title        self.description = description        self.plugin = plugin",40cdccf6-4195-4e0a-b3fd-4d390e54eea0
datatypes,data.py,__init__,234,236,"def __init__(self, rid=None, data=None):        self.rid = rid        self.data = data",,"def __init__(self, rid=None, data=None):        self.rid = rid        self.data = data",4abe6ff2-0553-4d62-a903-3affbd7f9689
datatypes,data.py,__init__,242,249,"def __init__(        self, name=None, plugin=None, packagename=None, status=None, size=None    ):        self.name = name        self.plugin = plugin        self.packagename = packagename        self.status = status        self.size = size",,"def __init__(        self, name=None, plugin=None, packagename=None, status=None, size=None    ):        self.name = name        self.plugin = plugin        self.packagename = packagename        self.status = status        self.size = size",cb888678-45b0-46aa-bc3e-3185f329935b
datatypes,data.py,__init__,269,297,"def __init__(        self,        pid=None,        name=None,        folder=None,        site=None,        password=None,        dest=None,        order=None,        linksdone=None,        sizedone=None,        sizetotal=None,        linkstotal=None,        links=None,        fids=None,    ):        self.pid = pid        self.name = name        self.folder = folder        self.site = site        self.password = password        self.dest = dest        self.order = order        self.linksdone = linksdone        self.sizedone = sizedone        self.sizetotal = sizetotal        self.linkstotal = linkstotal        self.links = links        self.fids = fids",,"def __init__(        self,        pid=None,        name=None,        folder=None,        site=None,        password=None,        dest=None,        order=None,        linksdone=None,        sizedone=None,        sizetotal=None,        linkstotal=None,        links=None,        fids=None,    ):        self.pid = pid        self.name = name        self.folder = folder        self.site = site        self.password = password        self.dest = dest        self.order = order        self.linksdone = linksdone        self.sizedone = sizedone        self.sizetotal = sizetotal        self.linkstotal = linkstotal        self.links = links        self.fids = fids",e90573a7-b2bc-4e63-99f1-5cc921c9f229
datatypes,data.py,__init__,312,330,"def __init__(        self,        pause=None,        active=None,        queue=None,        total=None,        speed=None,        download=None,        reconnect=None,        captcha=None,    ):        self.pause = pause        self.active = active        self.queue = queue        self.total = total        self.speed = speed        self.download = download        self.reconnect = reconnect        self.captcha = captcha",,"def __init__(        self,        pause=None,        active=None,        queue=None,        total=None,        speed=None,        download=None,        reconnect=None,        captcha=None,    ):        self.pause = pause        self.active = active        self.queue = queue        self.total = total        self.speed = speed        self.download = download        self.reconnect = reconnect        self.captcha = captcha",a4e7723c-60cf-4117-9575-a9f5628efb30
datatypes,data.py,__init__,336,340,"def __init__(self, plugin=None, func=None, arguments=None, parse_arguments=None):        self.plugin = plugin        self.func = func        self.arguments = arguments        self.parse_arguments = parse_arguments",,"def __init__(self, plugin=None, func=None, arguments=None, parse_arguments=None):        self.plugin = plugin        self.func = func        self.arguments = arguments        self.parse_arguments = parse_arguments",93aa9393-2a6e-4e49-98a7-b4b7b9df8334
datatypes,data.py,__init__,347,354,"def __init__(        self, name=None, email=None, role=None, permission=None, template_name=None    ):        self.name = name        self.email = email        self.role = role        self.permission = permission        self.template_name = template_name",,"def __init__(        self, name=None, email=None, role=None, permission=None, template_name=None    ):        self.name = name        self.email = email        self.role = role        self.permission = permission        self.template_name = template_name",0bff08d2-ba45-4bd7-b7a9-bafdfabafb67
datatypes,data.py,__init__,360,368,"def __init__(        self, id=None, name=None, email=None, role=None, permission=None, template=None    ):        self.id = id        self.name = name        self.email = email        self.role = role        self.permission = permission        self.template = template",,"def __init__(        self, id=None, name=None, email=None, role=None, permission=None, template=None    ):        self.id = id        self.name = name        self.email = email        self.role = role        self.permission = permission        self.template = template",9109a329-3661-41c6-a9a4-7d0caac15026
datatypes,exceptions.py,__init__,7,8,"def __init__(self, fid=None):        self.fid = fid",,"def __init__(self, fid=None):        self.fid = fid",23ca87be-ab7e-41cc-8e00-7a8372d1cff2
datatypes,exceptions.py,__init__,14,15,"def __init__(self, pid=None):        self.pid = pid",,"def __init__(self, pid=None):        self.pid = pid",135cfe70-51cc-42f5-8202-6f82e4b37ea7
datatypes,exceptions.py,__init__,21,23,"def __init__(self, plugin=None, func=None):        self.plugin = plugin        self.func = func",,"def __init__(self, plugin=None, func=None):        self.plugin = plugin        self.func = func",69623413-775a-4b57-803e-b2224ef5b140
datatypes,exceptions.py,__init__,29,30,"def __init__(self, msg=None):        self.msg = msg",,"def __init__(self, msg=None):        self.msg = msg",a5fddd33-c0c7-40d9-b491-6448590e8d1e
datatypes,pyfile.py,_set_size,29,30,"def _set_size(self, value):    self._size = int(value)",,"def _set_size(self, value):    self._size = int(value)",b593c9f6-8d4b-4466-b9a9-d9358c2886fb
datatypes,pyfile.py,_set_name,33,34,"def _set_name(self, value):    self._name = purge.name(value, sep="""")",,"def _set_name(self, value):    self._name = purge.name(value, sep="""")",00f953eb-9adc-4603-b788-ff9bbc64ff2a
datatypes,pyfile.py,__init__,42,78,"def __init__(        self, manager, id, url, name, size, status, error, pluginname, package, order    ):        self.m = self.manager = manager        self.m.cache[int(id)] = self        self.id = int(id)        self.url = url        self._name = None        self.name = name        self._size = None        self.size = size        self.status = status        self.pluginname = pluginname        self.packageid = package  #: should not be used, use package() instead        self.error = error        self.order = order        # database information ends here        self.lock = RLock()        self.plugin = None        # self.download = None        self.wait_until = 0  #: time.time() + time to wait        # status attributes        self.active = False  #: obsolete?        self.abort = False        self.reconnected = False        self.statusname = None        self.progress = 0        self.maxprogress = 100",,"def __init__(        self, manager, id, url, name, size, status, error, pluginname, package, order    ):        self.m = self.manager = manager        self.m.cache[int(id)] = self        self.id = int(id)        self.url = url        self._name = None        self.name = name        self._size = None        self.size = size        self.status = status        self.pluginname = pluginname        self.packageid = package  #: should not be used, use package() instead        self.error = error        self.order = order        # database information ends here        self.lock = RLock()        self.plugin = None        # self.download = None        self.wait_until = 0  #: time.time() + time to wait        # status attributes        self.active = False  #: obsolete?        self.abort = False        self.reconnected = False        self.statusname = None        self.progress = 0        self.maxprogress = 100",c3b68be3-6996-4b46-8d77-61d28fdb44f5
datatypes,pyfile.py,__repr__,86,87,"def __repr__(self):        return f""PyFile {self.id}: {self.name}@{self.pluginname}""",,"def __repr__(self):        return f""PyFile {self.id}: {self.name}@{self.pluginname}""",5cdc5bc6-d7e8-469e-be67-324b1743f6f0
datatypes,pyfile.py,init_plugin,90,100,"def init_plugin(self):                if not self.plugin:            self.pluginmodule = self.m.pyload.plugin_manager.get_plugin(self.pluginname)            self.pluginclass = getattr(                self.pluginmodule,                self.m.pyload.plugin_manager.get_plugin_name(self.pluginname),            )            self.plugin = self.pluginclass(self)",inits plugin instance.,"def init_plugin(self):        """"""        inits plugin instance.        """"""        if not self.plugin:            self.pluginmodule = self.m.pyload.plugin_manager.get_plugin(self.pluginname)            self.pluginclass = getattr(                self.pluginmodule,                self.m.pyload.plugin_manager.get_plugin_name(self.pluginname),            )            self.plugin = self.pluginclass(self)

inits plugin instance.",2275c4be-d93a-49dd-8c11-93b369d6c18d
datatypes,pyfile.py,has_plugin,103,109,"def has_plugin(self):                return hasattr(self, ""plugin"") and self.plugin","Thread safe way to determine this file has initialized plugin attribute.

:return:","def has_plugin(self):        """"""        Thread safe way to determine this file has initialized plugin attribute.        :return:        """"""        return hasattr(self, ""plugin"") and self.plugin

Thread safe way to determine this file has initialized plugin attribute.

:return:",58ccc1c8-9c80-44b6-a826-f344a5b64d13
datatypes,pyfile.py,package,111,115,def package(self):                return self.m.get_package(self.packageid),return package instance.,"def package(self):        """"""        return package instance.        """"""        return self.m.get_package(self.packageid)

return package instance.",ede17349-e6d0-4b76-a8a2-0e8cd4ee5836
datatypes,pyfile.py,set_status,117,119,"def set_status(self, status):        self.status = status_map[status]        self.sync()",,"def set_status(self, status):        self.status = status_map[status]        self.sync()",dcf98c5e-c8cc-4a4d-b54e-9c652bd575ff
datatypes,pyfile.py,set_custom_status,121,123,"def set_custom_status(self, msg, status=""processing""):        self.statusname = msg        self.set_status(status)",,"def set_custom_status(self, msg, status=""processing""):        self.statusname = msg        self.set_status(status)",f8ef168a-3315-4b9b-8682-a20efa2e7ffa
datatypes,pyfile.py,get_status_name,125,129,"def get_status_name(self):        if self.status not in (13, 14) or not self.statusname:            return self.m.status_msg[self.status]        else:            return self.statusname",,"def get_status_name(self):        if self.status not in (13, 14) or not self.statusname:            return self.m.status_msg[self.status]        else:            return self.statusname",bfdc505e-035b-4027-b430-df6b90584992
datatypes,pyfile.py,has_status,131,132,"def has_status(self, status):        return status_map[status] == self.status",,"def has_status(self, status):        return status_map[status] == self.status",097f850b-b2e5-491b-8266-c36667e77bd5
datatypes,pyfile.py,sync,134,138,def sync(self):                self.m.update_link(self),sync PyFile instance with database.,"def sync(self):        """"""        sync PyFile instance with database.        """"""        self.m.update_link(self)

sync PyFile instance with database.",aee7cb77-eab0-4367-915c-5729c48b9d66
datatypes,pyfile.py,release,141,153,"def release(self):                # file has valid package        if self.packageid > 0:            self.sync()        if hasattr(self, ""plugin"") and self.plugin:            self.plugin.clean()            del self.plugin        self.m.release_link(self.id)",sync and remove from cache.,"def release(self):        """"""        sync and remove from cache.        """"""        # file has valid package        if self.packageid > 0:            self.sync()        if hasattr(self, ""plugin"") and self.plugin:            self.plugin.clean()            del self.plugin        self.m.release_link(self.id)

sync and remove from cache.",5a3a123d-aa1d-4bf8-940a-d700468d576a
datatypes,pyfile.py,delete,155,159,def delete(self):                self.m.delete_link(self.id),delete pyfile from database.,"def delete(self):        """"""        delete pyfile from database.        """"""        self.m.delete_link(self.id)

delete pyfile from database.",ac3c7bbe-cb97-4f09-9ea6-08b8d501b3c8
datatypes,pyfile.py,to_dict,161,165,def to_dict(self):                return self.to_db_dict(),return dict with all information for interface.,"def to_dict(self):        """"""        return dict with all information for interface.        """"""        return self.to_db_dict()

return dict with all information for interface.",2bf9d6ca-c252-485b-89fe-d4bac40c67ac
datatypes,pyfile.py,to_db_dict,167,191,"def to_db_dict(self):                return {            self.id: {                ""id"": self.id,                ""url"": self.url,                ""name"": self.name,                ""plugin"": self.pluginname,                ""size"": self.get_size(),                ""format_size"": self.format_size(),                ""status"": self.status,                ""statusmsg"": self.get_status_name(),                ""package"": self.packageid,                ""error"": self.error,                ""order"": self.order,            }        }","return data as dict for databse.

format:

{
    id: {'url': url, 'name': name ... }
}","def to_db_dict(self):        """"""        return data as dict for databse.        format:        {            id: {'url': url, 'name': name ... }        }        """"""        return {            self.id: {                ""id"": self.id,                ""url"": self.url,                ""name"": self.name,                ""plugin"": self.pluginname,                ""size"": self.get_size(),                ""format_size"": self.format_size(),                ""status"": self.status,                ""statusmsg"": self.get_status_name(),                ""package"": self.packageid,                ""error"": self.error,                ""order"": self.order,            }        }

return data as dict for databse.

format:

{
    id: {'url': url, 'name': name ... }
}",64509ced-7fd0-4fe1-8b53-ac7bf977b49b
datatypes,pyfile.py,abort_download,193,207,def abort_download(self):                while self.id in self.m.pyload.thread_manager.processing_ids():            self.abort = True            if self.plugin and self.plugin.req:                self.plugin.req.abort_downloads()            time.sleep(0.1)        self.abort = False        if self.has_plugin() and self.plugin.req:            self.plugin.req.abort_downloads()        self.release(),abort pyfile if possible.,"def abort_download(self):        """"""        abort pyfile if possible.        """"""        while self.id in self.m.pyload.thread_manager.processing_ids():            self.abort = True            if self.plugin and self.plugin.req:                self.plugin.req.abort_downloads()            time.sleep(0.1)        self.abort = False        if self.has_plugin() and self.plugin.req:            self.plugin.req.abort_downloads()        self.release()

abort pyfile if possible.",b292a309-5a63-43ec-a07d-aeb931d51142
datatypes,pyfile.py,finish_if_done,209,219,"def finish_if_done(self):                if self.id in self.m.pyload.thread_manager.processing_ids():            return False        self.set_status(""finished"")        self.release()        self.m.check_all_links_finished()        return True",set status to finish and release file if every thread is finished with it.,"def finish_if_done(self):        """"""        set status to finish and release file if every thread is finished with it.        """"""        if self.id in self.m.pyload.thread_manager.processing_ids():            return False        self.set_status(""finished"")        self.release()        self.m.check_all_links_finished()        return True

set status to finish and release file if every thread is finished with it.",92b63156-f5df-4073-93f9-9305fc3d7ddd
datatypes,pyfile.py,check_if_processed,221,222,def check_if_processed(self):        self.m.check_all_links_processed(self.id),,def check_if_processed(self):        self.m.check_all_links_processed(self.id),2999fa54-45d7-4873-b35b-8eb988311ae6
datatypes,pyfile.py,format_wait,224,229,"def format_wait(self):                seconds = int(self.wait_until - time.time())        return format.time(seconds, literally=False)",formats and return wait time in human readable format.,"def format_wait(self):        """"""        formats and return wait time in human readable format.        """"""        seconds = int(self.wait_until - time.time())        return format.time(seconds, literally=False)

formats and return wait time in human readable format.",68622c14-ff2f-4fde-865f-4fdc1c7ff1c9
datatypes,pyfile.py,format_size,231,235,def format_size(self):                return format.size(self.get_size()),formats size to readable format.,"def format_size(self):        """"""        formats size to readable format.        """"""        return format.size(self.get_size())

formats size to readable format.",42b1604c-2b0c-4f97-90ba-e1d5ff2a5251
datatypes,pyfile.py,format_eta,237,242,"def format_eta(self):                seconds = self.get_eta()        return format.time(seconds, literally=False)",formats eta to readable format.,"def format_eta(self):        """"""        formats eta to readable format.        """"""        seconds = self.get_eta()        return format.time(seconds, literally=False)

formats eta to readable format.",2293674d-f61b-488c-9ca0-22f5e599c953
datatypes,pyfile.py,get_speed,244,251,def get_speed(self):                try:            return self.plugin.req.speed        except Exception:            return 0,calculates speed.,"def get_speed(self):        """"""        calculates speed.        """"""        try:            return self.plugin.req.speed        except Exception:            return 0

calculates speed.",d8f28719-114a-4aec-84a5-6df724486f4f
datatypes,pyfile.py,get_eta,253,260,def get_eta(self):                try:            return int(self.get_bytes_left() // self.get_speed())        except ZeroDivisionError:            return 0,gets established time of arrival.,"def get_eta(self):        """"""        gets established time of arrival.        """"""        try:            return int(self.get_bytes_left() // self.get_speed())        except ZeroDivisionError:            return 0

gets established time of arrival.",8c14296b-67ae-47c4-b3fb-36c97de06bd1
datatypes,pyfile.py,get_bytes_left,262,269,"def get_bytes_left(self):                try:            return max(self.get_size() - self.plugin.req.arrived, 0)        except Exception:            return 0",gets bytes left.,"def get_bytes_left(self):        """"""        gets bytes left.        """"""        try:            return max(self.get_size() - self.plugin.req.arrived, 0)        except Exception:            return 0

gets bytes left.",83e6d060-7881-4971-8b07-9556fa91fdc4
datatypes,pyfile.py,get_percent,271,281,def get_percent(self):                if self.status == 12:            try:                return self.plugin.req.percent            except Exception:                return 0        else:            return self.progress,get % of download.,"def get_percent(self):        """"""        get % of download.        """"""        if self.status == 12:            try:                return self.plugin.req.percent            except Exception:                return 0        else:            return self.progress

get % of download.",fb105228-a9bb-4c21-b113-46d1b2c579bb
datatypes,pyfile.py,get_size,283,293,def get_size(self):                try:            if self.plugin.req.size:                return self.plugin.req.size            else:                return self.size        except Exception:            return self.size,get size of download.,"def get_size(self):        """"""        get size of download.        """"""        try:            if self.plugin.req.size:                return self.plugin.req.size            else:                return self.size        except Exception:            return self.size

get size of download.",3ee57286-6b90-41f4-9c18-edbc0b7beb58
datatypes,pyfile.py,notify_change,295,299,"def notify_change(self):        e = UpdateEvent(            ""file"", self.id, ""collector"" if not self.package().queue else ""queue""        )        self.m.pyload.event_manager.add_event(e)",,"def notify_change(self):        e = UpdateEvent(            ""file"", self.id, ""collector"" if not self.package().queue else ""queue""        )        self.m.pyload.event_manager.add_event(e)",75943d19-7e9f-487d-a386-c3dbc521a353
datatypes,pyfile.py,set_progress,301,304,"def set_progress(self, value):        if value != self.progress:            self.progress = value            self.notify_change()",,"def set_progress(self, value):        if value != self.progress:            self.progress = value            self.notify_change()",2bb6708e-4c86-46ba-946a-bf06ec278117
datatypes,pyfile.py,set_name,306,309,"def set_name(self, value):        if value != self.name:            self.name = value            self.notify_change()",,"def set_name(self, value):        if value != self.name:            self.name = value            self.notify_change()",27d7d626-68ba-4105-98a0-089d9f7e60c2
datatypes,pypackage.py,__init__,13,24,"def __init__(self, manager, id, name, folder, site, password, queue, order):        self.m = self.manager = manager        self.m.package_cache[int(id)] = self        self.id = int(id)        self.name = name        self._folder = folder        self.site = site        self.password = password        self.queue = queue        self.order = order        self.set_finished = False",,"def __init__(self, manager, id, name, folder, site, password, queue, order):        self.m = self.manager = manager        self.m.package_cache[int(id)] = self        self.id = int(id)        self.name = name        self._folder = folder        self.site = site        self.password = password        self.queue = queue        self.order = order        self.set_finished = False",2dd19106-69d3-4260-8194-2fb054ed79ef
datatypes,pypackage.py,folder,27,28,def folder(self):        return safepath(self._folder),,def folder(self):        return safepath(self._folder),7d9be1e3-b2c5-48fc-b115-5d2aff9d4225
datatypes,pypackage.py,to_dict,30,47,"def to_dict(self):                return {            self.id: {                ""id"": self.id,                ""name"": self.name,                ""folder"": self.folder,                ""site"": self.site,                ""password"": self.password,                ""queue"": self.queue,                ""order"": self.order,                ""links"": {},            }        }","Returns a dictionary representation of the data.

:return: dict: {id: { attr: value }}","def to_dict(self):        """"""        Returns a dictionary representation of the data.        :return: dict: {id: { attr: value }}        """"""        return {            self.id: {                ""id"": self.id,                ""name"": self.name,                ""folder"": self.folder,                ""site"": self.site,                ""password"": self.password,                ""queue"": self.queue,                ""order"": self.order,                ""links"": {},            }        }

Returns a dictionary representation of the data.

:return: dict: {id: { attr: value }}",10c4c960-b379-496b-80b3-6f9105d9d1f3
datatypes,pypackage.py,get_children,49,53,"def get_children(self):                return self.m.get_package_data(self.id)[""links""]",get information about contained links.,"def get_children(self):        """"""        get information about contained links.        """"""        return self.m.get_package_data(self.id)[""links""]

get information about contained links.",5edd16ab-ef88-4186-8a47-aa878c309d1e
datatypes,pypackage.py,sync,55,59,def sync(self):                self.m.update_package(self),sync with db.,"def sync(self):        """"""        sync with db.        """"""        self.m.update_package(self)

sync with db.",25348e9e-b98b-473a-a2da-576a41775fcd
datatypes,pypackage.py,release,61,66,def release(self):                self.sync()        self.m.release_package(self.id),sync and delete from cache.,"def release(self):        """"""        sync and delete from cache.        """"""        self.sync()        self.m.release_package(self.id)

sync and delete from cache.",b713b016-8bb2-4d15-977c-cc14b6417783
datatypes,pypackage.py,delete,68,69,def delete(self):        self.m.delete_package(self.id),,def delete(self):        self.m.delete_package(self.id),273dff21-8309-40c9-8aaf-3a720109a56e
datatypes,pypackage.py,notify_change,71,73,"def notify_change(self):        e = UpdateEvent(""pack"", self.id, ""collector"" if not self.queue else ""queue"")        self.m.pyload.event_manager.add_event(e)",,"def notify_change(self):        e = UpdateEvent(""pack"", self.id, ""collector"" if not self.queue else ""queue"")        self.m.pyload.event_manager.add_event(e)",287a4480-85f8-49bb-9db4-942f35cdc54b
managers,account_manager.py,__init__,20,35,"def __init__(self, core):                self.pyload = core        self._ = core._        self.lock = Lock()        # TODO: Recheck        configdir = os.path.join(core.userdir, ""settings"")        os.makedirs(configdir, exist_ok=True)        self.configpath = os.path.join(configdir, ""accounts.cfg"")        self.init_plugins()        self.save_accounts()",Constructor.,"def __init__(self, core):        """"""        Constructor.        """"""        self.pyload = core        self._ = core._        self.lock = Lock()        # TODO: Recheck        configdir = os.path.join(core.userdir, ""settings"")        os.makedirs(configdir, exist_ok=True)        self.configpath = os.path.join(configdir, ""accounts.cfg"")        self.init_plugins()        self.save_accounts()

Constructor.",553b05c0-3ef3-409c-9853-0ae328071b21
managers,account_manager.py,init_plugins,37,42,def init_plugins(self):        self.accounts = {}  #: key = ( plugin )        self.plugins = {}        self.init_account_plugins()        self.load_accounts(),,def init_plugins(self):        self.accounts = {}  #: key = ( plugin )        self.plugins = {}        self.init_account_plugins()        self.load_accounts(),7a9c20c5-18d0-40e5-8028-bcbd329480ae
managers,account_manager.py,get_account_plugin,44,60,"def get_account_plugin(self, plugin):                if plugin in self.accounts:            if plugin not in self.plugins:                klass = self.pyload.plugin_manager.load_class(""account"", plugin)                if klass:                    self.plugins[plugin] = klass(self, self.accounts[plugin])                else:                    return None            return self.plugins[plugin]        else:            return None",get account instance for plugin or None if anonymous.,"def get_account_plugin(self, plugin):        """"""        get account instance for plugin or None if anonymous.        """"""        if plugin in self.accounts:            if plugin not in self.plugins:                klass = self.pyload.plugin_manager.load_class(""account"", plugin)                if klass:                    self.plugins[plugin] = klass(self, self.accounts[plugin])                else:                    return None            return self.plugins[plugin]        else:            return None

get account instance for plugin or None if anonymous.",20c4936e-ee6f-4d44-af10-931d46f2f039
managers,account_manager.py,get_account_plugins,62,70,def get_account_plugins(self):                plugins = []        for plugin in self.accounts.keys():            plugins.append(self.get_account_plugin(plugin))        return plugins,get all account instances.,"def get_account_plugins(self):        """"""        get all account instances.        """"""        plugins = []        for plugin in self.accounts.keys():            plugins.append(self.get_account_plugin(plugin))        return plugins

get all account instances.",1baedba4-66d0-4de0-90da-797b9364c8cb
managers,account_manager.py,load_accounts,74,131,"def load_accounts(self):                if not os.path.exists(self.configpath):            with open(self.configpath, mode=""w"") as fp:                fp.write(f""version: {__version__}"")        with open(self.configpath) as fp:            content = fp.readlines()            version = content[0].split("":"")[1].strip() if content else """"        if not version or int(version) < __version__:            shutil.copy(self.configpath, ""accounts.backup"")            with open(self.configpath, mode=""w"") as fp:                fp.write(f""version: {__version__}"")            self.pyload.log.warning(                self._(""Account settings deleted, due to new config format."")            )            return        plugin = """"        name = """"        for line in content[1:]:            line = line.strip()            if not line:                continue            if line.startswith(""#""):                continue            if line.startswith(""version""):                continue            if line.endswith("":"") and line.count("":"") == 1:                plugin = line[:-1]                self.accounts[plugin] = {}            elif line.startswith(""@""):                try:                    option = line[1:].split()                    self.accounts[plugin][name][""options""][option[0]] = (                        []                        if len(option) < 2                        else ([option[1]] if len(option) < 3 else option[1:])                    )                except Exception:                    pass            elif "":"" in line:                name, sep, pw = line.partition("":"")                name = name.replace(r""\x3a"", "":"")                pw = pw.replace(r""\x3a"", "":"")                self.accounts[plugin][name] = {                    ""password"": pw,                    ""options"": {},                    ""valid"": True,                }",loads all accounts available.,"def load_accounts(self):        """"""        loads all accounts available.        """"""        if not os.path.exists(self.configpath):            with open(self.configpath, mode=""w"") as fp:                fp.write(f""version: {__version__}"")        with open(self.configpath) as fp:            content = fp.readlines()            version = content[0].split("":"")[1].strip() if content else """"        if not version or int(version) < __version__:            shutil.copy(self.configpath, ""accounts.backup"")            with open(self.configpath, mode=""w"") as fp:                fp.write(f""version: {__version__}"")            self.pyload.log.warning(                self._(""Account settings deleted, due to new config format."")            )            return        plugin = """"        name = """"        for line in content[1:]:            line = line.strip()            if not line:                continue            if line.startswith(""#""):                continue            if line.startswith(""version""):                continue            if line.endswith("":"") and line.count("":"") == 1:                plugin = line[:-1]                self.accounts[plugin] = {}            elif line.startswith(""@""):                try:                    option = line[1:].split()                    self.accounts[plugin][name][""options""][option[0]] = (                        []                        if len(option) < 2                        else ([option[1]] if len(option) < 3 else option[1:])                    )                except Exception:                    pass            elif "":"" in line:                name, sep, pw = line.partition("":"")                name = name.replace(r""\x3a"", "":"")                pw = pw.replace(r""\x3a"", "":"")                self.accounts[plugin][name] = {                    ""password"": pw,                    ""options"": {},                    ""valid"": True,                }

loads all accounts available.",cecd0675-ae52-4095-a9ac-0fb0f9b7a52b
managers,account_manager.py,save_accounts,135,157,"def save_accounts(self):                account_plugins = self.pyload.plugin_manager.get_account_plugins()        with open(self.configpath, mode=""w"") as fp:            fp.write(f""version: {__version__}\n"")            for plugin, accounts in sorted(self.accounts.items()):                if plugin in account_plugins:                    fp.write(""\n"")                    fp.write(plugin + "":\n"")                    for name, data in accounts.items():                        pw = data[""password""]                        name = name.replace("":"", r""\x3a"")                        pw = pw.replace("":"", r""\x3a"")                        fp.write(f""\n\t{name}:{pw}\n"")                        if data[""options""]:                            for option, values in data[""options""].items():                                line = "" "".join(values)                                fp.write(f""\t@{option} {line}\n"")            os.chmod(fp.name, 0o600)",save all account information.,"def save_accounts(self):        """"""        save all account information.        """"""        account_plugins = self.pyload.plugin_manager.get_account_plugins()        with open(self.configpath, mode=""w"") as fp:            fp.write(f""version: {__version__}\n"")            for plugin, accounts in sorted(self.accounts.items()):                if plugin in account_plugins:                    fp.write(""\n"")                    fp.write(plugin + "":\n"")                    for name, data in accounts.items():                        pw = data[""password""]                        name = name.replace("":"", r""\x3a"")                        pw = pw.replace("":"", r""\x3a"")                        fp.write(f""\n\t{name}:{pw}\n"")                        if data[""options""]:                            for option, values in data[""options""].items():                                line = "" "".join(values)                                fp.write(f""\t@{option} {line}\n"")            os.chmod(fp.name, 0o600)

save all account information.",0f3460f3-ea99-4886-8475-b3e2b964a876
managers,account_manager.py,init_account_plugins,161,166,def init_account_plugins(self):                for name in self.pyload.plugin_manager.get_account_plugins():            self.accounts[name] = {},init names.,"def init_account_plugins(self):        """"""        init names.        """"""        for name in self.pyload.plugin_manager.get_account_plugins():            self.accounts[name] = {}

init names.",9008dea1-7642-412a-9178-911fa2b498e7
managers,account_manager.py,update_account,169,182,"def update_account(self, plugin, user, password=None, options={}):                if plugin in self.accounts and user:            p = self.get_account_plugin(plugin)            if p is not None:                updated = p.update_accounts(user, password, options)                # since accounts is a ref in plugin self.accounts doesn't need to be                # updated here                self.save_accounts()                if updated:                    p.schedule_refresh(user, force=False)",add or update an account.,"def update_account(self, plugin, user, password=None, options={}):        """"""        add or update an account.        """"""        if plugin in self.accounts and user:            p = self.get_account_plugin(plugin)            if p is not None:                updated = p.update_accounts(user, password, options)                # since accounts is a ref in plugin self.accounts doesn't need to be                # updated here                self.save_accounts()                if updated:                    p.schedule_refresh(user, force=False)

add or update an account.",95f043a5-7eff-450e-aa45-3431ada36075
managers,account_manager.py,remove_account,185,193,"def remove_account(self, plugin, user):                if plugin in self.accounts:            p = self.get_account_plugin(plugin)            p.remove_account(user)            self.save_accounts()",remove account.,"def remove_account(self, plugin, user):        """"""        remove account.        """"""        if plugin in self.accounts:            p = self.get_account_plugin(plugin)            p.remove_account(user)            self.save_accounts()

remove account.",e9c9e616-0906-4d5c-bb5a-063d69df3c1d
managers,account_manager.py,get_account_infos,196,218,"def get_account_infos(self, force=True, refresh=False):        data = {}        if refresh:            self.pyload.scheduler.add_job(                0, self.pyload.account_manager.get_account_infos            )            force = False        for acc in self.accounts.keys():            if self.accounts[acc]:                plugin = self.get_account_plugin(acc)                if plugin is not None:                    data[plugin.__name__] = plugin.get_all_accounts(force)                else:                    self.pyload.log.error(self._(""Bad or missing plugin: ACCOUNT {}"").format(acc))                    data[acc] = []            else:                data[acc] = []        e = AccountUpdateEvent()        self.pyload.event_manager.add_event(e)        return data",,"def get_account_infos(self, force=True, refresh=False):        data = {}        if refresh:            self.pyload.scheduler.add_job(                0, self.pyload.account_manager.get_account_infos            )            force = False        for acc in self.accounts.keys():            if self.accounts[acc]:                plugin = self.get_account_plugin(acc)                if plugin is not None:                    data[plugin.__name__] = plugin.get_all_accounts(force)                else:                    self.pyload.log.error(self._(""Bad or missing plugin: ACCOUNT {}"").format(acc))                    data[acc] = []            else:                data[acc] = []        e = AccountUpdateEvent()        self.pyload.event_manager.add_event(e)        return data",72589ed0-b22e-4c38-8498-755ba8b832d5
managers,account_manager.py,send_change,220,222,def send_change(self):        e = AccountUpdateEvent()        self.pyload.event_manager.add_event(e),,def send_change(self):        e = AccountUpdateEvent()        self.pyload.event_manager.add_event(e),35045b92-00f9-40cf-9071-1fb9ff002360
managers,addon_manager.py,try_catch,15,25,"def try_catch(func):    @wraps(func)    def wrapper(self, *args):        try:            return func(self, *args)        except Exception as exc:            self.pyload.log.error(                exc, exc_info=self.pyload.debug > 1, stack_info=self.pyload.debug > 2            )    return wrapper",,"def try_catch(func):    @wraps(func)    def wrapper(self, *args):        try:            return func(self, *args)        except Exception as exc:            self.pyload.log.error(                exc, exc_info=self.pyload.debug > 1, stack_info=self.pyload.debug > 2            )    return wrapper",4160f780-0122-4675-9e9d-a207c4fe73d1
managers,addon_manager.py,__init__,59,77,"def __init__(self, core):        self.pyload = core        self._ = core._        self.plugins = []        self.plugin_map = {}        self.rpc_methods = {}  #: dict of names and list of methods usable by rpc        self.events = {}  #: contains events        # registering callback for config event        self.pyload.config.plugin_cb = MethodType(            self.dispatch_event, ""plugin_config_changed""        )        self.add_event(""plugin_config_changed"", self.manage_addons)        self.lock = RLock()        self.create_index()",,"def __init__(self, core):        self.pyload = core        self._ = core._        self.plugins = []        self.plugin_map = {}        self.rpc_methods = {}  #: dict of names and list of methods usable by rpc        self.events = {}  #: contains events        # registering callback for config event        self.pyload.config.plugin_cb = MethodType(            self.dispatch_event, ""plugin_config_changed""        )        self.add_event(""plugin_config_changed"", self.manage_addons)        self.lock = RLock()        self.create_index()",511736b2-0685-4378-aee1-fd77573cdf90
managers,addon_manager.py,add_rpc,79,86,"def add_rpc(self, plugin, func, doc):        plugin = plugin.rpartition(""."")[2]        doc = doc.strip() if doc else """"        if plugin in self.rpc_methods:            self.rpc_methods[plugin][func] = doc        else:            self.rpc_methods[plugin] = {func: doc}",,"def add_rpc(self, plugin, func, doc):        plugin = plugin.rpartition(""."")[2]        doc = doc.strip() if doc else """"        if plugin in self.rpc_methods:            self.rpc_methods[plugin][func] = doc        else:            self.rpc_methods[plugin] = {func: doc}",05eb2bdb-baf6-4a16-ba22-427c378ff381
managers,addon_manager.py,call_rpc,88,96,"def call_rpc(self, plugin, func, args, parse):        if not args:            args = tuple()        if parse:            args = tuple(literal_eval(x) for x in args)        plugin = self.plugin_map[plugin]        f = getattr(plugin, func)        return f(*args)",,"def call_rpc(self, plugin, func, args, parse):        if not args:            args = tuple()        if parse:            args = tuple(literal_eval(x) for x in args)        plugin = self.plugin_map[plugin]        f = getattr(plugin, func)        return f(*args)",a8b579d8-ddfa-42d7-a4af-c4e76a655c6a
managers,addon_manager.py,create_index,98,137,"def create_index(self):        plugins = []        active = []        inactive = []        for plugin_name in self.pyload.plugin_manager.addon_plugins:            try:                # addon_class = getattr(plugin, plugin.__name__)                if self.pyload.config.get_plugin(plugin_name, ""enabled""):                    plugin_class = self.pyload.plugin_manager.load_class(                        ""addon"", plugin_name                    )                    if not plugin_class:                        continue                    plugin = plugin_class(self.pyload, self)                    plugins.append(plugin)                    self.plugin_map[plugin_class.__name__] = plugin                    if plugin.is_activated():                        active.append(plugin_class.__name__)                else:                    inactive.append(plugin_name)            except Exception:                self.pyload.log.warning(                    self._(""Failed activating {}"").format(plugin_name),                    exc_info=self.pyload.debug > 1,                    stack_info=self.pyload.debug > 2,                )        self.pyload.log.info(            self._(""Activated addons: {}"").format("", "".join(sorted(active)))        )        self.pyload.log.info(            self._(""Deactivate addons: {}"").format("", "".join(sorted(inactive)))        )        self.plugins = plugins",,"def create_index(self):        plugins = []        active = []        inactive = []        for plugin_name in self.pyload.plugin_manager.addon_plugins:            try:                # addon_class = getattr(plugin, plugin.__name__)                if self.pyload.config.get_plugin(plugin_name, ""enabled""):                    plugin_class = self.pyload.plugin_manager.load_class(                        ""addon"", plugin_name                    )                    if not plugin_class:                        continue                    plugin = plugin_class(self.pyload, self)                    plugins.append(plugin)                    self.plugin_map[plugin_class.__name__] = plugin                    if plugin.is_activated():                        active.append(plugin_class.__name__)                else:                    inactive.append(plugin_name)            except Exception:                self.pyload.log.warning(                    self._(""Failed activating {}"").format(plugin_name),                    exc_info=self.pyload.debug > 1,                    stack_info=self.pyload.debug > 2,                )        self.pyload.log.info(            self._(""Activated addons: {}"").format("", "".join(sorted(active)))        )        self.pyload.log.info(            self._(""Deactivate addons: {}"").format("", "".join(sorted(inactive)))        )        self.plugins = plugins",5bcce8d3-0b6c-4efd-b44d-9c99934c27b0
managers,addon_manager.py,manage_addons,139,143,"def manage_addons(self, plugin, name, value):        if name == ""enabled"" and value:            self.activate_addon(plugin)        elif name == ""enabled"" and not value:            self.deactivate_addon(plugin)",,"def manage_addons(self, plugin, name, value):        if name == ""enabled"" and value:            self.activate_addon(plugin)        elif name == ""enabled"" and not value:            self.deactivate_addon(plugin)",7b73b84d-adb6-4b59-907f-199ce9d5ea41
managers,addon_manager.py,activate_addon,145,164,"def activate_addon(self, plugin):        # check if already loaded        for inst in self.plugins:            if inst.__name__ == plugin:                return        plugin_class = self.pyload.plugin_manager.load_class(""addon"", plugin)        if not plugin_class:            return        self.pyload.log.debug(f""Plugin loaded: {plugin}"")        plugin = plugin_class(self.pyload, self)        self.plugins.append(plugin)        self.plugin_map[plugin_class.__name__] = plugin        # call core Ready        start_new_thread(plugin.core_ready, tuple())",,"def activate_addon(self, plugin):        # check if already loaded        for inst in self.plugins:            if inst.__name__ == plugin:                return        plugin_class = self.pyload.plugin_manager.load_class(""addon"", plugin)        if not plugin_class:            return        self.pyload.log.debug(f""Plugin loaded: {plugin}"")        plugin = plugin_class(self.pyload, self)        self.plugins.append(plugin)        self.plugin_map[plugin_class.__name__] = plugin        # call core Ready        start_new_thread(plugin.core_ready, tuple())",a896ab07-386d-4c62-a613-0a81146878fa
managers,addon_manager.py,deactivate_addon,166,184,"def deactivate_addon(self, plugin):        addon = None        for inst in self.plugins:            if inst.__name__ == plugin:                addon = inst        if not addon:            return        self.pyload.log.debug(f""Plugin unloaded: {plugin}"")        addon.unload()        # remove periodic call        res = self.pyload.scheduler.remove_job(addon.cb)        self.pyload.log.debug(f""Removed callback {res}"")        self.plugins.remove(addon)        del self.plugin_map[addon.__name__]",,"def deactivate_addon(self, plugin):        addon = None        for inst in self.plugins:            if inst.__name__ == plugin:                addon = inst        if not addon:            return        self.pyload.log.debug(f""Plugin unloaded: {plugin}"")        addon.unload()        # remove periodic call        res = self.pyload.scheduler.remove_job(addon.cb)        self.pyload.log.debug(f""Removed callback {res}"")        self.plugins.remove(addon)        del self.plugin_map[addon.__name__]",8e707336-b496-4e69-9c99-7ef610a0e5cf
managers,addon_manager.py,core_ready,187,192,"def core_ready(self):        for plugin in self.plugins:            if plugin.is_activated():                plugin.core_ready()        self.dispatch_event(""core_ready"")",,"def core_ready(self):        for plugin in self.plugins:            if plugin.is_activated():                plugin.core_ready()        self.dispatch_event(""core_ready"")",860e75ae-f60c-4f4b-a41a-e4ec846ad697
managers,addon_manager.py,core_exiting,195,200,"def core_exiting(self):        for plugin in self.plugins:            if plugin.is_activated():                plugin.core_exiting()        self.dispatch_event(""core_exiting"")",,"def core_exiting(self):        for plugin in self.plugins:            if plugin.is_activated():                plugin.core_exiting()        self.dispatch_event(""core_exiting"")",f1bf9d4a-907d-47f7-959e-504ad37adf0a
managers,addon_manager.py,download_preparing,203,208,"def download_preparing(self, pyfile):        for plugin in self.plugins:            if plugin.is_activated():                plugin.download_preparing(pyfile)        self.dispatch_event(""download_preparing"", pyfile)",,"def download_preparing(self, pyfile):        for plugin in self.plugins:            if plugin.is_activated():                plugin.download_preparing(pyfile)        self.dispatch_event(""download_preparing"", pyfile)",333f054c-2da9-431d-9ba7-6563b9a2e95b
managers,addon_manager.py,download_finished,211,216,"def download_finished(self, pyfile):        for plugin in self.plugins:            if plugin.is_activated():                plugin.download_finished(pyfile)        self.dispatch_event(""download_finished"", pyfile)",,"def download_finished(self, pyfile):        for plugin in self.plugins:            if plugin.is_activated():                plugin.download_finished(pyfile)        self.dispatch_event(""download_finished"", pyfile)",eaec6ae5-b717-46e4-8ab3-62b70ba845d4
managers,addon_manager.py,download_failed,220,225,"def download_failed(self, pyfile):        for plugin in self.plugins:            if plugin.is_activated():                plugin.download_failed(pyfile)        self.dispatch_event(""download_failed"", pyfile)",,"def download_failed(self, pyfile):        for plugin in self.plugins:            if plugin.is_activated():                plugin.download_failed(pyfile)        self.dispatch_event(""download_failed"", pyfile)",e3ff0080-34cb-48f1-87bc-7cb689aa857b
managers,addon_manager.py,package_finished,228,233,"def package_finished(self, package):        for plugin in self.plugins:            if plugin.is_activated():                plugin.package_finished(package)        self.dispatch_event(""package_finished"", package)",,"def package_finished(self, package):        for plugin in self.plugins:            if plugin.is_activated():                plugin.package_finished(package)        self.dispatch_event(""package_finished"", package)",64caee9d-0f9d-46d1-b270-f2ee0e694aba
managers,addon_manager.py,before_reconnect,236,240,"def before_reconnect(self, ip):        for plugin in self.plugins:            plugin.before_reconnect(ip)        self.dispatch_event(""before_reconnect"", ip)",,"def before_reconnect(self, ip):        for plugin in self.plugins:            plugin.before_reconnect(ip)        self.dispatch_event(""before_reconnect"", ip)",ff20a771-f468-4df5-a4ed-f59eccd4825a
managers,addon_manager.py,after_reconnect,243,248,"def after_reconnect(self, ip, old_ip):        for plugin in self.plugins:            if plugin.is_activated():                plugin.after_reconnect(ip, old_ip)        self.dispatch_event(""after_reconnect"", old_ip, ip)",,"def after_reconnect(self, ip, old_ip):        for plugin in self.plugins:            if plugin.is_activated():                plugin.after_reconnect(ip, old_ip)        self.dispatch_event(""after_reconnect"", old_ip, ip)",4ca8602c-e7c2-4a59-a109-f4b5d7570748
managers,addon_manager.py,start_thread,250,251,"def start_thread(self, function, *args, **kwargs):        return AddonThread(self.pyload.thread_manager, function, args, kwargs)",,"def start_thread(self, function, *args, **kwargs):        return AddonThread(self.pyload.thread_manager, function, args, kwargs)",98cac550-172b-400c-ac2a-0a155126ecaa
managers,addon_manager.py,active_plugins,253,257,def active_plugins(self):                return [x for x in self.plugins if x.is_activated()],returns all active plugins.,"def active_plugins(self):        """"""        returns all active plugins.        """"""        return [x for x in self.plugins if x.is_activated()]

returns all active plugins.",e2464ca1-c548-438c-83e4-5bd5f92e4a1e
managers,addon_manager.py,get_all_info,259,268,"def get_all_info(self):                info = {}        for name, plugin in self.plugin_map.items():            if plugin.info:                # copy and convert so str                info[name] = {x: str(y) for x, y in plugin.info.items()}        return info",returns info stored by addon plugins.,"def get_all_info(self):        """"""        returns info stored by addon plugins.        """"""        info = {}        for name, plugin in self.plugin_map.items():            if plugin.info:                # copy and convert so str                info[name] = {x: str(y) for x, y in plugin.info.items()}        return info

returns info stored by addon plugins.",6eba09d4-e006-4779-82d2-06cd99b9f623
managers,addon_manager.py,get_info,270,275,"def get_info(self, plugin):        info = {}        if plugin in self.plugin_map and self.plugin_map[plugin].info:            info = {x: str(y) for x, y in self.plugin_map[plugin].info.items()}        return info",,"def get_info(self, plugin):        info = {}        if plugin in self.plugin_map and self.plugin_map[plugin].info:            info = {x: str(y) for x, y in self.plugin_map[plugin].info.items()}        return info",dcc03daa-ec0d-4416-a173-a424375d5ad3
managers,addon_manager.py,add_event,277,285,"def add_event(self, event, func):                if event in self.events:            if func not in self.events[event]:                self.events[event].append(func)        else:            self.events[event] = [func]",Adds an event listener for event name.,"def add_event(self, event, func):        """"""        Adds an event listener for event name.        """"""        if event in self.events:            if func not in self.events[event]:                self.events[event].append(func)        else:            self.events[event] = [func]

Adds an event listener for event name.",35db0240-446e-4535-82bc-e0a1850fb91f
managers,addon_manager.py,remove_event,287,293,"def remove_event(self, event, func):                if event in self.events:            if func in self.events[event]:                self.events[event].remove(func)",removes previously added event listener.,"def remove_event(self, event, func):        """"""        removes previously added event listener.        """"""        if event in self.events:            if func in self.events[event]:                self.events[event].remove(func)

removes previously added event listener.",8685a5ba-8d00-4cd1-8bb3-60f19628b4d7
managers,addon_manager.py,dispatch_event,295,310,"def dispatch_event(self, event, *args):                if event in self.events:            for f in self.events[event]:                try:                    f(*args)                except Exception as exc:                    self.pyload.log.warning(                        self._(""Error calling event handler {}: {}, {}, {}"").format(                            event, f, args, exc                        ),                        exc_info=self.pyload.debug > 1,                        stack_info=self.pyload.debug > 2,                    )",dispatches event with args.,"def dispatch_event(self, event, *args):        """"""        dispatches event with args.        """"""        if event in self.events:            for f in self.events[event]:                try:                    f(*args)                except Exception as exc:                    self.pyload.log.warning(                        self._(""Error calling event handler {}: {}, {}, {}"").format(                            event, f, args, exc                        ),                        exc_info=self.pyload.debug > 1,                        stack_info=self.pyload.debug > 2,                    )

dispatches event with args.",156279a9-076d-40f2-80b6-8dd7410c1a74
managers,captcha_manager.py,__init__,10,16,"def __init__(self, core):        self.lock = Lock()        self.pyload = core        self._ = core._        self.tasks = []  #: Task store, for outgoing tasks only        self.ids = 0",,"def __init__(self, core):        self.lock = Lock()        self.pyload = core        self._ = core._        self.tasks = []  #: Task store, for outgoing tasks only        self.ids = 0",22d21f91-5592-4fe9-98e0-ef478e8da261
managers,captcha_manager.py,new_task,18,21,"def new_task(self, format, params, result_type):        task = CaptchaTask(self.ids, format, params, result_type)        self.ids += 1        return task",,"def new_task(self, format, params, result_type):        task = CaptchaTask(self.ids, format, params, result_type)        self.ids += 1        return task",cabba52e-018a-4240-93f3-439445e96485
managers,captcha_manager.py,remove_task,24,26,"def remove_task(self, task):        if task in self.tasks:            self.tasks.remove(task)",,"def remove_task(self, task):        if task in self.tasks:            self.tasks.remove(task)",616d59ae-2b1c-433e-8ce2-0aa8660ec417
managers,captcha_manager.py,get_task,29,33,"def get_task(self):        for task in self.tasks:            if task.status in (""waiting"", ""shared-user""):                return task        return None",,"def get_task(self):        for task in self.tasks:            if task.status in (""waiting"", ""shared-user""):                return task        return None",87a8f19d-43c4-4748-82a3-9a654089aab6
managers,captcha_manager.py,get_task_by_id,36,40,"def get_task_by_id(self, tid):        for task in self.tasks:            if task.id == str(tid):  #: Task ids are strings                return task        return None",,"def get_task_by_id(self, tid):        for task in self.tasks:            if task.id == str(tid):  #: Task ids are strings                return task        return None",c6d22deb-265e-4510-89ca-84537a87c7eb
managers,captcha_manager.py,handle_captcha,42,66,"def handle_captcha(self, task, timeout):        cli = self.pyload.is_client_connected()        task.set_waiting(timeout)        # if cli:  #: Client connected -> should solve the captcha        #     task.set_waiting(50)  #: Wait minimum 50 sec for response        for plugin in self.pyload.addon_manager.active_plugins():            try:                plugin.captcha_task(task)            except Exception:                self.pyload.log.warning(                    self.pyload._(""Unable to create captcha task""),                    exc_info=self.pyload.debug > 1,                    stack_info=self.pyload.debug > 2                )        if task.handler or cli:  #: The captcha was handled            self.tasks.append(task)            return True        task.error = self._(""No Client connected for captcha decrypting"")        return False",,"def handle_captcha(self, task, timeout):        cli = self.pyload.is_client_connected()        task.set_waiting(timeout)        # if cli:  #: Client connected -> should solve the captcha        #     task.set_waiting(50)  #: Wait minimum 50 sec for response        for plugin in self.pyload.addon_manager.active_plugins():            try:                plugin.captcha_task(task)            except Exception:                self.pyload.log.warning(                    self.pyload._(""Unable to create captcha task""),                    exc_info=self.pyload.debug > 1,                    stack_info=self.pyload.debug > 2                )        if task.handler or cli:  #: The captcha was handled            self.tasks.append(task)            return True        task.error = self._(""No Client connected for captcha decrypting"")        return False",093c133d-2e46-4998-80e5-6b5798ec3635
managers,captcha_manager.py,__init__,70,81,"def __init__(self, id, format, params={}, result_type=""textual""):        self.id = str(id)        self.captcha_params = params        self.captcha_format = format        self.captcha_result_type = result_type        self.handler = []  #: the addon plugins that will take care of the solution        self.result = None        self.wait_until = 0        self.error = None  #: error message        self.status = ""init""        self.data = {}",,"def __init__(self, id, format, params={}, result_type=""textual""):        self.id = str(id)        self.captcha_params = params        self.captcha_format = format        self.captcha_result_type = result_type        self.handler = []  #: the addon plugins that will take care of the solution        self.result = None        self.wait_until = 0        self.error = None  #: error message        self.status = ""init""        self.data = {}",eaaaa48e-e630-4259-9386-c374976d5c06
managers,captcha_manager.py,get_captcha,83,84,"def get_captcha(self):        return self.captcha_params, self.captcha_format, self.captcha_result_type",,"def get_captcha(self):        return self.captcha_params, self.captcha_format, self.captcha_result_type",b4b61aa4-68f4-4510-b763-05a4cd814ee6
managers,captcha_manager.py,set_result,86,95,"def set_result(self, result):        if self.is_textual() or self.is_interactive() or self.is_invisible():            self.result = result        elif self.is_positional():            try:                parts = result.split("","")                self.result = (int(parts[0]), int(parts[1]))            except Exception:                self.result = None",,"def set_result(self, result):        if self.is_textual() or self.is_interactive() or self.is_invisible():            self.result = result        elif self.is_positional():            try:                parts = result.split("","")                self.result = (int(parts[0]), int(parts[1]))            except Exception:                self.result = None",ae05fc5d-8ac7-4ec6-9171-aaaeba97479d
managers,captcha_manager.py,get_result,97,98,def get_result(self):        return self.result,,def get_result(self):        return self.result,d019a4fd-bbe5-4d99-ba0c-5762b8294896
managers,captcha_manager.py,get_status,100,101,def get_status(self):        return self.status,,def get_status(self):        return self.status,06529ef6-b772-459f-8c97-ec99c9365d9c
managers,captcha_manager.py,set_waiting,103,108,"def set_waiting(self, sec):                self.wait_until = max(time.time() + sec, self.wait_until)        self.status = ""waiting""",let the captcha wait secs for the solution.,"def set_waiting(self, sec):        """"""        let the captcha wait secs for the solution.        """"""        self.wait_until = max(time.time() + sec, self.wait_until)        self.status = ""waiting""

let the captcha wait secs for the solution.",369237c7-d6cb-490d-a4a0-e9d80ccc6ac8
managers,captcha_manager.py,is_waiting,110,114,def is_waiting(self):        if self.result or self.error or time.time() > self.wait_until:            return False        return True,,def is_waiting(self):        if self.result or self.error or time.time() > self.wait_until:            return False        return True,8e2a0e22-74fb-43ae-b6e1-3759b1529fb2
managers,captcha_manager.py,is_textual,116,120,"def is_textual(self):                return self.captcha_result_type == ""textual""",returns if text is written on the captcha.,"def is_textual(self):        """"""        returns if text is written on the captcha.        """"""        return self.captcha_result_type == ""textual""

returns if text is written on the captcha.",6c4b3666-b802-4df7-a062-8b265d597394
managers,captcha_manager.py,is_positional,122,126,"def is_positional(self):                return self.captcha_result_type == ""positional""",returns if user have to click a specific region on the captcha.,"def is_positional(self):        """"""        returns if user have to click a specific region on the captcha.        """"""        return self.captcha_result_type == ""positional""

returns if user have to click a specific region on the captcha.",b0d4d35e-572f-459b-a249-5674435d309e
managers,captcha_manager.py,is_interactive,128,132,"def is_interactive(self):                return self.captcha_result_type == ""interactive""",returns if user has to solve the captcha in an interactive iframe.,"def is_interactive(self):        """"""        returns if user has to solve the captcha in an interactive iframe.        """"""        return self.captcha_result_type == ""interactive""

returns if user has to solve the captcha in an interactive iframe.",0bc903ad-dca1-4d95-95c8-6f29082017c1
managers,captcha_manager.py,is_invisible,134,138,"def is_invisible(self):                return self.captcha_result_type == ""invisible""","returns if invisible (browser only, no user interaction) captcha.","def is_invisible(self):        """"""        returns if invisible (browser only, no user interaction) captcha.        """"""        return self.captcha_result_type == ""invisible""

returns if invisible (browser only, no user interaction) captcha.",f0f2bdc9-3a83-4912-acb4-35dc7deee5e4
managers,captcha_manager.py,set_waiting_for_user,140,144,"def set_waiting_for_user(self, exclusive):        if exclusive:            self.status = ""user""        else:            self.status = ""shared-user""",,"def set_waiting_for_user(self, exclusive):        if exclusive:            self.status = ""user""        else:            self.status = ""shared-user""",9f0c2f0f-56c2-4dc0-b06b-3d9c20b34eb7
managers,captcha_manager.py,timed_out,146,147,def timed_out(self):        return time.time() > self.wait_until,,def timed_out(self):        return time.time() > self.wait_until,dc90933f-e11d-4a0d-ad70-cf20148c5be3
managers,captcha_manager.py,invalid,149,153,def invalid(self):                [x.captcha_invalid(self) for x in self.handler],indicates the captcha was not correct.,"def invalid(self):        """"""        indicates the captcha was not correct.        """"""        [x.captcha_invalid(self) for x in self.handler]

indicates the captcha was not correct.",1967cb33-7550-4085-8e0d-d042d15851c3
managers,captcha_manager.py,correct,155,156,def correct(self):        [x.captcha_correct(self) for x in self.handler],,def correct(self):        [x.captcha_correct(self) for x in self.handler],c727c1cd-7ca9-4022-bf68-19aff924e714
managers,captcha_manager.py,__str__,158,159,"def __str__(self):        return f""<CaptchaTask '{self.id}'>""",,"def __str__(self):        return f""<CaptchaTask '{self.id}'>""",c0bcc271-9aa3-415b-b52a-f660d1c0d105
managers,event_manager.py,__init__,9,12,"def __init__(self, core):        self.pyload = core        self._ = core._        self.clients = []",,"def __init__(self, core):        self.pyload = core        self._ = core._        self.clients = []",dcce6f9c-5e29-4eaf-92ed-d75aad821088
managers,event_manager.py,new_client,14,15,"def new_client(self, uuid):        self.clients.append(Client(uuid))",,"def new_client(self, uuid):        self.clients.append(Client(uuid))",5cdec907-204c-4472-ba49-a451d2808848
managers,event_manager.py,clean,17,20,"def clean(self):        for n, client in enumerate(self.clients):            if client.last_active + 30 < time.time():                del self.clients[n]",,"def clean(self):        for n, client in enumerate(self.clients):            if client.last_active + 30 < time.time():                del self.clients[n]",32d2ac5c-83ad-4d8b-be14-9adf3490e165
managers,event_manager.py,get_events,22,38,"def get_events(self, uuid):        events = []        valid_uuid = False        for client in self.clients:            if client.uuid == uuid:                client.last_active = time.time()                valid_uuid = True                while client.new_events():                    events.append(client.pop_event().to_list())                break        if not valid_uuid:            self.new_client(uuid)            events = [                ReloadAllEvent(""queue"").to_list(),                ReloadAllEvent(""collector"").to_list(),            ]        return uniquify(events)",,"def get_events(self, uuid):        events = []        valid_uuid = False        for client in self.clients:            if client.uuid == uuid:                client.last_active = time.time()                valid_uuid = True                while client.new_events():                    events.append(client.pop_event().to_list())                break        if not valid_uuid:            self.new_client(uuid)            events = [                ReloadAllEvent(""queue"").to_list(),                ReloadAllEvent(""collector"").to_list(),            ]        return uniquify(events)",322e2d22-a2d0-4d63-b62d-261eb0a02cd1
managers,event_manager.py,add_event,40,42,"def add_event(self, event):        for client in self.clients:            client.add_event(event)",,"def add_event(self, event):        for client in self.clients:            client.add_event(event)",7b77d0f5-af1c-4763-90bc-2b4b784a65f3
managers,event_manager.py,__init__,46,49,"def __init__(self, uuid):        self.uuid = uuid        self.last_active = time.time()        self.events = []",,"def __init__(self, uuid):        self.uuid = uuid        self.last_active = time.time()        self.events = []",c340dddb-d582-43fa-a085-76f5645e73a8
managers,event_manager.py,new_events,51,52,def new_events(self):        return len(self.events) > 0,,def new_events(self):        return len(self.events) > 0,e053b91a-6c3e-4931-9fee-9546d993f4a2
managers,event_manager.py,pop_event,54,57,def pop_event(self):        if not len(self.events):            return None        return self.events.pop(0),,def pop_event(self):        if not len(self.events):            return None        return self.events.pop(0),05675765-bd63-4eca-a1fe-b455b8271514
managers,event_manager.py,add_event,59,60,"def add_event(self, event):        self.events.append(event)",,"def add_event(self, event):        self.events.append(event)",e3c46ca2-1fde-438c-b5cf-e353ee8361e7
managers,event_manager.py,__init__,64,69,"def __init__(self, itype, iid, destination):        assert itype == ""pack"" or itype == ""file""        assert destination == ""queue"" or destination == ""collector""        self.type = itype        self.id = iid        self.destination = destination",,"def __init__(self, itype, iid, destination):        assert itype == ""pack"" or itype == ""file""        assert destination == ""queue"" or destination == ""collector""        self.type = itype        self.id = iid        self.destination = destination",21f85c09-ff53-4bc9-8056-578ddbcc26ad
managers,event_manager.py,to_list,71,72,"def to_list(self):        return [""update"", self.destination, self.type, self.id]",,"def to_list(self):        return [""update"", self.destination, self.type, self.id]",aad52467-7368-42f7-b274-a32855b83e4a
managers,event_manager.py,__init__,76,81,"def __init__(self, itype, iid, destination):        assert itype == ""pack"" or itype == ""file""        assert destination == ""queue"" or destination == ""collector""        self.type = itype        self.id = iid        self.destination = destination",,"def __init__(self, itype, iid, destination):        assert itype == ""pack"" or itype == ""file""        assert destination == ""queue"" or destination == ""collector""        self.type = itype        self.id = iid        self.destination = destination",2fb2cf3a-a5a2-4491-b9e0-679c011ee6b3
managers,event_manager.py,to_list,83,84,"def to_list(self):        return [""remove"", self.destination, self.type, self.id]",,"def to_list(self):        return [""remove"", self.destination, self.type, self.id]",fca5e70a-97da-4a3d-9c3b-edb6f38ff163
managers,event_manager.py,__init__,88,94,"def __init__(self, itype, iid, after, destination):        assert itype == ""pack"" or itype == ""file""        assert destination == ""queue"" or destination == ""collector""        self.type = itype        self.id = iid        self.after = after        self.destination = destination",,"def __init__(self, itype, iid, after, destination):        assert itype == ""pack"" or itype == ""file""        assert destination == ""queue"" or destination == ""collector""        self.type = itype        self.id = iid        self.after = after        self.destination = destination",7e903ee1-fb96-4fca-8f9b-74ededc5829c
managers,event_manager.py,to_list,96,97,"def to_list(self):        return [""insert"", self.destination, self.type, self.id, self.after]",,"def to_list(self):        return [""insert"", self.destination, self.type, self.id, self.after]",1ac123b3-5007-4f8a-a616-3a00cd4b99f6
managers,event_manager.py,__init__,101,103,"def __init__(self, destination):        assert destination == ""queue"" or destination == ""collector""        self.destination = destination",,"def __init__(self, destination):        assert destination == ""queue"" or destination == ""collector""        self.destination = destination",1a37916b-65b3-42c4-934c-2eb931d2987b
managers,event_manager.py,to_list,105,106,"def to_list(self):        return [""reload"", self.destination]",,"def to_list(self):        return [""reload"", self.destination]",601d85e5-07c6-4154-9d54-6f487b40a55a
managers,event_manager.py,to_list,110,111,"def to_list(self):        return [""account""]",,"def to_list(self):        return [""account""]",af859bdb-35e3-483a-bc7a-8acab5e4ac2b
managers,event_manager.py,to_list,115,116,"def to_list(self):        return [""config""]",,"def to_list(self):        return [""config""]",e81bb06c-2244-4b7f-987d-7f5aad157e82
managers,file_manager.py,change,11,19,"def change(func):    def new(self, *args):        self.unchanged = False        self.filecount = -1        self.queuecount = -1        self.job_cache = {}        return func(self, *args)    return new",,"def change(func):    def new(self, *args):        self.unchanged = False        self.filecount = -1        self.queuecount = -1        self.job_cache = {}        return func(self, *args)    return new",04942cc4-bbb0-48ff-a7ac-38e3d59bc256
managers,file_manager.py,__init__,28,65,"def __init__(self, core):                self.pyload = core        self._ = core._        # translations        self.status_msg = [            self._(""finished""),            self._(""offline""),            self._(""online""),            self._(""queued""),            self._(""skipped""),            self._(""waiting""),            self._(""temp. offline""),            self._(""starting""),            self._(""failed""),            self._(""aborted""),            self._(""decrypting""),            self._(""custom""),            self._(""downloading""),            self._(""processing""),            self._(""unknown""),        ]        # TODO: purge the cache        self.cache = {}  #: holds instances for files        self.package_cache = {}  #: same for packages        self.job_cache = {}        self.lock = RLock()  # TODO: should be a Lock w/o R        # self.lock._Verbose__verbose = True        self.filecount = -1  #: if an invalid value is set get current value from db        self.queuecount = -1  #: number of package to be loaded        self.unchanged = False",Constructor.,"def __init__(self, core):        """"""        Constructor.        """"""        self.pyload = core        self._ = core._        # translations        self.status_msg = [            self._(""finished""),            self._(""offline""),            self._(""online""),            self._(""queued""),            self._(""skipped""),            self._(""waiting""),            self._(""temp. offline""),            self._(""starting""),            self._(""failed""),            self._(""aborted""),            self._(""decrypting""),            self._(""custom""),            self._(""downloading""),            self._(""processing""),            self._(""unknown""),        ]        # TODO: purge the cache        self.cache = {}  #: holds instances for files        self.package_cache = {}  #: same for packages        self.job_cache = {}        self.lock = RLock()  # TODO: should be a Lock w/o R        # self.lock._Verbose__verbose = True        self.filecount = -1  #: if an invalid value is set get current value from db        self.queuecount = -1  #: number of package to be loaded        self.unchanged = False

Constructor.",8af9aa9f-d103-4c41-9035-0157f6f66458
managers,file_manager.py,save,68,72,def save(self):                self.pyload.db.commit(),saves all data to backend.,"def save(self):        """"""        saves all data to backend.        """"""        self.pyload.db.commit()

saves all data to backend.",008f465f-07b2-482d-bfff-edac40297d9d
managers,file_manager.py,sync_save,75,87,def sync_save(self):                pyfiles = self.cache.values()        for pyfile in pyfiles:            pyfile.sync()        pypacks = self.package_cache.values()        for pypack in pypacks:            pypack.sync()        self.pyload.db.sync_save(),saves all data to backend and waits until all the data is written.,"def sync_save(self):        """"""        saves all data to backend and waits until all the data is written.        """"""        pyfiles = self.cache.values()        for pyfile in pyfiles:            pyfile.sync()        pypacks = self.package_cache.values()        for pypack in pypacks:            pypack.sync()        self.pyload.db.sync_save()

saves all data to backend and waits until all the data is written.",f47b2c02-0d8e-47cb-aaea-5285bba52f5c
managers,file_manager.py,get_complete_data,90,109,"def get_complete_data(self, queue=Destination.QUEUE):                queue = queue.value        data = self.pyload.db.get_all_links(queue)        packs = self.pyload.db.get_all_packages(queue)        data.update((x.id, x.to_db_dict()[x.id]) for x in self.cache.values())        for x in self.package_cache.values():            if x.queue != queue or x.id not in packs:                continue            packs[x.id].update(x.to_dict()[x.id])        for key, value in data.items():            if value[""package""] in packs:                packs[value[""package""]][""links""][key] = value        return packs",gets a complete data representation.,"def get_complete_data(self, queue=Destination.QUEUE):        """"""        gets a complete data representation.        """"""        queue = queue.value        data = self.pyload.db.get_all_links(queue)        packs = self.pyload.db.get_all_packages(queue)        data.update((x.id, x.to_db_dict()[x.id]) for x in self.cache.values())        for x in self.package_cache.values():            if x.queue != queue or x.id not in packs:                continue            packs[x.id].update(x.to_dict()[x.id])        for key, value in data.items():            if value[""package""] in packs:                packs[value[""package""]][""links""][key] = value        return packs

gets a complete data representation.",f167390c-4a04-4401-b308-577f84cc5506
managers,file_manager.py,get_info_data,112,123,"def get_info_data(self, queue=Destination.QUEUE):                queue = queue.value        packs = self.pyload.db.get_all_packages(queue)        for x in self.package_cache.values():            if x.queue != queue or x.id not in packs:                continue            packs[x.id].update(x.to_dict()[x.id])        return packs",gets a data representation without links.,"def get_info_data(self, queue=Destination.QUEUE):        """"""        gets a data representation without links.        """"""        queue = queue.value        packs = self.pyload.db.get_all_packages(queue)        for x in self.package_cache.values():            if x.queue != queue or x.id not in packs:                continue            packs[x.id].update(x.to_dict()[x.id])        return packs

gets a data representation without links.",2cbceef5-a686-41c5-aad7-a06fe3e0b7b0
managers,file_manager.py,add_links,127,139,"def add_links(self, urls, package):                self.pyload.addon_manager.dispatch_event(""links_added"", urls, package)        data = self.pyload.plugin_manager.parse_urls(urls)        self.pyload.db.add_links(data, package)        self.pyload.thread_manager.create_info_thread(data, package)        # TODO: change from reload_all event to package update event        self.pyload.event_manager.add_event(ReloadAllEvent(""collector""))",adds links.,"def add_links(self, urls, package):        """"""        adds links.        """"""        self.pyload.addon_manager.dispatch_event(""links_added"", urls, package)        data = self.pyload.plugin_manager.parse_urls(urls)        self.pyload.db.add_links(data, package)        self.pyload.thread_manager.create_info_thread(data, package)        # TODO: change from reload_all event to package update event        self.pyload.event_manager.add_event(ReloadAllEvent(""collector""))

adds links.",fd2b1f09-ff4a-4e1a-a037-fe9b892cbcbf
managers,file_manager.py,add_package,144,157,"def add_package(self, name, folder, queue=Destination.QUEUE):                last_id = self.pyload.db.add_package(name, folder, queue.value)        p = self.pyload.db.get_package(last_id)        e = InsertEvent(            ""pack"",            last_id,            p.order,            ""collector"" if queue is Destination.COLLECTOR else ""queue"",        )        self.pyload.event_manager.add_event(e)        return last_id","adds a package, default to link collector.","def add_package(self, name, folder, queue=Destination.QUEUE):        """"""        adds a package, default to link collector.        """"""        last_id = self.pyload.db.add_package(name, folder, queue.value)        p = self.pyload.db.get_package(last_id)        e = InsertEvent(            ""pack"",            last_id,            p.order,            ""collector"" if queue is Destination.COLLECTOR else ""queue"",        )        self.pyload.event_manager.add_event(e)        return last_id

adds a package, default to link collector.",c8687b0f-840e-424b-bb53-0496d31aadb0
managers,file_manager.py,delete_package,162,194,"def delete_package(self, id):                p = self.get_package(id)        if not p:            if id in self.package_cache:                del self.package_cache[id]            return        oldorder = p.order        queue = p.queue        e = RemoveEvent(""pack"", id, ""collector"" if not p.queue else ""queue"")        pyfiles = list(self.cache.values())        for pyfile in pyfiles:            if pyfile.packageid == id:                pyfile.abort_download()                pyfile.release()        self.pyload.db.delete_package(p)        self.pyload.event_manager.add_event(e)        self.pyload.addon_manager.dispatch_event(""package_deleted"", id)        if id in self.package_cache:            del self.package_cache[id]        packs = self.package_cache.values()        for pack in packs:            if pack.queue == queue and pack.order > oldorder:                pack.order -= 1                pack.notify_change()",delete package and all contained links.,"def delete_package(self, id):        """"""        delete package and all contained links.        """"""        p = self.get_package(id)        if not p:            if id in self.package_cache:                del self.package_cache[id]            return        oldorder = p.order        queue = p.queue        e = RemoveEvent(""pack"", id, ""collector"" if not p.queue else ""queue"")        pyfiles = list(self.cache.values())        for pyfile in pyfiles:            if pyfile.packageid == id:                pyfile.abort_download()                pyfile.release()        self.pyload.db.delete_package(p)        self.pyload.event_manager.add_event(e)        self.pyload.addon_manager.dispatch_event(""package_deleted"", id)        if id in self.package_cache:            del self.package_cache[id]        packs = self.package_cache.values()        for pack in packs:            if pack.queue == queue and pack.order > oldorder:                pack.order -= 1                pack.notify_change()

delete package and all contained links.",47f7f446-9729-473a-8e10-c5710a1e64ad
managers,file_manager.py,delete_link,199,230,"def delete_link(self, id):                f = self.get_file(id)        if not f:            return None        pid = f.packageid        e = RemoveEvent(""file"", id, ""collector"" if not f.package().queue else ""queue"")        oldorder = f.order        if id in self.pyload.thread_manager.processing_ids():            self.cache[id].abort_download()        if id in self.cache:            del self.cache[id]        self.pyload.db.delete_link(f)        self.pyload.event_manager.add_event(e)        p = self.get_package(pid)        if not len(p.get_children()):            p.delete()        pyfiles = self.cache.values()        for pyfile in pyfiles:            if pyfile.packageid == pid and pyfile.order > oldorder:                pyfile.order -= 1                pyfile.notify_change()",deletes links.,"def delete_link(self, id):        """"""        deletes links.        """"""        f = self.get_file(id)        if not f:            return None        pid = f.packageid        e = RemoveEvent(""file"", id, ""collector"" if not f.package().queue else ""queue"")        oldorder = f.order        if id in self.pyload.thread_manager.processing_ids():            self.cache[id].abort_download()        if id in self.cache:            del self.cache[id]        self.pyload.db.delete_link(f)        self.pyload.event_manager.add_event(e)        p = self.get_package(pid)        if not len(p.get_children()):            p.delete()        pyfiles = self.cache.values()        for pyfile in pyfiles:            if pyfile.packageid == pid and pyfile.order > oldorder:                pyfile.order -= 1                pyfile.notify_change()

deletes links.",6dc8e82a-082b-4d68-bc92-81ff4b22fa30
managers,file_manager.py,release_link,233,238,"def release_link(self, id):                if id in self.cache:            del self.cache[id]",removes pyfile from cache.,"def release_link(self, id):        """"""        removes pyfile from cache.        """"""        if id in self.cache:            del self.cache[id]

removes pyfile from cache.",59def596-4124-447f-9b58-8f251d210b07
managers,file_manager.py,release_package,241,246,"def release_package(self, id):                if id in self.package_cache:            del self.package_cache[id]",removes package from cache.,"def release_package(self, id):        """"""        removes package from cache.        """"""        if id in self.package_cache:            del self.package_cache[id]

removes package from cache.",caa9b8ff-18cd-40ef-b942-b25b37fe5272
managers,file_manager.py,update_link,249,258,"def update_link(self, pyfile):                self.pyload.db.update_link(pyfile)        e = UpdateEvent(            ""file"", pyfile.id, ""collector"" if not pyfile.package().queue else ""queue""        )        self.pyload.event_manager.add_event(e)",updates link.,"def update_link(self, pyfile):        """"""        updates link.        """"""        self.pyload.db.update_link(pyfile)        e = UpdateEvent(            ""file"", pyfile.id, ""collector"" if not pyfile.package().queue else ""queue""        )        self.pyload.event_manager.add_event(e)

updates link.",a68cf68c-8caf-443c-808c-447724b15c3d
managers,file_manager.py,update_package,261,268,"def update_package(self, pypack):                self.pyload.db.update_package(pypack)        e = UpdateEvent(""pack"", pypack.id, ""collector"" if not pypack.queue else ""queue"")        self.pyload.event_manager.add_event(e)",updates a package.,"def update_package(self, pypack):        """"""        updates a package.        """"""        self.pyload.db.update_package(pypack)        e = UpdateEvent(""pack"", pypack.id, ""collector"" if not pypack.queue else ""queue"")        self.pyload.event_manager.add_event(e)

updates a package.",9a5585fd-e722-4179-a123-d8ffc4145ad6
managers,file_manager.py,get_package,271,278,"def get_package(self, id):                if id in self.package_cache:            return self.package_cache[id]        else:            return self.pyload.db.get_package(id)",return package instance.,"def get_package(self, id):        """"""        return package instance.        """"""        if id in self.package_cache:            return self.package_cache[id]        else:            return self.pyload.db.get_package(id)

return package instance.",5c04f9f8-5451-45c1-bdb1-6a58e17cd0d5
managers,file_manager.py,get_package_data,281,304,"def get_package_data(self, id):                pack = self.get_package(id)        if not pack:            return None        pack = pack.to_dict()[id]        data = self.pyload.db.get_package_data(id)        tmplist = []        cache = list(self.cache.values())        for x in cache:            if int(x.to_db_dict()[x.id][""package""]) == int(id):                tmplist.append((x.id, x.to_db_dict()[x.id]))        data.update(tmplist)        pack[""links""] = data        return pack",returns dict with package information.,"def get_package_data(self, id):        """"""        returns dict with package information.        """"""        pack = self.get_package(id)        if not pack:            return None        pack = pack.to_dict()[id]        data = self.pyload.db.get_package_data(id)        tmplist = []        cache = list(self.cache.values())        for x in cache:            if int(x.to_db_dict()[x.id][""package""]) == int(id):                tmplist.append((x.id, x.to_db_dict()[x.id]))        data.update(tmplist)        pack[""links""] = data        return pack

returns dict with package information.",e9c8e3e7-42da-4b3d-b819-d46bf1a2e40d
managers,file_manager.py,get_file_data,307,314,"def get_file_data(self, id):                if id in self.cache:            return self.cache[id].to_db_dict()        return self.pyload.db.get_link_data(id)",returns dict with file information.,"def get_file_data(self, id):        """"""        returns dict with file information.        """"""        if id in self.cache:            return self.cache[id].to_db_dict()        return self.pyload.db.get_link_data(id)

returns dict with file information.",e3052e1b-2c3e-4c51-a738-b44fdd0e0916
managers,file_manager.py,get_file,317,324,"def get_file(self, id):                if id in self.cache:            return self.cache[id]        else:            return self.pyload.db.get_file(id)",returns pyfile instance.,"def get_file(self, id):        """"""        returns pyfile instance.        """"""        if id in self.cache:            return self.cache[id]        else:            return self.pyload.db.get_file(id)

returns pyfile instance.",e72f5734-ae98-4781-88fa-3e389aae2e54
managers,file_manager.py,get_job,328,368,"def get_job(self, occupied):                # TODO: clean mess        # TODO: improve selection of valid jobs        if occupied in self.job_cache:            if self.job_cache[occupied]:                id = self.job_cache[occupied].pop()                if id == ""empty"":                    pyfile = None                    self.job_cache[occupied].append(""empty"")                else:                    pyfile = self.get_file(id)            else:                jobs = self.pyload.db.get_job(occupied)                jobs.reverse()                if not jobs:                    self.job_cache[occupied].append(""empty"")                    pyfile = None                else:                    self.job_cache[occupied].extend(jobs)                    pyfile = self.get_file(self.job_cache[occupied].pop())        else:            self.job_cache = {}  #: better not caching too much            jobs = self.pyload.db.get_job(occupied)            jobs.reverse()            self.job_cache[occupied] = jobs            if not jobs:                self.job_cache[occupied].append(""empty"")                pyfile = None            else:                pyfile = self.get_file(self.job_cache[occupied].pop())            # TODO: maybe the new job has to be approved...        # pyfile = self.get_file(self.job_cache[occ].pop())        return pyfile",get suitable job.,"def get_job(self, occupied):        """"""        get suitable job.        """"""        # TODO: clean mess        # TODO: improve selection of valid jobs        if occupied in self.job_cache:            if self.job_cache[occupied]:                id = self.job_cache[occupied].pop()                if id == ""empty"":                    pyfile = None                    self.job_cache[occupied].append(""empty"")                else:                    pyfile = self.get_file(id)            else:                jobs = self.pyload.db.get_job(occupied)                jobs.reverse()                if not jobs:                    self.job_cache[occupied].append(""empty"")                    pyfile = None                else:                    self.job_cache[occupied].extend(jobs)                    pyfile = self.get_file(self.job_cache[occupied].pop())        else:            self.job_cache = {}  #: better not caching too much            jobs = self.pyload.db.get_job(occupied)            jobs.reverse()            self.job_cache[occupied] = jobs            if not jobs:                self.job_cache[occupied].append(""empty"")                pyfile = None            else:                pyfile = self.get_file(self.job_cache[occupied].pop())            # TODO: maybe the new job has to be approved...        # pyfile = self.get_file(self.job_cache[occ].pop())        return pyfile

get suitable job.",a2b425b7-e81b-4770-8d3e-5eb206d8e73e
managers,file_manager.py,get_decrypt_job,371,390,"def get_decrypt_job(self):                if ""decrypt"" in self.job_cache:            return None        plugins = tuple(            chain(                self.pyload.plugin_manager.decrypter_plugins.keys(),                self.pyload.plugin_manager.container_plugins.keys(),            )        )        jobs = self.pyload.db.get_plugin_job(plugins)        if jobs:            return self.get_file(jobs[0])        else:            self.job_cache[""decrypt""] = ""empty""            return None",return job for decrypting.,"def get_decrypt_job(self):        """"""        return job for decrypting.        """"""        if ""decrypt"" in self.job_cache:            return None        plugins = tuple(            chain(                self.pyload.plugin_manager.decrypter_plugins.keys(),                self.pyload.plugin_manager.container_plugins.keys(),            )        )        jobs = self.pyload.db.get_plugin_job(plugins)        if jobs:            return self.get_file(jobs[0])        else:            self.job_cache[""decrypt""] = ""empty""            return None

return job for decrypting.",07759076-f14b-4631-bd8e-78b3bf059f76
managers,file_manager.py,get_file_count,392,399,def get_file_count(self):                if self.filecount == -1:            self.filecount = self.pyload.db.filecount(1)        return self.filecount,returns number of files.,"def get_file_count(self):        """"""        returns number of files.        """"""        if self.filecount == -1:            self.filecount = self.pyload.db.filecount(1)        return self.filecount

returns number of files.",697f6207-809a-4e13-8eb7-46356107bd79
managers,file_manager.py,get_queue_count,401,408,"def get_queue_count(self, force=False):                if self.queuecount == -1 or force:            self.queuecount = self.pyload.db.queuecount(1)        return self.queuecount",number of files that have to be processed.,"def get_queue_count(self, force=False):        """"""        number of files that have to be processed.        """"""        if self.queuecount == -1 or force:            self.queuecount = self.pyload.db.queuecount(1)        return self.queuecount

number of files that have to be processed.",4eeaebbd-d68e-4aa7-9717-227394f0db5b
managers,file_manager.py,check_all_links_finished,410,419,"def check_all_links_finished(self):                if not self.get_queue_count(True):            self.pyload.addon_manager.dispatch_event(""all_downloads_finished"")            self.pyload.log.debug(""All downloads finished"")            return True        return False",checks if all files are finished and dispatch event.,"def check_all_links_finished(self):        """"""        checks if all files are finished and dispatch event.        """"""        if not self.get_queue_count(True):            self.pyload.addon_manager.dispatch_event(""all_downloads_finished"")            self.pyload.log.debug(""All downloads finished"")            return True        return False

checks if all files are finished and dispatch event.",a7ee5e0a-47b7-4fab-82a4-df7ee9349658
managers,file_manager.py,check_all_links_processed,421,434,"def check_all_links_processed(self, fid):                # reset count so statistic will update (this is called when dl was processed)        self.reset_count()        if not self.pyload.db.processcount(1, fid):            self.pyload.addon_manager.dispatch_event(""all_downloads_processed"")            self.pyload.log.debug(""All downloads processed"")            return True        return False","checks if all files was processed and pyload would idle now, needs fid which
will be ignored when counting.","def check_all_links_processed(self, fid):        """"""        checks if all files was processed and pyload would idle now, needs fid which        will be ignored when counting.        """"""        # reset count so statistic will update (this is called when dl was processed)        self.reset_count()        if not self.pyload.db.processcount(1, fid):            self.pyload.addon_manager.dispatch_event(""all_downloads_processed"")            self.pyload.log.debug(""All downloads processed"")            return True        return False

checks if all files was processed and pyload would idle now, needs fid which
will be ignored when counting.",4a7731cd-9ca8-4a8d-a5e6-6da7d05057cc
managers,file_manager.py,reset_count,436,437,def reset_count(self):        self.queuecount = -1,,def reset_count(self):        self.queuecount = -1,2bcab7f4-bd36-491e-9057-18d9416ada1f
managers,file_manager.py,restart_package,441,458,"def restart_package(self, id):                pyfiles = list(self.cache.values())        for pyfile in pyfiles:            if pyfile.packageid == id:                self.restart_file(pyfile.id)        self.pyload.db.restart_package(id)        if id in self.package_cache:            self.package_cache[id].set_finished = False        e = UpdateEvent(            ""pack"", id, ""collector"" if not self.get_package(id).queue else ""queue""        )        self.pyload.event_manager.add_event(e)",restart package.,"def restart_package(self, id):        """"""        restart package.        """"""        pyfiles = list(self.cache.values())        for pyfile in pyfiles:            if pyfile.packageid == id:                self.restart_file(pyfile.id)        self.pyload.db.restart_package(id)        if id in self.package_cache:            self.package_cache[id].set_finished = False        e = UpdateEvent(            ""pack"", id, ""collector"" if not self.get_package(id).queue else ""queue""        )        self.pyload.event_manager.add_event(e)

restart package.",cc566acc-496e-4e70-9352-14b908698c43
managers,file_manager.py,restart_file,462,479,"def restart_file(self, id):                if id in self.cache:            self.cache[id].status = 3            self.cache[id].name = self.cache[id].url            self.cache[id].error = """"            self.cache[id].abort_download()        self.pyload.db.restart_file(id)        e = UpdateEvent(            ""file"",            id,            ""collector"" if not self.get_file(id).package().queue else ""queue"",        )        self.pyload.event_manager.add_event(e)",restart file.,"def restart_file(self, id):        """"""        restart file.        """"""        if id in self.cache:            self.cache[id].status = 3            self.cache[id].name = self.cache[id].url            self.cache[id].error = """"            self.cache[id].abort_download()        self.pyload.db.restart_file(id)        e = UpdateEvent(            ""file"",            id,            ""collector"" if not self.get_file(id).package().queue else ""queue"",        )        self.pyload.event_manager.add_event(e)

restart file.",1405e53f-6374-4b9d-a139-4a7e7545ab71
managers,file_manager.py,set_package_location,483,514,"def set_package_location(self, id, queue):                queue = queue.value        p = self.pyload.db.get_package(id)        oldorder = p.order        e = RemoveEvent(""pack"", id, ""collector"" if not p.queue else ""queue"")        self.pyload.event_manager.add_event(e)        self.pyload.db.clear_package_order(p)        p = self.pyload.db.get_package(id)        p.queue = queue        self.pyload.db.update_package(p)        self.pyload.db.reorder_package(p, -1, True)        packs = self.package_cache.values()        for pack in packs:            if pack.queue != queue and pack.order > oldorder:                pack.order -= 1                pack.notify_change()        self.pyload.db.commit()        self.release_package(id)        p = self.get_package(id)        e = InsertEvent(""pack"", id, p.order, ""collector"" if not p.queue else ""queue"")        self.pyload.event_manager.add_event(e)",push package to queue.,"def set_package_location(self, id, queue):        """"""        push package to queue.        """"""        queue = queue.value        p = self.pyload.db.get_package(id)        oldorder = p.order        e = RemoveEvent(""pack"", id, ""collector"" if not p.queue else ""queue"")        self.pyload.event_manager.add_event(e)        self.pyload.db.clear_package_order(p)        p = self.pyload.db.get_package(id)        p.queue = queue        self.pyload.db.update_package(p)        self.pyload.db.reorder_package(p, -1, True)        packs = self.package_cache.values()        for pack in packs:            if pack.queue != queue and pack.order > oldorder:                pack.order -= 1                pack.notify_change()        self.pyload.db.commit()        self.release_package(id)        p = self.get_package(id)        e = InsertEvent(""pack"", id, p.order, ""collector"" if not p.queue else ""queue"")        self.pyload.event_manager.add_event(e)

push package to queue.",d6e46b54-2913-417c-8bce-d9652b2a0f84
managers,file_manager.py,reorder_package,518,542,"def reorder_package(self, id, position):        p = self.get_package(id)        e = RemoveEvent(""pack"", id, ""collector"" if not p.queue else ""queue"")        self.pyload.event_manager.add_event(e)        self.pyload.db.reorder_package(p, position)        packs = self.package_cache.values()        for pack in packs:            if pack.queue != p.queue or pack.order < 0 or pack == p:                continue            if p.order > position:                if pack.order >= position and pack.order < p.order:                    pack.order += 1                    pack.notify_change()            elif p.order < position:                if pack.order <= position and pack.order > p.order:                    pack.order -= 1                    pack.notify_change()        p.order = position        self.pyload.db.commit()        e = InsertEvent(""pack"", id, position, ""collector"" if not p.queue else ""queue"")        self.pyload.event_manager.add_event(e)",,"def reorder_package(self, id, position):        p = self.get_package(id)        e = RemoveEvent(""pack"", id, ""collector"" if not p.queue else ""queue"")        self.pyload.event_manager.add_event(e)        self.pyload.db.reorder_package(p, position)        packs = self.package_cache.values()        for pack in packs:            if pack.queue != p.queue or pack.order < 0 or pack == p:                continue            if p.order > position:                if pack.order >= position and pack.order < p.order:                    pack.order += 1                    pack.notify_change()            elif p.order < position:                if pack.order <= position and pack.order > p.order:                    pack.order -= 1                    pack.notify_change()        p.order = position        self.pyload.db.commit()        e = InsertEvent(""pack"", id, position, ""collector"" if not p.queue else ""queue"")        self.pyload.event_manager.add_event(e)",9adc4d51-f3c2-4747-9a05-59c480adf1da
managers,file_manager.py,reorder_file,546,583,"def reorder_file(self, id, position):        f = self.get_file_data(id)        f = f[id]        e = RemoveEvent(            ""file"",            id,            ""collector"" if not self.get_package(f[""package""]).queue else ""queue"",        )        self.pyload.event_manager.add_event(e)        self.pyload.db.reorder_link(f, position)        pyfiles = self.cache.values()        for pyfile in pyfiles:            if pyfile.packageid != f[""package""] or pyfile.order < 0:                continue            if f[""order""] > position:                if pyfile.order >= position and pyfile.order < f[""order""]:                    pyfile.order += 1                    pyfile.notify_change()            elif f[""order""] < position:                if pyfile.order <= position and pyfile.order > f[""order""]:                    pyfile.order -= 1                    pyfile.notify_change()        if id in self.cache:            self.cache[id].order = position        self.pyload.db.commit()        e = InsertEvent(            ""file"",            id,            position,            ""collector"" if not self.get_package(f[""package""]).queue else ""queue"",        )        self.pyload.event_manager.add_event(e)",,"def reorder_file(self, id, position):        f = self.get_file_data(id)        f = f[id]        e = RemoveEvent(            ""file"",            id,            ""collector"" if not self.get_package(f[""package""]).queue else ""queue"",        )        self.pyload.event_manager.add_event(e)        self.pyload.db.reorder_link(f, position)        pyfiles = self.cache.values()        for pyfile in pyfiles:            if pyfile.packageid != f[""package""] or pyfile.order < 0:                continue            if f[""order""] > position:                if pyfile.order >= position and pyfile.order < f[""order""]:                    pyfile.order += 1                    pyfile.notify_change()            elif f[""order""] < position:                if pyfile.order <= position and pyfile.order > f[""order""]:                    pyfile.order -= 1                    pyfile.notify_change()        if id in self.cache:            self.cache[id].order = position        self.pyload.db.commit()        e = InsertEvent(            ""file"",            id,            position,            ""collector"" if not self.get_package(f[""package""]).queue else ""queue"",        )        self.pyload.event_manager.add_event(e)",d89437af-94d1-4be6-bb35-c298197ddbb5
managers,file_manager.py,update_file_info,586,594,"def update_file_info(self, data, pid):                self.pyload.db.update_link_info(data)        e = UpdateEvent(            ""pack"", pid, ""collector"" if not self.get_package(pid).queue else ""queue""        )        self.pyload.event_manager.add_event(e)","updates file info (name, size, status, url)","def update_file_info(self, data, pid):        """"""        updates file info (name, size, status, url)        """"""        self.pyload.db.update_link_info(data)        e = UpdateEvent(            ""pack"", pid, ""collector"" if not self.get_package(pid).queue else ""queue""        )        self.pyload.event_manager.add_event(e)

updates file info (name, size, status, url)",5ea95d69-88bd-426b-876e-405bf9721e5b
managers,file_manager.py,check_package_finished,596,607,"def check_package_finished(self, pyfile):                ids = self.pyload.db.get_unfinished(pyfile.packageid)        if not ids or (pyfile.id in ids and len(ids) == 1):            if not pyfile.package().set_finished:                self.pyload.log.info(                    self._(""Package finished: {}"").format(pyfile.package().name)                )                self.pyload.addon_manager.package_finished(pyfile.package())                pyfile.package().set_finished = True",checks if package is finished and calls addon_manager.,"def check_package_finished(self, pyfile):        """"""        checks if package is finished and calls addon_manager.        """"""        ids = self.pyload.db.get_unfinished(pyfile.packageid)        if not ids or (pyfile.id in ids and len(ids) == 1):            if not pyfile.package().set_finished:                self.pyload.log.info(                    self._(""Package finished: {}"").format(pyfile.package().name)                )                self.pyload.addon_manager.package_finished(pyfile.package())                pyfile.package().set_finished = True

checks if package is finished and calls addon_manager.",81cf4747-4ef7-4f50-9117-db2a3a1da98b
managers,file_manager.py,recheck_package,609,621,"def recheck_package(self, pid):                data = self.pyload.db.get_package_data(pid)        urls = []        for pyfile in data.values():            if pyfile[""status""] not in (0, 12, 13):                urls.append((pyfile[""url""], pyfile[""plugin""]))        self.pyload.thread_manager.create_info_thread(urls, pid)",recheck links in package.,"def recheck_package(self, pid):        """"""        recheck links in package.        """"""        data = self.pyload.db.get_package_data(pid)        urls = []        for pyfile in data.values():            if pyfile[""status""] not in (0, 12, 13):                urls.append((pyfile[""url""], pyfile[""plugin""]))        self.pyload.thread_manager.create_info_thread(urls, pid)

recheck links in package.",8c8b6beb-d605-497f-9efe-beccd4234831
managers,file_manager.py,delete_finished_links,625,644,def delete_finished_links(self):                old_packs = self.get_info_data(Destination.QUEUE)        old_packs.update(self.get_info_data(Destination.COLLECTOR))        self.pyload.db.delete_finished()        new_packs = self.pyload.db.get_all_packages(0)        new_packs.update(self.pyload.db.get_all_packages(1))        # get new packages only from db        deleted = []        for id in old_packs.keys():            if id not in new_packs:                deleted.append(id)                self.delete_package(int(id))        return deleted,"deletes finished links and packages, return deleted packages.","def delete_finished_links(self):        """"""        deletes finished links and packages, return deleted packages.        """"""        old_packs = self.get_info_data(Destination.QUEUE)        old_packs.update(self.get_info_data(Destination.COLLECTOR))        self.pyload.db.delete_finished()        new_packs = self.pyload.db.get_all_packages(0)        new_packs.update(self.pyload.db.get_all_packages(1))        # get new packages only from db        deleted = []        for id in old_packs.keys():            if id not in new_packs:                deleted.append(id)                self.delete_package(int(id))        return deleted

deletes finished links and packages, return deleted packages.",519fb5b3-3cc6-494e-941b-f95a527f4c31
managers,file_manager.py,restart_failed,648,652,def restart_failed(self):                self.pyload.db.restart_failed(),restart all failed links.,"def restart_failed(self):        """"""        restart all failed links.        """"""        self.pyload.db.restart_failed()

restart all failed links.",fe4edd14-487c-45cd-b344-10cf13f11123
managers,plugin_manager.py,__init__,20,36,"def __init__(self, core):        self.pyload = core        self._ = core._        userplugins_dir = os.path.join(self.pyload.userdir, *self.USERROOT.split("".""))        os.makedirs(userplugins_dir, exist_ok=True)        try:            with open(os.path.join(userplugins_dir, ""__init__.py""), mode=""wb""):                pass        except OSError:            pass        # add USERROOT to sys.path        sys.path.append(self.pyload.userdir)        # register for import addon        sys.meta_path.insert(0, self)",,"def __init__(self, core):        self.pyload = core        self._ = core._        userplugins_dir = os.path.join(self.pyload.userdir, *self.USERROOT.split("".""))        os.makedirs(userplugins_dir, exist_ok=True)        try:            with open(os.path.join(userplugins_dir, ""__init__.py""), mode=""wb""):                pass        except OSError:            pass        # add USERROOT to sys.path        sys.path.append(self.pyload.userdir)        # register for import addon        sys.meta_path.insert(0, self)",32d926dd-42d5-474d-920f-2d864dc0039e
managers,plugin_manager.py,find_spec,38,66,"def find_spec(self, fullname, path, target=None):        split = fullname.split(""."")        if fullname.startswith(self.ROOT) or fullname.startswith(self.USERROOT):            is_userimport = 1 if fullname.startswith(self.USERROOT) else 0  # used as bool and int            if len(split) == 4 - is_userimport:                plugin_subfolder, plugin_name = split[2 - is_userimport:4 - is_userimport]                if plugin_subfolder != ""base"" and plugin_subfolder[-1] == ""s"":                    plugin_type = plugin_subfolder[:-1]  #: remove trailing plural ""s"" character                else:                    plugin_type = plugin_subfolder                plugins = self.pyload.plugin_manager.plugins                if plugin_type in plugins and plugin_name in plugins[plugin_type]:                    newname = None                    # imported from pyLoad, but user-plugin is a newer version                    if not is_userimport and plugins[plugin_type][plugin_name][""user""]:                        newname = fullname.replace(self.ROOT, self.USERROOT)                    # imported from userplugins but user-plugin does not exist or pyLoad's version is newer                    elif is_userimport and not plugins[plugin_type][plugin_name][""user""]:                        newname = fullname.replace(self.USERROOT, self.ROOT)                    if newname is not None:                        self.pyload.log.debug(""Redirected import {} -> {}"".format(fullname, newname))                        spec = importlib.util.find_spec(newname)                        spec.loader = self                        return spec        # return None to tell the python this finder can't find the module        return None",,"def find_spec(self, fullname, path, target=None):        split = fullname.split(""."")        if fullname.startswith(self.ROOT) or fullname.startswith(self.USERROOT):            is_userimport = 1 if fullname.startswith(self.USERROOT) else 0  # used as bool and int            if len(split) == 4 - is_userimport:                plugin_subfolder, plugin_name = split[2 - is_userimport:4 - is_userimport]                if plugin_subfolder != ""base"" and plugin_subfolder[-1] == ""s"":                    plugin_type = plugin_subfolder[:-1]  #: remove trailing plural ""s"" character                else:                    plugin_type = plugin_subfolder                plugins = self.pyload.plugin_manager.plugins                if plugin_type in plugins and plugin_name in plugins[plugin_type]:                    newname = None                    # imported from pyLoad, but user-plugin is a newer version                    if not is_userimport and plugins[plugin_type][plugin_name][""user""]:                        newname = fullname.replace(self.ROOT, self.USERROOT)                    # imported from userplugins but user-plugin does not exist or pyLoad's version is newer                    elif is_userimport and not plugins[plugin_type][plugin_name][""user""]:                        newname = fullname.replace(self.USERROOT, self.ROOT)                    if newname is not None:                        self.pyload.log.debug(""Redirected import {} -> {}"".format(fullname, newname))                        spec = importlib.util.find_spec(newname)                        spec.loader = self                        return spec        # return None to tell the python this finder can't find the module        return None",09a549e4-859c-457f-a6c5-3c5111222e08
managers,plugin_manager.py,create_module,69,70,def create_module(spec):        return importlib.import_module(spec.name),,def create_module(spec):        return importlib.import_module(spec.name),99cc061e-8187-4bdd-b8a0-79a8aa96e551
managers,plugin_manager.py,exec_module,73,74,def exec_module(module):        pass,,def exec_module(module):        pass,895c0e86-8eea-42fb-ae12-1bdf4f42b76b
managers,plugin_manager.py,__init__,95,114,"def __init__(self, core):        self.pyload = core        self._ = core._        self.plugins = {}        self.account_plugins = []        self.addon_plugins = []        self.anticaptcha_plugins = []        self.container_plugins = []        self.decrypter_plugins = []        self.downloader_plugins = []        self.extractor_plugins = []        self.base_plugins = []        self.import_redirector = ImportRedirector(core)        self.create_index()        # save generated config        self.pyload.config.save_config(self.pyload.config.plugin, self.pyload.config.pluginpath)",,"def __init__(self, core):        self.pyload = core        self._ = core._        self.plugins = {}        self.account_plugins = []        self.addon_plugins = []        self.anticaptcha_plugins = []        self.container_plugins = []        self.decrypter_plugins = []        self.downloader_plugins = []        self.extractor_plugins = []        self.base_plugins = []        self.import_redirector = ImportRedirector(core)        self.create_index()        # save generated config        self.pyload.config.save_config(self.pyload.config.plugin, self.pyload.config.pluginpath)",a5baff2a-1d78-48ae-a22f-0d975512e83f
managers,plugin_manager.py,create_index,116,179,"def create_index(self):                def merge(dst, src, overwrite=False):                        for name in src:                if name in dst:                    if overwrite:                        dst[name].update(src[name])                    else:                        for k in set(src[name].keys()) - set(dst[name].keys()):                            dst[name][k] = src[name][k]                else:                    dst[name] = src[name]        self.pyload.log.debug(""Indexing plugins..."")        self.decrypter_plugins, config = self.parse(""decrypters"", pattern=True)        self.plugins[""decrypter""] = self.decrypter_plugins        default_config = config        self.container_plugins, config = self.parse(""containers"", pattern=True)        self.plugins[""container""] = self.container_plugins        merge(default_config, config)        self.downloader_plugins, config = self.parse(""downloaders"", pattern=True)        self.plugins[""downloader""] = self.downloader_plugins        merge(default_config, config)        self.addon_plugins, config = self.parse(""addons"")        self.plugins[""addon""] = self.addon_plugins        merge(default_config, config)        self.anticaptcha_plugins, config = self.parse(""anticaptchas"")        self.plugins[""anticaptcha""] = self.anticaptcha_plugins        merge(default_config, config)        self.extractor_plugins, config = self.parse(""extractors"")        self.plugins[""extractor""] = self.extractor_plugins        merge(default_config, config)        self.account_plugins, config = self.parse(""accounts"")        self.plugins[""account""] = self.account_plugins        merge(default_config, config)        self.base_plugins, config = self.parse(""base"")        self.plugins[""base""] = self.base_plugins        merge(default_config, config)        for name, config in default_config.items():            desc = config.pop(""desc"", """")            config = [[k] + list(v) for k, v in config.items()]            try:                self.pyload.config.add_plugin_config(name, config, desc)            except Exception:                self.pyload.log.error(                    self._(""Invalid config in {}: {}"").format(name, config),                    exc_info=self.pyload.debug > 1,                    stack_info=self.pyload.debug > 2,                )",create information for all plugins available.,"def create_index(self):        """"""        create information for all plugins available.        """"""        def merge(dst, src, overwrite=False):            """"""            merge dict of dicts.            """"""            for name in src:                if name in dst:                    if overwrite:                        dst[name].update(src[name])                    else:                        for k in set(src[name].keys()) - set(dst[name].keys()):                            dst[name][k] = src[name][k]                else:                    dst[name] = src[name]        self.pyload.log.debug(""Indexing plugins..."")        self.decrypter_plugins, config = self.parse(""decrypters"", pattern=True)        self.plugins[""decrypter""] = self.decrypter_plugins        default_config = config        self.container_plugins, config = self.parse(""containers"", pattern=True)        self.plugins[""container""] = self.container_plugins        merge(default_config, config)        self.downloader_plugins, config = self.parse(""downloaders"", pattern=True)        self.plugins[""downloader""] = self.downloader_plugins        merge(default_config, config)        self.addon_plugins, config = self.parse(""addons"")        self.plugins[""addon""] = self.addon_plugins        merge(default_config, config)        self.anticaptcha_plugins, config = self.parse(""anticaptchas"")        self.plugins[""anticaptcha""] = self.anticaptcha_plugins        merge(default_config, config)        self.extractor_plugins, config = self.parse(""extractors"")        self.plugins[""extractor""] = self.extractor_plugins        merge(default_config, config)        self.account_plugins, config = self.parse(""accounts"")        self.plugins[""account""] = self.account_plugins        merge(default_config, config)        self.base_plugins, config = self.parse(""base"")        self.plugins[""base""] = self.base_plugins        merge(default_config, config)        for name, config in default_config.items():            desc = config.pop(""desc"", """")            config = [[k] + list(v) for k, v in config.items()]            try:                self.pyload.config.add_plugin_config(name, config, desc)            except Exception:                self.pyload.log.error(                    self._(""Invalid config in {}: {}"").format(name, config),                    exc_info=self.pyload.debug > 1,                    stack_info=self.pyload.debug > 2,                )

create information for all plugins available.",de725996-3d89-453c-9eb6-000abe0d855f
managers,plugin_manager.py,parse,181,314,"def parse(self, folder, pattern=False, home={}):                plugins = {}        if home:            pfolder = os.path.join(self.pyload.userdir, ""plugins"", folder)            os.makedirs(pfolder, exist_ok=True)            try:                with open(os.path.join(pfolder, ""__init__.py""), mode=""wb""):                    pass            except OSError:                pass        else:            pfolder = os.path.join(PKGDIR, ""plugins"", folder)        configs = {}        for entry in os.listdir(pfolder):            if (                os.path.isfile(os.path.join(pfolder, entry)) and entry.endswith("".py"")            ) and not entry.startswith(""_""):                with open(os.path.join(pfolder, entry), encoding=""utf-8-sig"") as data:                    content = data.read()                name = entry[:-3]  #: Trim ending "".py""                # m_pyver = self._RE_PYLOAD_VERSION.search(content)                # if m_pyver is None:                #     self.pyload.log.debug(                #         f""__pyload_version__ not found in plugin {name}""                #     )                # else:                #     pyload_version = m_pyver.group(1)                #     requires_version = f""{pyload_version}.0""                #     requires_version_info = semver.parse_version_info(requires_version)                #     if self.pyload.version_info.major:                #         core_version = self.pyload.version_info.major                #         plugin_version = requires_version_info.major                #     else:                #         core_version = self.pyload.version_info.minor                #         plugin_version = requires_version_info.minor                #     if core_version > plugin_version:                #         self.pyload.log.warning(                #             self._(                #                 ""Plugin {} not compatible with current pyLoad version""                #             ).format(name)                #         )                #         continue                m_ver = self._RE_VERSION.search(content)                if m_ver is None:                    self.pyload.log.debug(f""__version__ not found in plugin {name}"")                    version = 0                else:                    version = float(m_ver.group(1))                # home contains plugins from pyload root                if isinstance(home, dict) and name in home:                    if home[name][""v""] >= version:                        continue                plugins[name] = {}                plugins[name][""v""] = version                # was the plugin is loaded from user directory?                plugins[name][""user""] = True if home else False                plugins[name][""name""] = name                plugins[name][""folder""] = folder                if pattern:                    m_pat = self._RE_PATTERN.search(content)                    pattern = r""^unmachtable$"" if m_pat is None else m_pat.group(1)                    plugins[name][""pattern""] = pattern                    try:                        plugins[name][""re""] = re.compile(pattern)                    except re.error:                        plugins[name][""re""] = re.compile(r""(?!.*)"")                        self.pyload.log.error(                            self._(""{} has a invalid pattern"").format(name)                        )                # internals have no config                if folder == ""base"":                    self.pyload.config.delete_config(name)                    continue                m_desc = self._RE_DESC.search(content)                desc = """" if m_desc is None else m_desc.group(1)                config = self._RE_CONFIG.findall(content)                if not config:                    new_config = {""enabled"": [""bool"", ""Activated"", False], ""desc"": desc}                    configs[name] = new_config                    continue                config = literal_eval(                    config[0].strip().replace(""\n"", """").replace(""\r"", """")                )                if isinstance(config, list) and all(                    isinstance(c, tuple) for c in config                ):                    config = {x[0]: x[1:] for x in config}                else:                    self.pyload.log.error(                        self._(""Invalid config in {}: {}"").format(name, config)                    )                    continue                if folder == ""addons"" and ""enabled"" not in config:                    config[""enabled""] = [""bool"", ""Activated"", False]                config[""desc""] = desc                configs[name] = config        if not home:            temp_plugins, temp_configs = self.parse(folder, pattern, plugins or True)            plugins.update(temp_plugins)            configs.update(temp_configs)        return plugins, configs","returns dict with information
home contains parsed plugins from pyload.

{
name : {path, version, config, (pattern, re), (plugin, class)}
}","def parse(self, folder, pattern=False, home={}):        """"""        returns dict with information        home contains parsed plugins from pyload.        {        name : {path, version, config, (pattern, re), (plugin, class)}        }        """"""        plugins = {}        if home:            pfolder = os.path.join(self.pyload.userdir, ""plugins"", folder)            os.makedirs(pfolder, exist_ok=True)            try:                with open(os.path.join(pfolder, ""__init__.py""), mode=""wb""):                    pass            except OSError:                pass        else:            pfolder = os.path.join(PKGDIR, ""plugins"", folder)        configs = {}        for entry in os.listdir(pfolder):            if (                os.path.isfile(os.path.join(pfolder, entry)) and entry.endswith("".py"")            ) and not entry.startswith(""_""):                with open(os.path.join(pfolder, entry), encoding=""utf-8-sig"") as data:                    content = data.read()                name = entry[:-3]  #: Trim ending "".py""                # m_pyver = self._RE_PYLOAD_VERSION.search(content)                # if m_pyver is None:                #     self.pyload.log.debug(                #         f""__pyload_version__ not found in plugin {name}""                #     )                # else:                #     pyload_version = m_pyver.group(1)                #     requires_version = f""{pyload_version}.0""                #     requires_version_info = semver.parse_version_info(requires_version)                #     if self.pyload.version_info.major:                #         core_version = self.pyload.version_info.major                #         plugin_version = requires_version_info.major                #     else:                #         core_version = self.pyload.version_info.minor                #         plugin_version = requires_version_info.minor                #     if core_version > plugin_version:                #         self.pyload.log.warning(                #             self._(                #                 ""Plugin {} not compatible with current pyLoad version""                #             ).format(name)                #         )                #         continue                m_ver = self._RE_VERSION.search(content)                if m_ver is None:                    self.pyload.log.debug(f""__version__ not found in plugin {name}"")                    version = 0                else:                    version = float(m_ver.group(1))                # home contains plugins from pyload root                if isinstance(home, dict) and name in home:                    if home[name][""v""] >= version:                        continue                plugins[name] = {}                plugins[name][""v""] = version                # was the plugin is loaded from user directory?                plugins[name][""user""] = True if home else False                plugins[name][""name""] = name                plugins[name][""folder""] = folder                if pattern:                    m_pat = self._RE_PATTERN.search(content)                    pattern = r""^unmachtable$"" if m_pat is None else m_pat.group(1)                    plugins[name][""pattern""] = pattern                    try:                        plugins[name][""re""] = re.compile(pattern)                    except re.error:                        plugins[name][""re""] = re.compile(r""(?!.*)"")                        self.pyload.log.error(                            self._(""{} has a invalid pattern"").format(name)                        )                # internals have no config                if folder == ""base"":                    self.pyload.config.delete_config(name)                    continue                m_desc = self._RE_DESC.search(content)                desc = """" if m_desc is None else m_desc.group(1)                config = self._RE_CONFIG.findall(content)                if not config:                    new_config = {""enabled"": [""bool"", ""Activated"", False], ""desc"": desc}                    configs[name] = new_config                    continue                config = literal_eval(                    config[0].strip().replace(""\n"", """").replace(""\r"", """")                )                if isinstance(config, list) and all(                    isinstance(c, tuple) for c in config                ):                    config = {x[0]: x[1:] for x in config}                else:                    self.pyload.log.error(                        self._(""Invalid config in {}: {}"").format(name, config)                    )                    continue                if folder == ""addons"" and ""enabled"" not in config:                    config[""enabled""] = [""bool"", ""Activated"", False]                config[""desc""] = desc                configs[name] = config        if not home:            temp_plugins, temp_configs = self.parse(folder, pattern, plugins or True)            plugins.update(temp_plugins)            configs.update(temp_configs)        return plugins, configs

returns dict with information
home contains parsed plugins from pyload.

{
name : {path, version, config, (pattern, re), (plugin, class)}
}",55b909f2-e92a-4986-a2dd-1afbca5c5403
managers,plugin_manager.py,parse_urls,316,351,"def parse_urls(self, urls):                last = (None, {})        res = []  #: tuples of (url, plugin)        for url in urls:            if type(url) not in (                str,                bytes,                memoryview,            ):  #: check memoryview (as py2 buffer)                continue            found = False            # NOTE: E1136: Value 'last' is unsubscriptable (unsubscriptable-object)            if last != (None, {}) and last[1][""re""].match(url):                res.append((url, last[0]))                continue            for name, value in chain(                self.decrypter_plugins.items(),                self.downloader_plugins.items(),                self.container_plugins.items(),            ):                if value[""re""].match(url):                    res.append((url, name))                    last = (name, value)                    found = True                    break            if not found:                res.append((url, ""DefaultPlugin""))        return res",parse plugins for given list of urls.,"def parse_urls(self, urls):        """"""        parse plugins for given list of urls.        """"""        last = (None, {})        res = []  #: tuples of (url, plugin)        for url in urls:            if type(url) not in (                str,                bytes,                memoryview,            ):  #: check memoryview (as py2 buffer)                continue            found = False            # NOTE: E1136: Value 'last' is unsubscriptable (unsubscriptable-object)            if last != (None, {}) and last[1][""re""].match(url):                res.append((url, last[0]))                continue            for name, value in chain(                self.decrypter_plugins.items(),                self.downloader_plugins.items(),                self.container_plugins.items(),            ):                if value[""re""].match(url):                    res.append((url, name))                    last = (name, value)                    found = True                    break            if not found:                res.append((url, ""DefaultPlugin""))        return res

parse plugins for given list of urls.",43b0d130-2271-4000-a043-1ed3dd8afcbe
managers,plugin_manager.py,find_plugin,353,357,"def find_plugin(self, name, pluginlist=(""decrypter"", ""downloader"", ""container"")):        for ptype in pluginlist:            if name in self.plugins[ptype]:                return self.plugins[ptype][name], ptype        return None, None",,"def find_plugin(self, name, pluginlist=(""decrypter"", ""downloader"", ""container"")):        for ptype in pluginlist:            if name in self.plugins[ptype]:                return self.plugins[ptype][name], ptype        return None, None",99c5b20d-3c1a-49b2-86dc-da4f792180aa
managers,plugin_manager.py,get_plugin,359,372,"def get_plugin(self, plugin_name, original=False):                plugin, plugin_type = self.find_plugin(plugin_name)        if not plugin:            self.pyload.log.warning(self._(""Plugin {} not found"").format(plugin_name))            plugin = self.downloader_plugins[""DefaultPlugin""]        if ""new_module"" in plugin and not original:            return plugin[""new_module""]        return self.load_module(plugin_type, plugin_name)",return plugin module from downloader|decrypter|container.,"def get_plugin(self, plugin_name, original=False):        """"""        return plugin module from downloader|decrypter|container.        """"""        plugin, plugin_type = self.find_plugin(plugin_name)        if not plugin:            self.pyload.log.warning(self._(""Plugin {} not found"").format(plugin_name))            plugin = self.downloader_plugins[""DefaultPlugin""]        if ""new_module"" in plugin and not original:            return plugin[""new_module""]        return self.load_module(plugin_type, plugin_name)

return plugin module from downloader|decrypter|container.",377330e4-1d1e-43d5-b9cb-b9f2253d003d
managers,plugin_manager.py,get_plugin_name,374,383,"def get_plugin_name(self, name):                plugin, plugin_type = self.find_plugin(name)        if ""new_name"" in plugin:            return plugin[""new_name""]        return name",used to obtain new name if other plugin was injected.,"def get_plugin_name(self, name):        """"""        used to obtain new name if other plugin was injected.        """"""        plugin, plugin_type = self.find_plugin(name)        if ""new_name"" in plugin:            return plugin[""new_name""]        return name

used to obtain new name if other plugin was injected.",fc26e3ef-bca6-49b5-84c3-d192fbfe69fc
managers,plugin_manager.py,load_module,385,411,"def load_module(self, module_type, module_name):                plugins = self.plugins[module_type]        if module_name in plugins:            if APPID in plugins[module_name]:                return plugins[module_name][APPID]  #: use cached module            try:                module_name = plugins[module_name][""name""]                module_folder = plugins[module_name][""folder""]                module_abs_name = f""{self.import_redirector.ROOT}{module_folder}.{module_name}""                module = importlib.import_module(module_abs_name)                plugins[module_name][APPID] = module  #: cache import, maybe unneeded                return module            except Exception as exc:                self.pyload.log.error(                    self._(""Error importing {name}: {msg}"").format(name=module_name, msg=exc),                    exc_info=self.pyload.debug > 1,                    stack_info=self.pyload.debug > 2,                )        else:            self.pyload.log.debug(f""Plugin {module_name} not found"")            self.pyload.log.debug(f""Available plugins : {plugins}"")","Returns loaded module for plugin.

:param module_type: plugin type, subfolder of pyload.plugins
:param module_name: plugin name","def load_module(self, module_type, module_name):        """"""        Returns loaded module for plugin.        :param module_type: plugin type, subfolder of pyload.plugins        :param module_name: plugin name        """"""        plugins = self.plugins[module_type]        if module_name in plugins:            if APPID in plugins[module_name]:                return plugins[module_name][APPID]  #: use cached module            try:                module_name = plugins[module_name][""name""]                module_folder = plugins[module_name][""folder""]                module_abs_name = f""{self.import_redirector.ROOT}{module_folder}.{module_name}""                module = importlib.import_module(module_abs_name)                plugins[module_name][APPID] = module  #: cache import, maybe unneeded                return module            except Exception as exc:                self.pyload.log.error(                    self._(""Error importing {name}: {msg}"").format(name=module_name, msg=exc),                    exc_info=self.pyload.debug > 1,                    stack_info=self.pyload.debug > 2,                )        else:            self.pyload.log.debug(f""Plugin {module_name} not found"")            self.pyload.log.debug(f""Available plugins : {plugins}"")

Returns loaded module for plugin.

:param module_type: plugin type, subfolder of pyload.plugins
:param module_name: plugin name",fc09d747-c22a-46b5-90e5-54a043d573d7
managers,plugin_manager.py,load_class,413,419,"def load_class(self, module_type, module_name):                module = self.load_module(module_type, module_name)        if module:            return getattr(module, module_name)",Returns the class of a plugin with the same name.,"def load_class(self, module_type, module_name):        """"""        Returns the class of a plugin with the same name.        """"""        module = self.load_module(module_type, module_name)        if module:            return getattr(module, module_name)

Returns the class of a plugin with the same name.",6548ed9d-92ce-48b9-9b45-403612c73547
managers,plugin_manager.py,get_account_plugins,421,425,def get_account_plugins(self):                return list(self.account_plugins.keys()),return list of account plugin names.,"def get_account_plugins(self):        """"""        return list of account plugin names.        """"""        return list(self.account_plugins.keys())

return list of account plugin names.",6619284c-6d7e-44c8-a3e8-9b31af7eb0c7
managers,plugin_manager.py,reload_plugins,427,515,"def reload_plugins(self, type_plugins):                def merge(dst, src, overwrite=False):                        for name in src:                if name in dst:                    if overwrite:                        dst[name].update(src[name])                    else:                        for k in set(src[name].keys()) - set(dst[name].keys()):                            dst[name][k] = src[name][k]                else:                    dst[name] = src[name]        if not type_plugins:            return False        self.pyload.log.debug(f""Request reload of plugins: {type_plugins}"")        as_dict = {}        for t, n in type_plugins:            if t in as_dict:                as_dict[t].append(n)            else:                as_dict[t] = [n]        # we do not reload addons or base, would cause too much side effects        if ""addon"" in as_dict or ""base"" in as_dict:            return False        for plugin_type in as_dict.keys():            for plugin_name in as_dict[plugin_type]:                if plugin_name in self.plugins[plugin_type]:                    if APPID in self.plugins[plugin_type][plugin_name]:                        self.pyload.log.debug(f""Reloading {plugin_name}"")                        importlib.reload(self.plugins[plugin_type][plugin_name][APPID])        # index creation        self.decrypter_plugins, config = self.parse(""decrypters"", pattern=True)        self.plugins[""decrypter""] = self.decrypter_plugins        default_config = config        self.container_plugins, config = self.parse(""containers"", pattern=True)        self.plugins[""container""] = self.container_plugins        merge(default_config, config)        self.downloader_plugins, config = self.parse(""downloaders"", pattern=True)        self.plugins[""downloader""] = self.downloader_plugins        merge(default_config, config)        temp, config = self.parse(""addons"")        merge(default_config, config)        self.anticaptcha_plugins, config = self.parse(""anticaptchas"")        self.plugins[""anticaptcha""] = self.anticaptcha_plugins        merge(default_config, config)        self.extractor_plugins, config = self.parse(""extractors"")        self.plugins[""extractor""] = self.extractor_plugins        merge(default_config, config)        self.account_plugins, config = self.parse(""accounts"")        self.plugins[""account""] = self.account_plugins        merge(default_config, config)        for name, config in default_config.items():            desc = config.pop(""desc"", """")            config = [[k] + list(v) for k, v in config.items()]            try:                self.pyload.config.add_plugin_config(name, config, desc)            except Exception:                self.pyload.log.error(                    self._(""Invalid config in {}: {}"").format(name, config),                    exc_info=self.pyload.debug > 1,                    stack_info=self.pyload.debug > 2,                )        if ""account"" in as_dict:  #: accounts needs to be reloaded            self.pyload.account_manager.init_plugins()            self.pyload.scheduler.add_job(                0, self.pyload.account_manager.get_account_infos            )        return True",reloads and reindex plugins.,"def reload_plugins(self, type_plugins):        """"""        reloads and reindex plugins.        """"""        def merge(dst, src, overwrite=False):            """"""            merge dict of dicts.            """"""            for name in src:                if name in dst:                    if overwrite:                        dst[name].update(src[name])                    else:                        for k in set(src[name].keys()) - set(dst[name].keys()):                            dst[name][k] = src[name][k]                else:                    dst[name] = src[name]        if not type_plugins:            return False        self.pyload.log.debug(f""Request reload of plugins: {type_plugins}"")        as_dict = {}        for t, n in type_plugins:            if t in as_dict:                as_dict[t].append(n)            else:                as_dict[t] = [n]        # we do not reload addons or base, would cause too much side effects        if ""addon"" in as_dict or ""base"" in as_dict:            return False        for plugin_type in as_dict.keys():            for plugin_name in as_dict[plugin_type]:                if plugin_name in self.plugins[plugin_type]:                    if APPID in self.plugins[plugin_type][plugin_name]:                        self.pyload.log.debug(f""Reloading {plugin_name}"")                        importlib.reload(self.plugins[plugin_type][plugin_name][APPID])        # index creation        self.decrypter_plugins, config = self.parse(""decrypters"", pattern=True)        self.plugins[""decrypter""] = self.decrypter_plugins        default_config = config        self.container_plugins, config = self.parse(""containers"", pattern=True)        self.plugins[""container""] = self.container_plugins        merge(default_config, config)        self.downloader_plugins, config = self.parse(""downloaders"", pattern=True)        self.plugins[""downloader""] = self.downloader_plugins        merge(default_config, config)        temp, config = self.parse(""addons"")        merge(default_config, config)        self.anticaptcha_plugins, config = self.parse(""anticaptchas"")        self.plugins[""anticaptcha""] = self.anticaptcha_plugins        merge(default_config, config)        self.extractor_plugins, config = self.parse(""extractors"")        self.plugins[""extractor""] = self.extractor_plugins        merge(default_config, config)        self.account_plugins, config = self.parse(""accounts"")        self.plugins[""account""] = self.account_plugins        merge(default_config, config)        for name, config in default_config.items():            desc = config.pop(""desc"", """")            config = [[k] + list(v) for k, v in config.items()]            try:                self.pyload.config.add_plugin_config(name, config, desc)            except Exception:                self.pyload.log.error(                    self._(""Invalid config in {}: {}"").format(name, config),                    exc_info=self.pyload.debug > 1,                    stack_info=self.pyload.debug > 2,                )        if ""account"" in as_dict:  #: accounts needs to be reloaded            self.pyload.account_manager.init_plugins()            self.pyload.scheduler.add_job(                0, self.pyload.account_manager.get_account_infos            )        return True

reloads and reindex plugins.",83b9bac8-78ed-4500-ad2f-698130c32f95
managers,thread_manager.py,__init__,27,60,"def __init__(self, core):                self.pyload = core        self._ = core._        self.threads = []  #: thread list        self.local_threads = []  #: addon+decrypter threads        self.pause = True        self.reconnecting = Event()        self.reconnecting.clear()        self.downloaded = 0  #: number of files downloaded since last cleanup        self.lock = Lock()        # some operations require to fetch url info from hoster, so we caching them so it wont be done twice        # contains a timestamp and will be purged after timeout        self.info_cache = {}        # pool of ids for online check        self.result_ids = 0        # threads which are fetching hoster results        self.info_results = {}        # timeout for cache purge        self.timestamp = 0        # pycurl.global_init(pycurl.GLOBAL_DEFAULT)        for i in range(self.pyload.config.get(""download"", ""max_downloads"")):            self.create_download_thread()",Constructor.,"def __init__(self, core):        """"""        Constructor.        """"""        self.pyload = core        self._ = core._        self.threads = []  #: thread list        self.local_threads = []  #: addon+decrypter threads        self.pause = True        self.reconnecting = Event()        self.reconnecting.clear()        self.downloaded = 0  #: number of files downloaded since last cleanup        self.lock = Lock()        # some operations require to fetch url info from hoster, so we caching them so it wont be done twice        # contains a timestamp and will be purged after timeout        self.info_cache = {}        # pool of ids for online check        self.result_ids = 0        # threads which are fetching hoster results        self.info_results = {}        # timeout for cache purge        self.timestamp = 0        # pycurl.global_init(pycurl.GLOBAL_DEFAULT)        for i in range(self.pyload.config.get(""download"", ""max_downloads"")):            self.create_download_thread()

Constructor.",69b2979d-efa1-49ac-879c-8c14653629af
managers,thread_manager.py,create_download_thread,62,67,def create_download_thread(self):                thread = DownloadThread(self)        self.threads.append(thread),create a download thread.,"def create_download_thread(self):        """"""        create a download thread.        """"""        thread = DownloadThread(self)        self.threads.append(thread)

create a download thread.",3dcb1f74-459a-4374-b174-ce14413c591c
managers,thread_manager.py,create_info_thread,69,76,"def create_info_thread(self, data, pid):                self.timestamp = time.time() + timedelta(minutes=5).total_seconds()        InfoThread(self, data, pid)","start a thread whichs fetches online status and other infos
data = [ .. () .. ]","def create_info_thread(self, data, pid):        """"""        start a thread whichs fetches online status and other infos        data = [ .. () .. ]        """"""        self.timestamp = time.time() + timedelta(minutes=5).total_seconds()        InfoThread(self, data, pid)

start a thread whichs fetches online status and other infos
data = [ .. () .. ]",90d34de5-de1a-44a7-a606-f995fe705a89
managers,thread_manager.py,create_result_thread,79,90,"def create_result_thread(self, data, add=False):                self.timestamp = time.time() + timedelta(minutes=5).total_seconds()        rid = self.result_ids        self.result_ids += 1        InfoThread(self, data, rid=rid, add=add)        return rid","creates a thread to fetch online status, returns result id.","def create_result_thread(self, data, add=False):        """"""        creates a thread to fetch online status, returns result id.        """"""        self.timestamp = time.time() + timedelta(minutes=5).total_seconds()        rid = self.result_ids        self.result_ids += 1        InfoThread(self, data, rid=rid, add=add)        return rid

creates a thread to fetch online status, returns result id.",4996f6d0-9faa-4cba-b251-3e48f1cae031
managers,thread_manager.py,get_info_result,93,104,"def get_info_result(self, rid):                self.timestamp = time.time() + timedelta(minutes=5).total_seconds()        if rid in self.info_results:            data = self.info_results[rid]            self.info_results[rid] = {}            return data        else:            return {}",returns result and clears it.,"def get_info_result(self, rid):        """"""        returns result and clears it.        """"""        self.timestamp = time.time() + timedelta(minutes=5).total_seconds()        if rid in self.info_results:            data = self.info_results[rid]            self.info_results[rid] = {}            return data        else:            return {}

returns result and clears it.",2bbdebe1-5375-483c-9c04-d20b899fd649
managers,thread_manager.py,set_info_results,107,108,"def set_info_results(self, rid, result):        self.info_results[rid].update(result)",,"def set_info_results(self, rid, result):        self.info_results[rid].update(result)",517b850e-911a-4602-b39b-8bb6d2597a3d
managers,thread_manager.py,get_active_files,110,118,"def get_active_files(self):        active = [            x.active for x in self.threads if x.active and isinstance(x.active, PyFile)        ]        for t in self.local_threads:            active.extend(t.get_active_files())        return active",,"def get_active_files(self):        active = [            x.active for x in self.threads if x.active and isinstance(x.active, PyFile)        ]        for t in self.local_threads:            active.extend(t.get_active_files())        return active",6e2c39ac-143c-47b8-9bb9-24ef516f3e9c
managers,thread_manager.py,processing_ids,120,124,def processing_ids(self):                return [x.id for x in self.get_active_files()],get an id list of all pyfiles processed.,"def processing_ids(self):        """"""        get an id list of all pyfiles processed.        """"""        return [x.id for x in self.get_active_files()]

get an id list of all pyfiles processed.",1241afea-ca7d-45b1-a94e-8e305c576353
managers,thread_manager.py,run,126,157,"def run(self):                try:            self.try_reconnect()        except Exception as exc:            self.pyload.log.error(                self._(""Reconnect Failed: {}"").format(exc),                exc_info=self.pyload.debug > 1,                stack_info=self.pyload.debug > 2,            )            self.reconnecting.clear()        self.check_thread_count()        try:            self.assign_job()        except Exception:            self.pyload.log.warning(                ""Assign job error"",                exc_info=self.pyload.debug > 1,                stack_info=self.pyload.debug > 2,            )            time.sleep(0.5)            # it may be failed non critical so we try it again            self.assign_job()        if (self.info_cache or self.info_results) and self.timestamp < time.time():            self.info_cache.clear()            self.info_results.clear()            self.pyload.log.debug(""Cleared Result cache"")",run all task which have to be done (this is for repetivive call by core),"def run(self):        """"""        run all task which have to be done (this is for repetivive call by core)        """"""        try:            self.try_reconnect()        except Exception as exc:            self.pyload.log.error(                self._(""Reconnect Failed: {}"").format(exc),                exc_info=self.pyload.debug > 1,                stack_info=self.pyload.debug > 2,            )            self.reconnecting.clear()        self.check_thread_count()        try:            self.assign_job()        except Exception:            self.pyload.log.warning(                ""Assign job error"",                exc_info=self.pyload.debug > 1,                stack_info=self.pyload.debug > 2,            )            time.sleep(0.5)            # it may be failed non critical so we try it again            self.assign_job()        if (self.info_cache or self.info_results) and self.timestamp < time.time():            self.info_cache.clear()            self.info_results.clear()            self.pyload.log.debug(""Cleared Result cache"")

run all task which have to be done (this is for repetivive call by core)",13ff5e65-258b-45a7-aab1-5528a070be0f
managers,thread_manager.py,try_reconnect,160,215,"def try_reconnect(self):                if not (            self.pyload.config.get(""reconnect"", ""enabled"")            and self.pyload.api.is_time_reconnect()        ):            return False        active = [            x.active.plugin.want_reconnect and x.active.plugin.waiting            for x in self.threads            if x.active        ]        if not (0 < active.count(True) == len(active)):            return False        reconnect_script = self.pyload.config.get(""reconnect"", ""script"")        if not os.path.isfile(reconnect_script):            self.pyload.config.set(""reconnect"", ""enabled"", False)            self.pyload.log.warning(self._(""Reconnect script not found!""))            return        self.reconnecting.set()        # Do reconnect        self.pyload.log.info(self._(""Starting reconnect""))        while [x.active.plugin.waiting for x in self.threads if x.active].count(            True        ) != 0:            time.sleep(0.25)        old_ip = self.get_ip()        self.pyload.addon_manager.before_reconnect(old_ip)        self.pyload.log.debug(f""Old IP: {old_ip}"")        try:            subprocess.run(reconnect_script)        except Exception:            self.pyload.log.warning(self._(""Failed executing reconnect script!""))            self.pyload.config.set(""reconnect"", ""enabled"", False)            self.reconnecting.clear()            return        time.sleep(1)        ip = self.get_ip()        self.pyload.addon_manager.after_reconnect(ip, old_ip)        self.pyload.log.info(self._(""Reconnected, new IP: {}"").format(ip))        self.reconnecting.clear()",checks if reconnect needed.,"def try_reconnect(self):        """"""        checks if reconnect needed.        """"""        if not (            self.pyload.config.get(""reconnect"", ""enabled"")            and self.pyload.api.is_time_reconnect()        ):            return False        active = [            x.active.plugin.want_reconnect and x.active.plugin.waiting            for x in self.threads            if x.active        ]        if not (0 < active.count(True) == len(active)):            return False        reconnect_script = self.pyload.config.get(""reconnect"", ""script"")        if not os.path.isfile(reconnect_script):            self.pyload.config.set(""reconnect"", ""enabled"", False)            self.pyload.log.warning(self._(""Reconnect script not found!""))            return        self.reconnecting.set()        # Do reconnect        self.pyload.log.info(self._(""Starting reconnect""))        while [x.active.plugin.waiting for x in self.threads if x.active].count(            True        ) != 0:            time.sleep(0.25)        old_ip = self.get_ip()        self.pyload.addon_manager.before_reconnect(old_ip)        self.pyload.log.debug(f""Old IP: {old_ip}"")        try:            subprocess.run(reconnect_script)        except Exception:            self.pyload.log.warning(self._(""Failed executing reconnect script!""))            self.pyload.config.set(""reconnect"", ""enabled"", False)            self.reconnecting.clear()            return        time.sleep(1)        ip = self.get_ip()        self.pyload.addon_manager.after_reconnect(ip, old_ip)        self.pyload.log.info(self._(""Reconnected, new IP: {}"").format(ip))        self.reconnecting.clear()

checks if reconnect needed.",ba4a1ace-7411-45df-9dee-e2f0030047b0
managers,thread_manager.py,get_ip,217,238,"def get_ip(self):                services = [            (""https://icanhazip.com/"", r""(\S+)""),            (""http://checkip.dyndns.org/"", r"".*Current IP Address: (\S+)</body>.*""),            (""https://ifconfig.io/ip"", r""(\S+)""),        ]        ip = """"        for i in range(10):            try:                sv = choice(services)                ip = get_url(sv[0])                ip = re.match(sv[1], ip).group(1)                break            except Exception:                ip = """"                time.sleep(1)        return ip",retrieve current ip.,"def get_ip(self):        """"""        retrieve current ip.        """"""        services = [            (""https://icanhazip.com/"", r""(\S+)""),            (""http://checkip.dyndns.org/"", r"".*Current IP Address: (\S+)</body>.*""),            (""https://ifconfig.io/ip"", r""(\S+)""),        ]        ip = """"        for i in range(10):            try:                sv = choice(services)                ip = get_url(sv[0])                ip = re.match(sv[1], ip).group(1)                break            except Exception:                ip = """"                time.sleep(1)        return ip

retrieve current ip.",d5d348f0-8679-461c-bebe-ae4bb219ff40
managers,thread_manager.py,check_thread_count,241,252,"def check_thread_count(self):                if len(self.threads) == self.pyload.config.get(""download"", ""max_downloads""):            return True        elif len(self.threads) < self.pyload.config.get(""download"", ""max_downloads""):            self.create_download_thread()        else:            free = [x for x in self.threads if not x.active]            if free:                free[0].put(""quit"")",checks if there are need for increasing or reducing thread count.,"def check_thread_count(self):        """"""        checks if there are need for increasing or reducing thread count.        """"""        if len(self.threads) == self.pyload.config.get(""download"", ""max_downloads""):            return True        elif len(self.threads) < self.pyload.config.get(""download"", ""max_downloads""):            self.create_download_thread()        else:            free = [x for x in self.threads if not x.active]            if free:                free[0].put(""quit"")

checks if there are need for increasing or reducing thread count.",e257928d-6bf4-42fe-8bbc-af63d5429c71
managers,thread_manager.py,assign_job,267,355,"def assign_job(self):                if self.pause or not self.pyload.api.is_time_download():            return        # if self.downloaded > 20:        #    if not self.clean_pycurl(): return        free_threads = [x for x in self.threads if not x.active]        inuse_plugins = set(            [                (x.active.pluginname, self.get_limit(x))                for x in self.threads                if x.active and x.active.has_plugin()            ]        )        # (pluginname, dl_limit, active_count)        inuse_plugins = [            (                x[0],                x[1],                len(                    [                        y                        for y in self.threads                        if y.active and y.active.pluginname == x[0]                    ]                ),            )            for x in inuse_plugins        ]        over_limit_plugins = [x[0] for x in inuse_plugins if x[2] >= x[1] > 0]        occupied_plugins = sorted(            [                x.active.pluginname                for x in self.threads                if x.active and x.active.has_plugin() and not x.active.plugin.multi_dl            ]            + over_limit_plugins        )        occupied_plugins = tuple(set(occupied_plugins))  # remove duplicates        job = self.pyload.files.get_job(occupied_plugins)        if job:            try:                job.init_plugin()            except Exception as exc:                self.pyload.log.critical(                    exc, exc_info=True, stack_info=self.pyload.debug > 2                )                job.set_status(""failed"")                job.error = str(exc)                job.release()                return            if job.plugin.__type__ == ""downloader"":                space_left = (                    fs.free_space(self.pyload.config.get(""general"", ""storage_folder""))                    >> 20                )                if space_left < self.pyload.config.get(""general"", ""min_free_space""):                    self.pyload.log.warning(self._(""Not enough space left on device""))                    self.pause = True                if free_threads and not self.pause:                    thread = free_threads[0]                    # self.downloaded += 1                    job.set_status(""starting"")                    thread.put(job)                else:                    # put job back                    if occupied_plugins not in self.pyload.files.job_cache:                        self.pyload.files.job_cache[occupied_plugins] = []                    self.pyload.files.job_cache[occupied_plugins].append(job.id)                    # check for decrypt jobs                    job = self.pyload.files.get_decrypt_job()                    if job:                        job.init_plugin()                        thread = DecrypterThread(self, job)            else:                thread = DecrypterThread(self, job)",assign a job to a thread if possible.,"def assign_job(self):        """"""        assign a job to a thread if possible.        """"""        if self.pause or not self.pyload.api.is_time_download():            return        # if self.downloaded > 20:        #    if not self.clean_pycurl(): return        free_threads = [x for x in self.threads if not x.active]        inuse_plugins = set(            [                (x.active.pluginname, self.get_limit(x))                for x in self.threads                if x.active and x.active.has_plugin()            ]        )        # (pluginname, dl_limit, active_count)        inuse_plugins = [            (                x[0],                x[1],                len(                    [                        y                        for y in self.threads                        if y.active and y.active.pluginname == x[0]                    ]                ),            )            for x in inuse_plugins        ]        over_limit_plugins = [x[0] for x in inuse_plugins if x[2] >= x[1] > 0]        occupied_plugins = sorted(            [                x.active.pluginname                for x in self.threads                if x.active and x.active.has_plugin() and not x.active.plugin.multi_dl            ]            + over_limit_plugins        )        occupied_plugins = tuple(set(occupied_plugins))  # remove duplicates        job = self.pyload.files.get_job(occupied_plugins)        if job:            try:                job.init_plugin()            except Exception as exc:                self.pyload.log.critical(                    exc, exc_info=True, stack_info=self.pyload.debug > 2                )                job.set_status(""failed"")                job.error = str(exc)                job.release()                return            if job.plugin.__type__ == ""downloader"":                space_left = (                    fs.free_space(self.pyload.config.get(""general"", ""storage_folder""))                    >> 20                )                if space_left < self.pyload.config.get(""general"", ""min_free_space""):                    self.pyload.log.warning(self._(""Not enough space left on device""))                    self.pause = True                if free_threads and not self.pause:                    thread = free_threads[0]                    # self.downloaded += 1                    job.set_status(""starting"")                    thread.put(job)                else:                    # put job back                    if occupied_plugins not in self.pyload.files.job_cache:                        self.pyload.files.job_cache[occupied_plugins] = []                    self.pyload.files.job_cache[occupied_plugins].append(job.id)                    # check for decrypt jobs                    job = self.pyload.files.get_decrypt_job()                    if job:                        job.init_plugin()                        thread = DecrypterThread(self, job)            else:                thread = DecrypterThread(self, job)

assign a job to a thread if possible.",3216c92a-a468-4663-80ef-ddd2331a1c90
managers,thread_manager.py,get_limit,357,380,"def get_limit(self, thread):        if thread.active.plugin.account:            account_limit = max(                int(                    thread.active.plugin.account.get_account_data(                        thread.active.plugin.account.user                    )[""options""].get(""limit_dl"", [""0""])[0]                ),                0,            )        else:            account_limit = 0        plugin_limit = (            max(thread.active.plugin.limit_dl, 0)            if hasattr(thread.active.plugin, ""limit_dl"")            else 0        )        if account_limit > 0 and plugin_limit > 0:            limit = min(account_limit, plugin_limit)        else:            limit = account_limit or plugin_limit        return limit",,"def get_limit(self, thread):        if thread.active.plugin.account:            account_limit = max(                int(                    thread.active.plugin.account.get_account_data(                        thread.active.plugin.account.user                    )[""options""].get(""limit_dl"", [""0""])[0]                ),                0,            )        else:            account_limit = 0        plugin_limit = (            max(thread.active.plugin.limit_dl, 0)            if hasattr(thread.active.plugin, ""limit_dl"")            else 0        )        if account_limit > 0 and plugin_limit > 0:            limit = min(account_limit, plugin_limit)        else:            limit = account_limit or plugin_limit        return limit",d2c87bc6-54d7-478d-a6b5-11c92e97b920
network,browser.py,__init__,12,23,"def __init__(self, bucket=None, options={}):        self.log = getLogger(APPID)        self.options = options  #: holds pycurl options        self.bucket = bucket        self.cj = None  #: needs to be set later        self.http = None        self._size = 0        self.renew_http_request()        self.dl = None",,"def __init__(self, bucket=None, options={}):        self.log = getLogger(APPID)        self.options = options  #: holds pycurl options        self.bucket = bucket        self.cj = None  #: needs to be set later        self.http = None        self._size = 0        self.renew_http_request()        self.dl = None",72a65fa4-87e0-451f-aa23-53f92da6b5a6
network,browser.py,renew_http_request,25,30,"def renew_http_request(self):        try:            self.http.close()        except Exception:            pass        self.http = HTTPRequest(self.cj, self.options)",,"def renew_http_request(self):        try:            self.http.close()        except Exception:            pass        self.http = HTTPRequest(self.cj, self.options)",ccf29d34-3677-4e50-996b-f33da1ba13a0
network,browser.py,set_last_url,32,33,"def set_last_url(self, val):        self.http.last_url = val",,"def set_last_url(self, val):        self.http.last_url = val",8295cbb7-5d31-432a-9f94-2f55c79da85a
network,browser.py,set_cookie_jar,41,43,"def set_cookie_jar(self, cj):        self.cj = cj        self.http.cj = cj",,"def set_cookie_jar(self, cj):        self.cj = cj        self.http.cj = cj",8f4269ea-918e-41eb-9b0a-8e1a6554d3ee
network,browser.py,speed,46,49,def speed(self):        if self.dl:            return self.dl.speed        return 0,,def speed(self):        if self.dl:            return self.dl.speed        return 0,cf625cfa-5c19-4a1f-bf90-cb2218b58f65
network,browser.py,size,52,57,def size(self):        if self._size:            return self._size        if self.dl:            return self.dl.size        return 0,,def size(self):        if self._size:            return self._size        if self.dl:            return self.dl.size        return 0,b05eda26-d855-4f35-a100-4e8a4da698ea
network,browser.py,arrived,60,63,def arrived(self):        if self.dl:            return self.dl.arrived        return 0,,def arrived(self):        if self.dl:            return self.dl.arrived        return 0,0ec27514-4333-4417-adc9-c51e2c3286b4
network,browser.py,percent,66,69,def percent(self):        if not self.size:            return 0        return (self.arrived * 100) // self.size,,def percent(self):        if not self.size:            return 0        return (self.arrived * 100) // self.size,5b9ecf55-7574-41b6-9e81-df671582925e
network,browser.py,clear_cookies,71,74,def clear_cookies(self):        if self.cj:            self.cj.clear()        self.http.clear_cookies(),,def clear_cookies(self):        if self.cj:            self.cj.clear()        self.http.clear_cookies(),85bef155-beee-4a09-b3d5-f03403dae3b5
network,browser.py,clear_referer,76,77,def clear_referer(self):        self.http.last_url = None,,def clear_referer(self):        self.http.last_url = None,9035db01-8bf4-4e14-b7d7-3a0566699035
network,browser.py,abort_downloads,79,83,def abort_downloads(self):        self.http.abort = True        if self.dl:            self._size = self.dl.size            self.dl.abort = True,,def abort_downloads(self):        self.http.abort = True        if self.dl:            self._size = self.dl.size            self.dl.abort = True,e1c43cdf-dc52-4261-8e1e-c494642fa465
network,browser.py,http_download,85,122,"def http_download(            self,            url,            filename,            size=0,            get={},            post={},            ref=True,            cookies=True,            chunks=1,            resume=False,            status_notify=None,            disposition=False,    ):                self._size = 0        self.dl = HTTPDownload(            url,            filename,            size=size,            get=get,            post=post,            referer=self.last_effective_url if ref else None,            cj=self.cj if cookies else None,            bucket=self.bucket,            options=self.options,            status_notify=status_notify,            disposition=disposition,        )        name = self.dl.download(chunks, resume)        self.http.code = self.dl.code        self._size = self.dl.size        self.dl = None        return name",this can also download ftp.,"def http_download(            self,            url,            filename,            size=0,            get={},            post={},            ref=True,            cookies=True,            chunks=1,            resume=False,            status_notify=None,            disposition=False,    ):        """"""        this can also download ftp.        """"""        self._size = 0        self.dl = HTTPDownload(            url,            filename,            size=size,            get=get,            post=post,            referer=self.last_effective_url if ref else None,            cj=self.cj if cookies else None,            bucket=self.bucket,            options=self.options,            status_notify=status_notify,            disposition=disposition,        )        name = self.dl.download(chunks, resume)        self.http.code = self.dl.code        self._size = self.dl.size        self.dl = None        return name

this can also download ftp.",bccfe782-e1c9-4edb-ab3b-895be5a6cf29
network,browser.py,load,124,128,"def load(self, *args, **kwargs):                return self.http.load(*args, **kwargs)",retrieves page.,"def load(self, *args, **kwargs):        """"""        retrieves page.        """"""        return self.http.load(*args, **kwargs)

retrieves page.",06b6ffc0-8f22-4512-bca0-c9a1d9037e91
network,browser.py,put_header,130,134,"def put_header(self, name, value):                self.http.put_header(name, value)",add a header to the request.,"def put_header(self, name, value):        """"""        add a header to the request.        """"""        self.http.put_header(name, value)

add a header to the request.",c61f71a5-579a-4dc3-886f-be049a8723f9
network,browser.py,add_auth,136,143,"def add_auth(self, pwd):                self.options[""auth""] = pwd        self.renew_http_request()","Adds user and pw for http auth.

:param pwd: string, user:password","def add_auth(self, pwd):        """"""        Adds user and pw for http auth.        :param pwd: string, user:password        """"""        self.options[""auth""] = pwd        self.renew_http_request()

Adds user and pw for http auth.

:param pwd: string, user:password",f00c9c78-740f-4b85-a161-4de747aac7b0
network,browser.py,remove_auth,145,148,"def remove_auth(self):        if ""auth"" in self.options:            del self.options[""auth""]        self.renew_http_request()",,"def remove_auth(self):        if ""auth"" in self.options:            del self.options[""auth""]        self.renew_http_request()",8b91f18c-1b15-49d6-95f6-9d55a2a38fe9
network,browser.py,set_option,150,154,"def set_option(self, name, value):                self.options[name] = value","Adds an option to the request, see HTTPRequest for existing ones.","def set_option(self, name, value):        """"""        Adds an option to the request, see HTTPRequest for existing ones.        """"""        self.options[name] = value

Adds an option to the request, see HTTPRequest for existing ones.",dcd741fe-58db-4015-8cb7-8a4ea9053106
network,browser.py,delete_option,156,158,"def delete_option(self, name):        if name in self.options:            del self.options[name]",,"def delete_option(self, name):        if name in self.options:            del self.options[name]",1f95f11c-db04-4f96-b4d3-a3bbd19a94ab
network,browser.py,clear_headers,160,161,def clear_headers(self):        self.http.clear_headers(),,def clear_headers(self):        self.http.clear_headers(),b322f529-e64b-4bd8-85cc-a2a8f94acc80
network,browser.py,close,163,173,"def close(self):                if hasattr(self, ""http""):            self.http.close()            del self.http        if hasattr(self, ""dl""):            del self.dl        if hasattr(self, ""cj""):            del self.cj",cleanup.,"def close(self):        """"""        cleanup.        """"""        if hasattr(self, ""http""):            self.http.close()            del self.http        if hasattr(self, ""dl""):            del self.dl        if hasattr(self, ""cj""):            del self.cj

cleanup.",ff621f72-3538-44b0-b611-0d86fc1b893a
network,bucket.py,__init__,13,17,def __init__(self):        self._rate = 0        self.token = 0        self.timestamp = time.time()        self.lock = Lock(),,def __init__(self):        self._rate = 0        self.token = 0        self.timestamp = time.time()        self.lock = Lock(),5a63488b-ef8f-4c2d-be4e-3d12d03507b8
network,bucket.py,__bool__,19,20,def __bool__(self):        return self._rate >= self.MIN_RATE,,def __bool__(self):        return self._rate >= self.MIN_RATE,d20075d4-e97f-4cdd-9a7e-30d7d61779df
network,bucket.py,set_rate,23,24,"def set_rate(self, rate):        self._rate = int(rate)",,"def set_rate(self, rate):        self._rate = int(rate)",9aaad76f-d8a2-4728-af99-576e6e837163
network,bucket.py,get_rate,26,27,def get_rate(self):        return self._rate,,def get_rate(self):        return self._rate,f300d664-ae9a-42a2-879b-42ad50666840
network,bucket.py,_calc_token,31,37,"def _calc_token(self):        if self.token >= self._rate:            return        now = time.time()        delta = self._rate * (now - self.timestamp)        self.token = min(self._rate, self.token + delta)        self.timestamp = now",,"def _calc_token(self):        if self.token >= self._rate:            return        now = time.time()        delta = self._rate * (now - self.timestamp)        self.token = min(self._rate, self.token + delta)        self.timestamp = now",20618567-e9fe-4c0b-a529-60d6b220a85f
network,bucket.py,consumed,40,49,"def consumed(self, amount):                if self.rate < self.MIN_RATE:            return 0  # NOTE: May become unresponsive otherwise        self._calc_token()        self.token -= amount        consumed = -self.token // self._rate if self.token < 0 else 0        return consumed","Return time the process have to sleep, after consumed specified amount.","def consumed(self, amount):        """"""        Return time the process have to sleep, after consumed specified amount.        """"""        if self.rate < self.MIN_RATE:            return 0  # NOTE: May become unresponsive otherwise        self._calc_token()        self.token -= amount        consumed = -self.token // self._rate if self.token < 0 else 0        return consumed

Return time the process have to sleep, after consumed specified amount.",8ecbf085-b1e1-4bba-9c50-49e16d61e95d
network,cookie_jar.py,__init__,8,11,"def __init__(self, pluginname, account=None):        self.cookies = {}        self.plugin = pluginname        self.account = account",,"def __init__(self, pluginname, account=None):        self.cookies = {}        self.plugin = pluginname        self.account = account",cd6c8629-eda7-49ae-8bdd-2f3933f6d016
network,cookie_jar.py,add_cookies,13,16,"def add_cookies(self, clist):        for c in clist:            name = c.split(""\t"")[5]            self.cookies[name] = c",,"def add_cookies(self, clist):        for c in clist:            name = c.split(""\t"")[5]            self.cookies[name] = c",dae6685f-9222-419c-a0bb-528eac963457
network,cookie_jar.py,get_cookies,18,19,def get_cookies(self):        return list(self.cookies.values()),,def get_cookies(self):        return list(self.cookies.values()),1140270b-4907-4a73-9d21-1afc2b7ba4c9
network,cookie_jar.py,parse_cookie,21,25,"def parse_cookie(self, name):        if name in self.cookies:            return self.cookies[name].split(""\t"")[6]        else:            return None",,"def parse_cookie(self, name):        if name in self.cookies:            return self.cookies[name].split(""\t"")[6]        else:            return None",31fe7300-acd2-45b3-85b0-0f69aec3971b
network,cookie_jar.py,get_cookie,27,28,"def get_cookie(self, name):        return self.parse_cookie(name)",,"def get_cookie(self, name):        return self.parse_cookie(name)",0a1f844f-362d-4558-a351-8030f476f72e
network,cookie_jar.py,set_cookie,30,40,"def set_cookie(        self,        domain,        name,        value,        path=""/"",        exp=time.time() + timedelta(days=31).total_seconds(),  #: 31 days retention    ):        self.cookies[            name        ] = f"".{domain}\tTRUE\t{path}\tFALSE\t{exp}\t{name}\t{value}""",,"def set_cookie(        self,        domain,        name,        value,        path=""/"",        exp=time.time() + timedelta(days=31).total_seconds(),  #: 31 days retention    ):        self.cookies[            name        ] = f"".{domain}\tTRUE\t{path}\tFALSE\t{exp}\t{name}\t{value}""",3ca02a87-d40c-430d-a3e7-b00fd5dd200d
network,cookie_jar.py,clear,42,43,def clear(self):        self.cookies = {},,def clear(self):        self.cookies = {},9c7b4649-bab0-4f36-880a-8ad88537cb2e
network,request_factory.py,__init__,16,27,"def __init__(self, core):        self.lock = Lock()        self.pyload = core        self._ = core._        self.bucket = Bucket()        self.update_bucket()        self.cookiejars = {}        # TODO: Rewrite...        global DEFAULT_REQUEST        if not DEFAULT_REQUEST:            DEFAULT_REQUEST = self",,"def __init__(self, core):        self.lock = Lock()        self.pyload = core        self._ = core._        self.bucket = Bucket()        self.update_bucket()        self.cookiejars = {}        # TODO: Rewrite...        global DEFAULT_REQUEST        if not DEFAULT_REQUEST:            DEFAULT_REQUEST = self",fddbc9aa-2b22-4320-978a-b0cbd3e1e566
network,request_factory.py,iface,29,30,"def iface(self):        return self.pyload.config.get(""download"", ""interface"")",,"def iface(self):        return self.pyload.config.get(""download"", ""interface"")",11ab922a-2b6f-4b14-adad-61d6a7db436a
network,request_factory.py,get_request,33,50,"def get_request(self, plugin_name, account=None, type=""HTTP"", **kwargs):        options = self.get_options()        options.update(kwargs)  #: submit kwargs as additional options        if type == ""XDCC"":            req = XDCCRequest(self.bucket, options)        else:            req = Browser(self.bucket, options)            if account:                cj = self.get_cookie_jar(plugin_name, account)            else:                cj = CookieJar(plugin_name)            req.set_cookie_jar(cj)        return req",,"def get_request(self, plugin_name, account=None, type=""HTTP"", **kwargs):        options = self.get_options()        options.update(kwargs)  #: submit kwargs as additional options        if type == ""XDCC"":            req = XDCCRequest(self.bucket, options)        else:            req = Browser(self.bucket, options)            if account:                cj = self.get_cookie_jar(plugin_name, account)            else:                cj = CookieJar(plugin_name)            req.set_cookie_jar(cj)        return req",ff515b9c-1424-4dd6-adbb-dc88e96edbbf
network,request_factory.py,get_http_request,52,58,"def get_http_request(self, **kwargs):                options = self.get_options()        options.update(kwargs)  #: submit kwargs as additional options        return HTTPRequest(CookieJar(None), options)","returns a http request, dont forget to close it !","def get_http_request(self, **kwargs):        """"""        returns a http request, dont forget to close it !        """"""        options = self.get_options()        options.update(kwargs)  #: submit kwargs as additional options        return HTTPRequest(CookieJar(None), options)

returns a http request, dont forget to close it !",ae4ff7ee-bebb-45b9-b404-72418d89fabd
network,request_factory.py,get_url,60,66,"def get_url(self, *args, **kwargs):                with HTTPRequest(None, self.get_options()) as h:            rep = h.load(*args, **kwargs)        return rep",see HTTPRequest for argument list.,"def get_url(self, *args, **kwargs):        """"""        see HTTPRequest for argument list.        """"""        with HTTPRequest(None, self.get_options()) as h:            rep = h.load(*args, **kwargs)        return rep

see HTTPRequest for argument list.",b9142616-a989-4634-bd6e-a2410f31e44b
network,request_factory.py,get_cookie_jar,68,75,"def get_cookie_jar(self, plugin_name, account=None):        if (plugin_name, account) in self.cookiejars:            return self.cookiejars[(plugin_name, account)]        cj = CookieJar(plugin_name, account)        if account:            self.cookiejars[(plugin_name, account)] = cj        return cj",,"def get_cookie_jar(self, plugin_name, account=None):        if (plugin_name, account) in self.cookiejars:            return self.cookiejars[(plugin_name, account)]        cj = CookieJar(plugin_name, account)        if account:            self.cookiejars[(plugin_name, account)] = cj        return cj",4b4a95b5-9396-4ba6-9edc-00398e7cfc34
network,request_factory.py,remove_cookie_jar,77,78,"def remove_cookie_jar(self, plugin_name, account):        self.cookiejars.pop((plugin_name, account), None)",,"def remove_cookie_jar(self, plugin_name, account):        self.cookiejars.pop((plugin_name, account), None)",70e80f69-875a-42a9-8a9f-b44a1c8b48a1
network,request_factory.py,get_proxies,80,101,"def get_proxies(self):                if not self.pyload.config.get(""proxy"", ""enabled""):            return {}        else:            proxy_type = self.pyload.config.get(""proxy"", ""type"")            socks_resolve_dns = self.pyload.config.get(""proxy"", ""socks_resolve_dns"")            proxy_host = self.pyload.config.get(""proxy"", ""host"")            proxy_port = self.pyload.config.get(""proxy"", ""port"")            proxy_username = self.pyload.config.get(""proxy"", ""username"") or None            proxy_password = self.pyload.config.get(""proxy"", ""password"") or None            return {                ""type"": proxy_type,                ""socks_resolve_dns"": socks_resolve_dns,                ""host"": proxy_host,                ""port"": proxy_port,                ""username"": proxy_username,                ""password"": proxy_password,            }",returns proxy related options.,"def get_proxies(self):        """"""        returns proxy related options.        """"""        if not self.pyload.config.get(""proxy"", ""enabled""):            return {}        else:            proxy_type = self.pyload.config.get(""proxy"", ""type"")            socks_resolve_dns = self.pyload.config.get(""proxy"", ""socks_resolve_dns"")            proxy_host = self.pyload.config.get(""proxy"", ""host"")            proxy_port = self.pyload.config.get(""proxy"", ""port"")            proxy_username = self.pyload.config.get(""proxy"", ""username"") or None            proxy_password = self.pyload.config.get(""proxy"", ""password"") or None            return {                ""type"": proxy_type,                ""socks_resolve_dns"": socks_resolve_dns,                ""host"": proxy_host,                ""port"": proxy_port,                ""username"": proxy_username,                ""password"": proxy_password,            }

returns proxy related options.",c2d172e6-d11b-43b8-a184-cda0680c705a
network,request_factory.py,get_options,103,112,"def get_options(self):                return {            ""interface"": self.iface(),            ""proxies"": self.get_proxies(),            ""ipv6"": self.pyload.config.get(""download"", ""ipv6""),            ""ssl_verify"": self.pyload.config.get(""general"", ""ssl_verify""),        }",returns options needed for pycurl.,"def get_options(self):        """"""        returns options needed for pycurl.        """"""        return {            ""interface"": self.iface(),            ""proxies"": self.get_proxies(),            ""ipv6"": self.pyload.config.get(""download"", ""ipv6""),            ""ssl_verify"": self.pyload.config.get(""general"", ""ssl_verify""),        }

returns options needed for pycurl.",674bc5a5-e349-490e-97f2-0b9985f74b34
network,request_factory.py,update_bucket,114,121,"def update_bucket(self):                if not self.pyload.config.get(""download"", ""limit_speed""):            self.bucket.set_rate(-1)        else:            self.bucket.set_rate(self.pyload.config.get(""download"", ""max_speed"") << 10)",set values in the bucket according to settings.,"def update_bucket(self):        """"""        set values in the bucket according to settings.        """"""        if not self.pyload.config.get(""download"", ""limit_speed""):            self.bucket.set_rate(-1)        else:            self.bucket.set_rate(self.pyload.config.get(""download"", ""max_speed"") << 10)

set values in the bucket according to settings.",f654d78f-2682-4d7e-ba2e-bff1c1054f91
network,request_factory.py,get_url,124,125,"def get_url(*args, **kwargs):    return DEFAULT_REQUEST.get_url(*args, **kwargs)",,"def get_url(*args, **kwargs):    return DEFAULT_REQUEST.get_url(*args, **kwargs)",df1e3548-df38-4a7b-a392-cb18376dab08
network,request_factory.py,get_request,128,129,"def get_request(*args, **kwargs):    return DEFAULT_REQUEST.get_http_request()",,"def get_request(*args, **kwargs):    return DEFAULT_REQUEST.get_http_request()",0260ca6e-7bf5-4c39-aa2c-e57b306495b2
http,exceptions.py,__init__,23,29,"def __init__(self, code, header="""", content=""""):        code = int(code)        response = http.client.responses.get(code, PROPRIETARY_RESPONSES.get(code, ""unknown error code""))        super().__init__(f""Bad server response: {code} {response}"")        self.code = code        self.header = header        self.content = content",,"def __init__(self, code, header="""", content=""""):        code = int(code)        response = http.client.responses.get(code, PROPRIETARY_RESPONSES.get(code, ""unknown error code""))        super().__init__(f""Bad server response: {code} {response}"")        self.code = code        self.header = header        self.content = content",b9b935d8-a7dd-4b7f-aa9a-bb01d9b4ac54
http,http_chunk.py,__init__,24,28,"def __init__(self, name):        self.name = os.fsdecode(name)        self.size = 0        self.resume = False        self.chunks = []",,"def __init__(self, name):        self.name = os.fsdecode(name)        self.size = 0        self.resume = False        self.chunks = []",78ad07c2-cd9d-4bdd-8dc8-f961b281437a
http,http_chunk.py,__repr__,30,35,"def __repr__(self):        ret = f""ChunkInfo: {self.name}, {self.size}\n""        for i, c in enumerate(self.chunks):            ret += f""{i}# {c[1]}\n""        return ret",,"def __repr__(self):        ret = f""ChunkInfo: {self.name}, {self.size}\n""        for i, c in enumerate(self.chunks):            ret += f""{i}# {c[1]}\n""        return ret",e66f5710-39f6-4277-9401-6768ab18a273
http,http_chunk.py,set_size,37,38,"def set_size(self, size):        self.size = int(size)",,"def set_size(self, size):        self.size = int(size)",f644dc8b-8480-4b5a-a921-992740416961
http,http_chunk.py,add_chunk,40,41,"def add_chunk(self, name, range):        self.chunks.append((name, range))",,"def add_chunk(self, name, range):        self.chunks.append((name, range))",4a604930-8c4a-40b5-b51f-49b0aee4bed3
http,http_chunk.py,clear,43,44,def clear(self):        self.chunks = [],,def clear(self):        self.chunks = [],340aafca-8662-4416-9703-970e36236a99
http,http_chunk.py,create_chunks,46,54,"def create_chunks(self, chunks):        self.clear()        chunk_size = self.size // chunks        current = 0        for i in range(chunks):            end = self.size - 1 if (i == chunks - 1) else current + chunk_size            self.add_chunk(f""{self.name}.chunk{i}"", (current, end))            current += chunk_size + 1",,"def create_chunks(self, chunks):        self.clear()        chunk_size = self.size // chunks        current = 0        for i in range(chunks):            end = self.size - 1 if (i == chunks - 1) else current + chunk_size            self.add_chunk(f""{self.name}.chunk{i}"", (current, end))            current += chunk_size + 1",ed863b3f-bfff-487a-951c-2f4f3845284d
http,http_chunk.py,save,56,64,"def save(self):        fs_name = f""{self.name}.chunks""        with open(fs_name, mode=""w"", encoding=""utf-8"", newline=""\n"") as fh:            fh.write(f""name:{self.name}\n"")            fh.write(f""size:{self.size}\n"")            for i, c in enumerate(self.chunks):                fh.write(f""#{i}:\n"")                fh.write(f""\tname:{c[0]}\n"")                fh.write(f""\trange:{c[1][0]}-{c[1][1]}\n"")",,"def save(self):        fs_name = f""{self.name}.chunks""        with open(fs_name, mode=""w"", encoding=""utf-8"", newline=""\n"") as fh:            fh.write(f""name:{self.name}\n"")            fh.write(f""size:{self.size}\n"")            for i, c in enumerate(self.chunks):                fh.write(f""#{i}:\n"")                fh.write(f""\tname:{c[0]}\n"")                fh.write(f""\trange:{c[1][0]}-{c[1][1]}\n"")",60c8616f-2517-4451-a5d2-872cd88664ab
http,http_chunk.py,load,67,96,"def load(name):        fs_name = f""{name}.chunks""        if not os.path.exists(fs_name):            raise IOError        with open(fs_name, encoding=""utf-8"") as fh:            name = fh.readline()[:-1]            size = fh.readline()[:-1]            if name.startswith(""name:"") and size.startswith(""size:""):                name = name[5:]                size = size[5:]            else:                fh.close()                raise WrongFormat            ci = ChunkInfo(name)            ci.loaded = True            ci.set_size(size)            while True:                if not fh.readline():  #: skip line                    break                name = fh.readline()[1:-1]                range = fh.readline()[1:-1]                if name.startswith(""name:"") and range.startswith(""range:""):                    name = name[5:]                    range = range[6:].split(""-"")                else:                    raise WrongFormat                ci.add_chunk(name, (int(range[0]), int(range[1])))        return ci",,"def load(name):        fs_name = f""{name}.chunks""        if not os.path.exists(fs_name):            raise IOError        with open(fs_name, encoding=""utf-8"") as fh:            name = fh.readline()[:-1]            size = fh.readline()[:-1]            if name.startswith(""name:"") and size.startswith(""size:""):                name = name[5:]                size = size[5:]            else:                fh.close()                raise WrongFormat            ci = ChunkInfo(name)            ci.loaded = True            ci.set_size(size)            while True:                if not fh.readline():  #: skip line                    break                name = fh.readline()[1:-1]                range = fh.readline()[1:-1]                if name.startswith(""name:"") and range.startswith(""range:""):                    name = name[5:]                    range = range[6:].split(""-"")                else:                    raise WrongFormat                ci.add_chunk(name, (int(range[0]), int(range[1])))        return ci",c050e486-333b-43af-a1e7-2355e4472f29
http,http_chunk.py,remove,98,101,"def remove(self):        fs_name = f""{self.name}.chunks""        if os.path.exists(fs_name):            os.remove(fs_name)",,"def remove(self):        fs_name = f""{self.name}.chunks""        if os.path.exists(fs_name):            os.remove(fs_name)",c08a8208-59af-4477-ae0c-23cce77f3e93
http,http_chunk.py,get_count,103,104,def get_count(self):        return len(self.chunks),,def get_count(self):        return len(self.chunks),04833d58-a83b-4bd7-ac20-080c9b1f8605
http,http_chunk.py,get_chunk_filename,106,107,"def get_chunk_filename(self, index):        return self.chunks[index][0]",,"def get_chunk_filename(self, index):        return self.chunks[index][0]",41388452-d571-4a19-8e3d-b2613bccd155
http,http_chunk.py,get_chunk_range,109,110,"def get_chunk_range(self, index):        return self.chunks[index][1]",,"def get_chunk_range(self, index):        return self.chunks[index][1]",fd487534-ae73-4014-83a7-f0f1f9500250
http,http_chunk.py,__init__,114,145,"def __init__(self, id, parent, range=None, resume=False):        self.id = id        self.p = parent  #: HTTPDownload instance        self.range = range  #: tuple (start, end)        self.resume = resume        self.log = parent.log        self.size = range[1] - range[0] if range else -1        self.arrived = 0        self.last_url = self.p.referer        self.code = 0  #: last http code, set by parent        self.aborted = False  # indicates that the chunk aborted gracefully        self.c = pycurl.Curl()        self.response_header = b""""        self.header_parsed = False  #: indicates if the header has been processed        self.fp = None  #: file handle        self.init_handle()        self.c.setopt(pycurl.ENCODING, None)  #: avoid pycurl error 61        self.set_interface(self.p.options)        self.BOMChecked = False  #: check and remove byte order mark        self.rep = None        self.sleep = 0.0        self.last_size = 0",,"def __init__(self, id, parent, range=None, resume=False):        self.id = id        self.p = parent  #: HTTPDownload instance        self.range = range  #: tuple (start, end)        self.resume = resume        self.log = parent.log        self.size = range[1] - range[0] if range else -1        self.arrived = 0        self.last_url = self.p.referer        self.code = 0  #: last http code, set by parent        self.aborted = False  # indicates that the chunk aborted gracefully        self.c = pycurl.Curl()        self.response_header = b""""        self.header_parsed = False  #: indicates if the header has been processed        self.fp = None  #: file handle        self.init_handle()        self.c.setopt(pycurl.ENCODING, None)  #: avoid pycurl error 61        self.set_interface(self.p.options)        self.BOMChecked = False  #: check and remove byte order mark        self.rep = None        self.sleep = 0.0        self.last_size = 0",3a034153-e477-417e-bba0-52ade1ed233d
http,http_chunk.py,__repr__,147,148,"def __repr__(self):        return f""<HTTPChunk id={self.id}, size={self.size}, arrived={self.arrived}>""",,"def __repr__(self):        return f""<HTTPChunk id={self.id}, size={self.size}, arrived={self.arrived}>""",47a6a3b3-7619-4d6e-bed2-c34f092e82b6
http,http_chunk.py,cj,151,152,def cj(self):        return self.p.cj,,def cj(self):        return self.p.cj,dd69dcea-1690-40c4-b728-10acfd7d08cc
http,http_chunk.py,format_range,154,168,"def format_range(self):        if self.id == len(self.p.info.chunks) - 1:  #: as last chunk don't set end range, so we get everything            end = """"            if self.resume:                start = self.arrived + self.range[0]            else:                start = self.range[0]        else:            end = min(self.range[1] + 1, self.p.size - 1)            if self.id == 0 and not self.resume:  #: special case for first chunk                start = 0            else:                start = self.arrived + self.range[0]        return f""{start}-{end}""",,"def format_range(self):        if self.id == len(self.p.info.chunks) - 1:  #: as last chunk don't set end range, so we get everything            end = """"            if self.resume:                start = self.arrived + self.range[0]            else:                start = self.range[0]        else:            end = min(self.range[1] + 1, self.p.size - 1)            if self.id == 0 and not self.resume:  #: special case for first chunk                start = 0            else:                start = self.arrived + self.range[0]        return f""{start}-{end}""",260e8d55-bfe6-4a17-9363-784bf17e58c3
http,http_chunk.py,get_handle,170,212,"def get_handle(self):                self.set_request_context(            self.p.url, self.p.get, self.p.post, self.p.referer, self.p.cj        )        self.c.setopt(pycurl.WRITEFUNCTION, self.write_body)        self.c.setopt(pycurl.HEADERFUNCTION, self.write_header)        # request all bytes, since some servers in russia seems to have a defect        # arithmetic unit        fs_name = self.p.info.get_chunk_filename(self.id)        if self.resume:            self.fp = open(fs_name, mode=""ab"")            self.arrived = self.fp.tell()            if not self.arrived:                self.arrived = os.stat(fs_name).st_size            if self.range:                #: do nothing if chunk already finished                if self.arrived + self.range[0] >= self.range[1]:                    return None                range = self.format_range()                self.log.debug(f""Chunk {self.id + 1} chunked with range {range}"")                self.c.setopt(pycurl.RANGE, range)            else:                self.log.debug(f""Resume File from {self.arrived}"")                self.c.setopt(pycurl.RESUME_FROM, self.arrived)        else:            if self.range:                range = self.format_range()                self.log.debug(f""Chunk {self.id + 1} chunked with range {range}"")                self.c.setopt(pycurl.RANGE, range)            self.fp = open(fs_name, mode=""wb"")        return self.c",returns a Curl handle ready to use for perform/multiperform.,"def get_handle(self):        """"""        returns a Curl handle ready to use for perform/multiperform.        """"""        self.set_request_context(            self.p.url, self.p.get, self.p.post, self.p.referer, self.p.cj        )        self.c.setopt(pycurl.WRITEFUNCTION, self.write_body)        self.c.setopt(pycurl.HEADERFUNCTION, self.write_header)        # request all bytes, since some servers in russia seems to have a defect        # arithmetic unit        fs_name = self.p.info.get_chunk_filename(self.id)        if self.resume:            self.fp = open(fs_name, mode=""ab"")            self.arrived = self.fp.tell()            if not self.arrived:                self.arrived = os.stat(fs_name).st_size            if self.range:                #: do nothing if chunk already finished                if self.arrived + self.range[0] >= self.range[1]:                    return None                range = self.format_range()                self.log.debug(f""Chunk {self.id + 1} chunked with range {range}"")                self.c.setopt(pycurl.RANGE, range)            else:                self.log.debug(f""Resume File from {self.arrived}"")                self.c.setopt(pycurl.RESUME_FROM, self.arrived)        else:            if self.range:                range = self.format_range()                self.log.debug(f""Chunk {self.id + 1} chunked with range {range}"")                self.c.setopt(pycurl.RANGE, range)            self.fp = open(fs_name, mode=""wb"")        return self.c

returns a Curl handle ready to use for perform/multiperform.",5350d616-7455-4150-ba0c-10cbe9f64bd8
http,http_chunk.py,write_header,214,227,"def write_header(self, buf):        self.response_header += buf        # TODO: forward headers?, this is possibly unneeded, when we just parse valid 200 headers        # as first chunk, we will parse the headers        if not self.range and self.response_header.endswith(b""\r\n\r\n""):            self.parse_header()        #: FTP file size parsing        elif not self.range and buf.startswith(b""150"") and b""data connection"" in buf:            size = re.search(rb""(\d+) bytes"", buf)            if size:                self.p.size = int(size.group(1))                self.p.chunk_support = True            self.header_parsed = True",,"def write_header(self, buf):        self.response_header += buf        # TODO: forward headers?, this is possibly unneeded, when we just parse valid 200 headers        # as first chunk, we will parse the headers        if not self.range and self.response_header.endswith(b""\r\n\r\n""):            self.parse_header()        #: FTP file size parsing        elif not self.range and buf.startswith(b""150"") and b""data connection"" in buf:            size = re.search(rb""(\d+) bytes"", buf)            if size:                self.p.size = int(size.group(1))                self.p.chunk_support = True            self.header_parsed = True",3ab30149-3158-44ab-8707-b1e5742a2a4d
http,http_chunk.py,write_body,229,260,"def write_body(self, buf):        #: ignore BOM, it confuses unrar        if not self.BOMChecked:            if buf[:3] == codecs.BOM_UTF8:                buf = buf[3:]            self.BOMChecked = True        size = len(buf)        self.arrived += size        self.fp.write(buf)        if self.p.bucket:            time.sleep(self.p.bucket.consumed(size))        else:            # Avoid small buffers, increasing sleep time slowly if buffer size gets smaller            # otherwise reduce sleep time percentual (values are based on tests)            # So in general cpu time is saved without reducing bandwidth too much            if size < self.last_size:                self.sleep += 0.002            else:                self.sleep *= 0.7            self.last_size = size            time.sleep(self.sleep)        if self.range and self.arrived > self.size:            self.aborted = True  #: tell parent to ignore the pycurl Exception            return 0",,"def write_body(self, buf):        #: ignore BOM, it confuses unrar        if not self.BOMChecked:            if buf[:3] == codecs.BOM_UTF8:                buf = buf[3:]            self.BOMChecked = True        size = len(buf)        self.arrived += size        self.fp.write(buf)        if self.p.bucket:            time.sleep(self.p.bucket.consumed(size))        else:            # Avoid small buffers, increasing sleep time slowly if buffer size gets smaller            # otherwise reduce sleep time percentual (values are based on tests)            # So in general cpu time is saved without reducing bandwidth too much            if size < self.last_size:                self.sleep += 0.002            else:                self.sleep *= 0.7            self.last_size = size            time.sleep(self.sleep)        if self.range and self.arrived > self.size:            self.aborted = True  #: tell parent to ignore the pycurl Exception            return 0",cf3fd247-6e2d-4c0d-be0a-ad897538858c
http,http_chunk.py,parse_header,262,360,"def parse_header(self):                location = None        for orgline in self.response_header.splitlines():            try:                orgline = orgline.decode(""utf-8"")            except UnicodeDecodeError:                try:                    orgline = orgline.decode(""iso-8859-1"")                except UnicodeDecodeError:                        continue            line = orgline.strip().lower()            if line.startswith(""accept-ranges"") and ""bytes"" in line:                self.p.chunk_support = True            elif line.startswith(""location""):                location = orgline.split("":"", 1)[1].strip()            elif line.startswith(""content-disposition""):                disposition_value = orgline.split("":"", 1)[1].strip()                disposition_type, disposition_params = parse_header_line(disposition_value)                fname = None                if 'filename*' in disposition_params:                    fname = disposition_params['filename*']                    m = re.search(r'=\?([^?]+)\?([QB])\?([^?]*)\?=', fname, re.I)  #: rfc2047                    if m is not None:                        data, encoding = parse_mime_header(fname)[0]                        try:                            fname = data.decode(encoding)                        except LookupError:                            self.log.warning(f""Content-Disposition: | error: No decoder found for {encoding}"")                            fname = None                        except UnicodeEncodeError:                            self.log.warning(f""Content-Disposition: | error: Error when decoding string from {encoding}"")                            fname = None                    else:                        m = re.search(r'(.+?)\'(.*)\'(.+)', fname)                        if m is not None:                            encoding, lang, data = m.groups()                            try:                                fname = urllib.parse.unquote(data, encoding=encoding, errors=""strict"")                            except LookupError:                                self.log.warning(f""Content-Disposition: | error: No decoder found for {encoding}"")                                fname = None                            except UnicodeDecodeError:                                self.log.warning(f""Content-Disposition: | error: Error when decoding string from {encoding}"")                                fname = None                        else:                            fname = None                if fname is None:                    if 'filename' in disposition_params:                        fname = disposition_params['filename']                        m = re.search(r'=\?([^?]+)\?([QB])\?([^?]*)\?=', fname, re.I)  #: rfc2047                        if m is not None:                            data, encoding = parse_mime_header(m.group(0))[0]                            try:                                fname = data.decode(encoding)                            except LookupError:                                self.log.warning(f""Content-Disposition: | error: No decoder found for {encoding}"")                                continue                            except UnicodeEncodeError:                                self.log.warning(f""Content-Disposition: | error: Error when decoding string from {encoding}"")                                continue                        else:                            try:                                fname = urllib.parse.unquote(fname, encoding=""iso-8859-1"", errors=""strict"")                            except UnicodeDecodeError:                                self.log.warning(""Content-Disposition: | error: Error when decoding string from iso-8859-1."")                                continue                    elif disposition_type.lower() == ""attachment"":                        if location is not None:                            fname = parse.name(location)                        else:                            fname = parse.name(self.p.url)                    else:                        continue                #: Drop unsafe characters                fname = posixpath_basename(fname)                fname = ntpath_basename(fname)                fname = purge.name(fname, sep="""")                fname = fname.lstrip('.')                self.log.debug(f""Content-Disposition: {fname}"")                self.p.update_disposition(fname)            if not self.resume and line.startswith(""content-length""):                self.p.size = int(line.split("":"", 1)[1])        self.header_parsed = True",parse data from received header.,"def parse_header(self):        """"""        parse data from received header.        """"""        location = None        for orgline in self.response_header.splitlines():            try:                orgline = orgline.decode(""utf-8"")            except UnicodeDecodeError:                try:                    orgline = orgline.decode(""iso-8859-1"")                except UnicodeDecodeError:                        continue            line = orgline.strip().lower()            if line.startswith(""accept-ranges"") and ""bytes"" in line:                self.p.chunk_support = True            elif line.startswith(""location""):                location = orgline.split("":"", 1)[1].strip()            elif line.startswith(""content-disposition""):                disposition_value = orgline.split("":"", 1)[1].strip()                disposition_type, disposition_params = parse_header_line(disposition_value)                fname = None                if 'filename*' in disposition_params:                    fname = disposition_params['filename*']                    m = re.search(r'=\?([^?]+)\?([QB])\?([^?]*)\?=', fname, re.I)  #: rfc2047                    if m is not None:                        data, encoding = parse_mime_header(fname)[0]                        try:                            fname = data.decode(encoding)                        except LookupError:                            self.log.warning(f""Content-Disposition: | error: No decoder found for {encoding}"")                            fname = None                        except UnicodeEncodeError:                            self.log.warning(f""Content-Disposition: | error: Error when decoding string from {encoding}"")                            fname = None                    else:                        m = re.search(r'(.+?)\'(.*)\'(.+)', fname)                        if m is not None:                            encoding, lang, data = m.groups()                            try:                                fname = urllib.parse.unquote(data, encoding=encoding, errors=""strict"")                            except LookupError:                                self.log.warning(f""Content-Disposition: | error: No decoder found for {encoding}"")                                fname = None                            except UnicodeDecodeError:                                self.log.warning(f""Content-Disposition: | error: Error when decoding string from {encoding}"")                                fname = None                        else:                            fname = None                if fname is None:                    if 'filename' in disposition_params:                        fname = disposition_params['filename']                        m = re.search(r'=\?([^?]+)\?([QB])\?([^?]*)\?=', fname, re.I)  #: rfc2047                        if m is not None:                            data, encoding = parse_mime_header(m.group(0))[0]                            try:                                fname = data.decode(encoding)                            except LookupError:                                self.log.warning(f""Content-Disposition: | error: No decoder found for {encoding}"")                                continue                            except UnicodeEncodeError:                                self.log.warning(f""Content-Disposition: | error: Error when decoding string from {encoding}"")                                continue                        else:                            try:                                fname = urllib.parse.unquote(fname, encoding=""iso-8859-1"", errors=""strict"")                            except UnicodeDecodeError:                                self.log.warning(""Content-Disposition: | error: Error when decoding string from iso-8859-1."")                                continue                    elif disposition_type.lower() == ""attachment"":                        if location is not None:                            fname = parse.name(location)                        else:                            fname = parse.name(self.p.url)                    else:                        continue                #: Drop unsafe characters                fname = posixpath_basename(fname)                fname = ntpath_basename(fname)                fname = purge.name(fname, sep="""")                fname = fname.lstrip('.')                self.log.debug(f""Content-Disposition: {fname}"")                self.p.update_disposition(fname)            if not self.resume and line.startswith(""content-length""):                self.p.size = int(line.split("":"", 1)[1])        self.header_parsed = True

parse data from received header.",0b279296-635a-44b6-9500-75e733d1e6f0
http,http_chunk.py,stop,362,367,"def stop(self):                self.range = [0, 0]        self.size = 0",The download will not proceed after next call of write_body.,"def stop(self):        """"""        The download will not proceed after next call of write_body.        """"""        self.range = [0, 0]        self.size = 0

The download will not proceed after next call of write_body.",560c0567-aaa1-4017-bba5-d1b7d8d6aed6
http,http_chunk.py,reset_range,369,373,def reset_range(self):                self.range = None,"Reset the range, so the download will load all data available.","def reset_range(self):        """"""        Reset the range, so the download will load all data available.        """"""        self.range = None

Reset the range, so the download will load all data available.",6f7e3e71-279b-43d1-92e6-36108b25eed3
http,http_chunk.py,set_range,375,378,"def set_range(self, range):        self.range = range        self.size = range[1] - range[0]        self.log.debug(""Chunk {id} chunked with range {range}"".format(id=self.id + 1, range=self.format_range()))",,"def set_range(self, range):        self.range = range        self.size = range[1] - range[0]        self.log.debug(""Chunk {id} chunked with range {range}"".format(id=self.id + 1, range=self.format_range()))",eb2c4e3b-8278-4580-9951-7ea483ce6142
http,http_chunk.py,flush_file,380,386,def flush_file(self):                self.fp.flush()        os.fsync(self.fp.fileno())  #: make sure everything was written to disk        self.fp.close(),flush and close file.,"def flush_file(self):        """"""        flush and close file.        """"""        self.fp.flush()        os.fsync(self.fp.fileno())  #: make sure everything was written to disk        self.fp.close()

flush and close file.",46156125-b3d6-41a8-8711-21b1c26b2e41
http,http_chunk.py,close,388,396,"def close(self):                if self.fp:            self.fp.close()        self.c.close()        if hasattr(self, ""p""):            del self.p","closes everything, unusable after this.","def close(self):        """"""        closes everything, unusable after this.        """"""        if self.fp:            self.fp.close()        self.c.close()        if hasattr(self, ""p""):            del self.p

closes everything, unusable after this.",01e90190-b711-441f-aac7-489727e68e2f
http,http_download.py,__init__,20,71,"def __init__(        self,        url,        filename,        size=0,        get={},        post={},        referer=None,        cj=None,        bucket=None,        options={},        status_notify=None,        disposition=False,    ):        self.url = url        self.filename = filename  #: complete file destination, not only name        self.get = get        self.post = post        self.referer = referer        self.cj = cj  #: cookiejar if cookies are needed        self.bucket = bucket        self.options = options        self.disposition = disposition        #: all arguments        self.code = 0  #: last http code, would be set from the first chunk        self.abort = False        self.size = size        self.name_disposition = None  #: will be parsed from content disposition        self.chunks = []        self.log = getLogger(APPID)        try:            self.info = ChunkInfo.load(filename)            self.info.resume = True  #: resume is only possible with valid info file            self.size = self.info.size            self.info_saved = True        except IOError:            self.info = ChunkInfo(filename)        self.chunk_support = None        self.m = self.manager = pycurl.CurlMulti()        #: needed for speed calculation        self.last_arrived = []        self.last_speeds = []        #: notifications callback        self.status_notify = status_notify",,"def __init__(        self,        url,        filename,        size=0,        get={},        post={},        referer=None,        cj=None,        bucket=None,        options={},        status_notify=None,        disposition=False,    ):        self.url = url        self.filename = filename  #: complete file destination, not only name        self.get = get        self.post = post        self.referer = referer        self.cj = cj  #: cookiejar if cookies are needed        self.bucket = bucket        self.options = options        self.disposition = disposition        #: all arguments        self.code = 0  #: last http code, would be set from the first chunk        self.abort = False        self.size = size        self.name_disposition = None  #: will be parsed from content disposition        self.chunks = []        self.log = getLogger(APPID)        try:            self.info = ChunkInfo.load(filename)            self.info.resume = True  #: resume is only possible with valid info file            self.size = self.info.size            self.info_saved = True        except IOError:            self.info = ChunkInfo(filename)        self.chunk_support = None        self.m = self.manager = pycurl.CurlMulti()        #: needed for speed calculation        self.last_arrived = []        self.last_speeds = []        #: notifications callback        self.status_notify = status_notify",171e7e23-f6b4-4f33-8ffd-41dd18eb3c58
http,http_download.py,speed,74,76,def speed(self):        #: bytes per second        return sum(self.last_speeds) // len(self.last_speeds),,def speed(self):        #: bytes per second        return sum(self.last_speeds) // len(self.last_speeds),471e59d0-610c-4b10-a7be-eaf40d48e769
http,http_download.py,arrived,79,80,def arrived(self):        return sum(c.arrived for c in self.chunks),,def arrived(self):        return sum(c.arrived for c in self.chunks),38c11276-e21a-448a-b8d1-add82df2e017
http,http_download.py,percent,83,86,def percent(self):        if not self.size:            return 0        return (self.arrived * 100) // self.size,,def percent(self):        if not self.size:            return 0        return (self.arrived * 100) // self.size,3c335e6e-7633-4cca-98a3-939e70fc9124
http,http_download.py,_copy_chunks,88,124,"def _copy_chunks(self):        init = self.info.get_chunk_filename(0)  #: initial chunk name        if self.info.get_count() > 1:            with open(init, mode=""rb+"") as fo:  #: first chunk file                for i in range(1, self.info.get_count()):                    #: input file                    #: seek to beginning of chunk, to get rid of overlapping chunks                    fo.seek(self.info.get_chunk_range(i - 1)[1] + 1)                    fname = f""{self.filename}.chunk{i}""                    with open(fname, mode=""rb"") as fi:                        buffer_size = 32 << 10                        while True:  #: copy in chunks, consumes less memory                            data = fi.read(buffer_size)                            if not data:                                break                            fo.write(data)                    if fo.tell() < self.info.get_chunk_range(i)[1]:                        fo.close()                        os.remove(init)                        self.info.remove()  #: there are probably invalid chunks                        raise Exception(                            ""Downloaded content was smaller than expected. Try to reduce download connections.""                        )                    os.remove(fname)  #: os.remove chunk        if self.name_disposition and self.disposition:            self.filename = os.path.join(                os.path.dirname(self.filename), self.name_disposition            )        try:            os.remove(self.filename)        except FileNotFoundError:            pass        os.rename(init, self.filename)        self.info.remove()",,"def _copy_chunks(self):        init = self.info.get_chunk_filename(0)  #: initial chunk name        if self.info.get_count() > 1:            with open(init, mode=""rb+"") as fo:  #: first chunk file                for i in range(1, self.info.get_count()):                    #: input file                    #: seek to beginning of chunk, to get rid of overlapping chunks                    fo.seek(self.info.get_chunk_range(i - 1)[1] + 1)                    fname = f""{self.filename}.chunk{i}""                    with open(fname, mode=""rb"") as fi:                        buffer_size = 32 << 10                        while True:  #: copy in chunks, consumes less memory                            data = fi.read(buffer_size)                            if not data:                                break                            fo.write(data)                    if fo.tell() < self.info.get_chunk_range(i)[1]:                        fo.close()                        os.remove(init)                        self.info.remove()  #: there are probably invalid chunks                        raise Exception(                            ""Downloaded content was smaller than expected. Try to reduce download connections.""                        )                    os.remove(fname)  #: os.remove chunk        if self.name_disposition and self.disposition:            self.filename = os.path.join(                os.path.dirname(self.filename), self.name_disposition            )        try:            os.remove(self.filename)        except FileNotFoundError:            pass        os.rename(init, self.filename)        self.info.remove()",db5b17cf-e4e6-4260-abaa-aef7477479f3
http,http_download.py,download,126,155,"def download(self, chunks=1, resume=False):                chunks = max(1, chunks)        resume = self.info.resume and resume        try:            self._download(chunks, resume)        except pycurl.error as exc:            #: code 33 - no resume            code = exc.args[0]            if code == 33:                #: try again without resume                self.log.debug(""Errno 33 -> Restart without resume"")                #: os.remove old handles                for chunk in self.chunks:                    self.close_chunk(chunk)                return self._download(chunks, False)            else:                raise        finally:            self.close()        if self.name_disposition and self.disposition:            return self.name_disposition        else:            return None",returns new filename or None.,"def download(self, chunks=1, resume=False):        """"""        returns new filename or None.        """"""        chunks = max(1, chunks)        resume = self.info.resume and resume        try:            self._download(chunks, resume)        except pycurl.error as exc:            #: code 33 - no resume            code = exc.args[0]            if code == 33:                #: try again without resume                self.log.debug(""Errno 33 -> Restart without resume"")                #: os.remove old handles                for chunk in self.chunks:                    self.close_chunk(chunk)                return self._download(chunks, False)            else:                raise        finally:            self.close()        if self.name_disposition and self.disposition:            return self.name_disposition        else:            return None

returns new filename or None.",a9f784e5-c96f-4d95-bde8-0174af849f29
http,http_download.py,_download,157,322,"def _download(self, chunks, resume):        if not resume:            self.info.clear()            self.info.add_chunk(                f""{self.filename}.chunk0"", (0, 0)            )  #: create an initial entry)        self.chunks = []        #: initial chunk that will load complete file (if needed)        init = HTTPChunk(0, self, None, resume)        self.chunks.append(init)        self.m.add_handle(init.get_handle())        last_finish_check = 0        last_time_check = 0        chunks_done = set()  #: list of curl handles that are finished        chunks_created = False        done = False        if (            self.info.get_count() > 1        ):  #: This is a resume, if we were chunked originally assume still can            self.chunk_support = True        while True:            #: do we need to create chunks?            if (                not chunks_created and self.chunk_support and self.size            ):  #: will be set later by first chunk                if not resume:                    self.info.set_size(self.size)                    self.info.create_chunks(chunks)                    self.info.save()                chunks = self.info.get_count()                init.set_range(self.info.get_chunk_range(0))                for i in range(1, chunks):                    c = HTTPChunk(i, self, self.info.get_chunk_range(i), resume)                    handle = c.get_handle()                    if handle:                        self.chunks.append(c)                        self.m.add_handle(handle)                    else:                        #: close immediately                        self.log.debug(""Invalid curl handle -> closed"")                        c.close()                chunks_created = True            while True:                ret, num_handles = self.m.perform()                if ret != pycurl.E_CALL_MULTI_PERFORM:                    break            t = time.time()            #: reduce these calls            while last_finish_check + 0.5 < t:                #: list of failed curl handles                failed = []                ex = None  #: save only last exception, we can only raise one anyway                num_queued, ok_list, err_list = self.m.info_read()                for c in ok_list:                    chunk = self.find_chunk(c)                    try:  #: check if the header implies success, else add it to failed list                        chunk.code = chunk.verify_header()                    except BadHeader as exc:                        self.log.debug(f""Chunk {chunk.id + 1} failed: {exc}"")                        chunk.code = exc.code                        failed.append(chunk)                        ex = exc                    else:                        self.log.debug(f""Chunk {chunk.id + 1} download finished"")                        chunks_done.add(c)                for c, errno, msg in err_list:                    chunk = self.find_chunk(c)                    #: test if chunk was finished                    if errno != pycurl.E_WRITE_ERROR or not chunk.aborted:                        failed.append(chunk)                        ex = pycurl.error(errno, msg)                        self.log.debug(f""Chunk {chunk.id + 1} failed: {ex}"")                        continue                    try:  #: check if the header implies success, else add it to failed list                        chunk.code = chunk.verify_header()                    except BadHeader as exc:                        self.log.debug(f""Chunk {chunk.id + 1} failed: {exc}"")                        chunk.code = exc.code                        failed.append(chunk)                        ex = exc                    else:                        self.log.debug(f""Chunk {chunk.id + 1} download finished"")                        chunks_done.add(c)                if num_queued == 0:  #: no more infos to get                    #: check if init is not finished, so we reset download connections                    #: note that other chunks are closed and downloaded with init too                    if failed and init not in failed and init.c not in chunks_done:                        self.log.error(                            f""Download chunks failed, fallback to single connection | {ex}""                        )                        #: list of chunks to clean and os.remove                        to_clean = [x for x in self.chunks if x is not init]                        for chunk in to_clean:                            self.close_chunk(chunk)                            self.chunks.remove(chunk)                            os.remove(self.info.get_chunk_filename(chunk.id))                        #: let first chunk load the rest and update the info file                        init.reset_range()                        self.info.clear()                        self.info.add_chunk(f""{self.filename}.chunk0"", (0, self.size))                        self.info.save()                    elif failed:                        raise ex or Exception                    last_finish_check = t                    if len(chunks_done) >= len(self.chunks):                        if len(chunks_done) > len(self.chunks):                            self.log.warning(                                ""Finished download chunks size incorrect, please report bug.""                            )                        done = True  #: all chunks loaded                    break            if done:                break  #: all chunks loaded            #: calc speed once per second, averaging over 3 seconds            if last_time_check + 1 < t:                arrived_delta = (                    chunk.arrived - (self.last_arrived[i] if len(self.last_arrived) > i else 0)                    for i, chunk in enumerate(self.chunks)                )                self.last_speeds = [                    sum(float(delta) / (t - last_time_check) for delta in arrived_delta)                ] + self.last_speeds[:2]                self.last_arrived = [c.arrived for c in self.chunks]                last_time_check = t                self.update_progress()            if self.abort:                raise Abort            # time.sleep(0.003)  #: suppress busy waiting - limits dl speed to  (1 / x) * buffersize            self.m.select(1)        for chunk in self.chunks:            chunk.flush_file()  #: make sure downloads are written to disk        self._copy_chunks()        self.code = init.code        self.size = self.arrived",,"def _download(self, chunks, resume):        if not resume:            self.info.clear()            self.info.add_chunk(                f""{self.filename}.chunk0"", (0, 0)            )  #: create an initial entry)        self.chunks = []        #: initial chunk that will load complete file (if needed)        init = HTTPChunk(0, self, None, resume)        self.chunks.append(init)        self.m.add_handle(init.get_handle())        last_finish_check = 0        last_time_check = 0        chunks_done = set()  #: list of curl handles that are finished        chunks_created = False        done = False        if (            self.info.get_count() > 1        ):  #: This is a resume, if we were chunked originally assume still can            self.chunk_support = True        while True:            #: do we need to create chunks?            if (                not chunks_created and self.chunk_support and self.size            ):  #: will be set later by first chunk                if not resume:                    self.info.set_size(self.size)                    self.info.create_chunks(chunks)                    self.info.save()                chunks = self.info.get_count()                init.set_range(self.info.get_chunk_range(0))                for i in range(1, chunks):                    c = HTTPChunk(i, self, self.info.get_chunk_range(i), resume)                    handle = c.get_handle()                    if handle:                        self.chunks.append(c)                        self.m.add_handle(handle)                    else:                        #: close immediately                        self.log.debug(""Invalid curl handle -> closed"")                        c.close()                chunks_created = True            while True:                ret, num_handles = self.m.perform()                if ret != pycurl.E_CALL_MULTI_PERFORM:                    break            t = time.time()            #: reduce these calls            while last_finish_check + 0.5 < t:                #: list of failed curl handles                failed = []                ex = None  #: save only last exception, we can only raise one anyway                num_queued, ok_list, err_list = self.m.info_read()                for c in ok_list:                    chunk = self.find_chunk(c)                    try:  #: check if the header implies success, else add it to failed list                        chunk.code = chunk.verify_header()                    except BadHeader as exc:                        self.log.debug(f""Chunk {chunk.id + 1} failed: {exc}"")                        chunk.code = exc.code                        failed.append(chunk)                        ex = exc                    else:                        self.log.debug(f""Chunk {chunk.id + 1} download finished"")                        chunks_done.add(c)                for c, errno, msg in err_list:                    chunk = self.find_chunk(c)                    #: test if chunk was finished                    if errno != pycurl.E_WRITE_ERROR or not chunk.aborted:                        failed.append(chunk)                        ex = pycurl.error(errno, msg)                        self.log.debug(f""Chunk {chunk.id + 1} failed: {ex}"")                        continue                    try:  #: check if the header implies success, else add it to failed list                        chunk.code = chunk.verify_header()                    except BadHeader as exc:                        self.log.debug(f""Chunk {chunk.id + 1} failed: {exc}"")                        chunk.code = exc.code                        failed.append(chunk)                        ex = exc                    else:                        self.log.debug(f""Chunk {chunk.id + 1} download finished"")                        chunks_done.add(c)                if num_queued == 0:  #: no more infos to get                    #: check if init is not finished, so we reset download connections                    #: note that other chunks are closed and downloaded with init too                    if failed and init not in failed and init.c not in chunks_done:                        self.log.error(                            f""Download chunks failed, fallback to single connection | {ex}""                        )                        #: list of chunks to clean and os.remove                        to_clean = [x for x in self.chunks if x is not init]                        for chunk in to_clean:                            self.close_chunk(chunk)                            self.chunks.remove(chunk)                            os.remove(self.info.get_chunk_filename(chunk.id))                        #: let first chunk load the rest and update the info file                        init.reset_range()                        self.info.clear()                        self.info.add_chunk(f""{self.filename}.chunk0"", (0, self.size))                        self.info.save()                    elif failed:                        raise ex or Exception                    last_finish_check = t                    if len(chunks_done) >= len(self.chunks):                        if len(chunks_done) > len(self.chunks):                            self.log.warning(                                ""Finished download chunks size incorrect, please report bug.""                            )                        done = True  #: all chunks loaded                    break            if done:                break  #: all chunks loaded            #: calc speed once per second, averaging over 3 seconds            if last_time_check + 1 < t:                arrived_delta = (                    chunk.arrived - (self.last_arrived[i] if len(self.last_arrived) > i else 0)                    for i, chunk in enumerate(self.chunks)                )                self.last_speeds = [                    sum(float(delta) / (t - last_time_check) for delta in arrived_delta)                ] + self.last_speeds[:2]                self.last_arrived = [c.arrived for c in self.chunks]                last_time_check = t                self.update_progress()            if self.abort:                raise Abort            # time.sleep(0.003)  #: suppress busy waiting - limits dl speed to  (1 / x) * buffersize            self.m.select(1)        for chunk in self.chunks:            chunk.flush_file()  #: make sure downloads are written to disk        self._copy_chunks()        self.code = init.code        self.size = self.arrived",5b626584-eefd-4e18-8123-207f3a06bbb5
http,http_download.py,update_progress,324,326,"def update_progress(self):        if self.status_notify:            self.status_notify({""progress"": self.percent})",,"def update_progress(self):        if self.status_notify:            self.status_notify({""progress"": self.percent})",fa8017cd-ea6e-4a88-af14-49259bea753d
http,http_download.py,update_disposition,328,334,"def update_disposition(self, disposition):        self.name_disposition = disposition        if self.disposition:            if self.status_notify:                self.status_notify({""disposition"": disposition})        else:            self.log.debug(""Ignoring Content-Disposition header"")",,"def update_disposition(self, disposition):        self.name_disposition = disposition        if self.disposition:            if self.status_notify:                self.status_notify({""disposition"": disposition})        else:            self.log.debug(""Ignoring Content-Disposition header"")",126e191c-acba-4987-9995-08798ac03ff9
http,http_download.py,find_chunk,336,342,"def find_chunk(self, handle):                for chunk in self.chunks:            if chunk.c == handle:                return chunk",linear search to find a chunk (should be ok since chunk size is usually low),"def find_chunk(self, handle):        """"""        linear search to find a chunk (should be ok since chunk size is usually low)        """"""        for chunk in self.chunks:            if chunk.c == handle:                return chunk

linear search to find a chunk (should be ok since chunk size is usually low)",3e2471c1-b990-46bc-986e-e541ca322d98
http,http_download.py,close_chunk,344,350,"def close_chunk(self, chunk):        try:            self.m.remove_handle(chunk.c)        except pycurl.error as exc:            self.log.debug(f""Error removing chunk: {exc}"")        finally:            chunk.close()",,"def close_chunk(self, chunk):        try:            self.m.remove_handle(chunk.c)        except pycurl.error as exc:            self.log.debug(f""Error removing chunk: {exc}"")        finally:            chunk.close()",904aee29-baa4-4efe-b176-18d32b20bf0d
http,http_download.py,close,352,366,"def close(self):                for chunk in self.chunks:            self.close_chunk(chunk)        self.chunks = []        if hasattr(self, ""m""):            self.m.close()            del self.m        if hasattr(self, ""cj""):            del self.cj        if hasattr(self, ""info""):            del self.info",cleanup.,"def close(self):        """"""        cleanup.        """"""        for chunk in self.chunks:            self.close_chunk(chunk)        self.chunks = []        if hasattr(self, ""m""):            self.m.close()            del self.m        if hasattr(self, ""cj""):            del self.cj        if hasattr(self, ""info""):            del self.info

cleanup.",f37d46ed-a32f-4012-8def-55a263cb6823
http,http_request.py,myquote,25,30,"def myquote(url):    try:        url = url.encode()    except AttributeError:        pass    return quote(url, safe=""%/:=&?~#+!$,;'@()*[]"")",,"def myquote(url):    try:        url = url.encode()    except AttributeError:        pass    return quote(url, safe=""%/:=&?~#+!$,;'@()*[]"")",4b3551c7-707f-472b-87b2-4c6203ba85f2
http,http_request.py,myurlencode,33,44,"def myurlencode(data):    data = dict(data)    return urlencode(        {            x.encode()            if hasattr(x, ""encode"")            else x: y.encode()            if hasattr(y, ""encode"")            else y            for x, y in data.items()        }    )",,"def myurlencode(data):    data = dict(data)    return urlencode(        {            x.encode()            if hasattr(x, ""encode"")            else x: y.encode()            if hasattr(y, ""encode"")            else y            for x, y in data.items()        }    )",7ab5600b-22f6-4d39-adbd-0d45f55a57ee
http,http_request.py,__init__,53,60,"def __init__(self, filename, data=None, mimetype=None):        self.filename = os.path.abspath(filename)        self.data = data        self.mimetype = (            mimetype or mimetypes.guess_type(filename)[0]            if not data and os.path.exists(filename)            else ""application/octet-stream""        )",,"def __init__(self, filename, data=None, mimetype=None):        self.filename = os.path.abspath(filename)        self.data = data        self.mimetype = (            mimetype or mimetypes.guess_type(filename)[0]            if not data and os.path.exists(filename)            else ""application/octet-stream""        )",a4072bc7-5fee-432c-9193-a2d2ea980e05
http,http_request.py,__repr__,62,63,"def __repr__(self):        return f""FormFile <'{os.path.basename(self.filename)}'>""",,"def __repr__(self):        return f""FormFile <'{os.path.basename(self.filename)}'>""",feef4f93-cb1d-4aa4-8b73-13531bff3e1d
http,http_request.py,__init__,67,93,"def __init__(self, cookies=None, options=None, limit=2_000_000):        self.exception = None        self.limit = limit        self.c = pycurl.Curl()        self.rep = None        self.cj = cookies  #: cookiejar        self.last_url = None        self.last_effective_url = None        self.code = 0  #: last http code        self.response_header = b""""        self.request_headers = []  #: temporary request header        self.abort = False        self.decode = False        self.init_handle()        self.set_interface(options)        self.c.setopt(pycurl.WRITEFUNCTION, self.write_body)        self.c.setopt(pycurl.HEADERFUNCTION, self.write_header)        self.log = getLogger(APPID)",,"def __init__(self, cookies=None, options=None, limit=2_000_000):        self.exception = None        self.limit = limit        self.c = pycurl.Curl()        self.rep = None        self.cj = cookies  #: cookiejar        self.last_url = None        self.last_effective_url = None        self.code = 0  #: last http code        self.response_header = b""""        self.request_headers = []  #: temporary request header        self.abort = False        self.decode = False        self.init_handle()        self.set_interface(options)        self.c.setopt(pycurl.WRITEFUNCTION, self.write_body)        self.c.setopt(pycurl.HEADERFUNCTION, self.write_header)        self.log = getLogger(APPID)",b2a7beb3-6e25-4511-b6f2-20132e665452
http,http_request.py,__enter__,95,96,def __enter__(self):        return self,,def __enter__(self):        return self,18b399f3-1b7f-41f3-9489-76b38b167234
http,http_request.py,__exit__,98,99,"def __exit__(self, exc_type, exc_val, exc_tb):        self.close()",,"def __exit__(self, exc_type, exc_val, exc_tb):        self.close()",aa82a13d-7dbe-41e9-a431-5ba3ae715986
http,http_request.py,init_handle,101,138,"def init_handle(self):                self.c.setopt(pycurl.FOLLOWLOCATION, 1)        self.c.setopt(pycurl.MAXREDIRS, 10)        self.c.setopt(pycurl.CONNECTTIMEOUT, 30)        self.c.setopt(pycurl.NOSIGNAL, 1)        self.c.setopt(pycurl.NOPROGRESS, 1)        if hasattr(pycurl, ""AUTOREFERER""):            self.c.setopt(pycurl.AUTOREFERER, 1)        self.c.setopt(pycurl.SSL_VERIFYPEER, 1)        self.c.setopt(pycurl.LOW_SPEED_TIME, 60)        self.c.setopt(pycurl.LOW_SPEED_LIMIT, 5)        if hasattr(pycurl, ""USE_SSL""):            self.c.setopt(pycurl.USE_SSL, pycurl.USESSL_TRY)        # self.c.setopt(pycurl.VERBOSE, 1)        # self.c.setopt(pycurl.HTTP_VERSION, pycurl.CURL_HTTP_VERSION_1_1)        self.c.setopt(            pycurl.USERAGENT,            b""Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/109.0"",        )        if pycurl.version_info()[7]:            self.c.setopt(pycurl.ENCODING, b""gzip, deflate"")        self.c.setopt(            pycurl.HTTPHEADER,            [                b""Accept: */*"",                b""Accept-Language: en-US,en"",                b""Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.7"",                b""Connection: keep-alive"",                b""Keep-Alive: 300"",                b""Expect:"",            ],        )",sets common options to curl handle.,"def init_handle(self):        """"""        sets common options to curl handle.        """"""        self.c.setopt(pycurl.FOLLOWLOCATION, 1)        self.c.setopt(pycurl.MAXREDIRS, 10)        self.c.setopt(pycurl.CONNECTTIMEOUT, 30)        self.c.setopt(pycurl.NOSIGNAL, 1)        self.c.setopt(pycurl.NOPROGRESS, 1)        if hasattr(pycurl, ""AUTOREFERER""):            self.c.setopt(pycurl.AUTOREFERER, 1)        self.c.setopt(pycurl.SSL_VERIFYPEER, 1)        self.c.setopt(pycurl.LOW_SPEED_TIME, 60)        self.c.setopt(pycurl.LOW_SPEED_LIMIT, 5)        if hasattr(pycurl, ""USE_SSL""):            self.c.setopt(pycurl.USE_SSL, pycurl.USESSL_TRY)        # self.c.setopt(pycurl.VERBOSE, 1)        # self.c.setopt(pycurl.HTTP_VERSION, pycurl.CURL_HTTP_VERSION_1_1)        self.c.setopt(            pycurl.USERAGENT,            b""Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:109.0) Gecko/20100101 Firefox/109.0"",        )        if pycurl.version_info()[7]:            self.c.setopt(pycurl.ENCODING, b""gzip, deflate"")        self.c.setopt(            pycurl.HTTPHEADER,            [                b""Accept: */*"",                b""Accept-Language: en-US,en"",                b""Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.7"",                b""Connection: keep-alive"",                b""Keep-Alive: 300"",                b""Expect:"",            ],        )

sets common options to curl handle.",6902dcb6-ab56-45b3-a376-3947dd834687
http,http_request.py,set_interface,140,197,"def set_interface(self, options):        options = {            k: v.encode() if hasattr(v, ""encode"") else v for k, v in options.items()        }        interface, proxy, ipv6 = (            options[""interface""],            options[""proxies""],            options[""ipv6""],        )        if interface and interface.lower() != ""none"":            self.c.setopt(pycurl.INTERFACE, interface)        if proxy:            if proxy[""type""] == ""http"":                self.c.setopt(pycurl.PROXYTYPE, pycurl.PROXYTYPE_HTTP)            elif proxy[""type""] == ""https"":                self.c.setopt(pycurl.PROXYTYPE, pycurl.PROXYTYPE_HTTPS)                self.c.setopt(pycurl.PROXY_SSL_VERIFYPEER, 0)            elif proxy[""type""] == ""socks4"":                self.c.setopt(                    pycurl.PROXYTYPE,                    pycurl.PROXYTYPE_SOCKS4A if proxy[""socks_resolve_dns""] else pycurl.PROXYTYPE_SOCKS4                )            elif proxy[""type""] == ""socks5"":                self.c.setopt(                    pycurl.PROXYTYPE,                    pycurl.PROXYTYPE_SOCKS5_HOSTNAME if proxy[""socks_resolve_dns""] else pycurl.PROXYTYPE_SOCKS5                )            self.c.setopt(pycurl.PROXY, proxy[""host""])            self.c.setopt(pycurl.PROXYPORT, int(proxy[""port""]))            if proxy[""username""]:                user = proxy[""username""]                pw = proxy[""password""]                self.c.setopt(pycurl.PROXYUSERPWD, f""{user}:{pw}"".encode())        if ipv6:            self.c.setopt(pycurl.IPRESOLVE, pycurl.IPRESOLVE_WHATEVER)        else:            self.c.setopt(pycurl.IPRESOLVE, pycurl.IPRESOLVE_V4)        if ""auth"" in options:            self.c.setopt(pycurl.USERPWD, options[""auth""])        if ""timeout"" in options:            self.c.setopt(pycurl.LOW_SPEED_TIME, int(options[""timeout""]))        if ""ssl_verify"" in options:            if options[""ssl_verify""]:                self.c.setopt(pycurl.CAINFO, certifi.where())                ssl_verify = 1            else:                ssl_verify = 0            self.c.setopt(pycurl.SSL_VERIFYPEER, ssl_verify)",,"def set_interface(self, options):        options = {            k: v.encode() if hasattr(v, ""encode"") else v for k, v in options.items()        }        interface, proxy, ipv6 = (            options[""interface""],            options[""proxies""],            options[""ipv6""],        )        if interface and interface.lower() != ""none"":            self.c.setopt(pycurl.INTERFACE, interface)        if proxy:            if proxy[""type""] == ""http"":                self.c.setopt(pycurl.PROXYTYPE, pycurl.PROXYTYPE_HTTP)            elif proxy[""type""] == ""https"":                self.c.setopt(pycurl.PROXYTYPE, pycurl.PROXYTYPE_HTTPS)                self.c.setopt(pycurl.PROXY_SSL_VERIFYPEER, 0)            elif proxy[""type""] == ""socks4"":                self.c.setopt(                    pycurl.PROXYTYPE,                    pycurl.PROXYTYPE_SOCKS4A if proxy[""socks_resolve_dns""] else pycurl.PROXYTYPE_SOCKS4                )            elif proxy[""type""] == ""socks5"":                self.c.setopt(                    pycurl.PROXYTYPE,                    pycurl.PROXYTYPE_SOCKS5_HOSTNAME if proxy[""socks_resolve_dns""] else pycurl.PROXYTYPE_SOCKS5                )            self.c.setopt(pycurl.PROXY, proxy[""host""])            self.c.setopt(pycurl.PROXYPORT, int(proxy[""port""]))            if proxy[""username""]:                user = proxy[""username""]                pw = proxy[""password""]                self.c.setopt(pycurl.PROXYUSERPWD, f""{user}:{pw}"".encode())        if ipv6:            self.c.setopt(pycurl.IPRESOLVE, pycurl.IPRESOLVE_WHATEVER)        else:            self.c.setopt(pycurl.IPRESOLVE, pycurl.IPRESOLVE_V4)        if ""auth"" in options:            self.c.setopt(pycurl.USERPWD, options[""auth""])        if ""timeout"" in options:            self.c.setopt(pycurl.LOW_SPEED_TIME, int(options[""timeout""]))        if ""ssl_verify"" in options:            if options[""ssl_verify""]:                self.c.setopt(pycurl.CAINFO, certifi.where())                ssl_verify = 1            else:                ssl_verify = 0            self.c.setopt(pycurl.SSL_VERIFYPEER, ssl_verify)",5c4d7cd7-b99d-4f62-bca4-ceaa5d52d039
http,http_request.py,add_cookies,199,204,def add_cookies(self):                if self.cj:            self.cj.add_cookies(self.c.getinfo(pycurl.INFO_COOKIELIST)),put cookies from curl handle to cj.,"def add_cookies(self):        """"""        put cookies from curl handle to cj.        """"""        if self.cj:            self.cj.add_cookies(self.c.getinfo(pycurl.INFO_COOKIELIST))

put cookies from curl handle to cj.",67a3dfb8-9914-4cb3-b5ec-07dda6a2f524
http,http_request.py,get_cookies,206,213,"def get_cookies(self):                if self.cj:            for c in self.cj.get_cookies():                self.c.setopt(pycurl.COOKIELIST, c)        return",add cookies from cj to curl handle.,"def get_cookies(self):        """"""        add cookies from cj to curl handle.        """"""        if self.cj:            for c in self.cj.get_cookies():                self.c.setopt(pycurl.COOKIELIST, c)        return

add cookies from cj to curl handle.",476312e0-111f-4a71-9d30-2bf2833929a4
http,http_request.py,clear_cookies,215,216,"def clear_cookies(self):        self.c.setopt(pycurl.COOKIELIST, """")",,"def clear_cookies(self):        self.c.setopt(pycurl.COOKIELIST, """")",ff391d04-7b7b-4b65-95b0-e2edaed96c63
http,http_request.py,set_request_context,218,286,"def set_request_context(self, url, get, post, referer, cookies, multipart=False, decode=True):                self.rep = io.BytesIO()        self.exception = None        self.decode = decode        url = myquote(url)        if get:            get = urlencode(get)            url = f""{url}?{get}""        self.c.setopt(pycurl.URL, url)        self.c.last_url = url        if post:            self.c.setopt(pycurl.POST, 1)            if not multipart:                if post is True:                    post = b""""                elif isinstance(post, str):                    post = post.encode()                elif is_mapping(post):                    post = myurlencode(post)                else:                    raise ValueError(""Invalid value for 'post'"")                self.c.setopt(pycurl.POSTFIELDS, post)            else:                multipart_post = []                for k, v in post.items():                    if isinstance(v, (str, bool, int)):                        multipart_post.append((k, to_str(v)))                    elif isinstance(v, FormFile):                        filename = os.path.basename(v.filename).encode(""utf8"")                        data = v.data                        if data is None:                            if not os.path.exists(v.filename):                                continue                            else:                                with open(v.filename, ""rb"") as f:                                    data = f.read()                        else:                            data = to_bytes(data)                        multipart_post.append((k, (pycurl.FORM_BUFFER, filename,                                                   pycurl.FORM_BUFFERPTR, data,                                                   pycurl.FORM_CONTENTTYPE, v.mimetype)))                self.c.setopt(pycurl.HTTPPOST, multipart_post)        else:            self.c.setopt(pycurl.POST, 0)            self.c.setopt(pycurl.HTTPGET, 1)        if referer and self.last_url:            self.c.setopt(pycurl.REFERER, to_bytes(self.last_url))        if cookies:            self.c.setopt(pycurl.COOKIEFILE, b"""")            self.c.setopt(pycurl.COOKIEJAR, b"""")            self.get_cookies()",sets everything needed for the request.,"def set_request_context(self, url, get, post, referer, cookies, multipart=False, decode=True):        """"""        sets everything needed for the request.        """"""        self.rep = io.BytesIO()        self.exception = None        self.decode = decode        url = myquote(url)        if get:            get = urlencode(get)            url = f""{url}?{get}""        self.c.setopt(pycurl.URL, url)        self.c.last_url = url        if post:            self.c.setopt(pycurl.POST, 1)            if not multipart:                if post is True:                    post = b""""                elif isinstance(post, str):                    post = post.encode()                elif is_mapping(post):                    post = myurlencode(post)                else:                    raise ValueError(""Invalid value for 'post'"")                self.c.setopt(pycurl.POSTFIELDS, post)            else:                multipart_post = []                for k, v in post.items():                    if isinstance(v, (str, bool, int)):                        multipart_post.append((k, to_str(v)))                    elif isinstance(v, FormFile):                        filename = os.path.basename(v.filename).encode(""utf8"")                        data = v.data                        if data is None:                            if not os.path.exists(v.filename):                                continue                            else:                                with open(v.filename, ""rb"") as f:                                    data = f.read()                        else:                            data = to_bytes(data)                        multipart_post.append((k, (pycurl.FORM_BUFFER, filename,                                                   pycurl.FORM_BUFFERPTR, data,                                                   pycurl.FORM_CONTENTTYPE, v.mimetype)))                self.c.setopt(pycurl.HTTPPOST, multipart_post)        else:            self.c.setopt(pycurl.POST, 0)            self.c.setopt(pycurl.HTTPGET, 1)        if referer and self.last_url:            self.c.setopt(pycurl.REFERER, to_bytes(self.last_url))        if cookies:            self.c.setopt(pycurl.COOKIEFILE, b"""")            self.c.setopt(pycurl.COOKIEJAR, b"""")            self.get_cookies()

sets everything needed for the request.",81444c03-76df-4f0c-b5de-c9b8e23e0a1b
http,http_request.py,load,288,350,"def load(        self,        url,        get={},        post={},        referer=True,        cookies=True,        just_header=False,        multipart=False,        decode=True,        follow_location=True,        save_cookies=True,    ):                self.set_request_context(url, get, post, referer, cookies, multipart, decode)        self.response_header = b""""        self.c.setopt(pycurl.HTTPHEADER, self.request_headers)        if not follow_location:            self.c.setopt(pycurl.FOLLOWLOCATION, 0)        if just_header:            self.c.setopt(pycurl.NOBODY, 1)        try:            self.c.perform()        except pycurl.error as exc:            if exc.args[0] == pycurl.E_WRITE_ERROR and self.exception:                raise self.exception from None            else:                raise        if not follow_location:            self.c.setopt(pycurl.FOLLOWLOCATION, 1)        if just_header:            self.c.setopt(pycurl.NOBODY, 0)        self.c.setopt(pycurl.POSTFIELDS, b"""")        self.last_effective_url = self.c.getinfo(pycurl.EFFECTIVE_URL)        if save_cookies:            self.add_cookies()        self.code = self.verify_header()        ret = self.response_header if just_header else self.get_response()        if decode:            ret = (                to_str(ret, encoding=""iso-8859-1"")                if just_header                else self.decode_response(ret)            )        self.rep.close()        self.rep = None        return ret",load and returns a given page.,"def load(        self,        url,        get={},        post={},        referer=True,        cookies=True,        just_header=False,        multipart=False,        decode=True,        follow_location=True,        save_cookies=True,    ):        """"""        load and returns a given page.        """"""        self.set_request_context(url, get, post, referer, cookies, multipart, decode)        self.response_header = b""""        self.c.setopt(pycurl.HTTPHEADER, self.request_headers)        if not follow_location:            self.c.setopt(pycurl.FOLLOWLOCATION, 0)        if just_header:            self.c.setopt(pycurl.NOBODY, 1)        try:            self.c.perform()        except pycurl.error as exc:            if exc.args[0] == pycurl.E_WRITE_ERROR and self.exception:                raise self.exception from None            else:                raise        if not follow_location:            self.c.setopt(pycurl.FOLLOWLOCATION, 1)        if just_header:            self.c.setopt(pycurl.NOBODY, 0)        self.c.setopt(pycurl.POSTFIELDS, b"""")        self.last_effective_url = self.c.getinfo(pycurl.EFFECTIVE_URL)        if save_cookies:            self.add_cookies()        self.code = self.verify_header()        ret = self.response_header if just_header else self.get_response()        if decode:            ret = (                to_str(ret, encoding=""iso-8859-1"")                if just_header                else self.decode_response(ret)            )        self.rep.close()        self.rep = None        return ret

load and returns a given page.",63820a46-a970-4a83-a4de-fefbc04870d1
http,http_request.py,verify_header,352,366,"def verify_header(self):                code = int(self.c.getinfo(pycurl.RESPONSE_CODE))        if code in BAD_STATUS_CODES:            response = self.decode_response(self.get_response()) if self.decode else self.get_response()            header = to_str(self.response_header, encoding=""iso-8859-1"") if self.decode else self.response_header            self.rep.close()            self.rep = None            # 404 will NOT raise an exception            raise BadHeader(code, header, response)        return code",raise an exceptions on bad headers.,"def verify_header(self):        """"""        raise an exceptions on bad headers.        """"""        code = int(self.c.getinfo(pycurl.RESPONSE_CODE))        if code in BAD_STATUS_CODES:            response = self.decode_response(self.get_response()) if self.decode else self.get_response()            header = to_str(self.response_header, encoding=""iso-8859-1"") if self.decode else self.response_header            self.rep.close()            self.rep = None            # 404 will NOT raise an exception            raise BadHeader(code, header, response)        return code

raise an exceptions on bad headers.",cfb697e9-5557-4b38-949d-588345a77510
http,http_request.py,check_header,368,372,def check_header(self):                return int(self.c.getinfo(pycurl.RESPONSE_CODE)) not in BAD_STATUS_CODES,check if header indicates failure.,"def check_header(self):        """"""        check if header indicates failure.        """"""        return int(self.c.getinfo(pycurl.RESPONSE_CODE)) not in BAD_STATUS_CODES

check if header indicates failure.",c2e46a19-1422-4622-be59-3389e30883ca
http,http_request.py,get_response,374,381,"def get_response(self):                if self.rep is None:            return b""""        else:            return self.rep.getvalue()",retrieve response from bytes io.,"def get_response(self):        """"""        retrieve response from bytes io.        """"""        if self.rep is None:            return b""""        else:            return self.rep.getvalue()

retrieve response from bytes io.",0107b7c7-e84a-4721-9f87-c3d8044f6398
http,http_request.py,decode_response,383,419,"def decode_response(self, response):                header = self.response_header.splitlines()        encoding = ""utf-8""  #: default encoding        for line in header:            line = line.lower().replace(b"" "", b"""")            if not line.startswith(b""content-type:"") or (b""text"" not in line and b""application"" not in line):                continue            none, delimiter, charset = line.rpartition(b""charset="")            if delimiter:                charset = charset.split(b"";"")                if charset:                    encoding = to_str(charset[0])        try:            # self.log.debug(f""Decoded {encoding}"")            if codecs.lookup(encoding).name == ""utf-8"" and response.startswith(                codecs.BOM_UTF8            ):                encoding = ""utf-8-sig""            decoder = codecs.getincrementaldecoder(encoding)(""replace"")            response = decoder.decode(response, True)            # TODO: html_unescape as default        except LookupError:            self.log.debug(f""No Decoder found for {encoding}"")        except Exception:            self.log.debug(f""Error when decoding string from {encoding}"", exc_info=True)        return response","decode with correct encoding, relies on header.","def decode_response(self, response):        """"""        decode with correct encoding, relies on header.        """"""        header = self.response_header.splitlines()        encoding = ""utf-8""  #: default encoding        for line in header:            line = line.lower().replace(b"" "", b"""")            if not line.startswith(b""content-type:"") or (b""text"" not in line and b""application"" not in line):                continue            none, delimiter, charset = line.rpartition(b""charset="")            if delimiter:                charset = charset.split(b"";"")                if charset:                    encoding = to_str(charset[0])        try:            # self.log.debug(f""Decoded {encoding}"")            if codecs.lookup(encoding).name == ""utf-8"" and response.startswith(                codecs.BOM_UTF8            ):                encoding = ""utf-8-sig""            decoder = codecs.getincrementaldecoder(encoding)(""replace"")            response = decoder.decode(response, True)            # TODO: html_unescape as default        except LookupError:            self.log.debug(f""No Decoder found for {encoding}"")        except Exception:            self.log.debug(f""Error when decoding string from {encoding}"", exc_info=True)        return response

decode with correct encoding, relies on header.",9872226e-5b96-465f-919e-2b71d2019ef4
http,http_request.py,write_body,421,438,"def write_body(self, buf):                if self.abort:            self.exception = Abort()            return pycurl.E_WRITE_ERROR        elif self.limit and self.rep.tell() > self.limit:            rep = self.get_response()            with open(""response.dump"", mode=""wb"") as fp:                fp.write(rep)            self.exception = Exception(f""Loaded URL exceeded limit ({self.limit})"")            return pycurl.E_WRITE_ERROR        self.rep.write(buf)        return None",writes response.,"def write_body(self, buf):        """"""        writes response.        """"""        if self.abort:            self.exception = Abort()            return pycurl.E_WRITE_ERROR        elif self.limit and self.rep.tell() > self.limit:            rep = self.get_response()            with open(""response.dump"", mode=""wb"") as fp:                fp.write(rep)            self.exception = Exception(f""Loaded URL exceeded limit ({self.limit})"")            return pycurl.E_WRITE_ERROR        self.rep.write(buf)        return None

writes response.",8bcf460a-40d0-4e57-9d66-0c0156bd6490
http,http_request.py,write_header,440,444,"def write_header(self, buf):                self.response_header += buf",writes header.,"def write_header(self, buf):        """"""        writes header.        """"""        self.response_header += buf

writes header.",4a1ad710-3e98-43eb-b096-feab60874d9b
http,http_request.py,put_header,446,447,"def put_header(self, name, value):        self.request_headers.append(f""{name}: {value}"")",,"def put_header(self, name, value):        self.request_headers.append(f""{name}: {value}"")",665b2af2-8f48-4a00-b4c4-3b4a1d54dbd9
http,http_request.py,clear_headers,449,450,def clear_headers(self):        self.request_headers = [],,def clear_headers(self):        self.request_headers = [],4d241e93-159f-4c2a-b532-876280c63fc3
http,http_request.py,close,452,465,"def close(self):                if self.rep:            self.rep.close()            del self.rep        if hasattr(self, ""cj""):            del self.cj        if hasattr(self, ""c""):            self.c.close()            del self.c","cleanup, unusable after this.","def close(self):        """"""        cleanup, unusable after this.        """"""        if self.rep:            self.rep.close()            del self.rep        if hasattr(self, ""cj""):            del self.cj        if hasattr(self, ""c""):            self.c.close()            del self.c

cleanup, unusable after this.",d41509d4-a972-479e-9dd6-c5d81e003d53
xdcc,request.py,__init__,14,31,"def __init__(self, bucket=None, options={}):        self.proxies = options.get(""proxies"", {})        self.bucket = bucket        self.fh = None        self.dccsock = None        self.filesize = 0        self.received = 0        self.speeds = [0, 0, 0]        self.sleep = 0.000        self.last_recv_size = 0        self.send_64bits_ack = False        self.abort = False        self.status_notify = None",,"def __init__(self, bucket=None, options={}):        self.proxies = options.get(""proxies"", {})        self.bucket = bucket        self.fh = None        self.dccsock = None        self.filesize = 0        self.received = 0        self.speeds = [0, 0, 0]        self.sleep = 0.000        self.last_recv_size = 0        self.send_64bits_ack = False        self.abort = False        self.status_notify = None",4cd224b5-131f-4277-8df6-0866347a5332
xdcc,request.py,create_socket,33,53,"def create_socket(self):        # proxytype = None        # proxy = None        # if self.proxies.has_key(""socks5""):        # proxytype = socks.PROXY_TYPE_SOCKS5        # proxy = self.proxies[""socks5""]        # elif self.proxies.has_key(""socks4""):        # proxytype = socks.PROXY_TYPE_SOCKS4        # proxy = self.proxies[""socks4""]        # if proxytype:        # sock = socks.socksocket()        # t = _parse_proxy(proxy)        # sock.setproxy(proxytype, addr=t[3].split("":"")[0], port=int(t[3].split("":"")[1]), username=t[1], password=t[2])        # else:        # sock = socket.socket()        # return sock        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)        # sock.setsockopt(socket.SOL_SOCKET, socket.SO_RCVBUF, 16384)        return sock",,"def create_socket(self):        # proxytype = None        # proxy = None        # if self.proxies.has_key(""socks5""):        # proxytype = socks.PROXY_TYPE_SOCKS5        # proxy = self.proxies[""socks5""]        # elif self.proxies.has_key(""socks4""):        # proxytype = socks.PROXY_TYPE_SOCKS4        # proxy = self.proxies[""socks4""]        # if proxytype:        # sock = socks.socksocket()        # t = _parse_proxy(proxy)        # sock.setproxy(proxytype, addr=t[3].split("":"")[0], port=int(t[3].split("":"")[1]), username=t[1], password=t[2])        # else:        # sock = socket.socket()        # return sock        sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)        # sock.setsockopt(socket.SOL_SOCKET, socket.SO_RCVBUF, 16384)        return sock",3c2b84d6-259e-408c-87ae-15e4540f1517
xdcc,request.py,_write_func,55,77,"def _write_func(self, buf):        size = len(buf)        self.received += size        self.fh.write(buf)        if self.bucket:            time.sleep(self.bucket.consumed(size))        else:            # Avoid small buffers, increasing sleep time slowly if buffer size gets smaller            # otherwise reduce sleep time percentequal (values are based on tests)            # So in general cpu time is saved without reducing bandwidth too much            if size < self.last_recv_size:                self.sleep += 0.002            else:                self.sleep *= 0.7            self.last_recv_size = size            time.sleep(self.sleep)",,"def _write_func(self, buf):        size = len(buf)        self.received += size        self.fh.write(buf)        if self.bucket:            time.sleep(self.bucket.consumed(size))        else:            # Avoid small buffers, increasing sleep time slowly if buffer size gets smaller            # otherwise reduce sleep time percentequal (values are based on tests)            # So in general cpu time is saved without reducing bandwidth too much            if size < self.last_recv_size:                self.sleep += 0.002            else:                self.sleep *= 0.7            self.last_recv_size = size            time.sleep(self.sleep)",6ff4b111-3edc-4556-824b-87dcbc2598c6
xdcc,request.py,_send_ack,79,87,"def _send_ack(self):        # acknowledge data by sending number of received bytes        try:            self.dccsock.send(                struct.pack(""!Q"" if self.send_64bits_ack else ""!I"", self.received)            )        except socket.error:            pass",,"def _send_ack(self):        # acknowledge data by sending number of received bytes        try:            self.dccsock.send(                struct.pack(""!Q"" if self.send_64bits_ack else ""!I"", self.received)            )        except socket.error:            pass",d394184c-6241-4e84-99e0-1a7f968966c9
xdcc,request.py,download,89,166,"def download(self, ip, port, filename, status_notify=None, resume=None):        self.status_notify = status_notify        self.send_64bits_ack = not self.filesize < 1 << 32        chunk_name = filename + "".chunk0""        if resume and os.path.exists(chunk_name):            self.fh = open(chunk_name, mode=""ab"")            resume_position = self.fh.tell()            if not resume_position:                resume_position = os.stat(chunk_name).st_size            resume_position = resume(resume_position)            self.fh.truncate(resume_position)            self.received = resume_position        else:            self.fh = open(chunk_name, mode=""wb"")        last_update = time.time()        num_recv_len = 0        self.dccsock = self.create_socket()        recv_list = [self.dccsock]        self.dccsock.connect((ip, port))        self.dccsock.setblocking(False)        # recv loop for dcc socket        while True:            if self.abort:                self.dccsock.close()                self.fh.close()                raise Abort            fdset = select.select(recv_list, [], [], 0.1)            if self.dccsock in fdset[0]:                try:                    data = self.dccsock.recv(16384)                except socket.error as exc:                    if exc.errno in (errno.EAGAIN, errno.EWOULDBLOCK):                        continue                    else:                        raise                data_len = len(data)                if (                    data_len == 0                    or self.received + data_len > self.filesize > 0                ):                    break                num_recv_len += data_len                self._write_func(data)                self._send_ack()            now = time.time()            timespan = now - last_update            if timespan > 1:                # calc speed once per second, averaging over 3 seconds                self.speeds[2] = self.speeds[1]                self.speeds[1] = self.speeds[0]                self.speeds[0] = num_recv_len // timespan                num_recv_len = 0                last_update = now                self.update_progress()        self.dccsock.close()        self.fh.close()        os.rename(chunk_name, filename)        return filename",,"def download(self, ip, port, filename, status_notify=None, resume=None):        self.status_notify = status_notify        self.send_64bits_ack = not self.filesize < 1 << 32        chunk_name = filename + "".chunk0""        if resume and os.path.exists(chunk_name):            self.fh = open(chunk_name, mode=""ab"")            resume_position = self.fh.tell()            if not resume_position:                resume_position = os.stat(chunk_name).st_size            resume_position = resume(resume_position)            self.fh.truncate(resume_position)            self.received = resume_position        else:            self.fh = open(chunk_name, mode=""wb"")        last_update = time.time()        num_recv_len = 0        self.dccsock = self.create_socket()        recv_list = [self.dccsock]        self.dccsock.connect((ip, port))        self.dccsock.setblocking(False)        # recv loop for dcc socket        while True:            if self.abort:                self.dccsock.close()                self.fh.close()                raise Abort            fdset = select.select(recv_list, [], [], 0.1)            if self.dccsock in fdset[0]:                try:                    data = self.dccsock.recv(16384)                except socket.error as exc:                    if exc.errno in (errno.EAGAIN, errno.EWOULDBLOCK):                        continue                    else:                        raise                data_len = len(data)                if (                    data_len == 0                    or self.received + data_len > self.filesize > 0                ):                    break                num_recv_len += data_len                self._write_func(data)                self._send_ack()            now = time.time()            timespan = now - last_update            if timespan > 1:                # calc speed once per second, averaging over 3 seconds                self.speeds[2] = self.speeds[1]                self.speeds[1] = self.speeds[0]                self.speeds[0] = num_recv_len // timespan                num_recv_len = 0                last_update = now                self.update_progress()        self.dccsock.close()        self.fh.close()        os.rename(chunk_name, filename)        return filename",3ab19aca-31c0-4bc3-8ecd-b89c2606ede2
xdcc,request.py,abort_downloads,168,169,def abort_downloads(self):        self.abort = True,,def abort_downloads(self):        self.abort = True,40e81736-9439-4726-8c88-c41f5efbf788
xdcc,request.py,update_progress,171,173,"def update_progress(self):        if self.status_notify:            self.status_notify({""progress"": self.percent})",,"def update_progress(self):        if self.status_notify:            self.status_notify({""progress"": self.percent})",94820d51-e65f-4c9d-a7ce-7106dcea69d6
xdcc,request.py,size,176,177,def size(self):        return self.filesize,,def size(self):        return self.filesize,9643e935-38e6-4e22-9d38-d2184a717362
xdcc,request.py,arrived,180,181,def arrived(self):        return self.received,,def arrived(self):        return self.received,56aafe6a-f888-4385-b467-7191150fa664
xdcc,request.py,speed,184,186,def speed(self):        speeds = [x for x in self.speeds if x]        return sum(speeds) // len(speeds),,def speed(self):        speeds = [x for x in self.speeds if x]        return sum(speeds) // len(speeds),ead5338c-6ea7-49fb-8fb8-212c3fd6be0d
xdcc,request.py,percent,189,192,def percent(self):        if not self.filesize:            return 0        return (self.received * 100) // self.filesize,,def percent(self):        if not self.filesize:            return 0        return (self.received * 100) // self.filesize,42ec07d1-3bc3-4fbb-b31d-25c3683c770e
xdcc,request.py,close,194,195,def close(self):        pass,,def close(self):        pass,ceb62af9-d092-4ba0-9faa-1434a55797e2
threads,addon_thread.py,__init__,14,28,"def __init__(self, manager, function, args, kwargs):                super().__init__(manager)        self.f = function        self.args = args        self.kwargs = kwargs        self.active = []        manager.local_threads.append(self)        self.start()",Constructor.,"def __init__(self, manager, function, args, kwargs):        """"""        Constructor.        """"""        super().__init__(manager)        self.f = function        self.args = args        self.kwargs = kwargs        self.active = []        manager.local_threads.append(self)        self.start()

Constructor.",5d5e5c3b-37fe-42e9-b236-496373188757
threads,addon_thread.py,get_active_files,30,31,def get_active_files(self):        return self.active,,def get_active_files(self):        return self.active,b7defd47-657a-452d-8b6e-90f1611c6221
threads,addon_thread.py,add_active,33,38,"def add_active(self, pyfile):                if pyfile not in self.active:            self.active.append(pyfile)",Adds a pyfile to active list and thus will be displayed on overview.,"def add_active(self, pyfile):        """"""        Adds a pyfile to active list and thus will be displayed on overview.        """"""        if pyfile not in self.active:            self.active.append(pyfile)

Adds a pyfile to active list and thus will be displayed on overview.",22e6842d-ddb9-4b37-9630-65e4a2e743fd
threads,addon_thread.py,finish_file,40,44,"def finish_file(self, pyfile):        if pyfile in self.active:            self.active.remove(pyfile)        pyfile.finish_if_done()",,"def finish_file(self, pyfile):        if pyfile in self.active:            self.active.remove(pyfile)        pyfile.finish_if_done()",ddff40b6-fc8a-4eee-8613-5b0e10d350e2
threads,addon_thread.py,run,46,68,"def run(self):        try:            retry = False            try:                self.kwargs[""thread""] = self                self.f(*self.args, **self.kwargs)            except TypeError as exc:                # dirty method to filter out exceptions                if ""unexpected keyword argument 'thread'"" not in exc.args[0]:                    raise                else:                    retry = True            if retry:                del self.kwargs[""thread""]                self.f(*self.args, **self.kwargs)        finally:            local = copy(self.active)            for x in local:                self.finish_file(x)            self.m.local_threads.remove(self)",,"def run(self):        try:            retry = False            try:                self.kwargs[""thread""] = self                self.f(*self.args, **self.kwargs)            except TypeError as exc:                # dirty method to filter out exceptions                if ""unexpected keyword argument 'thread'"" not in exc.args[0]:                    raise                else:                    retry = True            if retry:                del self.kwargs[""thread""]                self.f(*self.args, **self.kwargs)        finally:            local = copy(self.active)            for x in local:                self.finish_file(x)            self.m.local_threads.remove(self)",663290e1-e4e3-4b36-af09-cabac77f2d91
threads,clicknload_thread.py,__init__,19,24,"def __init__(self, manager):        super().__init__()        self.m = self.manager = manager        self.pyload = manager.pyload        self._ = manager.pyload._        self.enabled = True",,"def __init__(self, manager):        super().__init__()        self.m = self.manager = manager        self.pyload = manager.pyload        self._ = manager.pyload._        self.enabled = True",abfbb4db-e07f-4178-a6a2-47c5277c219e
threads,clicknload_thread.py,run,26,34,"def run(self):        try:            self.serve()        except Exception as exc:            self.pyload.log.error(                self._(""Remote backend error: {}"").format(exc),                exc_info=self.pyload.debug > 1,                stack_info=self.pyload.debug > 2,            )",,"def run(self):        try:            self.serve()        except Exception as exc:            self.pyload.log.error(                self._(""Remote backend error: {}"").format(exc),                exc_info=self.pyload.debug > 1,                stack_info=self.pyload.debug > 2,            )",6a3dc224-d31b-4205-aa01-890820cd58d0
threads,clicknload_thread.py,setup,36,37,"def setup(self, host, port):        pass",,"def setup(self, host, port):        pass",bab35262-4b80-4444-9c2e-b90c14e07e8d
threads,clicknload_thread.py,check_deps,39,40,def check_deps(self):        return True,,def check_deps(self):        return True,5f096960-c602-4892-847e-abf0b787ace8
threads,clicknload_thread.py,serve,42,43,def serve(self):        pass,,def serve(self):        pass,fd0ac7be-f3dd-4bb9-8bd2-94f5645a62c4
threads,clicknload_thread.py,shutdown,45,46,def shutdown(self):        pass,,def shutdown(self):        pass,1467e884-a1cc-48e8-8ad9-a29d9bcf63c4
threads,clicknload_thread.py,stop,48,50,"def stop(self):        self.enabled = False  #: set flag and call shutdown message, so thread can react        self.shutdown()",,"def stop(self):        self.enabled = False  #: set flag and call shutdown message, so thread can react        self.shutdown()",6eb35e6d-b240-4f10-9fbe-5f7c7ab0e9fa
threads,clicknload_thread.py,setup,54,58,"def setup(self, host, port):        self.httpd = HTTPServer((host, port), CNLHandler)        global core, js        core = self.m.pyload        js = core.js",,"def setup(self, host, port):        self.httpd = HTTPServer((host, port), CNLHandler)        global core, js        core = self.m.pyload        js = core.js",98760a83-f83f-452d-a3f6-97c2c2d18768
threads,clicknload_thread.py,serve,60,62,def serve(self):        while self.enabled:            self.httpd.handle_request(),,def serve(self):        while self.enabled:            self.httpd.handle_request(),5068bdc3-fdb4-45bb-8593-ccf6c96e2733
threads,clicknload_thread.py,add_package,66,69,"def add_package(self, name, urls, queue=0):        print(""name"", name)        print(""urls"", urls)        print(""queue"", queue)",,"def add_package(self, name, urls, queue=0):        print(""name"", name)        print(""urls"", urls)        print(""queue"", queue)",e439c830-195b-4e7d-9a33-7e8d47a27d91
threads,clicknload_thread.py,get_post,71,75,"def get_post(self, name, default=""""):        if name in self.post:            return self.post[name]        else:            return default",,"def get_post(self, name, default=""""):        if name in self.post:            return self.post[name]        else:            return default",06a0653c-b9df-422e-b8bc-a078d4ae7b20
threads,clicknload_thread.py,start_response,77,86,"def start_response(self, string):        self.send_response(200)        self.send_header(""Content-Length"", len(string))        self.send_header(""Content-Language"", ""de"")        self.send_header(""Vary"", ""Accept-Language, Cookie"")        self.send_header(""Cache-Control"", ""no-cache, must-revalidate"")        self.send_header(""Content-type"", ""text/html"")        self.end_headers()",,"def start_response(self, string):        self.send_response(200)        self.send_header(""Content-Length"", len(string))        self.send_header(""Content-Language"", ""de"")        self.send_header(""Vary"", ""Accept-Language, Cookie"")        self.send_header(""Cache-Control"", ""no-cache, must-revalidate"")        self.send_header(""Content-type"", ""text/html"")        self.end_headers()",8d16c023-06f7-4b68-9da0-5754a9b9e11a
threads,clicknload_thread.py,do_GET,88,120,"def do_GET(self):        path = self.path.strip(""/"").lower()        # self.wfile.write(path+""\n"")        self.map = [            (r""add$"", self.add),            (r""addcrypted$"", self.addcrypted),            (r""addcrypted2$"", self.addcrypted2),            (r""flashgot"", self.flashgot),            (r""crossdomain\.xml"", self.crossdomain),            (r""check_support_for_url"", self.checksupport),            (r""jdcheck.js"", self.jdcheck),            (r"""", self.flash),        ]        func = None        for r, f in self.map:            if re.match(r""(flash(got)?/?)?"" + r, path):                func = f                break        if func:            try:                resp = func()                if not resp:                    resp = ""success""                resp += ""\r\n""                self.start_response(resp)                self.wfile.write(resp)            except Exception as exc:                self.send_error(500, exc)        else:            self.send_error(404, ""Not Found"")",,"def do_GET(self):        path = self.path.strip(""/"").lower()        # self.wfile.write(path+""\n"")        self.map = [            (r""add$"", self.add),            (r""addcrypted$"", self.addcrypted),            (r""addcrypted2$"", self.addcrypted2),            (r""flashgot"", self.flashgot),            (r""crossdomain\.xml"", self.crossdomain),            (r""check_support_for_url"", self.checksupport),            (r""jdcheck.js"", self.jdcheck),            (r"""", self.flash),        ]        func = None        for r, f in self.map:            if re.match(r""(flash(got)?/?)?"" + r, path):                func = f                break        if func:            try:                resp = func()                if not resp:                    resp = ""success""                resp += ""\r\n""                self.start_response(resp)                self.wfile.write(resp)            except Exception as exc:                self.send_error(500, exc)        else:            self.send_error(404, ""Not Found"")",b6b6d1d3-9296-45fa-a115-92e7ae0fb6bd
threads,clicknload_thread.py,do_POST,122,136,"def do_POST(self):        form = FieldStorage(            fp=self.rfile,            headers=self.headers,            environ={                ""REQUEST_METHOD"": ""POST"",                ""CONTENT_TYPE"": self.headers[""Content-Type""],            },        )        self.post = {}        for name in form.keys():            self.post[name] = form[name].value        return self.do_GET()",,"def do_POST(self):        form = FieldStorage(            fp=self.rfile,            headers=self.headers,            environ={                ""REQUEST_METHOD"": ""POST"",                ""CONTENT_TYPE"": self.headers[""Content-Type""],            },        )        self.post = {}        for name in form.keys():            self.post[name] = form[name].value        return self.do_GET()",8ba05efc-5707-422f-bc0a-6e6edeef65c4
threads,clicknload_thread.py,flash,138,139,"def flash(self):        return ""JDownloader""",,"def flash(self):        return ""JDownloader""",1837aacb-5565-41f1-98a1-661169d0187a
threads,clicknload_thread.py,add,141,145,"def add(self):        package = self.get_post(""referer"", ""ClickNLoad Package"")        urls = [x for x in self.get_post(""urls"").split(""\n"") if x != """"]        self.add_package(package, urls, 0)",,"def add(self):        package = self.get_post(""referer"", ""ClickNLoad Package"")        urls = [x for x in self.get_post(""urls"").split(""\n"") if x != """"]        self.add_package(package, urls, 0)",f1b749dd-2799-4df8-a0db-7b869241337a
threads,clicknload_thread.py,addcrypted,147,151,"def addcrypted(self):        package = self.get_post(""referer"", ""ClickNLoad Package"")        dlc = self.get_post(""crypted"").replace("" "", ""+"")        core.upload_container(package, dlc)",,"def addcrypted(self):        package = self.get_post(""referer"", ""ClickNLoad Package"")        dlc = self.get_post(""crypted"").replace("" "", ""+"")        core.upload_container(package, dlc)",a733623e-db5f-416d-8801-221483c28f96
threads,clicknload_thread.py,addcrypted2,153,167,"def addcrypted2(self):        package = self.get_post(""source"", ""ClickNLoad Package"")        crypted = self.get_post(""crypted"")        jk = self.get_post(""jk"")        crypted = standard_b64decode(unquote(crypted.replace("" "", ""+"")))        jk = eval_js(f""{jk} f()"")        key = bytes.fromhex(jk)        obj = Fernet(key)        result = obj.decrypt(crypted).replace(""\x00"", """").replace(""\r"", """").split(""\n"")        result = [x for x in result if x != """"]        self.add_package(package, result, 0)",,"def addcrypted2(self):        package = self.get_post(""source"", ""ClickNLoad Package"")        crypted = self.get_post(""crypted"")        jk = self.get_post(""jk"")        crypted = standard_b64decode(unquote(crypted.replace("" "", ""+"")))        jk = eval_js(f""{jk} f()"")        key = bytes.fromhex(jk)        obj = Fernet(key)        result = obj.decrypt(crypted).replace(""\x00"", """").replace(""\r"", """").split(""\n"")        result = [x for x in result if x != """"]        self.add_package(package, result, 0)",9ec9f4bf-f16e-495a-a393-121777adff96
threads,clicknload_thread.py,flashgot,169,174,"def flashgot(self):        autostart = int(self.get_post(""autostart"", 0))        package = self.get_post(""package"", ""FlashGot"")        urls = [x for x in self.get_post(""urls"").split(""\n"") if x != """"]        self.add_package(package, urls, autostart)",,"def flashgot(self):        autostart = int(self.get_post(""autostart"", 0))        package = self.get_post(""package"", ""FlashGot"")        urls = [x for x in self.get_post(""urls"").split(""\n"") if x != """"]        self.add_package(package, urls, autostart)",9eaf4852-f708-4e4b-a778-11e148db403c
threads,clicknload_thread.py,crossdomain,176,182,"def crossdomain(self):        rep = '<?xml version=""1.0""?>\n'        rep += '<!DOCTYPE cross-domain-policy SYSTEM ""http://www.macromedia.com/xml/dtds/cross-domain-policy.dtd"">\n'        rep += ""<cross-domain-policy>\n""        rep += '<allow-access-from domain=""*"" />\n'        rep += ""</cross-domain-policy>""        return rep",,"def crossdomain(self):        rep = '<?xml version=""1.0""?>\n'        rep += '<!DOCTYPE cross-domain-policy SYSTEM ""http://www.macromedia.com/xml/dtds/cross-domain-policy.dtd"">\n'        rep += ""<cross-domain-policy>\n""        rep += '<allow-access-from domain=""*"" />\n'        rep += ""</cross-domain-policy>""        return rep",b9ba542a-cc59-4c81-8d54-b2c1367af571
threads,clicknload_thread.py,checksupport,184,185,def checksupport(self):        pass,,def checksupport(self):        pass,bac63db8-b6c0-42b9-a6b1-c938c3b3c399
threads,clicknload_thread.py,jdcheck,187,190,"def jdcheck(self):        rep = ""jdownloader=true;\n""        rep += ""var version='10629';\n""        return rep",,"def jdcheck(self):        rep = ""jdownloader=true;\n""        rep += ""var version='10629';\n""        return rep",2691b028-ad00-4595-9836-2c53743cb83a
threads,database_thread.py,__init__,21,31,"def __init__(self, f, *args, **kwargs):        self.done = Event()        self.f = f        self.args = args        self.kwargs = kwargs        self.result = None        self.exception = False        self.frame = inspect.currentframe()",,"def __init__(self, f, *args, **kwargs):        self.done = Event()        self.f = f        self.args = args        self.kwargs = kwargs        self.result = None        self.exception = False        self.frame = inspect.currentframe()",e37555c0-1088-43de-b0e2-0322612df7b9
threads,database_thread.py,__repr__,33,48,"def __repr__(self):        frame = self.frame.f_back        output = """"        for i in range(5):            bn = os.path.basename(frame.f_code.co_filename)            ln = frame.f_lineno            cn = frame.f_code.co_name            output += f""\t{bn}:{ln}, {cn}\n""            frame = frame.f_back        del frame        del self.frame        return f""DataBase Job {self.f.__name__}:{self.args[1:]}\n{output} Result: {self.result}""",,"def __repr__(self):        frame = self.frame.f_back        output = """"        for i in range(5):            bn = os.path.basename(frame.f_code.co_filename)            ln = frame.f_lineno            cn = frame.f_code.co_name            output += f""\t{bn}:{ln}, {cn}\n""            frame = frame.f_back        del frame        del self.frame        return f""DataBase Job {self.f.__name__}:{self.args[1:]}\n{output} Result: {self.result}""",e94a6921-abdf-47ef-a508-4cb441b20e53
threads,database_thread.py,process_job,50,58,"def process_job(self):        try:            self.result = self.f(*self.args, **self.kwargs)        except Exception as exc:            msg = f""Database Error @ {self.f.__name__} {self.args[1:]} {self.kwargs}""            exc_logger.exception(msg)            self.exception = exc        finally:            self.done.set()",,"def process_job(self):        try:            self.result = self.f(*self.args, **self.kwargs)        except Exception as exc:            msg = f""Database Error @ {self.f.__name__} {self.args[1:]} {self.kwargs}""            exc_logger.exception(msg)            self.exception = exc        finally:            self.done.set()",2b99243c-3000-487d-a76c-c9e1f57e72ba
threads,database_thread.py,wait,60,61,def wait(self):        self.done.wait(),,def wait(self):        self.done.wait(),b89eb1fa-8506-44ab-92db-bbe316e17eca
threads,database_thread.py,__init__,71,87,"def __init__(self, core):        super().__init__()        self.daemon = True        self.pyload = core        self._ = core._        datadir = os.path.join(self.pyload.userdir, ""data"")        os.makedirs(datadir, exist_ok=True)        self.db_path = os.path.join(datadir, self.DB_FILENAME)        self.version_path = os.path.join(datadir, self.VERSION_FILENAME)        self.jobs = Queue()        self.setuplock = Event()        style.set_db(self)",,"def __init__(self, core):        super().__init__()        self.daemon = True        self.pyload = core        self._ = core._        datadir = os.path.join(self.pyload.userdir, ""data"")        os.makedirs(datadir, exist_ok=True)        self.db_path = os.path.join(datadir, self.DB_FILENAME)        self.version_path = os.path.join(datadir, self.VERSION_FILENAME)        self.jobs = Queue()        self.setuplock = Event()        style.set_db(self)",2e55667f-9c8c-49d3-9c4f-261fb8e1663b
threads,database_thread.py,setup,89,91,def setup(self):        self.start()        self.setuplock.wait(),,def setup(self):        self.start()        self.setuplock.wait(),c974e3dc-a039-48a9-806b-fb36a1b1c6ce
threads,database_thread.py,run,93,119,"def run(self):                convert = self._check_version()  #: returns None or current version        self.conn = sqlite3.connect(self.db_path, isolation_level=None)        os.chmod(self.db_path, 0o600)        self.c = self.conn.cursor()  #: compatibility        if convert is not None:            self._convert_db(convert)        self._create_tables()        self.conn.commit()        self.setuplock.set()        while True:            j = self.jobs.get()            if j == ""quit"":                self.c.close()                self.conn.close()                break            j.process_job()","main loop, which executes commands.","def run(self):        """"""        main loop, which executes commands.        """"""        convert = self._check_version()  #: returns None or current version        self.conn = sqlite3.connect(self.db_path, isolation_level=None)        os.chmod(self.db_path, 0o600)        self.c = self.conn.cursor()  #: compatibility        if convert is not None:            self._convert_db(convert)        self._create_tables()        self.conn.commit()        self.setuplock.set()        while True:            j = self.jobs.get()            if j == ""quit"":                self.c.close()                self.conn.close()                break            j.process_job()

main loop, which executes commands.",25ee11ec-2848-4ac6-9415-a8868ef95881
threads,database_thread.py,shutdown,122,124,"def shutdown(self):        self.conn.commit()        self.jobs.put(""quit"")",,"def shutdown(self):        self.conn.commit()        self.jobs.put(""quit"")",7935867b-20ec-41c0-9590-3999382df089
threads,database_thread.py,_check_version,126,147,"def _check_version(self):                if not os.path.exists(self.version_path):            with open(self.version_path, mode=""w"") as fp:                fp.write(str(__version__))            return        with open(self.version_path) as fp:            v = int(fp.read().strip())        if v < __version__:            if v < 2:                self.pyload.log.warning(                    self._(""Filedatabase was deleted due to incompatible version."")                )                os.remove(self.version_path)                shutil.move(self.db_path, ""files.backup.db"")            with open(self.version_path, mode=""w"") as fp:                fp.write(str(__version__))            return v",check db version and delete it if needed.,"def _check_version(self):        """"""        check db version and delete it if needed.        """"""        if not os.path.exists(self.version_path):            with open(self.version_path, mode=""w"") as fp:                fp.write(str(__version__))            return        with open(self.version_path) as fp:            v = int(fp.read().strip())        if v < __version__:            if v < 2:                self.pyload.log.warning(                    self._(""Filedatabase was deleted due to incompatible version."")                )                os.remove(self.version_path)                shutil.move(self.db_path, ""files.backup.db"")            with open(self.version_path, mode=""w"") as fp:                fp.write(str(__version__))            return v

check db version and delete it if needed.",16140db7-2d65-462d-8606-0613592811e8
threads,database_thread.py,_convert_db,149,153,"def _convert_db(self, v):        try:            getattr(self, f""_convertV{v}"")()        except Exception:            self.pyload.log.error(self._(""Filedatabase could NOT be converted.""))",,"def _convert_db(self, v):        try:            getattr(self, f""_convertV{v}"")()        except Exception:            self.pyload.log.error(self._(""Filedatabase could NOT be converted.""))",1886bd72-41c3-4119-af73-b4daffdab1fb
threads,database_thread.py,_convertV2,157,162,"def _convertV2(self):        self.c.execute(            'CREATE TABLE IF NOT EXISTS ""storage"" (""id"" INTEGER PRIMARY KEY AUTOINCREMENT, ""identifier"" TEXT NOT NULL, ""key"" TEXT NOT NULL, ""value"" TEXT DEFAULT """")'        )        self.pyload.log.info(self._(""Database was converted from v2 to v3.""))        self._convertV3()",,"def _convertV2(self):        self.c.execute(            'CREATE TABLE IF NOT EXISTS ""storage"" (""id"" INTEGER PRIMARY KEY AUTOINCREMENT, ""identifier"" TEXT NOT NULL, ""key"" TEXT NOT NULL, ""value"" TEXT DEFAULT """")'        )        self.pyload.log.info(self._(""Database was converted from v2 to v3.""))        self._convertV3()",26284213-ddf9-4bf3-8eb9-ff39bc2801e3
threads,database_thread.py,_convertV3,164,168,"def _convertV3(self):        self.c.execute(            'CREATE TABLE IF NOT EXISTS ""users"" (""id"" INTEGER PRIMARY KEY AUTOINCREMENT, ""name"" TEXT NOT NULL, ""email"" TEXT DEFAULT """" NOT NULL, ""password"" TEXT NOT NULL, ""role"" INTEGER DEFAULT 0 NOT NULL, ""permission"" INTEGER DEFAULT 0 NOT NULL, ""template"" TEXT DEFAULT ""default"" NOT NULL)'        )        self.pyload.log.info(self._(""Database was converted from v3 to v4.""))",,"def _convertV3(self):        self.c.execute(            'CREATE TABLE IF NOT EXISTS ""users"" (""id"" INTEGER PRIMARY KEY AUTOINCREMENT, ""name"" TEXT NOT NULL, ""email"" TEXT DEFAULT """" NOT NULL, ""password"" TEXT NOT NULL, ""role"" INTEGER DEFAULT 0 NOT NULL, ""permission"" INTEGER DEFAULT 0 NOT NULL, ""template"" TEXT DEFAULT ""default"" NOT NULL)'        )        self.pyload.log.info(self._(""Database was converted from v3 to v4.""))",81afd21f-e4e3-45a0-9b24-6633ad01d1af
threads,database_thread.py,_create_tables,172,221,"def _create_tables(self):                self.c.execute(            'CREATE TABLE IF NOT EXISTS ""packages"" (""id"" INTEGER PRIMARY KEY AUTOINCREMENT, ""name"" TEXT NOT NULL, ""folder"" TEXT, ""password"" TEXT DEFAULT """", ""site"" TEXT DEFAULT """", ""queue"" INTEGER DEFAULT 0 NOT NULL, ""packageorder"" INTEGER DEFAULT 0 NOT NULL)'        )        self.c.execute(            'CREATE TABLE IF NOT EXISTS ""links"" (""id"" INTEGER PRIMARY KEY AUTOINCREMENT, ""url"" TEXT NOT NULL, ""name"" TEXT, ""size"" INTEGER DEFAULT 0 NOT NULL, ""status"" INTEGER DEFAULT 3 NOT NULL, ""plugin"" TEXT DEFAULT ""DefaultPlugin"" NOT NULL, ""error"" TEXT DEFAULT """", ""linkorder"" INTEGER DEFAULT 0 NOT NULL, ""package"" INTEGER DEFAULT 0 NOT NULL, FOREIGN KEY(package) REFERENCES packages(id))'        )        self.c.execute('CREATE INDEX IF NOT EXISTS ""p_id_index"" ON links(package)')        self.c.execute(            'CREATE TABLE IF NOT EXISTS ""storage"" (""id"" INTEGER PRIMARY KEY AUTOINCREMENT, ""identifier"" TEXT NOT NULL, ""key"" TEXT NOT NULL, ""value"" TEXT DEFAULT """")'        )        self.c.execute(            'CREATE TABLE IF NOT EXISTS ""users"" (""id"" INTEGER PRIMARY KEY AUTOINCREMENT, ""name"" TEXT NOT NULL, ""email"" TEXT DEFAULT """" NOT NULL, ""password"" TEXT NOT NULL, ""role"" INTEGER DEFAULT 0 NOT NULL, ""permission"" INTEGER DEFAULT 0 NOT NULL, ""template"" TEXT DEFAULT ""default"" NOT NULL)'        )        self.c.execute(            'CREATE VIEW IF NOT EXISTS ""pstats"" AS \        SELECT p.id AS id, SUM(l.size) AS sizetotal, COUNT(l.id) AS linkstotal, linksdone, sizedone\        FROM packages p JOIN links l ON p.id = l.package LEFT OUTER JOIN\        (SELECT p.id AS id, COUNT(*) AS linksdone, SUM(l.size) AS sizedone \        FROM packages p JOIN links l ON p.id = l.package AND l.status in (0,4,13) GROUP BY p.id) s ON s.id = p.id \        GROUP BY p.id'        )        # try to lower ids        self.c.execute(""SELECT max(id) FROM LINKS"")        fid = self.c.fetchone()[0]        if fid:            fid = int(fid)        else:            fid = 0        self.c.execute(""UPDATE SQLITE_SEQUENCE SET seq=? WHERE name=?"", (fid, ""links""))        self.c.execute(""SELECT max(id) FROM packages"")        pid = self.c.fetchone()[0]        if pid:            pid = int(pid)        else:            pid = 0        self.c.execute(            ""UPDATE SQLITE_SEQUENCE SET seq=? WHERE name=?"", (pid, ""packages"")        )        # set unfinished links as aborted        self.c.execute(""UPDATE links SET status=9 WHERE status NOT IN (0, 1, 4, 6, 8, 9)"")        self.c.execute(""VACUUM"")",create tables for database.,"def _create_tables(self):        """"""        create tables for database.        """"""        self.c.execute(            'CREATE TABLE IF NOT EXISTS ""packages"" (""id"" INTEGER PRIMARY KEY AUTOINCREMENT, ""name"" TEXT NOT NULL, ""folder"" TEXT, ""password"" TEXT DEFAULT """", ""site"" TEXT DEFAULT """", ""queue"" INTEGER DEFAULT 0 NOT NULL, ""packageorder"" INTEGER DEFAULT 0 NOT NULL)'        )        self.c.execute(            'CREATE TABLE IF NOT EXISTS ""links"" (""id"" INTEGER PRIMARY KEY AUTOINCREMENT, ""url"" TEXT NOT NULL, ""name"" TEXT, ""size"" INTEGER DEFAULT 0 NOT NULL, ""status"" INTEGER DEFAULT 3 NOT NULL, ""plugin"" TEXT DEFAULT ""DefaultPlugin"" NOT NULL, ""error"" TEXT DEFAULT """", ""linkorder"" INTEGER DEFAULT 0 NOT NULL, ""package"" INTEGER DEFAULT 0 NOT NULL, FOREIGN KEY(package) REFERENCES packages(id))'        )        self.c.execute('CREATE INDEX IF NOT EXISTS ""p_id_index"" ON links(package)')        self.c.execute(            'CREATE TABLE IF NOT EXISTS ""storage"" (""id"" INTEGER PRIMARY KEY AUTOINCREMENT, ""identifier"" TEXT NOT NULL, ""key"" TEXT NOT NULL, ""value"" TEXT DEFAULT """")'        )        self.c.execute(            'CREATE TABLE IF NOT EXISTS ""users"" (""id"" INTEGER PRIMARY KEY AUTOINCREMENT, ""name"" TEXT NOT NULL, ""email"" TEXT DEFAULT """" NOT NULL, ""password"" TEXT NOT NULL, ""role"" INTEGER DEFAULT 0 NOT NULL, ""permission"" INTEGER DEFAULT 0 NOT NULL, ""template"" TEXT DEFAULT ""default"" NOT NULL)'        )        self.c.execute(            'CREATE VIEW IF NOT EXISTS ""pstats"" AS \        SELECT p.id AS id, SUM(l.size) AS sizetotal, COUNT(l.id) AS linkstotal, linksdone, sizedone\        FROM packages p JOIN links l ON p.id = l.package LEFT OUTER JOIN\        (SELECT p.id AS id, COUNT(*) AS linksdone, SUM(l.size) AS sizedone \        FROM packages p JOIN links l ON p.id = l.package AND l.status in (0,4,13) GROUP BY p.id) s ON s.id = p.id \        GROUP BY p.id'        )        # try to lower ids        self.c.execute(""SELECT max(id) FROM LINKS"")        fid = self.c.fetchone()[0]        if fid:            fid = int(fid)        else:            fid = 0        self.c.execute(""UPDATE SQLITE_SEQUENCE SET seq=? WHERE name=?"", (fid, ""links""))        self.c.execute(""SELECT max(id) FROM packages"")        pid = self.c.fetchone()[0]        if pid:            pid = int(pid)        else:            pid = 0        self.c.execute(            ""UPDATE SQLITE_SEQUENCE SET seq=? WHERE name=?"", (pid, ""packages"")        )        # set unfinished links as aborted        self.c.execute(""UPDATE links SET status=9 WHERE status NOT IN (0, 1, 4, 6, 8, 9)"")        self.c.execute(""VACUUM"")

create tables for database.",032ed856-69d4-4d5a-96ed-d09bbe8d2b0b
threads,database_thread.py,create_cursor,223,224,def create_cursor(self):        return self.conn.cursor(),,def create_cursor(self):        return self.conn.cursor(),1c737848-301d-4090-af33-64dfdd5579c0
threads,database_thread.py,commit,227,228,def commit(self):        self.conn.commit(),,def commit(self):        self.conn.commit(),df35539c-a587-49ea-a92b-1e543d262d28
threads,database_thread.py,sync_save,231,232,def sync_save(self):        self.conn.commit(),,def sync_save(self):        self.conn.commit(),4c478496-7d1c-4022-a1ff-b3d1f39e0735
threads,database_thread.py,rollback,235,236,def rollback(self):        self.conn.rollback(),,def rollback(self):        self.conn.rollback(),f25f2fe5-bef9-42ba-940f-66443f36c5e2
threads,database_thread.py,async_,238,241,"def async_(self, f, *args, **kwargs):        args = (self,) + args        job = DatabaseJob(f, *args, **kwargs)        self.jobs.put(job)",,"def async_(self, f, *args, **kwargs):        args = (self,) + args        job = DatabaseJob(f, *args, **kwargs)        self.jobs.put(job)",7171b6ff-192b-4133-a2a7-498bedaeb0bb
threads,database_thread.py,queue,243,248,"def queue(self, f, *args, **kwargs):        args = (self,) + args        job = DatabaseJob(f, *args, **kwargs)        self.jobs.put(job)        job.wait()        return job.result",,"def queue(self, f, *args, **kwargs):        args = (self,) + args        job = DatabaseJob(f, *args, **kwargs)        self.jobs.put(job)        job.wait()        return job.result",30e91cf3-3448-4d95-ab1d-20539b718992
threads,database_thread.py,register_sub,251,252,"def register_sub(cls, klass):        cls.subs.append(klass)",,"def register_sub(cls, klass):        cls.subs.append(klass)",c4f5c52e-8277-4683-89f1-e1e10b29abb8
threads,database_thread.py,unregister_sub,255,256,"def unregister_sub(cls, klass):        cls.subs.remove(klass)",,"def unregister_sub(cls, klass):        cls.subs.remove(klass)",1e78917f-fa82-47eb-9c48-4dcf78b98bae
threads,database_thread.py,__getattr__,258,265,"def __getattr__(self, attr):        for sub in DatabaseThread.subs:            if hasattr(sub, attr):                return getattr(sub, attr)        raise AttributeError(            f""'{self.__class__.__name__}' object has no attribute '{attr}'""        )",,"def __getattr__(self, attr):        for sub in DatabaseThread.subs:            if hasattr(sub, attr):                return getattr(sub, attr)        raise AttributeError(            f""'{self.__class__.__name__}' object has no attribute '{attr}'""        )",5b905488-6ad7-41f6-af97-fffff2931a90
threads,decrypter_thread.py,__init__,13,24,"def __init__(self, manager, pyfile):                super().__init__(manager)        self.active = pyfile        manager.local_threads.append(self)        pyfile.set_status(""decrypting"")        self.start()",constructor.,"def __init__(self, manager, pyfile):        """"""        constructor.        """"""        super().__init__(manager)        self.active = pyfile        manager.local_threads.append(self)        pyfile.set_status(""decrypting"")        self.start()

constructor.",660f0255-ce55-4690-8b5f-380364f21c75
threads,decrypter_thread.py,get_active_files,26,27,def get_active_files(self):        return [self.active],,def get_active_files(self):        return [self.active],7e974253-f538-4b9f-9567-3a31d7498287
threads,decrypter_thread.py,run,29,107,"def run(self):                pyfile = self.active        retry = False        try:            self.pyload.log.info(                self._(""Decrypting starts: {}"").format(self.active.name)            )            self.active.plugin.preprocessing(self)        except NotImplementedError:            self.pyload.log.error(                self._(""Plugin {} is missing a function"").format(self.active.pluginname)            )            return        except Fail as exc:            msg = exc.args[0]            if msg == ""offline"":                self.active.set_status(""offline"")                self.pyload.log.warning(                    self._(""Download is offline: {}"").format(self.active.name)                )            else:                self.active.set_status(""failed"")                self.pyload.log.error(                    self._(""Decrypting failed: {name} | {msg}"").format(                        name=self.active.name, msg=msg                    )                )                self.active.error = msg            return        except Abort:            self.pyload.log.info(self._(""Download aborted: {}"").format(pyfile.name))            pyfile.set_status(""aborted"")            return        except Retry:            self.pyload.log.info(self._(""Retrying {}"").format(self.active.name))            retry = True            return self.run()        except Exception as exc:            self.active.set_status(""failed"")            self.pyload.log.warning(                self._(""Decrypting failed: {name} | {msg}"").format(                    name=self.active.name, msg=exc                ),                exc_info=self.pyload.debug > 1,                stack_info=self.pyload.debug > 2,            )            self.active.error = str(exc)            if self.pyload.debug:                self.write_debug_report(pyfile)            return        finally:            if not retry:                self.active.release()                self.active = False                self.pyload.files.save()                self.m.local_threads.remove(self)                # exc_clear()        # self.pyload.addon_manager.download_finished(pyfile)        # self.m.local_threads.remove(self)        # self.active.finish_if_done()        if not retry:            pyfile.delete()",run method.,"def run(self):        """"""        run method.        """"""        pyfile = self.active        retry = False        try:            self.pyload.log.info(                self._(""Decrypting starts: {}"").format(self.active.name)            )            self.active.plugin.preprocessing(self)        except NotImplementedError:            self.pyload.log.error(                self._(""Plugin {} is missing a function"").format(self.active.pluginname)            )            return        except Fail as exc:            msg = exc.args[0]            if msg == ""offline"":                self.active.set_status(""offline"")                self.pyload.log.warning(                    self._(""Download is offline: {}"").format(self.active.name)                )            else:                self.active.set_status(""failed"")                self.pyload.log.error(                    self._(""Decrypting failed: {name} | {msg}"").format(                        name=self.active.name, msg=msg                    )                )                self.active.error = msg            return        except Abort:            self.pyload.log.info(self._(""Download aborted: {}"").format(pyfile.name))            pyfile.set_status(""aborted"")            return        except Retry:            self.pyload.log.info(self._(""Retrying {}"").format(self.active.name))            retry = True            return self.run()        except Exception as exc:            self.active.set_status(""failed"")            self.pyload.log.warning(                self._(""Decrypting failed: {name} | {msg}"").format(                    name=self.active.name, msg=exc                ),                exc_info=self.pyload.debug > 1,                stack_info=self.pyload.debug > 2,            )            self.active.error = str(exc)            if self.pyload.debug:                self.write_debug_report(pyfile)            return        finally:            if not retry:                self.active.release()                self.active = False                self.pyload.files.save()                self.m.local_threads.remove(self)                # exc_clear()        # self.pyload.addon_manager.download_finished(pyfile)        # self.m.local_threads.remove(self)        # self.active.finish_if_done()        if not retry:            pyfile.delete()

run method.",69232852-b999-4b20-a845-09d835104490
threads,download_thread.py,__init__,18,27,"def __init__(self, manager):                super().__init__(manager)        self.queue = Queue()  #: job queue        self.active = False        self.start()",Constructor.,"def __init__(self, manager):        """"""        Constructor.        """"""        super().__init__(manager)        self.queue = Queue()  #: job queue        self.active = False        self.start()

Constructor.",e5a415c2-d272-4665-9243-5021a1b42623
threads,download_thread.py,run,30,218,"def run(self):                pyfile = None        while True:            del pyfile            pyfile = self.active = self.queue.get()            if self.active == ""quit"":                self.active = False                self.m.threads.remove(self)                return True            try:                if not pyfile.has_plugin():                    continue                # this pyfile was deleted while queueing                pyfile.plugin.check_for_same_files(starting=True)                self.pyload.log.info(self._(""Download starts: {}"").format(pyfile.name))                # start download                self.pyload.addon_manager.download_preparing(pyfile)                pyfile.plugin.preprocessing(self)                self.pyload.log.info(                    self._(""Download finished: {}"").format(pyfile.name)                )                self.pyload.addon_manager.download_finished(pyfile)                self.pyload.files.check_package_finished(pyfile)            except NotImplementedError:                self.pyload.log.error(                    self._(""Plugin {} is missing a function"").format(pyfile.pluginname)                )                pyfile.set_status(""failed"")                pyfile.error = ""Plugin does not work""                self.clean(pyfile)                continue            except Abort:                pyfile.set_status(""aborted"")                self.pyload.log.info(self._(""Download aborted: {}"").format(pyfile.name))                self.clean(pyfile)                continue            except Reconnect:                self.queue.put(pyfile)                # pyfile.req.clear_cookies()                while self.m.reconnecting.is_set():                    time.sleep(0.5)                continue            except Retry as exc:                reason = exc.args[0]                self.pyload.log.info(                    self._(""Download restarted: {name} | {msg}"").format(                        name=pyfile.name, msg=reason                    )                )                self.queue.put(pyfile)                continue            except Fail as exc:                msg = exc.args[0]                if msg == ""offline"":                    pyfile.set_status(""offline"")                    self.pyload.log.warning(                        self._(""Download is offline: {}"").format(pyfile.name)                    )                elif msg == ""temp. offline"":                    pyfile.set_status(""temp. offline"")                    self.pyload.log.warning(                        self._(""Download is temporary offline: {}"").format(pyfile.name)                    )                else:                    pyfile.set_status(""failed"")                    self.pyload.log.warning(                        self._(""Download failed: {name} | {msg}"").format(                            name=pyfile.name, msg=msg                        )                    )                    pyfile.error = msg                self.pyload.addon_manager.download_failed(pyfile)                self.clean(pyfile)                continue            # except pycurl.error as exc:            # if len(exc.args) == 2:            # code, msg = exc.args            # else:            # code = 0            # msg = exc.args            # self.pyload.log.debug(f""pycurl exception {code}: {msg}"")            # if code in (7, 18, 28, 52, 56):            # self.pyload.log.warning(            # self._(            # ""Couldn't connect to host or connection reset, waiting 1 minute and retry.""            # )            # )            # wait = time.time() + 60            # pyfile.wait_until = wait            # pyfile.set_status(""waiting"")            # while time.time() < wait:            # time.sleep(1)            # if pyfile.abort:            # break            # if pyfile.abort:            # self.pyload.log.info(            # self._(""Download aborted: {}"").format(pyfile.name)            # )            # pyfile.set_status(""aborted"")            # self.clean(pyfile)            # else:            # self.queue.put(pyfile)            # continue            # else:            # pyfile.set_status(""failed"")            # self.pyload.log.error(            # self._(""pycurl error {}: {}"").format(code, msg)            # )            # if self.pyload.debug:            # self.write_debug_report(pyfile)            # self.pyload.addon_manager.download_failed(pyfile)            # self.clean(pyfile)            # continue            except Skip as exc:                pyfile.set_status(""skipped"")                self.pyload.log.info(                    self._(""Download skipped: {name} due to {plugin}"").format(                        name=pyfile.name, plugin=exc                    )                )                self.clean(pyfile)                self.pyload.files.check_package_finished(pyfile)                self.active = False                self.pyload.files.save()                continue            except Exception as exc:                traceback.print_exc()                pyfile.set_status(""failed"")                self.pyload.log.warning(                    self._(""Download failed: {name} | {msg}"").format(                        name=pyfile.name, msg=exc                    ),                    exc_info=self.pyload.debug > 1,                    stack_info=self.pyload.debug > 2,                )                pyfile.error = str(exc)                if self.pyload.debug:                    self.write_debug_report(pyfile)                self.pyload.addon_manager.download_failed(pyfile)                self.clean(pyfile)                continue            finally:                self.pyload.files.save()                pyfile.check_if_processed()            # pyfile.plugin.req.clean()            self.active = False            pyfile.finish_if_done()            self.pyload.files.save()",run method.,"def run(self):        """"""        run method.        """"""        pyfile = None        while True:            del pyfile            pyfile = self.active = self.queue.get()            if self.active == ""quit"":                self.active = False                self.m.threads.remove(self)                return True            try:                if not pyfile.has_plugin():                    continue                # this pyfile was deleted while queueing                pyfile.plugin.check_for_same_files(starting=True)                self.pyload.log.info(self._(""Download starts: {}"").format(pyfile.name))                # start download                self.pyload.addon_manager.download_preparing(pyfile)                pyfile.plugin.preprocessing(self)                self.pyload.log.info(                    self._(""Download finished: {}"").format(pyfile.name)                )                self.pyload.addon_manager.download_finished(pyfile)                self.pyload.files.check_package_finished(pyfile)            except NotImplementedError:                self.pyload.log.error(                    self._(""Plugin {} is missing a function"").format(pyfile.pluginname)                )                pyfile.set_status(""failed"")                pyfile.error = ""Plugin does not work""                self.clean(pyfile)                continue            except Abort:                pyfile.set_status(""aborted"")                self.pyload.log.info(self._(""Download aborted: {}"").format(pyfile.name))                self.clean(pyfile)                continue            except Reconnect:                self.queue.put(pyfile)                # pyfile.req.clear_cookies()                while self.m.reconnecting.is_set():                    time.sleep(0.5)                continue            except Retry as exc:                reason = exc.args[0]                self.pyload.log.info(                    self._(""Download restarted: {name} | {msg}"").format(                        name=pyfile.name, msg=reason                    )                )                self.queue.put(pyfile)                continue            except Fail as exc:                msg = exc.args[0]                if msg == ""offline"":                    pyfile.set_status(""offline"")                    self.pyload.log.warning(                        self._(""Download is offline: {}"").format(pyfile.name)                    )                elif msg == ""temp. offline"":                    pyfile.set_status(""temp. offline"")                    self.pyload.log.warning(                        self._(""Download is temporary offline: {}"").format(pyfile.name)                    )                else:                    pyfile.set_status(""failed"")                    self.pyload.log.warning(                        self._(""Download failed: {name} | {msg}"").format(                            name=pyfile.name, msg=msg                        )                    )                    pyfile.error = msg                self.pyload.addon_manager.download_failed(pyfile)                self.clean(pyfile)                continue            # except pycurl.error as exc:            # if len(exc.args) == 2:            # code, msg = exc.args            # else:            # code = 0            # msg = exc.args            # self.pyload.log.debug(f""pycurl exception {code}: {msg}"")            # if code in (7, 18, 28, 52, 56):            # self.pyload.log.warning(            # self._(            # ""Couldn't connect to host or connection reset, waiting 1 minute and retry.""            # )            # )            # wait = time.time() + 60            # pyfile.wait_until = wait            # pyfile.set_status(""waiting"")            # while time.time() < wait:            # time.sleep(1)            # if pyfile.abort:            # break            # if pyfile.abort:            # self.pyload.log.info(            # self._(""Download aborted: {}"").format(pyfile.name)            # )            # pyfile.set_status(""aborted"")            # self.clean(pyfile)            # else:            # self.queue.put(pyfile)            # continue            # else:            # pyfile.set_status(""failed"")            # self.pyload.log.error(            # self._(""pycurl error {}: {}"").format(code, msg)            # )            # if self.pyload.debug:            # self.write_debug_report(pyfile)            # self.pyload.addon_manager.download_failed(pyfile)            # self.clean(pyfile)            # continue            except Skip as exc:                pyfile.set_status(""skipped"")                self.pyload.log.info(                    self._(""Download skipped: {name} due to {plugin}"").format(                        name=pyfile.name, plugin=exc                    )                )                self.clean(pyfile)                self.pyload.files.check_package_finished(pyfile)                self.active = False                self.pyload.files.save()                continue            except Exception as exc:                traceback.print_exc()                pyfile.set_status(""failed"")                self.pyload.log.warning(                    self._(""Download failed: {name} | {msg}"").format(                        name=pyfile.name, msg=exc                    ),                    exc_info=self.pyload.debug > 1,                    stack_info=self.pyload.debug > 2,                )                pyfile.error = str(exc)                if self.pyload.debug:                    self.write_debug_report(pyfile)                self.pyload.addon_manager.download_failed(pyfile)                self.clean(pyfile)                continue            finally:                self.pyload.files.save()                pyfile.check_if_processed()            # pyfile.plugin.req.clean()            self.active = False            pyfile.finish_if_done()            self.pyload.files.save()

run method.",760cbf5e-182a-4123-8928-00bdad6fbdd9
threads,download_thread.py,put,220,224,"def put(self, job):                self.queue.put(job)",assing job to thread.,"def put(self, job):        """"""        assing job to thread.        """"""        self.queue.put(job)

assing job to thread.",2a9da657-19c4-4c63-ac00-467168999dca
threads,download_thread.py,stop,226,230,"def stop(self):                self.put(""quit"")",stops the thread.,"def stop(self):        """"""        stops the thread.        """"""        self.put(""quit"")

stops the thread.",37805744-db50-4dbb-852f-f30947fef732
threads,info_thread.py,__init__,13,28,"def __init__(self, manager, data, pid=-1, rid=-1, add=False):                super().__init__(manager)        self.data = data        self.pid = pid  #: package id        # [ .. (name, plugin) .. ]        self.rid = rid  #: result id        self.add = add  #: add packages instead of return result        self.cache = []  #: accumulated data        self.start()",Constructor.,"def __init__(self, manager, data, pid=-1, rid=-1, add=False):        """"""        Constructor.        """"""        super().__init__(manager)        self.data = data        self.pid = pid  #: package id        # [ .. (name, plugin) .. ]        self.rid = rid  #: result id        self.add = add  #: add packages instead of return result        self.cache = []  #: accumulated data        self.start()

Constructor.",ec099705-7879-4007-b386-cb385ffc7cbe
threads,info_thread.py,run,30,123,"def run(self):                plugins = {}        container = []        for url, plugin in self.data:            if plugin in plugins:                plugins[plugin].append(url)            else:                plugins[plugin] = [url]        # filter out container plugins        for name in self.pyload.plugin_manager.container_plugins:            if name in plugins:                container.extend((name, url) for url in plugins[name])                del plugins[name]        # directly write to database        if self.pid > -1:            for pluginname, urls in plugins.items():                plugin = self.pyload.plugin_manager.get_plugin(pluginname, True)                if hasattr(plugin, ""get_info""):                    self.fetch_for_plugin(pluginname, plugin, urls, self.update_db)                    self.pyload.files.save()        elif self.add:            for pluginname, urls in plugins.items():                plugin = self.pyload.plugin_manager.get_plugin(pluginname, True)                if hasattr(plugin, ""get_info""):                    self.fetch_for_plugin(                        pluginname, plugin, urls, self.update_cache, True                    )                else:                    # generate default result                    result = [(url, 0, 3, url) for url in urls]                    self.update_cache(pluginname, result)            packs = parse_names((name, url) for name, x, y, url in self.cache)            self.pyload.log.debug(f""Fetched and generated {len(packs)} packages"")            for k, v in packs.items():                self.pyload.api.add_package(k, v)            # empty cache            del self.cache[:]        else:  #: post the results            for name, url in container:                # attach container content                try:                    data = self.decrypt_container(name, url)                except Exception:                    self.pyload.log.warning(                        ""Could not decrypt container."",                        exc_info=self.pyload.debug > 1,                        stack_info=self.pyload.debug > 2,                    )                    data = []                for url, plugin in data:                    if plugin in plugins:                        plugins[plugin].append(url)                    else:                        plugins[plugin] = [url]            self.m.info_results[self.rid] = {}            for pluginname, urls in plugins.items():                plugin = self.pyload.plugin_manager.get_plugin(pluginname, True)                if hasattr(plugin, ""get_info""):                    self.fetch_for_plugin(                        pluginname, plugin, urls, self.update_result, True                    )                    # force to process cache                    if self.cache:                        self.update_result(pluginname, [], True)                else:                    # generate default result                    result = [(url, 0, 3, url) for url in urls]                    self.update_result(pluginname, result, True)            self.m.info_results[self.rid][""ALL_INFO_FETCHED""] = {}        self.m.timestamp = time.time() + timedelta(minutes=5).total_seconds()",run method.,"def run(self):        """"""        run method.        """"""        plugins = {}        container = []        for url, plugin in self.data:            if plugin in plugins:                plugins[plugin].append(url)            else:                plugins[plugin] = [url]        # filter out container plugins        for name in self.pyload.plugin_manager.container_plugins:            if name in plugins:                container.extend((name, url) for url in plugins[name])                del plugins[name]        # directly write to database        if self.pid > -1:            for pluginname, urls in plugins.items():                plugin = self.pyload.plugin_manager.get_plugin(pluginname, True)                if hasattr(plugin, ""get_info""):                    self.fetch_for_plugin(pluginname, plugin, urls, self.update_db)                    self.pyload.files.save()        elif self.add:            for pluginname, urls in plugins.items():                plugin = self.pyload.plugin_manager.get_plugin(pluginname, True)                if hasattr(plugin, ""get_info""):                    self.fetch_for_plugin(                        pluginname, plugin, urls, self.update_cache, True                    )                else:                    # generate default result                    result = [(url, 0, 3, url) for url in urls]                    self.update_cache(pluginname, result)            packs = parse_names((name, url) for name, x, y, url in self.cache)            self.pyload.log.debug(f""Fetched and generated {len(packs)} packages"")            for k, v in packs.items():                self.pyload.api.add_package(k, v)            # empty cache            del self.cache[:]        else:  #: post the results            for name, url in container:                # attach container content                try:                    data = self.decrypt_container(name, url)                except Exception:                    self.pyload.log.warning(                        ""Could not decrypt container."",                        exc_info=self.pyload.debug > 1,                        stack_info=self.pyload.debug > 2,                    )                    data = []                for url, plugin in data:                    if plugin in plugins:                        plugins[plugin].append(url)                    else:                        plugins[plugin] = [url]            self.m.info_results[self.rid] = {}            for pluginname, urls in plugins.items():                plugin = self.pyload.plugin_manager.get_plugin(pluginname, True)                if hasattr(plugin, ""get_info""):                    self.fetch_for_plugin(                        pluginname, plugin, urls, self.update_result, True                    )                    # force to process cache                    if self.cache:                        self.update_result(pluginname, [], True)                else:                    # generate default result                    result = [(url, 0, 3, url) for url in urls]                    self.update_result(pluginname, result, True)            self.m.info_results[self.rid][""ALL_INFO_FETCHED""] = {}        self.m.timestamp = time.time() + timedelta(minutes=5).total_seconds()

run method.",d14f3a55-8feb-4fc5-b30d-044a13ddde5f
threads,info_thread.py,update_db,125,126,"def update_db(self, plugin, result):        self.pyload.files.update_file_info(result, self.pid)",,"def update_db(self, plugin, result):        self.pyload.files.update_file_info(result, self.pid)",2d339a29-74a6-4edd-b07f-78c133a75ce4
threads,info_thread.py,update_result,128,150,"def update_result(self, plugin, result, force=False):        # parse package name and generate result        # accumulate results        self.cache.extend(result)        if len(self.cache) >= 20 or force:            # used for package generating            tmp = [                (name, (url, OnlineStatus(name, plugin, ""unknown"", status, int(size))))                for name, size, status, url in self.cache            ]            data = parse_names(tmp)            result = {}            for k, v in data.items():                for url, status in v:                    status.packagename = k                    result[url] = status            self.m.set_info_results(self.rid, result)            self.cache = []",,"def update_result(self, plugin, result, force=False):        # parse package name and generate result        # accumulate results        self.cache.extend(result)        if len(self.cache) >= 20 or force:            # used for package generating            tmp = [                (name, (url, OnlineStatus(name, plugin, ""unknown"", status, int(size))))                for name, size, status, url in self.cache            ]            data = parse_names(tmp)            result = {}            for k, v in data.items():                for url, status in v:                    status.packagename = k                    result[url] = status            self.m.set_info_results(self.rid, result)            self.cache = []",1d63ead0-a50b-45a8-a2a6-09dea89fffd4
threads,info_thread.py,update_cache,152,153,"def update_cache(self, plugin, result):        self.cache.extend(result)",,"def update_cache(self, plugin, result):        self.cache.extend(result)",c8b23be0-291c-4ac6-b0a6-9d9c97b9a89a
threads,info_thread.py,fetch_for_plugin,155,196,"def fetch_for_plugin(self, pluginname, plugin, urls, cb, err=None):        try:            result = []  #: result loaded from cache            process = []  #: urls to process            for url in urls:                if url in self.m.info_cache:                    result.append(self.m.info_cache[url])                else:                    process.append(url)            if result:                self.pyload.log.debug(                    f""Fetched {len(result)} values from cache for {pluginname}""                )                cb(pluginname, result)            if process:                self.pyload.log.debug(f""Run Info Fetching for {pluginname}"")                for result in plugin.get_info(process):                    # result = [ .. (name, size, status, url) .. ]                    if not isinstance(result, list):                        result = [result]                    for res in result:                        self.m.info_cache[res[3]] = res                    cb(pluginname, result)            self.pyload.log.debug(f""Finished Info Fetching for {pluginname}"")        except Exception as exc:            self.pyload.log.warning(                self._(""Info Fetching for {name} failed | {err}"").format(                    name=pluginname, err=exc                ),                exc_info=self.pyload.debug > 1,                stack_info=self.pyload.debug > 2,            )            # generate default results            if err:                result = [(url, 0, 3, url) for url in urls]                cb(pluginname, result)",,"def fetch_for_plugin(self, pluginname, plugin, urls, cb, err=None):        try:            result = []  #: result loaded from cache            process = []  #: urls to process            for url in urls:                if url in self.m.info_cache:                    result.append(self.m.info_cache[url])                else:                    process.append(url)            if result:                self.pyload.log.debug(                    f""Fetched {len(result)} values from cache for {pluginname}""                )                cb(pluginname, result)            if process:                self.pyload.log.debug(f""Run Info Fetching for {pluginname}"")                for result in plugin.get_info(process):                    # result = [ .. (name, size, status, url) .. ]                    if not isinstance(result, list):                        result = [result]                    for res in result:                        self.m.info_cache[res[3]] = res                    cb(pluginname, result)            self.pyload.log.debug(f""Finished Info Fetching for {pluginname}"")        except Exception as exc:            self.pyload.log.warning(                self._(""Info Fetching for {name} failed | {err}"").format(                    name=pluginname, err=exc                ),                exc_info=self.pyload.debug > 1,                stack_info=self.pyload.debug > 2,            )            # generate default results            if err:                result = [(url, 0, 3, url) for url in urls]                cb(pluginname, result)",934a952b-462e-4383-b765-fe4c0de111b1
threads,info_thread.py,decrypt_container,198,231,"def decrypt_container(self, plugin, url):        data = []        # only works on container plugins        self.pyload.log.debug(f""Pre-decrypting {url} with {plugin}"")        # dummy pyfile        pyfile = PyFile(self.pyload.files, -1, url, url, 0, 0, """", plugin, -1, -1)        pyfile.init_plugin()        # little plugin lifecycle        try:            pyfile.plugin.setup()            pyfile.plugin.load_to_disk()            pyfile.plugin.decrypt(pyfile)            pyfile.plugin.delete_tmp()            for pack in pyfile.plugin.packages:                pyfile.plugin.urls.extend(pack[1])            data = self.pyload.plugin_manager.parse_urls(pyfile.plugin.urls)            self.pyload.log.debug(f""Got {len(data)} links."")        except Exception as exc:            self.pyload.log.debug(                f""Pre decrypting error: {exc}"",                exc_info=self.pyload.debug > 1,                stack_info=self.pyload.debug > 2,            )        finally:            pyfile.release()        return data",,"def decrypt_container(self, plugin, url):        data = []        # only works on container plugins        self.pyload.log.debug(f""Pre-decrypting {url} with {plugin}"")        # dummy pyfile        pyfile = PyFile(self.pyload.files, -1, url, url, 0, 0, """", plugin, -1, -1)        pyfile.init_plugin()        # little plugin lifecycle        try:            pyfile.plugin.setup()            pyfile.plugin.load_to_disk()            pyfile.plugin.decrypt(pyfile)            pyfile.plugin.delete_tmp()            for pack in pyfile.plugin.packages:                pyfile.plugin.urls.extend(pack[1])            data = self.pyload.plugin_manager.parse_urls(pyfile.plugin.urls)            self.pyload.log.debug(f""Got {len(data)} links."")        except Exception as exc:            self.pyload.log.debug(                f""Pre decrypting error: {exc}"",                exc_info=self.pyload.debug > 1,                stack_info=self.pyload.debug > 2,            )        finally:            pyfile.release()        return data",c08da206-9cab-4edb-ad38-c06f3cfc1225
threads,plugin_thread.py,__init__,18,27,"def __init__(self, manager):                super().__init__()        self.active = False        self.daemon = True        self.pyload = manager.pyload        self._ = manager._        self.m = self.manager = manager",Constructor.,"def __init__(self, manager):        """"""        Constructor.        """"""        super().__init__()        self.active = False        self.daemon = True        self.pyload = manager.pyload        self._ = manager._        self.m = self.manager = manager

Constructor.",0263f47b-66ef-42bf-af69-5cf463dda74f
threads,plugin_thread.py,write_debug_report,29,77,"def write_debug_report(self, pyfile):                date = time.strftime(""%Y-%m-%d_%H-%M-%S"")        dump_name = f""debug_{pyfile.pluginname}_{date}.zip""        dump_filename = os.path.join(self.pyload.tempdir, dump_name)        dump = self.get_debug_dump(pyfile)        try:            import zipfile            with zipfile.ZipFile(dump_filename, ""w"") as zip:                try:                    for entry in os.listdir(                        os.path.join(self.pyload.tempdir, pyfile.pluginname)                    ):                        try:                            # avoid encoding errors                            zip.write(                                os.path.join(self.pyload.tempdir, pyfile.pluginname, entry),                                os.path.join(pyfile.pluginname, entry),                            )                        except Exception:                            pass                except OSError:                    pass                info = zipfile.ZipInfo(                    os.path.join(pyfile.pluginname, ""debug_Report.txt""), time.gmtime()                )                info.external_attr = 0o644 << 16  #: change permissions                zip.writestr(info, dump)            if not os.stat(dump_filename).st_size:                raise Exception(""Empty Zipfile"")        except Exception as exc:            self.pyload.log.debug(f""Error creating zip file: {exc}"")            dump_filename = dump_filename.replace("".zip"", "".txt"")            with open(dump_filename, mode=""w"") as fp:                fp.write(dump)        self.pyload.log.info(self._(""Debug Report written to {}"").format(dump_filename))","writes a debug report.

:return:``","def write_debug_report(self, pyfile):        """"""        writes a debug report.        :return:``        """"""        date = time.strftime(""%Y-%m-%d_%H-%M-%S"")        dump_name = f""debug_{pyfile.pluginname}_{date}.zip""        dump_filename = os.path.join(self.pyload.tempdir, dump_name)        dump = self.get_debug_dump(pyfile)        try:            import zipfile            with zipfile.ZipFile(dump_filename, ""w"") as zip:                try:                    for entry in os.listdir(                        os.path.join(self.pyload.tempdir, pyfile.pluginname)                    ):                        try:                            # avoid encoding errors                            zip.write(                                os.path.join(self.pyload.tempdir, pyfile.pluginname, entry),                                os.path.join(pyfile.pluginname, entry),                            )                        except Exception:                            pass                except OSError:                    pass                info = zipfile.ZipInfo(                    os.path.join(pyfile.pluginname, ""debug_Report.txt""), time.gmtime()                )                info.external_attr = 0o644 << 16  #: change permissions                zip.writestr(info, dump)            if not os.stat(dump_filename).st_size:                raise Exception(""Empty Zipfile"")        except Exception as exc:            self.pyload.log.debug(f""Error creating zip file: {exc}"")            dump_filename = dump_filename.replace("".zip"", "".txt"")            with open(dump_filename, mode=""w"") as fp:                fp.write(dump)        self.pyload.log.info(self._(""Debug Report written to {}"").format(dump_filename))

writes a debug report.

:return:``",39078842-98f3-4cec-80e2-49ecf242715d
threads,plugin_thread.py,get_debug_dump,79,129,"def get_debug_dump(self, pyfile):        version = self.pyload.api.get_server_version()        dump = f""pyLoad {version} Debug Report of {pyfile.pluginname} {pyfile.plugin.__version__} \n\nTRACEBACK:\n {traceback.format_exc()} \n\nFRAMESTACK:\n""        tb = exc_info()[2]        stack = []        while tb:            stack.append(tb.tb_frame)            tb = tb.tb_next        for frame in stack[1:]:            dump += f""\n_frame {frame.f_code.co_name} in {frame.f_code.co_filename} at line {frame.f_lineno}\n""            for key, value in frame.f_locals.items():                dump += f""\t{key:20} = ""                try:                    dump += pprint.pformat(value) + ""\n""                except Exception as exc:                    dump += f""<ERROR WHILE PRINTING VALUE> {exc}\n""            del frame        del stack  #: delete it just to be sure...        dump += ""\n\n_PLUGIN OBJECT DUMP: \n\n""        for name in dir(pyfile.plugin):            attr = getattr(pyfile.plugin, name)            if not name.endswith(""__"") and not isinstance(attr, MethodType):                dump += f""\t{name:20} = ""                try:                    dump += pprint.pformat(attr) + ""\n""                except Exception as exc:                    dump += f""<ERROR WHILE PRINTING VALUE> {exc}\n""        dump += ""\n_PYFILE OBJECT DUMP: \n\n""        for name in dir(pyfile):            attr = getattr(pyfile, name)            if not name.endswith(""__"") and not isinstance(attr, MethodType):                dump += f""\t{name:20} = ""                try:                    dump += pprint.pformat(attr) + ""\n""                except Exception as exc:                    dump += f""<ERROR WHILE PRINTING VALUE> {exc}\n""        if pyfile.pluginname in self.pyload.config.plugin:            dump += ""\n\nCONFIG: \n\n""            dump += pprint.pformat(self.pyload.config.plugin[pyfile.pluginname]) + ""\n""        return dump",,"def get_debug_dump(self, pyfile):        version = self.pyload.api.get_server_version()        dump = f""pyLoad {version} Debug Report of {pyfile.pluginname} {pyfile.plugin.__version__} \n\nTRACEBACK:\n {traceback.format_exc()} \n\nFRAMESTACK:\n""        tb = exc_info()[2]        stack = []        while tb:            stack.append(tb.tb_frame)            tb = tb.tb_next        for frame in stack[1:]:            dump += f""\n_frame {frame.f_code.co_name} in {frame.f_code.co_filename} at line {frame.f_lineno}\n""            for key, value in frame.f_locals.items():                dump += f""\t{key:20} = ""                try:                    dump += pprint.pformat(value) + ""\n""                except Exception as exc:                    dump += f""<ERROR WHILE PRINTING VALUE> {exc}\n""            del frame        del stack  #: delete it just to be sure...        dump += ""\n\n_PLUGIN OBJECT DUMP: \n\n""        for name in dir(pyfile.plugin):            attr = getattr(pyfile.plugin, name)            if not name.endswith(""__"") and not isinstance(attr, MethodType):                dump += f""\t{name:20} = ""                try:                    dump += pprint.pformat(attr) + ""\n""                except Exception as exc:                    dump += f""<ERROR WHILE PRINTING VALUE> {exc}\n""        dump += ""\n_PYFILE OBJECT DUMP: \n\n""        for name in dir(pyfile):            attr = getattr(pyfile, name)            if not name.endswith(""__"") and not isinstance(attr, MethodType):                dump += f""\t{name:20} = ""                try:                    dump += pprint.pformat(attr) + ""\n""                except Exception as exc:                    dump += f""<ERROR WHILE PRINTING VALUE> {exc}\n""        if pyfile.pluginname in self.pyload.config.plugin:            dump += ""\n\nCONFIG: \n\n""            dump += pprint.pformat(self.pyload.config.plugin[pyfile.pluginname]) + ""\n""        return dump",293b7932-05b5-4c6c-af40-5aad5a4ccba8
threads,plugin_thread.py,clean,131,136,"def clean(self, pyfile):                self.active = False        pyfile.release()",set thread as inactive and release pyfile.,"def clean(self, pyfile):        """"""        set thread as inactive and release pyfile.        """"""        self.active = False        pyfile.release()

set thread as inactive and release pyfile.",9e8f2e43-1fa1-418c-96a6-5518f21f336e
utils,check.py,is_bits_set,7,9,"def is_bits_set(value, bits):        return bits == (value & bits)",Checks if all bits are set in value or some bits are zero.,"def is_bits_set(value, bits):    """"""Checks if all bits are set in value or some bits are zero.""""""    return bits == (value & bits)

Checks if all bits are set in value or some bits are zero.",88627d0d-b3ca-4807-9cf4-74855e07f721
utils,check.py,cmp,12,15,"def cmp(x, y):        return (x > y) - (x < y)","Compare the two objects x and y and return an integer according to the
outcome.","def cmp(x, y):    """"""Compare the two objects x and y and return an integer according to the    outcome.""""""    return (x > y) - (x < y)

Compare the two objects x and y and return an integer according to the
outcome.",ab9d8b88-96dc-4c4c-a015-7faba9a385b7
utils,check.py,has_method,18,20,"def has_method(obj, name):        return callable(getattr(obj, name, None))",Check if method `name` was defined in obj.,"def has_method(obj, name):    """"""Check if method `name` was defined in obj.""""""    return callable(getattr(obj, name, None))

Check if method `name` was defined in obj.",007540f8-1e72-45f1-a895-cd698ea1ec7f
utils,check.py,has_propriety,23,26,"def has_propriety(obj, name):        attr = getattr(obj, name, None)    return attr and not callable(attr)",Check if propriety `name` was defined in obj.,"def has_propriety(obj, name):    """"""Check if propriety `name` was defined in obj.""""""    attr = getattr(obj, name, None)    return attr and not callable(attr)

Check if propriety `name` was defined in obj.",c5921fe9-8944-4bba-817f-2b7b96a434c6
utils,check.py,methods,29,31,"def methods(obj):        return [name for name in dir(obj) if has_method(obj, name)]",List all the methods declared in obj.,"def methods(obj):    """"""List all the methods declared in obj.""""""    return [name for name in dir(obj) if has_method(obj, name)]

List all the methods declared in obj.",02ad6a9d-32ff-4f64-b4f5-18051d35acbd
utils,check.py,proprieties,34,36,"def proprieties(obj):        return [name for name in dir(obj) if has_propriety(obj, name)]",List all the propriety attribute declared in obj.,"def proprieties(obj):    """"""List all the propriety attribute declared in obj.""""""    return [name for name in dir(obj) if has_propriety(obj, name)]

List all the propriety attribute declared in obj.",8086e18d-f065-489e-bdde-ce210842297c
utils,check.py,is_iterable,39,44,"def is_iterable(obj, strict=False):        return isinstance(obj, Iterable) and (        strict or not isinstance(obj, str) or not isinstance(obj, bytes)    )","Check if object is iterable (`<type 'str'>` excluded if
strict=False).","def is_iterable(obj, strict=False):    """"""Check if object is iterable (`<type 'str'>` excluded if    strict=False).""""""    return isinstance(obj, Iterable) and (        strict or not isinstance(obj, str) or not isinstance(obj, bytes)    )

Check if object is iterable (`<type 'str'>` excluded if
strict=False).",340a08e9-a63d-4227-b6b4-efa5acfe8b5f
utils,check.py,is_sequence,47,49,"def is_sequence(obj):        return isinstance(obj, Sequence) and not isinstance(obj, (str, bytes, bytearray))",Check if object is sequence.,"def is_sequence(obj):    """"""Check if object is sequence.""""""    return isinstance(obj, Sequence) and not isinstance(obj, (str, bytes, bytearray))

Check if object is sequence.",43397172-e0a6-44ff-aa3f-431e14948300
utils,check.py,is_mapping,52,54,"def is_mapping(obj):        return isinstance(obj, Mapping)",Check if object is mapping.,"def is_mapping(obj):    """"""Check if object is mapping.""""""    return isinstance(obj, Mapping)

Check if object is mapping.",5d1b8509-9a30-464a-8d22-d788be282e5d
utils,check.py,is_module,57,59,def is_module(name):        return importlib.util.find_spec(name) is not None,Check if exists a module with given name.,"def is_module(name):    """"""Check if exists a module with given name.""""""    return importlib.util.find_spec(name) is not None

Check if exists a module with given name.",aa7e4248-f811-42ae-9d62-ede3bffca8d3
utils,check.py,missing,62,68,"def missing(iterable, start=None, end=None):        iter_seq = set(map(int, iterable))    min_val = start or min(iter_seq)    max_val = end or max(iter_seq)    full_seq = set(range(min_val, max_val + 1))    return sorted(full_seq - iter_seq)",List all the values between 'start' and 'stop' that are missing from 'iterable'.,"def missing(iterable, start=None, end=None):    """"""List all the values between 'start' and 'stop' that are missing from 'iterable'.""""""    iter_seq = set(map(int, iterable))    min_val = start or min(iter_seq)    max_val = end or max(iter_seq)    full_seq = set(range(min_val, max_val + 1))    return sorted(full_seq - iter_seq)

List all the values between 'start' and 'stop' that are missing from 'iterable'.",798309af-77c0-4e24-b8bc-95dde7c9b570
utils,convert.py,convert,8,29,"def convert(obj, rule, func, args=(), kwargs=None, fallback=None):    if kwargs is None:        kwargs = {}    res = None    cvargs = (rule, func, args, kwargs, fallback)    try:        if rule(obj):            res = func(obj, *args, **kwargs)        elif is_mapping(obj):            res = dict(                (convert(k, *cvargs), convert(v, *cvargs)) for k, v in obj.items()            )        elif is_iterable(obj):            res = type(obj)(convert(i, *cvargs) for i in obj)        else:            res = obj    except Exception as exc:        if callable(fallback):            fbargs = cvargs[:-1] + (exc,)            return fallback(obj, *fbargs)        raise    return res",,"def convert(obj, rule, func, args=(), kwargs=None, fallback=None):    if kwargs is None:        kwargs = {}    res = None    cvargs = (rule, func, args, kwargs, fallback)    try:        if rule(obj):            res = func(obj, *args, **kwargs)        elif is_mapping(obj):            res = dict(                (convert(k, *cvargs), convert(v, *cvargs)) for k, v in obj.items()            )        elif is_iterable(obj):            res = type(obj)(convert(i, *cvargs) for i in obj)        else:            res = obj    except Exception as exc:        if callable(fallback):            fbargs = cvargs[:-1] + (exc,)            return fallback(obj, *fbargs)        raise    return res",42249d61-f120-4f0a-a6d6-01a80b70183b
utils,convert.py,size,35,70,"def size(value, in_unit, out_unit):        in_unit = in_unit.strip()[0].upper()    out_unit = out_unit.strip()[0].upper()    if in_unit == out_unit:        return value    in_unit += ""yte"" if in_unit == ""B"" else ""iB""    out_unit += ""yte"" if out_unit == ""B"" else ""iB""    try:        # Create a bitmath instance representing the input value with its        # corresponding unit        in_size = getattr(bitmath, in_unit)(value)        # Call the instance method to convert it to the output unit        out_size = getattr(in_size, ""to_"" + out_unit)()        return out_size.value    except AttributeError:        sizemap = {u[0]: i * 10 for i, u in enumerate(BYTE_PREFIXES)}        in_magnitude = sizemap[in_unit]        out_magnitude = sizemap[out_unit]        magnitude = in_magnitude - out_magnitude        i, d = divmod(value, 1)        decimal = int(d * (1024 ** (abs(magnitude) // 10)))        if magnitude >= 0:            integer = int(i) << magnitude        else:            integer = int(i) >> magnitude * -1            decimal = -decimal        return integer + decimal",Convert file size.,"def size(value, in_unit, out_unit):    """"""Convert file size.""""""    in_unit = in_unit.strip()[0].upper()    out_unit = out_unit.strip()[0].upper()    if in_unit == out_unit:        return value    in_unit += ""yte"" if in_unit == ""B"" else ""iB""    out_unit += ""yte"" if out_unit == ""B"" else ""iB""    try:        # Create a bitmath instance representing the input value with its        # corresponding unit        in_size = getattr(bitmath, in_unit)(value)        # Call the instance method to convert it to the output unit        out_size = getattr(in_size, ""to_"" + out_unit)()        return out_size.value    except AttributeError:        sizemap = {u[0]: i * 10 for i, u in enumerate(BYTE_PREFIXES)}        in_magnitude = sizemap[in_unit]        out_magnitude = sizemap[out_unit]        magnitude = in_magnitude - out_magnitude        i, d = divmod(value, 1)        decimal = int(d * (1024 ** (abs(magnitude) // 10)))        if magnitude >= 0:            integer = int(i) << magnitude        else:            integer = int(i) >> magnitude * -1            decimal = -decimal        return integer + decimal

Convert file size.",4375db18-1d0d-49b5-b15a-de6bc3d765b5
utils,convert.py,to_bytes,73,77,"def to_bytes(obj, encoding=""utf-8"", errors=""strict""):    try:        return obj.encode(encoding, errors)    except AttributeError:        return bytes(obj, encoding)",,"def to_bytes(obj, encoding=""utf-8"", errors=""strict""):    try:        return obj.encode(encoding, errors)    except AttributeError:        return bytes(obj, encoding)",0a8eed26-baaf-4bae-9947-4b8ead9a8f3c
utils,convert.py,to_str,80,84,"def to_str(obj, encoding=""utf-8"", errors=""strict""):    try:        return obj.decode(encoding, errors)    except AttributeError:        return str(obj)",,"def to_str(obj, encoding=""utf-8"", errors=""strict""):    try:        return obj.decode(encoding, errors)    except AttributeError:        return str(obj)",6d444f09-e51a-4f2c-824a-8e5606a79f09
utils,convert.py,to_list,92,103,"def to_list(obj):        if isinstance(obj, list):        pass    elif is_mapping(obj):        return list(obj.items())    elif is_iterable(obj, strict=False):        return list(obj)    elif obj is not None:        return [obj]    else:        return list(obj)",Convert value to a list with value inside.,"def to_list(obj):    """"""Convert value to a list with value inside.""""""    if isinstance(obj, list):        pass    elif is_mapping(obj):        return list(obj.items())    elif is_iterable(obj, strict=False):        return list(obj)    elif obj is not None:        return [obj]    else:        return list(obj)

Convert value to a list with value inside.",beb1e844-7c1b-4a7c-8ab7-1d0d846a633a
utils,debug.py,report,14,23,"def report(value, dirname):    frame = inspect.currentframe()    try:        filename = f""{frame.f_back.f_code.co_name}_line{frame.f_back.f_lineno}.report""        filepath = os.path.join(dirname, filename)        makefile(filepath, exist_ok=True)        with io.open(filepath, mode=""wb"") as fp:            fp.write(value)    finally:        del frame",,"def report(value, dirname):    frame = inspect.currentframe()    try:        filename = f""{frame.f_back.f_code.co_name}_line{frame.f_back.f_lineno}.report""        filepath = os.path.join(dirname, filename)        makefile(filepath, exist_ok=True)        with io.open(filepath, mode=""wb"") as fp:            fp.write(value)    finally:        del frame",4dfc14d3-b476-4b6e-a2b4-d39897087474
utils,debug.py,_format_dump,26,38,"def _format_dump(obj):    dump = []    for attr_name in proprieties(obj):        if attr_name.endswith(""__""):            continue        try:            attr_dump = pprint.pformat(getattr(obj, attr_name))        except Exception as exc:            attr_dump = f""<ERROR WHILE PRINTING VALUE> {exc}""        dump.append((attr_name, attr_dump))    return dump",,"def _format_dump(obj):    dump = []    for attr_name in proprieties(obj):        if attr_name.endswith(""__""):            continue        try:            attr_dump = pprint.pformat(getattr(obj, attr_name))        except Exception as exc:            attr_dump = f""<ERROR WHILE PRINTING VALUE> {exc}""        dump.append((attr_name, attr_dump))    return dump",ae6a26fc-b3be-463a-9a51-5e6a28b3c108
utils,debug.py,format_dump,41,46,"def format_dump(obj):    title = f""DUMP {obj!r}:""    body = os.linesep.join(        f""\t{attr_name:20} = {attr_dump}"" for attr_name, attr_dump in _format_dump(obj)    )    return os.linesep.join((title, body))",,"def format_dump(obj):    title = f""DUMP {obj!r}:""    body = os.linesep.join(        f""\t{attr_name:20} = {attr_dump}"" for attr_name, attr_dump in _format_dump(obj)    )    return os.linesep.join((title, body))",26fbadea-f135-43c7-a380-b31b9200f2f0
utils,debug.py,print_dump,49,53,"def print_dump(obj, file=None):    text = format_dump(obj)    if file:        return file.write(text)    print(text)",,"def print_dump(obj, file=None):    text = format_dump(obj)    if file:        return file.write(text)    print(text)",0e5cd30e-c634-459d-8b4b-f203472dde08
utils,debug.py,_format_framestack,56,78,"def _format_framestack(limit=None):    limit = None if not limit else abs(limit)    stack = []    _, value, tb = sys.exc_info()    try:        while tb:            stack.append(tb.tb_frame)            tb = tb.tb_next        dump = []        for _frame in stack[1:limit]:            frame_name = f""Frame {_frame.f_code.co_name} in {_frame.f_code.co_filename} at line {_frame.f_lineno}""            frame_dump = []            for attr_name, value in _frame.f_locals.items():                try:                    attr_dump = pprint.pformat(value)                except Exception as exc:                    attr_dump = f""<ERROR WHILE PRINTING VALUE> {exc}""                frame_dump.append((attr_name, attr_dump))            dump.append((frame_name, frame_dump))            del _frame        return dump    finally:        del stack[:]",,"def _format_framestack(limit=None):    limit = None if not limit else abs(limit)    stack = []    _, value, tb = sys.exc_info()    try:        while tb:            stack.append(tb.tb_frame)            tb = tb.tb_next        dump = []        for _frame in stack[1:limit]:            frame_name = f""Frame {_frame.f_code.co_name} in {_frame.f_code.co_filename} at line {_frame.f_lineno}""            frame_dump = []            for attr_name, value in _frame.f_locals.items():                try:                    attr_dump = pprint.pformat(value)                except Exception as exc:                    attr_dump = f""<ERROR WHILE PRINTING VALUE> {exc}""                frame_dump.append((attr_name, attr_dump))            dump.append((frame_name, frame_dump))            del _frame        return dump    finally:        del stack[:]",6e311891-b77d-4c58-a742-bf0bf63af971
utils,debug.py,format_framestack,81,92,"def format_framestack(frame=None, limit=None):    framestack = _format_framestack(limit)    stack_desc = []    for frame_name, frame_dump in framestack:        dump = os.linesep.join(            f""\t{attr_name:20} = {attr_dump}"" for attr_name, attr_dump in frame_dump        )        stack_desc.append(f""{frame_name}{os.linesep}{dump}"")    title = f""FRAMESTACK {frame!r}:""    body = (os.linesep * 2).join(stack_desc)    return os.linesep.format((title, body))",,"def format_framestack(frame=None, limit=None):    framestack = _format_framestack(limit)    stack_desc = []    for frame_name, frame_dump in framestack:        dump = os.linesep.join(            f""\t{attr_name:20} = {attr_dump}"" for attr_name, attr_dump in frame_dump        )        stack_desc.append(f""{frame_name}{os.linesep}{dump}"")    title = f""FRAMESTACK {frame!r}:""    body = (os.linesep * 2).join(stack_desc)    return os.linesep.format((title, body))",61643f1a-b823-4fe4-bcc4-e2ae3698514c
utils,debug.py,print_framestack,95,99,"def print_framestack(frame=None, limit=None, file=None):    text = format_framestack(frame, limit)    if file:        return file.write(text)    print(text)",,"def print_framestack(frame=None, limit=None, file=None):    text = format_framestack(frame, limit)    if file:        return file.write(text)    print(text)",bf6210d0-8a94-41ba-8478-03bc21524e4c
utils,debug.py,_format_traceback,102,126,"def _format_traceback(frame=None, limit=None, offset=None):        limit = None if not limit else abs(limit)    offset = 1 if not offset else abs(offset) + 1    etype, value, tb = sys.exc_info()    try:        stack = []        exception = []        callstack = traceback.extract_stack(frame)[::-1][offset:limit][::-1]        if etype is not None:            exception_callstack = traceback.extract_tb(tb)            # Does this exception belongs to us?            if callstack[-1][0] == exception_callstack[0][0]:                callstack.pop()                callstack.extend(exception_callstack)                exception = traceback.format_exception_only(etype, value)        stack = traceback.format_list(callstack)        return stack, exception    finally:        del tb",Format call-stack and exception information (if available).,"def _format_traceback(frame=None, limit=None, offset=None):    """"""Format call-stack and exception information (if available).""""""    limit = None if not limit else abs(limit)    offset = 1 if not offset else abs(offset) + 1    etype, value, tb = sys.exc_info()    try:        stack = []        exception = []        callstack = traceback.extract_stack(frame)[::-1][offset:limit][::-1]        if etype is not None:            exception_callstack = traceback.extract_tb(tb)            # Does this exception belongs to us?            if callstack[-1][0] == exception_callstack[0][0]:                callstack.pop()                callstack.extend(exception_callstack)                exception = traceback.format_exception_only(etype, value)        stack = traceback.format_list(callstack)        return stack, exception    finally:        del tb

Format call-stack and exception information (if available).",c21ab2bb-69a3-467a-a8ed-656d028b20c8
utils,debug.py,format_traceback,129,134,"def format_traceback(frame=None, limit=None, offset=None):    offset = 1 if not offset else abs(offset) + 1    stack, exception = _format_traceback(frame, limit, offset)    title = ""Traceback (most recent call last):""    body = """".join(stack + exception)    return os.linesep.format((title, body))",,"def format_traceback(frame=None, limit=None, offset=None):    offset = 1 if not offset else abs(offset) + 1    stack, exception = _format_traceback(frame, limit, offset)    title = ""Traceback (most recent call last):""    body = """".join(stack + exception)    return os.linesep.format((title, body))",5df951a9-4b47-41bc-9f6e-46a06dee5ac0
utils,debug.py,print_traceback,137,141,"def print_traceback(frame=None, limit=None, file=None):    text = format_traceback(frame, limit, offset=1)    if file:        return file.write(text)    print(text)",,"def print_traceback(frame=None, limit=None, file=None):    text = format_traceback(frame, limit, offset=1)    if file:        return file.write(text)    print(text)",a9dce1ab-d1e2-465a-a2b9-861fd824277c
utils,format.py,attributes,14,20,"def attributes(obj, ignore=None):    if ignore is None:        attrs = tuple(map(to_str, obj))    else:        ignored = ignore if is_iterable(ignore) else (ignore,)        attrs = (to_str(x) for x in obj if x not in ignored)    return attrs",,"def attributes(obj, ignore=None):    if ignore is None:        attrs = tuple(map(to_str, obj))    else:        ignored = ignore if is_iterable(ignore) else (ignore,)        attrs = (to_str(x) for x in obj if x not in ignored)    return attrs",b83ef62f-d9bf-472d-8466-56ee4756262f
utils,format.py,items,23,29,"def items(obj, ignore=None):    if ignore is None:        res = (f""{k}={v}"" for k, v in obj.items())    else:        ignored = ignore if is_iterable(ignore) else (ignore,)        res = (f""{k}={v}"" for k, v in obj.items() if k not in ignored)    return res",,"def items(obj, ignore=None):    if ignore is None:        res = (f""{k}={v}"" for k, v in obj.items())    else:        ignored = ignore if is_iterable(ignore) else (ignore,)        res = (f""{k}={v}"" for k, v in obj.items() if k not in ignored)    return res",86e9d3ae-e0bb-4143-ba48-c1bef5224069
utils,format.py,path,32,33,def path(*paths):    return os.path.normcase(fullpath(os.path.join(*paths))),,def path(*paths):    return os.path.normcase(fullpath(os.path.join(*paths))),f1ff1600-ac32-4126-bab9-0479d4b0c30d
utils,format.py,size,39,43,"def size(value):        return bitmath.Byte(value).best_prefix().format(""{value:.2f} {unit}"")",formats size of bytes,"def size(value):    """"""    formats size of bytes    """"""    return bitmath.Byte(value).best_prefix().format(""{value:.2f} {unit}"")

formats size of bytes",2c4ec79d-983e-49a7-9449-3a29b28be59a
utils,format.py,speed,46,47,"def speed(obj):    return f""{size(obj)}/s""",,"def speed(obj):    return f""{size(obj)}/s""",7ba56d28-1105-4b09-85e5-426bf94f6529
utils,format.py,time,50,77,"def time(obj, literally=True):    if literally:        seconds = abs(int(obj))        dt = datetime.datetime(1, 1, 1) + datetime.timedelta(seconds=seconds)        days = dt.day - 1 if dt.day > 1 else 0        timelist = []        if days:            timelist.append(f""{days} day"" + (""s"" if is_plural(days) else """"))        timenames = (""hour"", ""minute"", ""second"")        for name in timenames:            value = getattr(dt, name)            if not value:                continue            timelist.append(f""{value} {name}"" + (""s"" if is_plural(value) else """"))        return "", "".join(timelist)    else:        seconds = int(obj)        if seconds < 0:            return ""00:00:00""        hours, seconds = divmod(seconds, 3600)        minutes, seconds = divmod(seconds, 60)        return f""{hours:02}:{minutes:02}:{seconds:02}""",,"def time(obj, literally=True):    if literally:        seconds = abs(int(obj))        dt = datetime.datetime(1, 1, 1) + datetime.timedelta(seconds=seconds)        days = dt.day - 1 if dt.day > 1 else 0        timelist = []        if days:            timelist.append(f""{days} day"" + (""s"" if is_plural(days) else """"))        timenames = (""hour"", ""minute"", ""second"")        for name in timenames:            value = getattr(dt, name)            if not value:                continue            timelist.append(f""{value} {name}"" + (""s"" if is_plural(value) else """"))        return "", "".join(timelist)    else:        seconds = int(obj)        if seconds < 0:            return ""00:00:00""        hours, seconds = divmod(seconds, 3600)        minutes, seconds = divmod(seconds, 60)        return f""{hours:02}:{minutes:02}:{seconds:02}""",1e5075e4-685a-4eab-825e-4f6e7258a0d3
utils,fs.py,guess_mime,20,21,"def guess_mime(filename):        return magic.from_file(filename, mime=True)",,"def guess_mime(filename):        return magic.from_file(filename, mime=True)",93ce5076-fa35-4849-aa80-72cefcde5f1a
utils,fs.py,free_space,30,46,"def free_space(path):    availspace = None    if os.name == ""nt"":        import ctypes        free_bytes = ctypes.c_ulonglong(0)        ctypes.windll.kernel32.GetDiskFreeSpaceExW(            ctypes.c_wchar_p(path), None, None, ctypes.pointer(free_bytes)        )        availspace = free_bytes.value    else:        s = os.statvfs(path)        availspace = s.f_frsize * s.f_bavail    return availspace",,"def free_space(path):    availspace = None    if os.name == ""nt"":        import ctypes        free_bytes = ctypes.c_ulonglong(0)        ctypes.windll.kernel32.GetDiskFreeSpaceExW(            ctypes.c_wchar_p(path), None, None, ctypes.pointer(free_bytes)        )        availspace = free_bytes.value    else:        s = os.statvfs(path)        availspace = s.f_frsize * s.f_bavail    return availspace",a328e978-11d5-4ba3-9f7f-6dfd2dbce966
utils,fs.py,_shdo,49,63,"def _shdo(func, src, dst, overwrite=None, ref=None):    mtime = os.path.getmtime    try:        if os.path.isfile(dst):            if overwrite is None and mtime(src) <= mtime(dst):                return            elif not overwrite:                return            if os.name == ""nt"":                os.remove(dst)        func(src, dst)        if isinstance(ref, list):            del ref[:]    except (IOError, OSError):        pass",,"def _shdo(func, src, dst, overwrite=None, ref=None):    mtime = os.path.getmtime    try:        if os.path.isfile(dst):            if overwrite is None and mtime(src) <= mtime(dst):                return            elif not overwrite:                return            if os.name == ""nt"":                os.remove(dst)        func(src, dst)        if isinstance(ref, list):            del ref[:]    except (IOError, OSError):        pass",f811747b-289c-47f3-9d24-d56c7551af17
utils,fs.py,_shdorc,66,71,"def _shdorc(func, filenames, src_dir, dst_dir, overwrite=None):    join = os.path.join    for fname in filenames:        src_file = join(src_dir, fname)        dst_file = join(dst_dir, fname)        _shdo(func, src_file, dst_file, overwrite)",,"def _shdorc(func, filenames, src_dir, dst_dir, overwrite=None):    join = os.path.join    for fname in filenames:        src_file = join(src_dir, fname)        dst_file = join(dst_dir, fname)        _shdo(func, src_file, dst_file, overwrite)",3d22369b-257a-4096-9a85-825603421cbc
utils,fs.py,_copyrc,74,83,"def _copyrc(src, dst, overwrite, preserve_metadata):    copy = shutil.copy2 if preserve_metadata else shutil.copy    copytree = shutil.copytree    exists = os.path.exists    for src_dir, dirnames, filenames in os.walk(src):        dst_dir = src_dir.replace(src, dst, 1)        if exists(dst_dir):            _shdorc(copy, filenames, src_dir, dst_dir, overwrite)        else:            _shdo(copytree, src_dir, dst_dir, overwrite, dirnames)",,"def _copyrc(src, dst, overwrite, preserve_metadata):    copy = shutil.copy2 if preserve_metadata else shutil.copy    copytree = shutil.copytree    exists = os.path.exists    for src_dir, dirnames, filenames in os.walk(src):        dst_dir = src_dir.replace(src, dst, 1)        if exists(dst_dir):            _shdorc(copy, filenames, src_dir, dst_dir, overwrite)        else:            _shdo(copytree, src_dir, dst_dir, overwrite, dirnames)",722134fd-6bfd-472c-9b5d-ad245d6ee4b1
utils,fs.py,copy,86,89,"def copy(src, dst, overwrite=None, preserve_metadata=True):    if not os.path.isdir(dst) or not os.path.isdir(src):        return _shdo(shutil.copytree, src, dst, overwrite)    return _copyrc(src, dst, overwrite, preserve_metadata)",,"def copy(src, dst, overwrite=None, preserve_metadata=True):    if not os.path.isdir(dst) or not os.path.isdir(src):        return _shdo(shutil.copytree, src, dst, overwrite)    return _copyrc(src, dst, overwrite, preserve_metadata)",49fa353d-446f-476f-a755-c17783526abd
utils,fs.py,exists,92,99,"def exists(path, strict=False):        if not strict:        return os.path.exists(path)    if os.path.exists(path):        dirpath, name = os.path.split(path)        return name in os.listdir(dirpath)    return False",Case-sensitive os.path.exists.,"def exists(path, strict=False):    """"""Case-sensitive os.path.exists.""""""    if not strict:        return os.path.exists(path)    if os.path.exists(path):        dirpath, name = os.path.split(path)        return name in os.listdir(dirpath)    return False

Case-sensitive os.path.exists.",74c4a565-227e-487a-8ac8-1240ea302e05
utils,fs.py,filesize,102,103,def filesize(filename):    return os.stat(filename).st_size,,def filesize(filename):    return os.stat(filename).st_size,46fd1279-0b09-48c2-8b1f-ed935410869d
utils,fs.py,filetype,106,107,def filetype(filename):    return guess_mime(filename),,def filetype(filename):    return guess_mime(filename),d729e116-28e9-4da4-93e4-6982fb6196bd
utils,fs.py,encode,110,114,def encode(path):    try:        return os.fsencode(path)    except AttributeError:        return to_bytes(path),,def encode(path):    try:        return os.fsencode(path)    except AttributeError:        return to_bytes(path),61b6413e-2fd1-4bf1-a466-5802f7f21c4b
utils,fs.py,decode,117,121,def decode(path):    try:        return os.fsdecode(path)    except AttributeError:        return to_str(path),,def decode(path):    try:        return os.fsdecode(path)    except AttributeError:        return to_str(path),7e09f6dd-1225-4405-b748-8577c40b4e29
utils,fs.py,fullpath,124,125,def fullpath(path):    return os.path.realpath(os.path.expanduser(path)),,def fullpath(path):    return os.path.realpath(os.path.expanduser(path)),0e07b810-7a20-4d61-b60f-160d7570c7c9
utils,fs.py,blksize,128,146,"def blksize(path):        if os.name != ""nt"":        size = os.statvfs(path).f_bsize    else:        import ctypes        drive = os.path.splitdrive(os.path.abspath(path))[0] + ""\\""        cluster_sectors = ctypes.c_longlong(0)        sector_size = ctypes.c_longlong(0)        ctypes.windll.kernel32.GetDiskFreeSpaceW(            ctypes.c_wchar_p(drive),            ctypes.pointer(cluster_sectors),            ctypes.pointer(sector_size),            None,            None,        )        size = int(cluster_sectors.value * sector_size.value)    return size",Get optimal file system buffer size (in bytes) for I/O calls.,"def blksize(path):    """"""Get optimal file system buffer size (in bytes) for I/O calls.""""""    if os.name != ""nt"":        size = os.statvfs(path).f_bsize    else:        import ctypes        drive = os.path.splitdrive(os.path.abspath(path))[0] + ""\\""        cluster_sectors = ctypes.c_longlong(0)        sector_size = ctypes.c_longlong(0)        ctypes.windll.kernel32.GetDiskFreeSpaceW(            ctypes.c_wchar_p(drive),            ctypes.pointer(cluster_sectors),            ctypes.pointer(sector_size),            None,            None,        )        size = int(cluster_sectors.value * sector_size.value)    return size

Get optimal file system buffer size (in bytes) for I/O calls.",3a7c9fb7-d3a4-422f-9e08-66bc128d15e9
utils,fs.py,bufread,149,152,"def bufread(fp, buffering=-1, sentinel=b""""):    buf = blksize(fp.name) if buffering < 0 else buffering    func = fp.readline if buffering == 1 else lambda: fp.read(buf)    return iter(func, sentinel)",,"def bufread(fp, buffering=-1, sentinel=b""""):    buf = blksize(fp.name) if buffering < 0 else buffering    func = fp.readline if buffering == 1 else lambda: fp.read(buf)    return iter(func, sentinel)",e3c92d4d-d569-4dc6-9fe7-dafd0c10a23e
utils,fs.py,_crcsum,155,161,"def _crcsum(filename, chkname, buffering):    last = 0    call = getattr(zlib, chkname)    with io.open(filename, mode=""rb"") as fp:        for chunk in bufread(fp, buffering):            last = call(chunk, last)    return f""{last & 0xffffffff:x}""",,"def _crcsum(filename, chkname, buffering):    last = 0    call = getattr(zlib, chkname)    with io.open(filename, mode=""rb"") as fp:        for chunk in bufread(fp, buffering):            last = call(chunk, last)    return f""{last & 0xffffffff:x}""",8520bffa-009e-435a-b508-23616522cc42
utils,fs.py,_hashsum,164,170,"def _hashsum(filename, chkname, buffering):    h = hashlib.new(chkname)    buffering *= h.block_size    with io.open(filename, mode=""rb"") as fp:        for chunk in bufread(fp, buffering):            h.update(chunk)    return h.hexdigest()",,"def _hashsum(filename, chkname, buffering):    h = hashlib.new(chkname)    buffering *= h.block_size    with io.open(filename, mode=""rb"") as fp:        for chunk in bufread(fp, buffering):            h.update(chunk)    return h.hexdigest()",5e1b8c6d-87ec-4904-b58f-e2b9a17da956
utils,fs.py,checksum,173,180,"def checksum(filename, chkname, buffering=None):    res = None    buf = buffering or blksize(filename)    if chkname in (""adler32"", ""crc32""):        res = _crcsum(filename, chkname, buf)    elif chkname in hashlib.algorithms_available:        res = _hashsum(filename, chkname, buf)    return res",,"def checksum(filename, chkname, buffering=None):    res = None    buf = buffering or blksize(filename)    if chkname in (""adler32"", ""crc32""):        res = _crcsum(filename, chkname, buf)    elif chkname in hashlib.algorithms_available:        res = _hashsum(filename, chkname, buf)    return res",e319c38c-3747-4532-bfce-f0ed3e7830e4
utils,fs.py,is_exec,183,184,"def is_exec(filename):    return os.path.isfile(filename) and os.access(filename, os.X_OK)",,"def is_exec(filename):    return os.path.isfile(filename) and os.access(filename, os.X_OK)",52d047f2-5dee-4453-8608-922d4ce67d4b
utils,fs.py,flush,197,202,"def flush(filename, exist_ok=False):    if not exist_ok and not os.path.exists(filename):        raise OSError(""Path not exists"")    with io.open(filename) as fp:        fp.flush()        os.fsync(fp.fileno())",,"def flush(filename, exist_ok=False):    if not exist_ok and not os.path.exists(filename):        raise OSError(""Path not exists"")    with io.open(filename) as fp:        fp.flush()        os.fsync(fp.fileno())",7c144074-3b7e-45a3-9cb7-ed27829ba35d
utils,fs.py,merge,205,209,"def merge(dst_file, src_file):    with io.open(dst_file, mode=""ab"") as dfp:        with io.open(src_file, mode=""rb"") as sfp:            for chunk in bufread(sfp):                dfp.write(chunk)",,"def merge(dst_file, src_file):    with io.open(dst_file, mode=""ab"") as dfp:        with io.open(src_file, mode=""rb"") as sfp:            for chunk in bufread(sfp):                dfp.write(chunk)",fe8b41fb-4f44-4cfa-97f6-e724399308b7
utils,fs.py,mountpoint,212,218,"def mountpoint(path):    path = fullpath(path)    rest = True    while rest:        if os.path.ismount(path):            return path        path, rest = path.rsplit(os.sep, 1)",,"def mountpoint(path):    path = fullpath(path)    rest = True    while rest:        if os.path.ismount(path):            return path        path, rest = path.rsplit(os.sep, 1)",27a89423-7ace-49ff-9ed2-d9783728c3ff
utils,fs.py,mkfile,227,232,"def mkfile(filename, size=None):    if os.path.isfile(filename):        raise OSError(""Path already exists"")    with io.open(filename, mode=""wb"") as fp:        if size and os.name == ""nt"":            fp.truncate(size)",,"def mkfile(filename, size=None):    if os.path.isfile(filename):        raise OSError(""Path already exists"")    with io.open(filename, mode=""wb"") as fp:        if size and os.name == ""nt"":            fp.truncate(size)",e24a6061-d914-4e73-be7f-446259146ca5
utils,fs.py,makedirs,235,241,"def makedirs(dirname, mode=0o777, exist_ok=False):    try:        os.makedirs(dirname, mode)    except OSError as exc:        if not os.path.isdir(dirname) or not exist_ok:            raise OSError(exc)",,"def makedirs(dirname, mode=0o777, exist_ok=False):    try:        os.makedirs(dirname, mode)    except OSError as exc:        if not os.path.isdir(dirname) or not exist_ok:            raise OSError(exc)",febe1f29-103f-4ec8-8688-701721766bea
utils,fs.py,makefile,244,252,"def makefile(filepath, mode=0o700, size=None, exist_ok=False):    dirname, _ = os.path.split(filepath)    makedirs(dirname, mode, exist_ok=True)    try:        mkfile(filepath, size)    except OSError as exc:        if not os.path.isfile(filepath) or not exist_ok:            raise OSError(exc)",,"def makefile(filepath, mode=0o700, size=None, exist_ok=False):    dirname, _ = os.path.split(filepath)    makedirs(dirname, mode, exist_ok=True)    try:        mkfile(filepath, size)    except OSError as exc:        if not os.path.isfile(filepath) or not exist_ok:            raise OSError(exc)",a1bf3a83-685a-43bb-931e-a213187da8ea
utils,fs.py,_moverc,255,268,"def _moverc(src, dst, overwrite):    exists = os.path.exists    move = shutil.move    removedirs = os.removedirs    for src_dir, dirnames, filenames in os.walk(src):        dst_dir = src_dir.replace(src, dst, 1)        if exists(dst_dir):            _shdorc(move, filenames, src_dir, dst_dir, overwrite)        else:            _shdo(move, src_dir, dst_dir, overwrite, dirnames)        try:            removedirs(src_dir)        except Exception:            pass",,"def _moverc(src, dst, overwrite):    exists = os.path.exists    move = shutil.move    removedirs = os.removedirs    for src_dir, dirnames, filenames in os.walk(src):        dst_dir = src_dir.replace(src, dst, 1)        if exists(dst_dir):            _shdorc(move, filenames, src_dir, dst_dir, overwrite)        else:            _shdo(move, src_dir, dst_dir, overwrite, dirnames)        try:            removedirs(src_dir)        except Exception:            pass",37ed61ca-68f1-40ed-a654-c44eb9e3e530
utils,fs.py,move,271,278,"def move(src, dst, overwrite=None):    if not os.path.isdir(dst) or not os.path.isdir(src):        return _shdo(shutil.move, src, dst, overwrite)    _moverc(src, dst, overwrite)    try:        os.rmdir(src)    except Exception:        pass",,"def move(src, dst, overwrite=None):    if not os.path.isdir(dst) or not os.path.isdir(src):        return _shdo(shutil.move, src, dst, overwrite)    _moverc(src, dst, overwrite)    try:        os.rmdir(src)    except Exception:        pass",63eb34ac-cc4a-455f-b528-f1c6c3130839
utils,fs.py,mtime,281,294,"def mtime(path):    getmtime = os.path.getmtime    join = os.path.join    if not os.path.isdir(path):        return getmtime(path)    mtimes = (        getmtime(join(root, fname))        for root, dirnames, filenames in os.walk(path)        for fname in filenames    )    return max(0, 0, *mtimes)",,"def mtime(path):    getmtime = os.path.getmtime    join = os.path.join    if not os.path.isdir(path):        return getmtime(path)    mtimes = (        getmtime(join(root, fname))        for root, dirnames, filenames in os.walk(path)        for fname in filenames    )    return max(0, 0, *mtimes)",50b54b24-b00d-4219-97ac-dd089e87b4f2
utils,fs.py,_cleanpy2,297,306,"def _cleanpy2(root, filenames):    join = os.path.join    remove = os.remove    for fname in filenames:        if fname[-4:] not in ("".pyc"", "".pyo"", "".pyd""):            continue        try:            remove(join(root, fname))        except OSError:            pass",,"def _cleanpy2(root, filenames):    join = os.path.join    remove = os.remove    for fname in filenames:        if fname[-4:] not in ("".pyc"", "".pyo"", "".pyd""):            continue        try:            remove(join(root, fname))        except OSError:            pass",db3c246d-6999-47fc-a736-74bce717db2d
utils,fs.py,_cleanpy3,309,317,"def _cleanpy3(root, dirnames):    name = ""__pycache__""    if name not in dirnames:        return    dirnames.remove(name)    try:        os.remove(os.path.join(root, name))    except OSError:        pass",,"def _cleanpy3(root, dirnames):    name = ""__pycache__""    if name not in dirnames:        return    dirnames.remove(name)    try:        os.remove(os.path.join(root, name))    except OSError:        pass",eb87e634-cc10-407e-8336-555181219eba
utils,fs.py,cleanpy,320,326,"def cleanpy(dirname, recursive=True):    walk_it = os.walk(dirname)    if not recursive:        walk_it = next(walk_it)    for dirpath, dirnames, filenames in walk_it:        _cleanpy2(dirpath, filenames)        _cleanpy3(dirpath, dirnames)",,"def cleanpy(dirname, recursive=True):    walk_it = os.walk(dirname)    if not recursive:        walk_it = next(walk_it)    for dirpath, dirnames, filenames in walk_it:        _cleanpy2(dirpath, filenames)        _cleanpy3(dirpath, dirnames)",058f0f4c-7746-464f-8b60-8454234cf112
utils,fs.py,remove,329,345,"def remove(path, try_trash=True):    # path = os.fsdecode(path)    if not os.path.exists(path):        return    if try_trash:        try:            send2trash.send2trash(path)        except AttributeError as exc:            exc_logger.exception(exc)    elif os.path.isdir(path):        shutil.rmtree(path, ignore_errors=True)    else:        os.remove(path)",,"def remove(path, try_trash=True):    # path = os.fsdecode(path)    if not os.path.exists(path):        return    if try_trash:        try:            send2trash.send2trash(path)        except AttributeError as exc:            exc_logger.exception(exc)    elif os.path.isdir(path):        shutil.rmtree(path, ignore_errors=True)    else:        os.remove(path)",60e4c008-b72e-449d-934b-bea0e003c704
utils,fs.py,empty,348,366,"def empty(path, try_trash=False, exist_ok=True):    if not exist_ok and not os.path.exists(path):        raise OSError(""Path not exists"")    if os.path.isfile(path):        if try_trash:            origfile = path + "".orig""            os.rename(path, origfile)            shutil.copy2(origfile, path)            remove(path, try_trash)            os.rename(origfile, path)        fp = io.open(path, mode=""wb"")        fp.close()    elif os.path.isdir(path):        for name in os.listdir(path):            remove(name, try_trash)    else:        raise TypeError",,"def empty(path, try_trash=False, exist_ok=True):    if not exist_ok and not os.path.exists(path):        raise OSError(""Path not exists"")    if os.path.isfile(path):        if try_trash:            origfile = path + "".orig""            os.rename(path, origfile)            shutil.copy2(origfile, path)            remove(path, try_trash)            os.rename(origfile, path)        fp = io.open(path, mode=""wb"")        fp.close()    elif os.path.isdir(path):        for name in os.listdir(path):            remove(name, try_trash)    else:        raise TypeError",99631525-fe17-4023-bd00-599f75fc5e7a
utils,fs.py,which,369,382,"def which(filename):    try:        return shutil.which(filename)  # NOTE: Available only under Python 3    except AttributeError:        pass    dirname = os.path.dirname(filename)    if dirname:        return filename if is_exec(filename) else None    for envpath in os.environ[""PATH""].split(os.pathsep):        filename = os.path.join(envpath.strip('""'), filename)        if is_exec(filename):            return filename",,"def which(filename):    try:        return shutil.which(filename)  # NOTE: Available only under Python 3    except AttributeError:        pass    dirname = os.path.dirname(filename)    if dirname:        return filename if is_exec(filename) else None    for envpath in os.environ[""PATH""].split(os.pathsep):        filename = os.path.join(envpath.strip('""'), filename)        if is_exec(filename):            return filename",0a288096-9ccc-4167-8529-2d3714c5d945
utils,misc.py,monkey_patch,8,16,"def monkey_patch():                from js2py.constructors.jsobject import Object        fn = Object.own[""getOwnPropertyNames""][""value""].code        def wraps(*args, **kwargs):            result = fn(*args, **kwargs)            return list(result)        Object.own[""getOwnPropertyNames""][""value""].code = wraps",Patching js2py for CVE-2024-28397,"def monkey_patch():        """"""Patching js2py for CVE-2024-28397""""""        from js2py.constructors.jsobject import Object        fn = Object.own[""getOwnPropertyNames""][""value""].code        def wraps(*args, **kwargs):            result = fn(*args, **kwargs)            return list(result)        Object.own[""getOwnPropertyNames""][""value""].code = wraps

Patching js2py for CVE-2024-28397",1559a291-2a5c-4935-9049-24744c6aed9e
utils,misc.py,random_string,26,27,"def random_string(length, valid_chars=string.ascii_letters + string.digits + string.punctuation):    return """".join(random.choice(valid_chars) for _ in range(length))",,"def random_string(length, valid_chars=string.ascii_letters + string.digits + string.punctuation):    return """".join(random.choice(valid_chars) for _ in range(length))",b2bccaee-dfd9-4471-ae69-2fceb2320d97
utils,misc.py,is_plural,30,35,"def is_plural(value):    try:        n = abs(float(value))        return n == 0 or n > 1    except ValueError:        return value.endswith(""s"")",,"def is_plural(value):    try:        n = abs(float(value))        return n == 0 or n > 1    except ValueError:        return value.endswith(""s"")",14672123-5cb9-4111-8935-eadb6bdad807
utils,misc.py,eval_js,38,42,"def eval_js(script, es6=False):    if sys.version_info < (3, 12):        return (js2py.eval_js6 if es6 else js2py.eval_js)(script)    else:        return dukpy.evaljs(script)",,"def eval_js(script, es6=False):    if sys.version_info < (3, 12):        return (js2py.eval_js6 if es6 else js2py.eval_js)(script)    else:        return dukpy.evaljs(script)",43db91c5-145c-4603-be6b-49e01be25271
utils,misc.py,accumulate,45,53,"def accumulate(iterable, to_map=None):        if to_map is None:        to_map = {}    for key, value in iterable:        to_map.setdefault(value, []).append(key)    return to_map","Accumulate (key, value) data to {value : [key]} dictionary.","def accumulate(iterable, to_map=None):    """"""    Accumulate (key, value) data to {value : [key]} dictionary.    """"""    if to_map is None:        to_map = {}    for key, value in iterable:        to_map.setdefault(value, []).append(key)    return to_map

Accumulate (key, value) data to {value : [key]} dictionary.",6a57c69e-c438-439c-841f-d829ce1fc84f
utils,misc.py,reversemap,56,60,def reversemap(obj):        return obj.__class__(reversed(item) for item in obj.items()),Invert mapping object preserving type and ordering.,"def reversemap(obj):    """"""    Invert mapping object preserving type and ordering.    """"""    return obj.__class__(reversed(item) for item in obj.items())

Invert mapping object preserving type and ordering.",d46eacfd-02e1-479d-8efd-bd0d4bd1975f
utils,parse.py,boolean,30,31,def boolean(text):    return _BOOLMAP.get(text.strip().lower()),,def boolean(text):    return _BOOLMAP.get(text.strip().lower()),cfc19a6d-a896-4b8e-8827-11bf04434af6
utils,parse.py,entries,34,39,"def entries(text, allow_whitespaces=False):    chars = "";,|""    if not allow_whitespaces:        chars += r""\s""    pattr = rf""[{chars}]+""    return [entry for entry in re.split(pattr, text) if entry]",,"def entries(text, allow_whitespaces=False):    chars = "";,|""    if not allow_whitespaces:        chars += r""\s""    pattr = rf""[{chars}]+""    return [entry for entry in re.split(pattr, text) if entry]",e0ec84e1-68f9-442c-8aa5-b949749e1a88
utils,parse.py,name,42,51,"def name(text, safe_name=True):    try:        name = web_parse.name(text, safe_name=safe_name)        name = os.path.basename(name)    except Exception:        name = os.path.basename(text).strip()        if safe_name:            name = purge.name(name)    return name",,"def name(text, safe_name=True):    try:        name = web_parse.name(text, safe_name=safe_name)        name = os.path.basename(name)    except Exception:        name = os.path.basename(text).strip()        if safe_name:            name = purge.name(name)    return name",cd18fce0-9a12-4095-9558-afd1e9de4ab8
utils,parse.py,number,89,103,"def number(text):    # try:    #     text = web.misc.translate(text).lower()    # except Exception:    #     text = text.lower()    text = text.lower()    o_tuple = [(w, i) for i, w in enumerate(_ONEWORDS)]    t_tuple = [(w, i * 10) for i, w in enumerate(_TENWORDS, 2)]    numwords = dict(o_tuple + t_tuple)    tokens = _RE_NUMBER.split(text)    numbers = [_f for _f in (numwords.get(word) for word in tokens) if _f]    return sum(numbers) if numbers else None",,"def number(text):    # try:    #     text = web.misc.translate(text).lower()    # except Exception:    #     text = text.lower()    text = text.lower()    o_tuple = [(w, i) for i, w in enumerate(_ONEWORDS)]    t_tuple = [(w, i * 10) for i, w in enumerate(_TENWORDS, 2)]    numwords = dict(o_tuple + t_tuple)    tokens = _RE_NUMBER.split(text)    numbers = [_f for _f in (numwords.get(word) for word in tokens) if _f]    return sum(numbers) if numbers else None",ad44a2a9-9be9-4801-ad17-980a77a809b8
utils,parse.py,packs,109,123,"def packs(nameurls):    DEFAULT_URLNAME = ""Unknown""    packs = {}    for urlname, url in nameurls:        urlname = name(urlname, safe_name=True)        urlname = os.path.splitext(urlname)[0].strip()        urlname = _RE_PACKS.sub(""_"", urlname).strip(""_"")        if not urlname:            urlname = DEFAULT_URLNAME        packs.setdefault(urlname, []).append(url)    return packs",,"def packs(nameurls):    DEFAULT_URLNAME = ""Unknown""    packs = {}    for urlname, url in nameurls:        urlname = name(urlname, safe_name=True)        urlname = os.path.splitext(urlname)[0].strip()        urlname = _RE_PACKS.sub(""_"", urlname).strip(""_"")        if not urlname:            urlname = DEFAULT_URLNAME        packs.setdefault(urlname, []).append(url)    return packs",66b4cafe-2fb0-47ac-bebc-e01361ce0079
utils,parse.py,bytesize,132,156,"def bytesize(text, from_unit=None):  # returns integer bytes    DEFAULT_UNIT = ""byte""    m = _RE_SIZE.match(convert.to_str(text))    if m is None:        return None    raw_size = m.group(""S"")    if re.match(_RE_SIZEFORMAT1, raw_size):        raw_size = raw_size.replace("","", """")    elif re.match(_RE_SIZEFORMAT2, raw_size):        raw_size = raw_size.replace("","", ""."")    elif not re.match(_RE_SIZEFORMAT3, raw_size):        return 0  #: Unknown format    if from_unit is None:        from_unit = m.group(""U"") or DEFAULT_UNIT    size = float(raw_size)    unit = from_unit[0].lower()    return int(convert.size(size, unit, ""byte""))",,"def bytesize(text, from_unit=None):  # returns integer bytes    DEFAULT_UNIT = ""byte""    m = _RE_SIZE.match(convert.to_str(text))    if m is None:        return None    raw_size = m.group(""S"")    if re.match(_RE_SIZEFORMAT1, raw_size):        raw_size = raw_size.replace("","", """")    elif re.match(_RE_SIZEFORMAT2, raw_size):        raw_size = raw_size.replace("","", ""."")    elif not re.match(_RE_SIZEFORMAT3, raw_size):        return 0  #: Unknown format    if from_unit is None:        from_unit = m.group(""U"") or DEFAULT_UNIT    size = float(raw_size)    unit = from_unit[0].lower()    return int(convert.size(size, unit, ""byte""))",b5d49701-225e-4a30-80d8-d3b07941e96c
utils,parse.py,seconds,164,188,"def seconds(text):    def to_int(obj):        try:            return int(obj)        except ValueError:            return None    # try:    #     text = web.misc.translate(text).lower()    # except Exception:    #     text = text.lower()    text = text.lower()    w = ""|"".join(_TIMEWORDS)    pattr = rf""(?:(?:{w})\s+day)|today|daily""    m = re.search(pattr, text)    if m is not None:        return seconds_to_midnight()    seconds = sum(        (w in _TIMEWORDS or to_int(i or w) or number(w) or 1) * _TIMEMAP.get(u, 1)        for w, u, i in _RE_TIME.findall(text)    )    return seconds",,"def seconds(text):    def to_int(obj):        try:            return int(obj)        except ValueError:            return None    # try:    #     text = web.misc.translate(text).lower()    # except Exception:    #     text = text.lower()    text = text.lower()    w = ""|"".join(_TIMEWORDS)    pattr = rf""(?:(?:{w})\s+day)|today|daily""    m = re.search(pattr, text)    if m is not None:        return seconds_to_midnight()    seconds = sum(        (w in _TIMEWORDS or to_int(i or w) or number(w) or 1) * _TIMEMAP.get(u, 1)        for w, u, i in _RE_TIME.findall(text)    )    return seconds",92a27558-bd29-4f31-bdaa-78781baa85a0
utils,parse.py,minutes,191,192,def minutes(text):    return seconds(text) / 60,,def minutes(text):    return seconds(text) / 60,511ccf6c-6db2-49d6-b80b-a8458b83db77
utils,parse.py,hours,195,196,def hours(text):    return seconds(text) / 60 ** 2,,def hours(text):    return seconds(text) / 60 ** 2,0fd50302-831a-42e9-b027-b03eb3df42c2
utils,purge.py,chars,6,11,"def chars(text, chars, repl=""""):        chars = chars.replace(""\\"", ""\\\\"")    return re.sub(rf""[{chars}]"", repl, text)",Removes all chars in repl from text.,"def chars(text, chars, repl=""""):    """"""    Removes all chars in repl from text.    """"""    chars = chars.replace(""\\"", ""\\\\"")    return re.sub(rf""[{chars}]"", repl, text)

Removes all chars in repl from text.",57ad25a9-7b3f-47c9-bada-c6f33b9a99bb
utils,purge.py,name,41,50,"def name(text, sep=""_"", allow_whitespaces=True):        bc = uniquify(_WINBADCHARS + _MACBADCHARS + _UNIXBADCHARS)    repl = r"""".join(bc)    if not allow_whitespaces:        repl += "" ""    res = chars(text, repl, sep).strip()    if res.lower() in _WINBADWORDS:        res = (sep or ""_"") + res    return res",Remove invalid characters.,"def name(text, sep=""_"", allow_whitespaces=True):    """"""Remove invalid characters.""""""    bc = uniquify(_WINBADCHARS + _MACBADCHARS + _UNIXBADCHARS)    repl = r"""".join(bc)    if not allow_whitespaces:        repl += "" ""    res = chars(text, repl, sep).strip()    if res.lower() in _WINBADWORDS:        res = (sep or ""_"") + res    return res

Remove invalid characters.",6e4c2b5c-a3d3-4247-ab1c-e6e3e22b00ea
utils,purge.py,pattern,53,61,"def pattern(text, rules):    for rule in rules:        try:            pattr, repl, flags = rule        except ValueError:            pattr, repl = rule            flags = 0        text = re.sub(pattr, repl, text, flags)    return text",,"def pattern(text, rules):    for rule in rules:        try:            pattr, repl, flags = rule        except ValueError:            pattr, repl = rule            flags = 0        text = re.sub(pattr, repl, text, flags)    return text",64a14213-f48f-4c8f-9997-e717ff6a18de
utils,purge.py,truncate,64,69,"def truncate(text, to_length):    min_length = len(text) // 2    if to_length <= min_length:        raise OSError(""File name too long"")    offset = to_length // 3    return f""{text[:offset * 2]}~{text[-(offset - 1 + to_length % 3):]}""",,"def truncate(text, to_length):    min_length = len(text) // 2    if to_length <= min_length:        raise OSError(""File name too long"")    offset = to_length // 3    return f""{text[:offset * 2]}~{text[-(offset - 1 + to_length % 3):]}""",020980f7-df07-48a1-b6b6-831abcd32447
utils,purge.py,uniquify,72,76,def uniquify(seq):        seen = set()    seen_add = seen.add    return type(seq)(x for x in seq if x not in seen and not seen_add(x)),Remove duplicates from list preserving order.,"def uniquify(seq):    """"""Remove duplicates from list preserving order.""""""    seen = set()    seen_add = seen.add    return type(seq)(x for x in seq if x not in seen and not seen_add(x))

Remove duplicates from list preserving order.",ddfd6bcd-fa75-4446-9763-ff31a75d9494
utils,seconds.py,compare,7,21,"def compare(start, end):    start = tuple(int(n) for n in start)    end = tuple(int(n) for n in end)    if start == end:        return True    now = time.localtime()[3:5]    if start < now < end or start < now > end < start:        return True    elif start > end and (now > start or now < end):        return True    return False",,"def compare(start, end):    start = tuple(int(n) for n in start)    end = tuple(int(n) for n in end)    if start == end:        return True    now = time.localtime()[3:5]    if start < now < end or start < now > end < start:        return True    elif start > end and (now > start or now < end):        return True    return False",893bdf35-a330-46ff-b9b6-8af281c6fcf9
utils,seconds.py,to_midnight,24,34,"def to_midnight(utc=None, strict=False):    if utc is None:        now = datetime.datetime.today()    else:        now = datetime.datetime.utcnow() + datetime.timedelta(hours=utc)    midnight = now.replace(        hour=0, minute=0 if strict else 1, second=0, microsecond=0    ) + datetime.timedelta(days=1)    return (midnight - now).total_seconds()",,"def to_midnight(utc=None, strict=False):    if utc is None:        now = datetime.datetime.today()    else:        now = datetime.datetime.utcnow() + datetime.timedelta(hours=utc)    midnight = now.replace(        hour=0, minute=0 if strict else 1, second=0, microsecond=0    ) + datetime.timedelta(days=1)    return (midnight - now).total_seconds()",61bdb149-2eae-4096-8517-b956860a2ca1
utils,seconds.py,to_nexthour,37,42,"def to_nexthour(strict=False):    now = datetime.datetime.today()    nexthour = now.replace(        minute=0 if strict else 1, second=0, microsecond=0    ) + datetime.timedelta(hours=1)    return (nexthour - now).seconds",,"def to_nexthour(strict=False):    now = datetime.datetime.today()    nexthour = now.replace(        minute=0 if strict else 1, second=0, microsecond=0    ) + datetime.timedelta(hours=1)    return (nexthour - now).seconds",2552ba53-63e4-425e-8170-39d900af8f93
utils,system.py,exec_cmd,28,33,"def exec_cmd(command, *args, **kwargs):    cmd = shlex.split(command)    cmd.extend(map(convert.to_bytes, args))    xargs = {""bufsize"": -1, ""stdout"": PIPE, ""stderr"": PIPE}    xargs.update(kwargs)    return Popen(cmd, **xargs)",,"def exec_cmd(command, *args, **kwargs):    cmd = shlex.split(command)    cmd.extend(map(convert.to_bytes, args))    xargs = {""bufsize"": -1, ""stdout"": PIPE, ""stderr"": PIPE}    xargs.update(kwargs)    return Popen(cmd, **xargs)",a8e183d8-054f-4ebd-801f-a5fc4d6d376e
utils,system.py,call_cmd,37,52,"def call_cmd(command, *args, **kwargs):    ignore_errors = kwargs.pop(""ignore_errors"", False)    try:        sp = exec_cmd(command, *args, **kwargs)    except Exception as exc:        if not ignore_errors:            raise        returncode = 1        stdoutdata = """"        stderrdata = to_str(exc).strip()    else:        returncode = sp.returncode        stdoutdata, stderrdata = map(str.strip, sp.communicate())    return returncode, stdoutdata, stderrdata",,"def call_cmd(command, *args, **kwargs):    ignore_errors = kwargs.pop(""ignore_errors"", False)    try:        sp = exec_cmd(command, *args, **kwargs)    except Exception as exc:        if not ignore_errors:            raise        returncode = 1        stdoutdata = """"        stderrdata = to_str(exc).strip()    else:        returncode = sp.returncode        stdoutdata, stderrdata = map(str.strip, sp.communicate())    return returncode, stdoutdata, stderrdata",f425ca3f-5b8a-4784-9991-c5c7125ec9c3
old,packagetools.py,match_first,8,19,"def match_first(string, *args):        for patternlist in args:        for pattern in patternlist:            r = pattern.search(string)            if r is not None:                name = r.group(1)                return name    return string",matches against list of regexp and returns first match.,"def match_first(string, *args):    """"""    matches against list of regexp and returns first match.    """"""    for patternlist in args:        for pattern in patternlist:            r = pattern.search(string)            if r is not None:                name = r.group(1)                return name    return string

matches against list of regexp and returns first match.",730dbd5d-e27c-4b99-880f-117e9c20014a
old,packagetools.py,parse_names,22,147,"def parse_names(files):        packs = {}    endings = ""\\.(3gp|7zip|7z|abr|ac3|aiff|aifc|aif|ai|au|avi|bin|bz2|cbr|cbz|ccf|cue|cvd|chm|dta|deb|divx|djvu|dlc|dmg|doc|docx|dot|eps|exe|ff|flv|f4v|gsd|gif|gz|iwd|iso|ipsw|java|jar|jpg|jpeg|jdeatme|load|mws|mw|m4v|m4a|mkv|mp2|mp3|mp4|mov|movie|mpeg|mpe|mpg|msi|msu|msp|nfo|npk|oga|ogg|ogv|otrkey|pkg|png|pdf|pptx|ppt|pps|ppz|pot|psd|qt|rmvb|rm|rar|ram|ra|rev|rnd|r\\d+|rpm|run|rsdf|rtf|sh(!?tml)|srt|snd|sfv|swf|tar|tif|tiff|ts|txt|viv|vivo|vob|wav|wmv|xla|xls|xpi|zeno|zip|z\\d+|_[_a-z]{2}|\\d+$)""    rar_pats = [        re.compile(""(.*)(\\.|_|-)pa?r?t?\\.?[0-9]+.(rar|exe)$"", re.I),        re.compile(""(.*)(\\.|_|-)part\\.?[0]*[1].(rar|exe)$"", re.I),        re.compile(""(.*)\\.rar$"", re.I),        re.compile(""(.*)\\.r\\d+$"", re.I),        re.compile(""(.*)(\\.|_|-)\\d+$"", re.I),    ]    zip_pats = [        re.compile(""(.*)\\.zip$"", re.I),        re.compile(""(.*)\\.z\\d+$"", re.I),        re.compile(""(?is).*\\.7z\\.[\\d]+$"", re.I),        re.compile(""(.*)\\.a.$"", re.I),    ]    ffsj_pats = [        re.compile(""(.*)\\._((_[a-z])|([a-z]{2}))(\\.|$)""),        re.compile(""(.*)(\\.|_|-)[\\d]+("" + endings + ""$)"", re.I),    ]    isz_pats = [re.compile(""(.*)\\.isz$"", re.I), re.compile(""(.*)\\.i\\d{2}$"", re.I)]    pat1 = re.compile(""(\\.?CD\\d+)"", re.I)    pat2 = re.compile(""(\\.?part\\d+)"", re.I)    pat3 = re.compile(""(.+)[\\.\\-_]+$"")    pat4 = re.compile(""(.+)\\.\\d+\\.xtm$"")    for file, url in files:        pattern_match = False        if file is None:            continue        # remove trailing /        name = file.rstrip(""/"")        # extract last path part .. if there is a path        split = name.rsplit(""/"", 1)        if len(split) > 1:            name = split.pop(1)            # check if a already existing package may be ok for this file        #        found = False        #        for pack in packs:        #            if pack in file:        #                packs[pack].append(url)        #                found = True        #                break        #        #        if found: continue        # unrar pattern, 7zip/zip and hjmerge pattern, isz pattern, FFSJ pattern        before = name        name = match_first(name, rar_pats, zip_pats, isz_pats, ffsj_pats)        if before != name:            pattern_match = True        # xtremsplit pattern        r = pat4.search(name)        if r is not None:            name = r.group(1)        # remove part and cd pattern        r = pat1.search(name)        if r is not None:            name = name.replace(r.group(0), """")            pattern_match = True        r = pat2.search(name)        if r is not None:            name = name.replace(r.group(0), """")            pattern_match = True        # additional checks if extension pattern matched        if pattern_match:            # remove extension            index = name.rfind(""."")            if index <= 0:                index = name.rfind(""_"")            if index > 0:                length = len(name) - index                if length <= 4:                    name = name[:-length]            # remove endings like . _ -            r = pat3.search(name)            if r is not None:                name = r.group(1)            # replace . and _ with space            name = name.replace(""."", "" "")            name = name.replace(""_"", "" "")            name = name.strip()        else:            name = """"        # fallback: package by hoster        if not name:            name = urlparse(file).hostname            if name:                name = name.replace(""www."", """")        # fallback : default name        if not name:            name = ""unknown""        # build mapping        if name in packs:            packs[name].append(url)        else:            packs[name] = [url]    return packs","Generates packages names from name, data lists.

:param files: list of (name, data)
:return: packagenames mapt to data lists (eg. urls)","def parse_names(files):    """"""    Generates packages names from name, data lists.    :param files: list of (name, data)    :return: packagenames mapt to data lists (eg. urls)    """"""    packs = {}    endings = ""\\.(3gp|7zip|7z|abr|ac3|aiff|aifc|aif|ai|au|avi|bin|bz2|cbr|cbz|ccf|cue|cvd|chm|dta|deb|divx|djvu|dlc|dmg|doc|docx|dot|eps|exe|ff|flv|f4v|gsd|gif|gz|iwd|iso|ipsw|java|jar|jpg|jpeg|jdeatme|load|mws|mw|m4v|m4a|mkv|mp2|mp3|mp4|mov|movie|mpeg|mpe|mpg|msi|msu|msp|nfo|npk|oga|ogg|ogv|otrkey|pkg|png|pdf|pptx|ppt|pps|ppz|pot|psd|qt|rmvb|rm|rar|ram|ra|rev|rnd|r\\d+|rpm|run|rsdf|rtf|sh(!?tml)|srt|snd|sfv|swf|tar|tif|tiff|ts|txt|viv|vivo|vob|wav|wmv|xla|xls|xpi|zeno|zip|z\\d+|_[_a-z]{2}|\\d+$)""    rar_pats = [        re.compile(""(.*)(\\.|_|-)pa?r?t?\\.?[0-9]+.(rar|exe)$"", re.I),        re.compile(""(.*)(\\.|_|-)part\\.?[0]*[1].(rar|exe)$"", re.I),        re.compile(""(.*)\\.rar$"", re.I),        re.compile(""(.*)\\.r\\d+$"", re.I),        re.compile(""(.*)(\\.|_|-)\\d+$"", re.I),    ]    zip_pats = [        re.compile(""(.*)\\.zip$"", re.I),        re.compile(""(.*)\\.z\\d+$"", re.I),        re.compile(""(?is).*\\.7z\\.[\\d]+$"", re.I),        re.compile(""(.*)\\.a.$"", re.I),    ]    ffsj_pats = [        re.compile(""(.*)\\._((_[a-z])|([a-z]{2}))(\\.|$)""),        re.compile(""(.*)(\\.|_|-)[\\d]+("" + endings + ""$)"", re.I),    ]    isz_pats = [re.compile(""(.*)\\.isz$"", re.I), re.compile(""(.*)\\.i\\d{2}$"", re.I)]    pat1 = re.compile(""(\\.?CD\\d+)"", re.I)    pat2 = re.compile(""(\\.?part\\d+)"", re.I)    pat3 = re.compile(""(.+)[\\.\\-_]+$"")    pat4 = re.compile(""(.+)\\.\\d+\\.xtm$"")    for file, url in files:        pattern_match = False        if file is None:            continue        # remove trailing /        name = file.rstrip(""/"")        # extract last path part .. if there is a path        split = name.rsplit(""/"", 1)        if len(split) > 1:            name = split.pop(1)            # check if a already existing package may be ok for this file        #        found = False        #        for pack in packs:        #            if pack in file:        #                packs[pack].append(url)        #                found = True        #                break        #        #        if found: continue        # unrar pattern, 7zip/zip and hjmerge pattern, isz pattern, FFSJ pattern        before = name        name = match_first(name, rar_pats, zip_pats, isz_pats, ffsj_pats)        if before != name:            pattern_match = True        # xtremsplit pattern        r = pat4.search(name)        if r is not None:            name = r.group(1)        # remove part and cd pattern        r = pat1.search(name)        if r is not None:            name = name.replace(r.group(0), """")            pattern_match = True        r = pat2.search(name)        if r is not None:            name = name.replace(r.group(0), """")            pattern_match = True        # additional checks if extension pattern matched        if pattern_match:            # remove extension            index = name.rfind(""."")            if index <= 0:                index = name.rfind(""_"")            if index > 0:                length = len(name) - index                if length <= 4:                    name = name[:-length]            # remove endings like . _ -            r = pat3.search(name)            if r is not None:                name = r.group(1)            # replace . and _ with space            name = name.replace(""."", "" "")            name = name.replace(""_"", "" "")            name = name.strip()        else:            name = """"        # fallback: package by hoster        if not name:            name = urlparse(file).hostname            if name:                name = name.replace(""www."", """")        # fallback : default name        if not name:            name = ""unknown""        # build mapping        if name in packs:            packs[name].append(url)        else:            packs[name] = [url]    return packs

Generates packages names from name, data lists.

:param files: list of (name, data)
:return: packagenames mapt to data lists (eg. urls)",9f8f2235-0044-49bd-a04f-86d66dbd499d
old,__init__.py,safepath,36,61,"def safepath(value):        drive, filename = os.path.splitdrive(value)    filesep = os.sep if os.path.isabs(filename) else """"    fileparts = (safename(name) for name in filename.split(os.sep))    filename = os.path.join(filesep, *fileparts)    path = drive + filename    try:        if os.name != ""nt"":            return        excess_chars = len(path) - 259        if excess_chars < 1:            return        dirname, basename = os.path.split(filename)        name, ext = os.path.splitext(basename)        path = drive + dirname + purge.truncate(name, len(name) - excess_chars) + ext    finally:        return path",Remove invalid characters and truncate the path if needed.,"def safepath(value):    """"""    Remove invalid characters and truncate the path if needed.    """"""    drive, filename = os.path.splitdrive(value)    filesep = os.sep if os.path.isabs(filename) else """"    fileparts = (safename(name) for name in filename.split(os.sep))    filename = os.path.join(filesep, *fileparts)    path = drive + filename    try:        if os.name != ""nt"":            return        excess_chars = len(path) - 259        if excess_chars < 1:            return        dirname, basename = os.path.split(filename)        name, ext = os.path.splitext(basename)        path = drive + dirname + purge.truncate(name, len(name) - excess_chars) + ext    finally:        return path

Remove invalid characters and truncate the path if needed.",f6f3e5c9-8f80-484e-9398-2f8f0a211ba6
old,__init__.py,safejoin,64,68,def safejoin(*args):        return safepath(os.path.join(*args)),os.path.join + safepath.,"def safejoin(*args):    """"""    os.path.join + safepath.    """"""    return safepath(os.path.join(*args))

os.path.join + safepath.",e00685a0-197d-4fb6-b7c2-8e2bbd406756
old,__init__.py,safename,71,78,"def safename(value):        # repl = '<>:""/\\|?*' if os.name == ""nt"" else '\0/\\""'    repl = '<>:""/\\|?*\0'    name = purge.chars(value, repl)    return name",Remove invalid characters.,"def safename(value):    """"""    Remove invalid characters.    """"""    # repl = '<>:""/\\|?*' if os.name == ""nt"" else '\0/\\""'    repl = '<>:""/\\|?*\0'    name = purge.chars(value, repl)    return name

Remove invalid characters.",75f815f7-4e32-41f8-a415-bc6e830b76a1
old,__init__.py,fixurl,81,99,"def fixurl(url, unquote=None):    old = url    url = urllib.parse.unquote(url)    if unquote is None:        unquote = url == old    # try:    # url = url.decode(""unicode-escape"")    # except UnicodeDecodeError:    # pass    url = html_unescape(url)    url = re.sub(r""(?<!:)/{2,}"", ""/"", url).strip().lstrip(""."")    if not unquote:        url = urllib.parse.quote(url)    return url",,"def fixurl(url, unquote=None):    old = url    url = urllib.parse.unquote(url)    if unquote is None:        unquote = url == old    # try:    # url = url.decode(""unicode-escape"")    # except UnicodeDecodeError:    # pass    url = html_unescape(url)    url = re.sub(r""(?<!:)/{2,}"", ""/"", url).strip().lstrip(""."")    if not unquote:        url = urllib.parse.quote(url)    return url",87eb096c-6d88-4e08-a240-623bbdecf3c3
struct,base.py,__call__,11,14,"def __call__(cls, *args, **kwargs):        if cls not in cls._inst:            cls._inst[cls] = super(Singleton, cls).__call__(*args, **kwargs)        return cls._inst[cls]",,"def __call__(cls, *args, **kwargs):        if cls not in cls._inst:            cls._inst[cls] = super(Singleton, cls).__call__(*args, **kwargs)        return cls._inst[cls]",326a5f6c-ce10-456f-a183-4cf8d4eab155
struct,base.py,__init__,21,22,"def __init__(self, *args, **kwargs):        super().__init__(*args, **kwargs)",,"def __init__(self, *args, **kwargs):        super().__init__(*args, **kwargs)",55769423-1249-4f9d-a8f9-828f70e7b1a4
struct,base.py,__getitem__,24,25,"def __getitem__(self, key):        return self.__dict__[key.lower()][-1]",,"def __getitem__(self, key):        return self.__dict__[key.lower()][-1]",f4954f05-3206-414e-9625-1d7eabd4d42e
struct,base.py,__setitem__,27,30,"def __setitem__(self, key, value):        # NOTE: Use the lowercased key for lookups, but store the actual key        # alongside the value        self.__dict__[key.lower()] = (key, value)",,"def __setitem__(self, key, value):        # NOTE: Use the lowercased key for lookups, but store the actual key        # alongside the value        self.__dict__[key.lower()] = (key, value)",a5eb9fdf-17ff-4c4c-80e3-56d427317b91
struct,base.py,__delitem__,32,33,"def __delitem__(self, key):        del self.__dict__[key.lower()]",,"def __delitem__(self, key):        del self.__dict__[key.lower()]",98f8811d-f0c6-4941-b4aa-9fa6f228d173
struct,base.py,__len__,35,36,def __len__(self):        return len(self.__dict__),,def __len__(self):        return len(self.__dict__),00dcfda1-40f9-462f-8427-3f62434ebdd6
struct,base.py,__iter__,38,39,"def __iter__(self):        return iter(key for key, val in self.__dict__.values())",,"def __iter__(self):        return iter(key for key, val in self.__dict__.values())",1fce4efa-3d75-4e31-bdc5-f26aee658644
struct,base.py,__str__,41,42,"def __str__(self):        return f""<InscDict {self.__dict__}>""",,"def __str__(self):        return f""<InscDict {self.__dict__}>""",f2dd0fc1-1aa4-4d61-9b7f-9c19de368583
struct,base.py,__eq__,44,48,"def __eq__(self, other):        if not isinstance(other, Mapping):            raise TypeError        # Compare insensitively        return self.loweritems() == InscDict(other).loweritems()",,"def __eq__(self, other):        if not isinstance(other, Mapping):            raise TypeError        # Compare insensitively        return self.loweritems() == InscDict(other).loweritems()",6cc7e1fe-e1e4-4cc4-ad7d-703cd573768e
struct,base.py,lowerkeys,50,52,def lowerkeys(self):                return self.__dict__.keys(),"Like `keys`, but with all lowercase keys.","def lowerkeys(self):        """"""Like `keys`, but with all lowercase keys.""""""        return self.__dict__.keys()

Like `keys`, but with all lowercase keys.",62020300-9ea2-44cc-9841-3ff701b82d04
struct,base.py,loweritems,54,56,"def loweritems(self):                return ((lowerkey, val) for lowerkey, (key, val) in self.__dict__.items())","Like `items`, but with all lowercase keys.","def loweritems(self):        """"""Like `items`, but with all lowercase keys.""""""        return ((lowerkey, val) for lowerkey, (key, val) in self.__dict__.items())

Like `items`, but with all lowercase keys.",a18d6840-5382-4831-bc1f-34355bffd750
struct,base.py,copy,58,59,def copy(self):        return InscDict(self.__dict__.values()),,def copy(self):        return InscDict(self.__dict__.values()),5ee6b0b0-4e8a-49cc-a27d-666234883013
struct,info.py,__init__,27,28,"def __init__(self, *args, **kwargs):        super(Info, self).__init__(*args, **kwargs)",,"def __init__(self, *args, **kwargs):        super(Info, self).__init__(*args, **kwargs)",5b309420-4ded-48e3-a1b6-f0208969f271
struct,info.py,__getattr__,30,31,"def __getattr__(self, name):        return self.__getitem__(name)",,"def __getattr__(self, name):        return self.__getitem__(name)",4a6bf44f-1e37-4237-bfdf-3ada2a437e2a
struct,info.py,__setattr__,33,34,"def __setattr__(self, name, value):        self.__setitem__(name, value)",,"def __setattr__(self, name, value):        self.__setitem__(name, value)",490b18e0-32e2-4887-99c8-f7e92b345a97
struct,info.py,__delattr__,36,42,"def __delattr__(self, name):        try:            self.__delitem__(name)        except DeleteError:            raise        except KeyError:            pass",,"def __delattr__(self, name):        try:            self.__delitem__(name)        except DeleteError:            raise        except KeyError:            pass",80d35e18-227e-43b4-b673-8eb61d847aaa
struct,info.py,__getitem__,44,47,"def __getitem__(self, key):        if not self.readable:            raise ReadError        return self.__dict__[key]",,"def __getitem__(self, key):        if not self.readable:            raise ReadError        return self.__dict__[key]",a18f8f63-1d6a-44c1-abee-34b79a1dacf7
struct,info.py,__setitem__,49,54,"def __setitem__(self, key, value):        if not self.writable:            raise WriteError        if not self.updateable and key not in self.__dict__:            raise WriteError        self.__dict__[key] = value",,"def __setitem__(self, key, value):        if not self.writable:            raise WriteError        if not self.updateable and key not in self.__dict__:            raise WriteError        self.__dict__[key] = value",9b75b4a6-ac60-46a0-af6b-7b7d109a752f
struct,info.py,__delitem__,56,59,"def __delitem__(self, key):        if not self.deletable:            raise DeleteError        del self.__dict__[key]",,"def __delitem__(self, key):        if not self.deletable:            raise DeleteError        del self.__dict__[key]",a483915e-5332-4a7c-a553-1f9b63f4b50f
struct,info.py,__len__,61,62,def __len__(self):        return len(self.__dict__),,def __len__(self):        return len(self.__dict__),5f837430-cd57-4107-9279-8151c3be7932
struct,info.py,__iter__,64,65,def __iter__(self):        return iter(self.__dict__),,def __iter__(self):        return iter(self.__dict__),7e121307-d2d6-4738-8569-194b46a67b61
struct,info.py,__str__,67,68,"def __str__(self):        return f""<Info {self.__dict__}>""",,"def __str__(self):        return f""<Info {self.__dict__}>""",b6cb2515-78ea-476d-afa1-4f1a81730754
struct,info.py,readable,71,72,def readable(self):        return bool(self.__readable__),,def readable(self):        return bool(self.__readable__),64be626b-54e2-4407-a471-0ec457dc36da
struct,info.py,writable,75,76,def writable(self):        return bool(self.__writeable__),,def writable(self):        return bool(self.__writeable__),bf9f036e-b27e-46fc-8b82-fb251e505502
struct,info.py,updateable,79,80,def updateable(self):        return bool(self.__updateable__),,def updateable(self):        return bool(self.__updateable__),d67aea89-187d-44d5-ad05-1423b610c238
struct,info.py,deletable,83,84,def deletable(self):        return bool(self.__deleteable__),,def deletable(self):        return bool(self.__deleteable__),17cecd56-824e-4a66-a250-0d8633b0b2b2
struct,info.py,lock,86,90,"def lock(self, read=True, write=True, update=False, delete=False):        self.__readable__ = read        self.__writeable__ = write        self.__updateable__ = update        self.__deleteable__ = delete",,"def lock(self, read=True, write=True, update=False, delete=False):        self.__readable__ = read        self.__writeable__ = write        self.__updateable__ = update        self.__deleteable__ = delete",4710b7fd-288d-49e6-b567-1ad80da2c2b1
struct,info.py,unlock,92,96,def unlock(self):        self.__readable__ = True        self.__writeable__ = True        self.__updateable__ = True        self.__deleteable__ = True,,def unlock(self):        self.__readable__ = True        self.__writeable__ = True        self.__updateable__ = True        self.__deleteable__ = True,9cdc9dd5-6202-411f-894c-6f700ef3cabc
struct,info.py,__getitem__,103,106,"def __getitem__(self, key):        if not self.readable:            raise ReadError        return InscDict.__getitem__(self, key)",,"def __getitem__(self, key):        if not self.readable:            raise ReadError        return InscDict.__getitem__(self, key)",37f21cf0-04cb-4486-83d1-d00716cb0323
struct,info.py,__setitem__,108,113,"def __setitem__(self, key, value):        if not self.writable:            raise WriteError        if not self.updateable and key.lower() not in self.__dict__:            raise WriteError        InscDict.__setitem__(self, key, value)",,"def __setitem__(self, key, value):        if not self.writable:            raise WriteError        if not self.updateable and key.lower() not in self.__dict__:            raise WriteError        InscDict.__setitem__(self, key, value)",62474371-492d-44cb-82bb-99a794c35272
struct,info.py,__delitem__,115,118,"def __delitem__(self, key):        if not self.deletable:            raise DeleteError        InscDict.__delitem__(self, key)",,"def __delitem__(self, key):        if not self.deletable:            raise DeleteError        InscDict.__delitem__(self, key)",5ea3734a-6908-474a-9f30-902d7adf3d7b
struct,info.py,__str__,120,121,"def __str__(self):        return f""<InscInfo {self.__dict__}>""",,"def __str__(self):        return f""<InscInfo {self.__dict__}>""",3147ad4f-0213-4ba0-9de0-3b714a5d3186
struct,info.py,__init__,128,132,"def __init__(self, remotedict, *args, **kwargs):        super().__init__(*args, **kwargs)        self.__local__ = self.__dict__        self.__remote__ = remotedict        self.sync()",,"def __init__(self, remotedict, *args, **kwargs):        super().__init__(*args, **kwargs)        self.__local__ = self.__dict__        self.__remote__ = remotedict        self.sync()",da99b002-24ea-4400-bdda-f4cd9cd9103c
struct,info.py,__setitem__,134,136,"def __setitem__(self, key, value):        Info.__setitem__(self, key, value)        self.__remote__[key] = value",,"def __setitem__(self, key, value):        Info.__setitem__(self, key, value)        self.__remote__[key] = value",b5b7927a-5a56-46e6-a7c0-9fdc4c662cc2
struct,info.py,__delitem__,138,140,"def __delitem__(self, key):        Info.__delitem__(self, key)        del self.__remote__[key]",,"def __delitem__(self, key):        Info.__delitem__(self, key)        del self.__remote__[key]",54a0c85b-ed69-4898-bdbb-38992681a49e
struct,info.py,sync,142,146,"def sync(self, reverse=False):        if reverse:            self.synclocal()        else:            self.syncremote()",,"def sync(self, reverse=False):        if reverse:            self.synclocal()        else:            self.syncremote()",a7c353bb-2aad-4dc7-a198-d9b4f5efe320
struct,info.py,syncremote,148,149,def syncremote(self):        self.__remote__.update(self.copy()),,def syncremote(self):        self.__remote__.update(self.copy()),ede046cc-b558-4d08-bc6b-1382775454d1
struct,info.py,synclocal,151,153,"def synclocal(self):        d = dict((k, v) for k, v in self.__remote__.items() if k in self)        self.update(d)",,"def synclocal(self):        d = dict((k, v) for k, v in self.__remote__.items() if k in self)        self.update(d)",cdf2e722-ac6f-41e9-a64b-aa76695f04de
struct,lock.py,lock,9,26,"def lock(func=None, **kwgs):    # If the decorator was used with parameters, then `func` will be empty.    # If that is the case, return the decorator with the parameters set.    # This allows using it as `@lock` or `@lock(shared=True)`.    # Explanation can be found at:    # https://blogs.it.ox.ac.uk/inapickle/2012/01/05/python-decorators-with-optional-arguments/    if func is None:        return partial(lock, **kwgs)    @wraps(func)    def wrapped(self, *args, **kwargs):        self.lock.acquire(**kwgs)        try:            return func(self, *args, **kwargs)        finally:            self.lock.release()    return wrapped",,"def lock(func=None, **kwgs):    # If the decorator was used with parameters, then `func` will be empty.    # If that is the case, return the decorator with the parameters set.    # This allows using it as `@lock` or `@lock(shared=True)`.    # Explanation can be found at:    # https://blogs.it.ox.ac.uk/inapickle/2012/01/05/python-decorators-with-optional-arguments/    if func is None:        return partial(lock, **kwgs)    @wraps(func)    def wrapped(self, *args, **kwargs):        self.lock.acquire(**kwgs)        try:            return func(self, *args, **kwargs)        finally:            self.lock.release()    return wrapped",55291057-b8b3-4a58-9065-8c5960e5045d
struct,lock.py,__init__,74,87,"def __init__(self):                # Condition variable, used to signal waiters of a change in object        # state.        self.__condition = Condition(Lock())        # Initialize with no writers.        self.__writer = None        self.__writercount = 0        self.__upgradewritercount = 0        self.__pendingwriters = []        # Initialize with no readers.        self.__readers = {}",Initialize this read-write lock.,"def __init__(self):        """"""Initialize this read-write lock.""""""        # Condition variable, used to signal waiters of a change in object        # state.        self.__condition = Condition(Lock())        # Initialize with no writers.        self.__writer = None        self.__writercount = 0        self.__upgradewritercount = 0        self.__pendingwriters = []        # Initialize with no readers.        self.__readers = {}

Initialize this read-write lock.",f99f0156-8904-45d9-8a17-fb0108f41a70
struct,lock.py,acquire,89,93,"def acquire(self, blocking=True, timeout=None, shared=False):        if shared:            self.acquireread(blocking, timeout)        else:            self.acquirewrite(timeout)",,"def acquire(self, blocking=True, timeout=None, shared=False):        if shared:            self.acquireread(blocking, timeout)        else:            self.acquirewrite(timeout)",21374e1a-301f-4707-8c64-db7281e0e445
struct,lock.py,acquireread,95,145,"def acquireread(self, blocking=True, timeout=True):                if not blocking:            endtime = -1        elif timeout is not None:            endtime = time.time() + timeout        else:            endtime = None        me = current_thread()        self.__condition.acquire()        try:            if self.__writer is me:                # If we are the writer, grant a new read lock, always.                self.__writercount += 1                return            while True:                if self.__writer is None:                    # Only test anything if there is no current writer.                    if self.__upgradewritercount or self.__pendingwriters:                        if me in self.__readers:                            # Only grant a read lock if we already have one                            # in case writers are waiting for their turn.                            # This means that writers can't easily get starved                            # (but see below, readers can).                            self.__readers[me] += 1                            return                            # No, we aren't a reader (yet), wait for our turn.                    else:                        # Grant a new read lock, always, in case there are                        # no pending writers (and no writer).                        self.__readers[me] = self.__readers.get(me, 0) + 1                        return                if timeout is not None:                    remaining = endtime - time.time()                    if remaining <= 0:                        # Timeout has expired, signal caller of this.                        raise RuntimeError(""Acquiring read lock timed out"")                    self.__condition.wait(remaining)                else:                    self.__condition.wait()        finally:            self.__condition.release()","Acquire a read lock for the current thread, waiting at most timeout
seconds or doing a non-blocking check in case timeout is <= 0.

In case timeout is None, the call to acquireread blocks until the
lock request can be serviced.

In case the timeout expires before the lock could be serviced, a
RuntimeError is thrown.","def acquireread(self, blocking=True, timeout=True):        """"""Acquire a read lock for the current thread, waiting at most timeout        seconds or doing a non-blocking check in case timeout is <= 0.        In case timeout is None, the call to acquireread blocks until the        lock request can be serviced.        In case the timeout expires before the lock could be serviced, a        RuntimeError is thrown.        """"""        if not blocking:            endtime = -1        elif timeout is not None:            endtime = time.time() + timeout        else:            endtime = None        me = current_thread()        self.__condition.acquire()        try:            if self.__writer is me:                # If we are the writer, grant a new read lock, always.                self.__writercount += 1                return            while True:                if self.__writer is None:                    # Only test anything if there is no current writer.                    if self.__upgradewritercount or self.__pendingwriters:                        if me in self.__readers:                            # Only grant a read lock if we already have one                            # in case writers are waiting for their turn.                            # This means that writers can't easily get starved                            # (but see below, readers can).                            self.__readers[me] += 1                            return                            # No, we aren't a reader (yet), wait for our turn.                    else:                        # Grant a new read lock, always, in case there are                        # no pending writers (and no writer).                        self.__readers[me] = self.__readers.get(me, 0) + 1                        return                if timeout is not None:                    remaining = endtime - time.time()                    if remaining <= 0:                        # Timeout has expired, signal caller of this.                        raise RuntimeError(""Acquiring read lock timed out"")                    self.__condition.wait(remaining)                else:                    self.__condition.wait()        finally:            self.__condition.release()

Acquire a read lock for the current thread, waiting at most timeout
seconds or doing a non-blocking check in case timeout is <= 0.

In case timeout is None, the call to acquireread blocks until the
lock request can be serviced.

In case the timeout expires before the lock could be serviced, a
RuntimeError is thrown.",513b7ff1-7699-4506-9455-a11839884317
struct,lock.py,acquirewrite,147,236,"def acquirewrite(self, timeout=None):                if timeout is not None:            endtime = time.time() + timeout        me, upgradewriter = current_thread(), False        self.__condition.acquire()        try:            if self.__writer is me:                # If we are the writer, grant a new write lock, always.                self.__writercount += 1                return            elif me in self.__readers:                # If we are a reader, no need to add us to pendingwriters,                # we get the upgradewriter slot.                if self.__upgradewritercount:                    # If we are a reader and want to upgrade, and someone                    # else also wants to upgrade, there is no way we can do                    # this except if one of us releases all his read locks.                    # Signal this to user.                    if timeout is not None:                        raise RuntimeError(                            ""Write lock upgrade would deadlock until timeout""                        )                    else:                        raise ValueError(""Inevitable dead lock, denying write lock"")                upgradewriter = True                self.__upgradewritercount = self.__readers.pop(me)            else:                # We aren't a reader, so add us to the pending writers queue                # for synchronization with the readers.                self.__pendingwriters.append(me)            while True:                if not self.__readers and self.__writer is None:                    # Only test anything if there are no readers and writers.                    if self.__upgradewritercount:                        if upgradewriter:                            # There is a writer to upgrade, and it's us. Take                            # the write lock.                            self.__writer = me                            self.__writercount = self.__upgradewritercount + 1                            self.__upgradewritercount = 0                            return                            # There is a writer to upgrade, but it's not us.                            # Always leave the upgrade writer the advance slot,                            # because he presumes he'll get a write lock                            # directly from a previously held read lock.                    elif self.__pendingwriters[0] is me:                        # If there are no readers and writers, it's always                        # fine for us to take the writer slot, removing us                        # from the pending writers queue.                        # This might mean starvation for readers, though.                        self.__writer = me                        self.__writercount = 1                        self.__pendingwriters = self.__pendingwriters[1:]                        return                if timeout is not None:                    remaining = endtime - time.time()                    if remaining <= 0:                        # Timeout has expired, signal caller of this.                        if upgradewriter:                            # Put us back on the reader queue. No need to                            # signal anyone of this change, because no other                            # writer could've taken our spot before we got                            # here (because of remaining readers), as the test                            # for proper conditions is at the start of the                            # loop, not at the end.                            self.__readers[me] = self.__upgradewritercount                            self.__upgradewritercount = 0                        else:                            # We were a simple pending writer, just remove us                            # from the FIFO list.                            self.__pendingwriters.remove(me)                        raise RuntimeError(""Acquiring write lock timed out"")                    self.__condition.wait(remaining)                else:                    self.__condition.wait()        finally:            self.__condition.release()","Acquire a write lock for the current thread, waiting at most timeout
seconds or doing a non-blocking check in case timeout is <= 0.

In case the write lock cannot be serviced due to the deadlock
condition mentioned above, a ValueError is raised.

In case timeout is None, the call to acquirewrite blocks until the
lock request can be serviced.

In case the timeout expires before the lock could be serviced, a
RuntimeError is thrown.","def acquirewrite(self, timeout=None):        """"""Acquire a write lock for the current thread, waiting at most timeout        seconds or doing a non-blocking check in case timeout is <= 0.        In case the write lock cannot be serviced due to the deadlock        condition mentioned above, a ValueError is raised.        In case timeout is None, the call to acquirewrite blocks until the        lock request can be serviced.        In case the timeout expires before the lock could be serviced, a        RuntimeError is thrown.        """"""        if timeout is not None:            endtime = time.time() + timeout        me, upgradewriter = current_thread(), False        self.__condition.acquire()        try:            if self.__writer is me:                # If we are the writer, grant a new write lock, always.                self.__writercount += 1                return            elif me in self.__readers:                # If we are a reader, no need to add us to pendingwriters,                # we get the upgradewriter slot.                if self.__upgradewritercount:                    # If we are a reader and want to upgrade, and someone                    # else also wants to upgrade, there is no way we can do                    # this except if one of us releases all his read locks.                    # Signal this to user.                    if timeout is not None:                        raise RuntimeError(                            ""Write lock upgrade would deadlock until timeout""                        )                    else:                        raise ValueError(""Inevitable dead lock, denying write lock"")                upgradewriter = True                self.__upgradewritercount = self.__readers.pop(me)            else:                # We aren't a reader, so add us to the pending writers queue                # for synchronization with the readers.                self.__pendingwriters.append(me)            while True:                if not self.__readers and self.__writer is None:                    # Only test anything if there are no readers and writers.                    if self.__upgradewritercount:                        if upgradewriter:                            # There is a writer to upgrade, and it's us. Take                            # the write lock.                            self.__writer = me                            self.__writercount = self.__upgradewritercount + 1                            self.__upgradewritercount = 0                            return                            # There is a writer to upgrade, but it's not us.                            # Always leave the upgrade writer the advance slot,                            # because he presumes he'll get a write lock                            # directly from a previously held read lock.                    elif self.__pendingwriters[0] is me:                        # If there are no readers and writers, it's always                        # fine for us to take the writer slot, removing us                        # from the pending writers queue.                        # This might mean starvation for readers, though.                        self.__writer = me                        self.__writercount = 1                        self.__pendingwriters = self.__pendingwriters[1:]                        return                if timeout is not None:                    remaining = endtime - time.time()                    if remaining <= 0:                        # Timeout has expired, signal caller of this.                        if upgradewriter:                            # Put us back on the reader queue. No need to                            # signal anyone of this change, because no other                            # writer could've taken our spot before we got                            # here (because of remaining readers), as the test                            # for proper conditions is at the start of the                            # loop, not at the end.                            self.__readers[me] = self.__upgradewritercount                            self.__upgradewritercount = 0                        else:                            # We were a simple pending writer, just remove us                            # from the FIFO list.                            self.__pendingwriters.remove(me)                        raise RuntimeError(""Acquiring write lock timed out"")                    self.__condition.wait(remaining)                else:                    self.__condition.wait()        finally:            self.__condition.release()

Acquire a write lock for the current thread, waiting at most timeout
seconds or doing a non-blocking check in case timeout is <= 0.

In case the write lock cannot be serviced due to the deadlock
condition mentioned above, a ValueError is raised.

In case timeout is None, the call to acquirewrite blocks until the
lock request can be serviced.

In case the timeout expires before the lock could be serviced, a
RuntimeError is thrown.",c0de8ec5-921b-4f55-913a-d86ec353d13b
struct,lock.py,release,238,269,"def release(self):                me = current_thread()        self.__condition.acquire()        try:            if self.__writer is me:                # We are the writer, take one nesting depth away.                self.__writercount -= 1                if not self.__writercount:                    # No more write locks; take our writer position away and                    # notify waiters of the new circumstances.                    self.__writer = None                    self.__condition.notifyAll()            elif me in self.__readers:                # We are a reader currently, take one nesting depth away.                self.__readers[me] -= 1                if not self.__readers[me]:                    # No more read locks, take our reader position away.                    del self.__readers[me]                    if not self.__readers:                        # No more readers, notify waiters of the new                        # circumstances.                        self.__condition.notifyAll()            else:                raise ValueError(""Trying to release unheld lock"")        finally:            self.__condition.release()","Release the currently held lock.

In case the current thread holds no lock, a ValueError is
thrown.","def release(self):        """"""Release the currently held lock.        In case the current thread holds no lock, a ValueError is        thrown.        """"""        me = current_thread()        self.__condition.acquire()        try:            if self.__writer is me:                # We are the writer, take one nesting depth away.                self.__writercount -= 1                if not self.__writercount:                    # No more write locks; take our writer position away and                    # notify waiters of the new circumstances.                    self.__writer = None                    self.__condition.notifyAll()            elif me in self.__readers:                # We are a reader currently, take one nesting depth away.                self.__readers[me] -= 1                if not self.__readers[me]:                    # No more read locks, take our reader position away.                    del self.__readers[me]                    if not self.__readers:                        # No more readers, notify waiters of the new                        # circumstances.                        self.__condition.notifyAll()            else:                raise ValueError(""Trying to release unheld lock"")        finally:            self.__condition.release()

Release the currently held lock.

In case the current thread holds no lock, a ValueError is
thrown.",68c4a6c7-b4d3-4fe9-921c-35ea40cf9bf6
struct,lock.py,__delete__,271,272,"def __delete__(self, instance):  # pragma: no cover        instance.release()",,"def __delete__(self, instance):  # pragma: no cover        instance.release()",54d29940-109d-4a9c-83f7-6f4911597f91
struct,lock.py,__init__,279,281,"def __init__(self, *args, **kwargs):        self._init_lock()        self.init(*args, **kwargs)",,"def __init__(self, *args, **kwargs):        self._init_lock()        self.init(*args, **kwargs)",130474b8-de20-429a-ba4c-90b6d681e7bd
struct,lock.py,init,283,284,"def init(self, *args, **kwargs):        pass",,"def init(self, *args, **kwargs):        pass",2e68b865-1bdd-4095-9a81-83be95b41f2b
struct,lock.py,_init_lock,286,287,def _init_lock(self):        self.lock = Lock(),,def _init_lock(self):        self.lock = Lock(),b11c477c-8f02-4bd6-8fbd-b87ca89e4214
struct,lock.py,__getattribute__,289,298,"def __getattribute__(self, name):        attr = object.__getattribute__(self, name)        if name.startswith(""_"") or not callable(attr):            return attr        @lock        def wrapper(*args, **kwargs):            return attr(*args[1:], **kwargs)        return wrapper",,"def __getattribute__(self, name):        attr = object.__getattribute__(self, name)        if name.startswith(""_"") or not callable(attr):            return attr        @lock        def wrapper(*args, **kwargs):            return attr(*args[1:], **kwargs)        return wrapper",1a5a422e-2d07-4e56-a497-9da0992601d9
struct,lock.py,_init_lock,305,306,def _init_lock(self):        self.lock = RLock(),,def _init_lock(self):        self.lock = RLock(),3204297c-d2d9-481d-9949-ab2deaf50d81
struct,lock.py,_init_lock,313,314,def _init_lock(self):        self.lock = RWLock(),,def _init_lock(self):        self.lock = RWLock(),fb0ded05-b9ba-4777-9c86-acced4682dfc
struct,style.py,set_db,8,9,"def set_db(cls, db):        cls.db = db",,"def set_db(cls, db):        cls.db = db",099cab68-b596-4052-8705-cf54c24e90f7
struct,style.py,inner,12,17,"def inner(cls, fn):        @staticmethod        def x(*args, **kwargs):            return fn(cls.db, *args, **kwargs)        return x",,"def inner(cls, fn):        @staticmethod        def x(*args, **kwargs):            return fn(cls.db, *args, **kwargs)        return x",6e351cd4-9538-4d28-9917-9442c9723abb
struct,style.py,queue,20,25,"def queue(cls, fn):        @staticmethod        def x(*args, **kwargs):            return cls.db.queue(fn, *args, **kwargs)        return x",,"def queue(cls, fn):        @staticmethod        def x(*args, **kwargs):            return cls.db.queue(fn, *args, **kwargs)        return x",58d7cc3d-f67c-4e19-ab29-7ed831d3d87e
struct,style.py,async_,28,33,"def async_(cls, fn):        @staticmethod        def x(*args, **kwargs):            return cls.db.async_(fn, *args, **kwargs)        return x",,"def async_(cls, fn):        @staticmethod        def x(*args, **kwargs):            return cls.db.async_(fn, *args, **kwargs)        return x",e4ab1069-52a4-49de-be0f-c184d4f50da3
web,format.py,url,13,31,"def url(value):    url = urllib.parse.unquote(to_str(value))    #: Translate 'unicode-escape' escapes    url = re.sub(_RE_UNICODE_ESCAPE, lambda x: chr(int(x.group(1), 16)), url)    #: Removes HTML tags and translate HTML escape characters    url = purge.text(url)    #: Decode RFC2047 email message header    url = purge.rfc2047(url)    #: Remove redundant '/'    url = _RE_DOUBLE_SLASH.sub(""/"", url)    #: Final cleanup    url = url.lstrip(""."").rstrip(""/"")    return url",,"def url(value):    url = urllib.parse.unquote(to_str(value))    #: Translate 'unicode-escape' escapes    url = re.sub(_RE_UNICODE_ESCAPE, lambda x: chr(int(x.group(1), 16)), url)    #: Removes HTML tags and translate HTML escape characters    url = purge.text(url)    #: Decode RFC2047 email message header    url = purge.rfc2047(url)    #: Remove redundant '/'    url = _RE_DOUBLE_SLASH.sub(""/"", url)    #: Final cleanup    url = url.lstrip(""."").rstrip(""/"")    return url",732f7b84-35a6-409f-a4fe-796c4ee06e23
web,misc.py,get_ip,8,9,def get_ip():    return socket.gethostbyname(socket.getfqdn()),,def get_ip():    return socket.gethostbyname(socket.getfqdn()),5cca34b3-b8f6-4e32-92ec-38ea0cc0c0ba
web,parse.py,name,109,122,"def name(url, safe_name=True):    url = format.url(url)    up = urllib.parse.urlparse(url)    name = up.path.split(""/"")[-1]    if not name:        name = up.query.split(""="", 1)[::-1][0].split(""&"", 1)[0]    if not name and up.fragment:        name = ""#"" + up.fragment    elif name and up.fragment:        name += ""#"" + up.fragment    if not name:        name = up.netloc.split(""."", 1)[0]    return safe_nm(name) if safe_name else name",,"def name(url, safe_name=True):    url = format.url(url)    up = urllib.parse.urlparse(url)    name = up.path.split(""/"")[-1]    if not name:        name = up.query.split(""="", 1)[::-1][0].split(""&"", 1)[0]    if not name and up.fragment:        name = ""#"" + up.fragment    elif name and up.fragment:        name += ""#"" + up.fragment    if not name:        name = up.netloc.split(""."", 1)[0]    return safe_nm(name) if safe_name else name",c642244a-e407-4517-ba8c-fbac41e52f60
web,purge.py,comments,12,14,"def comments(value):        return _RE_COMMENTS.sub("""", value).strip()",Removes HTML comments from a text string.,"def comments(value):    """"""Removes HTML comments from a text string.""""""    return _RE_COMMENTS.sub("""", value).strip()

Removes HTML comments from a text string.",b155249d-ba2f-4568-a184-2bc7fa12f849
web,purge.py,unescape,17,19,def unescape(value):        return html.unescape(value),Translates HTML or XML escape character references and entities from a text string.,"def unescape(value):    """"""Translates HTML or XML escape character references and entities from a text string.""""""    return html.unescape(value)

Translates HTML or XML escape character references and entities from a text string.",539567e6-f50d-4f92-97a3-a2cb0eb3b820
web,purge.py,tags,22,24,"def tags(value):        return _RE_TAGS.sub("""", value).strip()",Removes HTML tags from a text string.,"def tags(value):    """"""Removes HTML tags from a text string.""""""    return _RE_TAGS.sub("""", value).strip()

Removes HTML tags from a text string.",53134460-61cc-4af7-9c8f-05ff0b77688b
web,purge.py,rfc2047,27,38,"def rfc2047(value):        def decode_chunk(m):        data, encoding = decode_rfc2047_header(m.group(0))[0]        try:            res = data.decode(encoding)        except (LookupError, UnicodeEncodeError):            res = m.group(0)        return res    return _RE_RFC2047.sub(decode_chunk, value, re.I)",Decodes RFC2047 email message header value,"def rfc2047(value):    """"""Decodes RFC2047 email message header value""""""    def decode_chunk(m):        data, encoding = decode_rfc2047_header(m.group(0))[0]        try:            res = data.decode(encoding)        except (LookupError, UnicodeEncodeError):            res = m.group(0)        return res    return _RE_RFC2047.sub(decode_chunk, value, re.I)

Decodes RFC2047 email message header value",b8cb3f98-fdb0-4c78-92a6-0c172a38017a
web,purge.py,text,41,43,"def text(value):        return tags(unescape(value)).strip(""'\"" "")","Removes HTML tags, translate HTML escape characters and removes surrounding quotation marks","def text(value):    """"""Removes HTML tags, translate HTML escape characters and removes surrounding quotation marks""""""    return tags(unescape(value)).strip(""'\"" "")

Removes HTML tags, translate HTML escape characters and removes surrounding quotation marks",971c7941-dd3c-44b2-9dcf-1434f63095f8
plugins,helpers.py,__init__,25,26,"def __init__(self, plugin):        self.plugin = plugin",,"def __init__(self, plugin):        self.plugin = plugin",1b1c4cdc-449e-4289-a773-5de01f7ca948
plugins,helpers.py,set,28,38,"def set(self, option, value, plugin=None):                self.plugin.pyload.api.set_config_value(            plugin or self.plugin.classname, option, value, section=""plugin""        )","Set config value for current plugin.

:param option:
:param value:
:return:","def set(self, option, value, plugin=None):        """"""        Set config value for current plugin.        :param option:        :param value:        :return:        """"""        self.plugin.pyload.api.set_config_value(            plugin or self.plugin.classname, option, value, section=""plugin""        )

Set config value for current plugin.

:param option:
:param value:
:return:",1eec0602-5233-4b3e-8a9a-76028815e972
plugins,helpers.py,get,40,56,"def get(self, option, default=None, plugin=None):                try:            return self.plugin.pyload.config.get_plugin(                plugin or self.plugin.classname, option            )        except KeyError:            self.plugin.log_debug(                ""Config option `{}` not found, use default `{}`"".format(option, default)            )  # TODO: Restore to `log_warning` in 0.6.x            return default","Returns config value for current plugin.

:param option:
:return:","def get(self, option, default=None, plugin=None):        """"""        Returns config value for current plugin.        :param option:        :return:        """"""        try:            return self.plugin.pyload.config.get_plugin(                plugin or self.plugin.classname, option            )        except KeyError:            self.plugin.log_debug(                ""Config option `{}` not found, use default `{}`"".format(option, default)            )  # TODO: Restore to `log_warning` in 0.6.x            return default

Returns config value for current plugin.

:param option:
:return:",50267d32-a47f-4e24-8026-dfdd6f473129
plugins,helpers.py,__init__,60,61,"def __init__(self, plugin):        self.plugin = plugin",,"def __init__(self, plugin):        self.plugin = plugin",ac8e14cd-ae23-4a25-bde0-788babd2466e
plugins,helpers.py,store,63,69,"def store(self, key, value):                # NOTE: value must not be <bytes> otherwise BOOM! and moreover our sqlite db always return strings as <str>        entry = b85encode(json.dumps(value, ensure_ascii=False).encode()).decode()        self.plugin.pyload.db.set_storage(self.plugin.classname, key, entry)",Saves a value persistently to the database.,"def store(self, key, value):        """"""        Saves a value persistently to the database.        """"""        # NOTE: value must not be <bytes> otherwise BOOM! and moreover our sqlite db always return strings as <str>        entry = b85encode(json.dumps(value, ensure_ascii=False).encode()).decode()        self.plugin.pyload.db.set_storage(self.plugin.classname, key, entry)

Saves a value persistently to the database.",f1935da3-9ef5-44e1-80e2-27c4b977b68d
plugins,helpers.py,retrieve,71,88,"def retrieve(self, key=None, default=None):                entry = self.plugin.pyload.db.get_storage(self.plugin.classname, key)        if key:            if entry is None:                value = default            else:                value = json.loads(b85decode(entry).decode())        else:            if not entry:                value = default            else:                value = {k: json.loads(b85decode(v).decode()) for k, v in entry.items()}        return value",Retrieves saved value or dict of all saved entries if key is None.,"def retrieve(self, key=None, default=None):        """"""        Retrieves saved value or dict of all saved entries if key is None.        """"""        entry = self.plugin.pyload.db.get_storage(self.plugin.classname, key)        if key:            if entry is None:                value = default            else:                value = json.loads(b85decode(entry).decode())        else:            if not entry:                value = default            else:                value = {k: json.loads(b85decode(v).decode()) for k, v in entry.items()}        return value

Retrieves saved value or dict of all saved entries if key is None.",c482bcdd-ef9f-45d2-b2a8-394503967411
plugins,helpers.py,delete,90,94,"def delete(self, key):                self.plugin.pyload.db.del_storage(self.plugin.classname, key)",Delete entry in db.,"def delete(self, key):        """"""        Delete entry in db.        """"""        self.plugin.pyload.db.del_storage(self.plugin.classname, key)

Delete entry in db.",4fcab8bd-4b11-46af-a512-1593fba38ca6
plugins,helpers.py,__init__,98,103,"def __init__(self, plugin, task=lambda x: x, interval=None):        self.plugin = plugin        self.task = task        self.cb = None        self._ = self.plugin.pyload        self.interval = interval",,"def __init__(self, plugin, task=lambda x: x, interval=None):        self.plugin = plugin        self.task = task        self.cb = None        self._ = self.plugin.pyload        self.interval = interval",42dcb1a3-d7be-4304-b25b-0262c94b3b71
plugins,helpers.py,set_interval,105,114,"def set_interval(self, value):        newinterval = max(0, value)        if newinterval != value:            return False        if newinterval != self.interval:            self.interval = newinterval        return True",,"def set_interval(self, value):        newinterval = max(0, value)        if newinterval != value:            return False        if newinterval != self.interval:            self.interval = newinterval        return True",db438e4f-d660-4735-aef0-bbe004a367fe
plugins,helpers.py,start,116,123,"def start(self, interval=None, threaded=False, delay=0):        if interval is not None and self.set_interval(interval) is False:            return False        else:            self.cb = self.plugin.pyload.scheduler.add_job(                max(1, delay), self._task, [threaded], threaded=threaded            )            return True",,"def start(self, interval=None, threaded=False, delay=0):        if interval is not None and self.set_interval(interval) is False:            return False        else:            self.cb = self.plugin.pyload.scheduler.add_job(                max(1, delay), self._task, [threaded], threaded=threaded            )            return True",7fb39031-d298-4f3c-83cb-f573493ab826
plugins,helpers.py,restart,125,127,"def restart(self, *args, **kwargs):        self.stop()        return self.start(*args, **kwargs)",,"def restart(self, *args, **kwargs):        self.stop()        return self.start(*args, **kwargs)",4cb335c7-fd1b-49fc-afe6-a10e82dae705
plugins,helpers.py,stop,129,137,def stop(self):        try:            return self.plugin.pyload.scheduler.remove_job(self.cb)        except Exception:            return False        finally:            self.cb = None,,def stop(self):        try:            return self.plugin.pyload.scheduler.remove_job(self.cb)        except Exception:            return False        finally:            self.cb = None,13879d4c-9ca8-4ab6-a377-054b5e9e29fc
plugins,helpers.py,_task,141,149,"def _task(self, threaded):        try:            self.task()        except Exception as exc:            self.plugin.log_error(self._(""Error performing periodical task""), exc)        if not self.stopped:            self.restart(threaded=threaded, delay=self.interval)",,"def _task(self, threaded):        try:            self.task()        except Exception as exc:            self.plugin.log_error(self._(""Error performing periodical task""), exc)        if not self.stopped:            self.restart(threaded=threaded, delay=self.interval)",d743b56a-5d3a-48cf-98c1-64a05b18a66d
plugins,helpers.py,__init__,153,155,"def __init__(self, plugin, storage=""queue""):        self.plugin = plugin        self.storage = storage",,"def __init__(self, plugin, storage=""queue""):        self.plugin = plugin        self.storage = storage",5e9a2e47-089d-4004-8f5f-390d6013ea3d
plugins,helpers.py,get,157,158,"def get(self):        return self.plugin.db.retrieve(self.storage, default=[])",,"def get(self):        return self.plugin.db.retrieve(self.storage, default=[])",fa07e960-c468-4743-b016-94b7ea76f706
plugins,helpers.py,set,160,161,"def set(self, value):        return self.plugin.db.store(self.storage, value)",,"def set(self, value):        return self.plugin.db.store(self.storage, value)",7326899d-7a0e-4374-9e5a-960b6287b300
plugins,helpers.py,delete,163,164,def delete(self):        return self.plugin.db.delete(self.storage),,def delete(self):        return self.plugin.db.delete(self.storage),70556055-3839-480e-8647-9d7b82021be8
plugins,helpers.py,add,166,171,"def add(self, item):        queue = self.get()        if item not in queue:            return self.set(queue + [item])        else:            return True",,"def add(self, item):        queue = self.get()        if item not in queue:            return self.set(queue + [item])        else:            return True",15063252-7396-4f2e-b324-33f27e007e5e
plugins,helpers.py,remove,173,184,"def remove(self, item):        queue = self.get()        try:            queue.remove(item)        except ValueError:            pass        if isinstance(queue, list):            return self.delete()        return self.set(queue)",,"def remove(self, item):        queue = self.get()        try:            queue.remove(item)        except ValueError:            pass        if isinstance(queue, list):            return self.delete()        return self.set(queue)",3f10fca3-a4d9-4c00-a3a1-8a061f12c880
plugins,helpers.py,sign_string,187,206,"def sign_string(message, pem_private, pem_passphrase="""", sign_algo=""SHA384""):        from Cryptodome.PublicKey import RSA    from Cryptodome.Signature import PKCS1_v1_5    from binascii import b2a_hex    if sign_algo not in (""MD5"", ""SHA1"", ""SHA256"", ""SHA384"", ""SHA512""):        raise ValueError(""Unsupported Signing algorithm"")    message = to_bytes(message)    priv_key = RSA.import_key(pem_private, passphrase=pem_passphrase)    signer = PKCS1_v1_5.new(priv_key)    digest = getattr(        __import__(""Cryptodome.Hash"", fromlist=[sign_algo]), sign_algo    ).new()    digest.update(message)    return b2a_hex(signer.sign(digest))",Generate a signature for string using the `sign_algo` and `RSA` algorithms.,"def sign_string(message, pem_private, pem_passphrase="""", sign_algo=""SHA384""):    """"""    Generate a signature for string using the `sign_algo` and `RSA` algorithms.    """"""    from Cryptodome.PublicKey import RSA    from Cryptodome.Signature import PKCS1_v1_5    from binascii import b2a_hex    if sign_algo not in (""MD5"", ""SHA1"", ""SHA256"", ""SHA384"", ""SHA512""):        raise ValueError(""Unsupported Signing algorithm"")    message = to_bytes(message)    priv_key = RSA.import_key(pem_private, passphrase=pem_passphrase)    signer = PKCS1_v1_5.new(priv_key)    digest = getattr(        __import__(""Cryptodome.Hash"", fromlist=[sign_algo]), sign_algo    ).new()    digest.update(message)    return b2a_hex(signer.sign(digest))

Generate a signature for string using the `sign_algo` and `RSA` algorithms.",c7f0b528-7125-4f7b-8b8c-9ed05ba8d609
plugins,helpers.py,fsbsize,209,231,"def fsbsize(path):        path = os.fsdecode(path)    if os.name == ""nt"":        import ctypes        drive = ""{}\\"".format(os.path.splitdrive(path)[0])        cluster_sectors, sector_size = ctypes.c_longlong(0)        ctypes.windll.kernel32.GetDiskFreeSpaceW(            ctypes.c_wchar_p(drive),            ctypes.pointer(cluster_sectors),            ctypes.pointer(sector_size),            None,            None,        )        return cluster_sectors * sector_size    else:        return os.statvfs(path).f_frsize",Get optimal file system buffer size (in bytes) for I/O calls.,"def fsbsize(path):    """"""    Get optimal file system buffer size (in bytes) for I/O calls.    """"""    path = os.fsdecode(path)    if os.name == ""nt"":        import ctypes        drive = ""{}\\"".format(os.path.splitdrive(path)[0])        cluster_sectors, sector_size = ctypes.c_longlong(0)        ctypes.windll.kernel32.GetDiskFreeSpaceW(            ctypes.c_wchar_p(drive),            ctypes.pointer(cluster_sectors),            ctypes.pointer(sector_size),            None,            None,        )        return cluster_sectors * sector_size    else:        return os.statvfs(path).f_frsize

Get optimal file system buffer size (in bytes) for I/O calls.",5d8e3945-79dc-468b-a89a-a0d1f21b9686
plugins,helpers.py,get_console_encoding,234,242,"def get_console_encoding(enc):    if os.name == ""nt"":        if enc == ""cp65001"":  #: aka UTF-8            enc = ""cp850""            # print(""WARNING: Windows codepage 65001 (UTF-8) is not supported, used `{}` instead"".format(enc))    else:        enc = ""utf-8""    return enc",,"def get_console_encoding(enc):    if os.name == ""nt"":        if enc == ""cp65001"":  #: aka UTF-8            enc = ""cp850""            # print(""WARNING: Windows codepage 65001 (UTF-8) is not supported, used `{}` instead"".format(enc))    else:        enc = ""utf-8""    return enc",ca47961d-29d4-4106-b401-ebd9e43778f0
plugins,helpers.py,exists,245,256,"def exists(path):    path = os.fsdecode(path)    if os.path.exists(path):        if os.name == ""nt"":            dir, name = os.path.split(path.rstrip(os.sep))            name_lw = name.lower()            return any(True for entry in os.listdir(dir) if entry.lower() == name_lw)        else:            return True    else:        return False",,"def exists(path):    path = os.fsdecode(path)    if os.path.exists(path):        if os.name == ""nt"":            dir, name = os.path.split(path.rstrip(os.sep))            name_lw = name.lower()            return any(True for entry in os.listdir(dir) if entry.lower() == name_lw)        else:            return True    else:        return False",f4d7ae95-3e7e-4e8d-ac91-d2977cb9060e
plugins,helpers.py,str2int,259,309,"def str2int(value):    try:        return int(value)    except Exception:        pass    ones = (        ""zero"",        ""one"",        ""two"",        ""three"",        ""four"",        ""five"",        ""six"",        ""seven"",        ""eight"",        ""nine"",        ""ten"",        ""eleven"",        ""twelve"",        ""thirteen"",        ""fourteen"",        ""fifteen"",        ""sixteen"",        ""seventeen"",        ""eighteen"",        ""nineteen"",    )    tens = (        """",        """",        ""twenty"",        ""thirty"",        ""forty"",        ""fifty"",        ""sixty"",        ""seventy"",        ""eighty"",        ""ninety"",    )    o_tuple = [(w, i) for i, w in enumerate(ones)]    t_tuple = [(w, i * 10) for i, w in enumerate(tens)]    numwords = dict(o_tuple + t_tuple)    tokens = re.split(r""[\s\-]+"", value.lower())    try:        return sum(numwords[word] for word in tokens)    except Exception:        return 0",,"def str2int(value):    try:        return int(value)    except Exception:        pass    ones = (        ""zero"",        ""one"",        ""two"",        ""three"",        ""four"",        ""five"",        ""six"",        ""seven"",        ""eight"",        ""nine"",        ""ten"",        ""eleven"",        ""twelve"",        ""thirteen"",        ""fourteen"",        ""fifteen"",        ""sixteen"",        ""seventeen"",        ""eighteen"",        ""nineteen"",    )    tens = (        """",        """",        ""twenty"",        ""thirty"",        ""forty"",        ""fifty"",        ""sixty"",        ""seventy"",        ""eighty"",        ""ninety"",    )    o_tuple = [(w, i) for i, w in enumerate(ones)]    t_tuple = [(w, i * 10) for i, w in enumerate(tens)]    numwords = dict(o_tuple + t_tuple)    tokens = re.split(r""[\s\-]+"", value.lower())    try:        return sum(numwords[word] for word in tokens)    except Exception:        return 0",6c62f78e-e4ad-4b8c-a97b-3222fb33ba9f
plugins,helpers.py,timestamp,312,313,def timestamp():    return int(time.time() * 1000),,def timestamp():    return int(time.time() * 1000),f940be43-64e2-4663-9c24-89fde4159f84
plugins,helpers.py,check_module,316,324,def check_module(module):    try:        __import__(module)    except Exception:        return False    else:        return True,,def check_module(module):    try:        __import__(module)    except Exception:        return False    else:        return True,f696d7c5-a960-4296-af37-859057331984
plugins,helpers.py,check_prog,327,336,"def check_prog(command):    pipe = subprocess.PIPE    try:        subprocess.call(command, stdout=pipe, stderr=pipe)    except Exception:        return False    else:        return True",,"def check_prog(command):    pipe = subprocess.PIPE    try:        subprocess.call(command, stdout=pipe, stderr=pipe)    except Exception:        return False    else:        return True",d28225df-86f6-4415-a2ea-f6b58730b064
plugins,helpers.py,is_executable,339,341,"def is_executable(filename):    file = os.fsdecode(filename)    return os.path.isfile(file) and os.access(file, os.X_OK)",,"def is_executable(filename):    file = os.fsdecode(filename)    return os.path.isfile(file) and os.access(file, os.X_OK)",f0dd4a54-7930-4694-ac06-ec202b08af6f
plugins,helpers.py,which,344,358,"def which(filename):        dirname, basename = os.path.split(filename)    if dirname:        return filename if is_executable(filename) else None    else:        for path in os.environ[""PATH""].split(os.pathsep):            filename = os.path.join(path.strip('""'), filename)            if is_executable(filename):                return filename","Works exactly like the unix command which Courtesy of
http://stackoverflow.com/a/377028/675646.","def which(filename):    """"""    Works exactly like the unix command which Courtesy of    http://stackoverflow.com/a/377028/675646.    """"""    dirname, basename = os.path.split(filename)    if dirname:        return filename if is_executable(filename) else None    else:        for path in os.environ[""PATH""].split(os.pathsep):            filename = os.path.join(path.strip('""'), filename)            if is_executable(filename):                return filename

Works exactly like the unix command which Courtesy of
http://stackoverflow.com/a/377028/675646.",69944532-cb12-491f-92f7-8380ac94c209
plugins,helpers.py,format_exc,361,386,"def format_exc(frame=None):        exc_info = sys.exc_info()    exc_desc = """"    callstack = traceback.extract_stack(frame)    callstack = callstack[:-1]    if exc_info[0] is not None:        exception_callstack = traceback.extract_tb(exc_info[2])        # NOTE: Does this exception belongs to us?        if callstack[-1][0] == exception_callstack[0][0]:            callstack = callstack[:-1]            callstack.extend(exception_callstack)            exc_desc = """".join(                traceback.format_exception_only(exc_info[0], exc_info[1])            )    msg = ""Traceback (most recent call last):\n""    msg += """".join(traceback.format_list(callstack))    msg += exc_desc    return msg",Format call-stack and display exception information (if availible),"def format_exc(frame=None):    """"""    Format call-stack and display exception information (if availible)    """"""    exc_info = sys.exc_info()    exc_desc = """"    callstack = traceback.extract_stack(frame)    callstack = callstack[:-1]    if exc_info[0] is not None:        exception_callstack = traceback.extract_tb(exc_info[2])        # NOTE: Does this exception belongs to us?        if callstack[-1][0] == exception_callstack[0][0]:            callstack = callstack[:-1]            callstack.extend(exception_callstack)            exc_desc = """".join(                traceback.format_exception_only(exc_info[0], exc_info[1])            )    msg = ""Traceback (most recent call last):\n""    msg += """".join(traceback.format_list(callstack))    msg += exc_desc    return msg

Format call-stack and display exception information (if availible)",4b93daba-0424-4423-a14c-88054f540fcb
plugins,helpers.py,search_pattern,389,403,"def search_pattern(pattern, value, flags=0):    try:        pattern, reflags = pattern    except ValueError:        reflags = 0    except TypeError:        return None    try:        return re.search(pattern, value, reflags | flags)    except TypeError:        return None",,"def search_pattern(pattern, value, flags=0):    try:        pattern, reflags = pattern    except ValueError:        reflags = 0    except TypeError:        return None    try:        return re.search(pattern, value, reflags | flags)    except TypeError:        return None",8544cbd1-2ba1-4e42-b83c-0162a4451be2
plugins,helpers.py,replace_patterns,406,417,"def replace_patterns(value, rules):    for r in rules:        try:            pattern, repl, flags = r        except ValueError:            pattern, repl = r            flags = 0        value = re.sub(pattern, repl, value, flags)    return value",,"def replace_patterns(value, rules):    for r in rules:        try:            pattern, repl, flags = r        except ValueError:            pattern, repl = r            flags = 0        value = re.sub(pattern, repl, value, flags)    return value",c2baf909-fc1c-46cd-8f53-bf3e6536be59
plugins,helpers.py,set_cookie,421,425,"def set_cookie(    cj, domain, name, value, path=""/"", exp=time.time() + timedelta(days=31).total_seconds()):  #: 31 days retention    args = [domain, name, value, path, int(exp)]    return cj.set_cookie(*args)",,"def set_cookie(    cj, domain, name, value, path=""/"", exp=time.time() + timedelta(days=31).total_seconds()):  #: 31 days retention    args = [domain, name, value, path, int(exp)]    return cj.set_cookie(*args)",09f944d6-5a43-4cfd-9bad-ea4e67e6b3bd
plugins,helpers.py,set_cookies,428,436,"def set_cookies(cj, cookies):    for cookie in cookies:        if not isinstance(cookie, tuple):            continue        if len(cookie) != 3:            continue        set_cookie(cj, *cookie)",,"def set_cookies(cj, cookies):    for cookie in cookies:        if not isinstance(cookie, tuple):            continue        if len(cookie) != 3:            continue        set_cookie(cj, *cookie)",c448ba32-6560-4d04-a604-a310c0daf883
plugins,helpers.py,parse_html_header,439,456,"def parse_html_header(header):    header = to_str(header, encoding=""iso-8859-1"")    hdict = {}    _re = r""[ ]*(?P<key>.+?)[ ]*:[ ]*(?P<value>.+?)[ ]*\r?\n""    for key, value in re.findall(_re, header):        key = key.lower()        if key in hdict:            current_value = hdict.get(key)            if isinstance(current_value, list):                current_value.append(value)            else:                hdict[key] = [current_value, value]        else:            hdict[key] = value    return hdict",,"def parse_html_header(header):    header = to_str(header, encoding=""iso-8859-1"")    hdict = {}    _re = r""[ ]*(?P<key>.+?)[ ]*:[ ]*(?P<value>.+?)[ ]*\r?\n""    for key, value in re.findall(_re, header):        key = key.lower()        if key in hdict:            current_value = hdict.get(key)            if isinstance(current_value, list):                current_value.append(value)            else:                hdict[key] = [current_value, value]        else:            hdict[key] = value    return hdict",01478c83-0d07-44ee-9d4e-0f8e43a35819
plugins,helpers.py,parse_html_tag_attr_value,459,467,"def parse_html_tag_attr_value(attr_name, tag):    m = re.search(        r'{}\s*=\s*([""\']?)((?<="")[^""]+|(?<=\')[^\']+|[^>\s""\'][^>\s]*)\1'.format(            attr_name        ),        tag,        re.I,    )    return m.group(2) if m else None",,"def parse_html_tag_attr_value(attr_name, tag):    m = re.search(        r'{}\s*=\s*([""\']?)((?<="")[^""]+|(?<=\')[^\']+|[^>\s""\'][^>\s]*)\1'.format(            attr_name        ),        tag,        re.I,    )    return m.group(2) if m else None",95a40b1b-1f6d-4cfa-b5fa-1984f0ea8821
plugins,helpers.py,parse_html_form,470,517,"def parse_html_form(attr_filter, html, input_names={}):    attr_str = """" if callable(attr_filter) else attr_filter    for form in re.finditer(        rf""(?P<TAG><form[^>]*{attr_str}.*?>)(?P<CONTENT>.*?)</?(form|body|html).*?>"",        html,        re.I | re.S,    ):        if callable(attr_filter) and not attr_filter(form.group('TAG')):            continue        inputs = {}        action = parse_html_tag_attr_value(""action"", form.group(""TAG""))        for inputtag in re.finditer(            r""(<(input|textarea).*?>)([^<]*(?=</\2)|)"",            re.sub(re.compile(r""<!--.+?-->"", re.I | re.S), """", form.group(""CONTENT"")),            re.I | re.S,        ):            name = parse_html_tag_attr_value(""name"", inputtag.group(1))            if name:                value = parse_html_tag_attr_value(""value"", inputtag.group(1))                if not value:                    inputs[name] = inputtag.group(3) or """"                else:                    inputs[name] = value        if not input_names:            #: No attribute check            return action, inputs        else:            #: Check input attributes            for key, value in input_names.items():                if key in inputs:                    if isinstance(value, str) and inputs[key] == value:                        continue                    elif isinstance(value, tuple) and inputs[key] in value:                        continue                    elif hasattr(value, ""search"") and re.match(value, inputs[key]):                        continue                    else:                        break  #: Attibute value does not match                else:                    break  #: Attibute name does not match            else:                return action, inputs  #: Passed attribute check    return None, None",,"def parse_html_form(attr_filter, html, input_names={}):    attr_str = """" if callable(attr_filter) else attr_filter    for form in re.finditer(        rf""(?P<TAG><form[^>]*{attr_str}.*?>)(?P<CONTENT>.*?)</?(form|body|html).*?>"",        html,        re.I | re.S,    ):        if callable(attr_filter) and not attr_filter(form.group('TAG')):            continue        inputs = {}        action = parse_html_tag_attr_value(""action"", form.group(""TAG""))        for inputtag in re.finditer(            r""(<(input|textarea).*?>)([^<]*(?=</\2)|)"",            re.sub(re.compile(r""<!--.+?-->"", re.I | re.S), """", form.group(""CONTENT"")),            re.I | re.S,        ):            name = parse_html_tag_attr_value(""name"", inputtag.group(1))            if name:                value = parse_html_tag_attr_value(""value"", inputtag.group(1))                if not value:                    inputs[name] = inputtag.group(3) or """"                else:                    inputs[name] = value        if not input_names:            #: No attribute check            return action, inputs        else:            #: Check input attributes            for key, value in input_names.items():                if key in inputs:                    if isinstance(value, str) and inputs[key] == value:                        continue                    elif isinstance(value, tuple) and inputs[key] in value:                        continue                    elif hasattr(value, ""search"") and re.match(value, inputs[key]):                        continue                    else:                        break  #: Attibute value does not match                else:                    break  #: Attibute name does not match            else:                return action, inputs  #: Passed attribute check    return None, None",c741e7d6-ce18-42cf-8733-2c18ce156f33
plugins,helpers.py,chunks,520,525,"def chunks(iterable, size):    it = iter(iterable)    item = list(itertools.islice(it, size))    while item:        yield item        item = list(itertools.islice(it, size))",,"def chunks(iterable, size):    it = iter(iterable)    item = list(itertools.islice(it, size))    while item:        yield item        item = list(itertools.islice(it, size))",0c3159ff-4edc-461d-9d82-28d16e703c1f
plugins,helpers.py,renice,528,535,"def renice(pid, value):    if not value or os.name == ""nt"":        return    try:        subprocess.run([""renice"", str(value), str(pid)])    except Exception:        pass",,"def renice(pid, value):    if not value or os.name == ""nt"":        return    try:        subprocess.run([""renice"", str(value), str(pid)])    except Exception:        pass",f2f9a1d7-96d7-4b65-83cf-4f7bb24bee8c
plugins,helpers.py,forward,538,556,"def forward(source, destination, recv_timeout=None, buffering=1024):        timeout = source.gettimeout()    source.settimeout(recv_timeout)    try:        raw_data = source.recv(buffering)    except socket.timeout:        pass    else:        while raw_data:            destination.sendall(raw_data)            try:                raw_data = source.recv(buffering)            except socket.timeout:                break    source.settimeout(timeout)",Forward data from one socket to another,"def forward(source, destination, recv_timeout=None, buffering=1024):    """"""    Forward data from one socket to another    """"""    timeout = source.gettimeout()    source.settimeout(recv_timeout)    try:        raw_data = source.recv(buffering)    except socket.timeout:        pass    else:        while raw_data:            destination.sendall(raw_data)            try:                raw_data = source.recv(buffering)            except socket.timeout:                break    source.settimeout(timeout)

Forward data from one socket to another",8c8ed8b2-380c-46a5-98e4-3b5cfc129c0b
plugins,helpers.py,compute_checksum,559,587,"def compute_checksum(filename, hashtype):    file = os.fsdecode(filename)    if not exists(file):        return None    buf = fsbsize(filename)    if hashtype in (""adler32"", ""crc32""):        hf = getattr(zlib, hashtype)        last = 0        with open(file, mode=""rb"") as fp:            for chunk in iter(lambda: fp.read(buf), """"):                last = hf(chunk, last)        return ""{:x}"".format(last)    elif hashtype in hashlib.algorithms_available:        h = hashlib.new(hashtype)        with open(file, mode=""rb"") as fp:            for chunk in iter(lambda: fp.read(buf * h.block_size), """"):                h.update(chunk)        return h.hexdigest()    else:        return None",,"def compute_checksum(filename, hashtype):    file = os.fsdecode(filename)    if not exists(file):        return None    buf = fsbsize(filename)    if hashtype in (""adler32"", ""crc32""):        hf = getattr(zlib, hashtype)        last = 0        with open(file, mode=""rb"") as fp:            for chunk in iter(lambda: fp.read(buf), """"):                last = hf(chunk, last)        return ""{:x}"".format(last)    elif hashtype in hashlib.algorithms_available:        h = hashlib.new(hashtype)        with open(file, mode=""rb"") as fp:            for chunk in iter(lambda: fp.read(buf * h.block_size), """"):                h.update(chunk)        return h.hexdigest()    else:        return None",aa56845c-9791-4747-926e-3e41431e91c5
plugins,helpers.py,copy_tree,590,620,"def copy_tree(src, dst, overwrite=False, preserve_metadata=False):    pmode = preserve_metadata or overwrite is None    mtime = os.path.getmtime    copy = shutil.copy2 if pmode else shutil.copy    if preserve_metadata and not exists(dst):        return shutil.copytree(src, dst)    for src_dir, dirs, files in os.walk(src, topdown=False):        dst_dir = src_dir.replace(src, dst, 1)        if not exists(dst_dir):            os.makedirs(dst_dir)            if pmode:                shutil.copystat(src_dir, dst_dir)        elif pmode:            if overwrite or overwrite is None and mtime(src_dir) > mtime(dst_dir):                shutil.copystat(src_dir, dst_dir)        for filename in files:            src_file = os.path.join(src_dir, filename)            dst_file = os.path.join(dst_dir, filename)            if exists(dst_file):                if overwrite or overwrite is None and mtime(src_file) > mtime(dst_file):                    os.remove(dst_file)                else:                    continue            copy(src_file, dst_dir)",,"def copy_tree(src, dst, overwrite=False, preserve_metadata=False):    pmode = preserve_metadata or overwrite is None    mtime = os.path.getmtime    copy = shutil.copy2 if pmode else shutil.copy    if preserve_metadata and not exists(dst):        return shutil.copytree(src, dst)    for src_dir, dirs, files in os.walk(src, topdown=False):        dst_dir = src_dir.replace(src, dst, 1)        if not exists(dst_dir):            os.makedirs(dst_dir)            if pmode:                shutil.copystat(src_dir, dst_dir)        elif pmode:            if overwrite or overwrite is None and mtime(src_dir) > mtime(dst_dir):                shutil.copystat(src_dir, dst_dir)        for filename in files:            src_file = os.path.join(src_dir, filename)            dst_file = os.path.join(dst_dir, filename)            if exists(dst_file):                if overwrite or overwrite is None and mtime(src_file) > mtime(dst_file):                    os.remove(dst_file)                else:                    continue            copy(src_file, dst_dir)",259ba261-347f-49e7-b55d-6d8e764bc04e
plugins,helpers.py,move_tree,623,658,"def move_tree(src, dst, overwrite=False):    mtime = os.path.getmtime    for src_dir, dirs, files in os.walk(src, topdown=False):        dst_dir = src_dir.replace(src, dst, 1)        del_dir = True        if not exists(dst_dir):            os.makedirs(dst_dir)            shutil.copystat(src_dir, dst_dir)        elif overwrite or overwrite is None and mtime(src_dir) > mtime(dst_dir):            shutil.copystat(src_dir, dst_dir)        else:            del_dir = False        for filename in files:            src_file = os.path.join(src_dir, filename)            dst_file = os.path.join(dst_dir, filename)            if exists(dst_file):                if overwrite or overwrite is None and mtime(src_file) > mtime(dst_file):                    os.remove(dst_file)                else:                    continue            shutil.move(src_file, dst_dir)        if not del_dir:            continue        try:            os.rmdir(src_dir)        except OSError:            pass",,"def move_tree(src, dst, overwrite=False):    mtime = os.path.getmtime    for src_dir, dirs, files in os.walk(src, topdown=False):        dst_dir = src_dir.replace(src, dst, 1)        del_dir = True        if not exists(dst_dir):            os.makedirs(dst_dir)            shutil.copystat(src_dir, dst_dir)        elif overwrite or overwrite is None and mtime(src_dir) > mtime(dst_dir):            shutil.copystat(src_dir, dst_dir)        else:            del_dir = False        for filename in files:            src_file = os.path.join(src_dir, filename)            dst_file = os.path.join(dst_dir, filename)            if exists(dst_file):                if overwrite or overwrite is None and mtime(src_file) > mtime(dst_file):                    os.remove(dst_file)                else:                    continue            shutil.move(src_file, dst_dir)        if not del_dir:            continue        try:            os.rmdir(src_dir)        except OSError:            pass",25f34067-4c72-4208-be0b-782d2216e1ee
plugins,helpers.py,ttl_cache,661,677,"def ttl_cache(maxsize=128, typed=False, ttl=-1):        if ttl <= 0:        ttl = 65536    start_time = time.time()    def wrapper(func):        @functools.lru_cache(maxsize, typed)        def ttl_func(ttl_hash,  *args, **kwargs):            return func(*args, **kwargs)        def wrapped(*args, **kwargs):            ttl_hash = int((time.time() - start_time) / ttl)            return ttl_func(ttl_hash, *args, **kwargs)        return functools.update_wrapper(wrapped, func)    return wrapper",Like functools.lru_cache decorator with time to live feature,"def ttl_cache(maxsize=128, typed=False, ttl=-1):    """"""Like functools.lru_cache decorator with time to live feature""""""    if ttl <= 0:        ttl = 65536    start_time = time.time()    def wrapper(func):        @functools.lru_cache(maxsize, typed)        def ttl_func(ttl_hash,  *args, **kwargs):            return func(*args, **kwargs)        def wrapped(*args, **kwargs):            ttl_hash = int((time.time() - start_time) / ttl)            return ttl_func(ttl_hash, *args, **kwargs)        return functools.update_wrapper(wrapped, func)    return wrapper

Like functools.lru_cache decorator with time to live feature",ffd80fed-18c7-47cd-ac38-f572182a2dd2
accounts,AccioDebridCom.py,args,11,12,def args(**kwargs):    return kwargs,,def args(**kwargs):    return kwargs,b6cce2a0-7c36-472d-9dd2-6e71dd350538
accounts,AccioDebridCom.py,api_response,33,41,"def api_response(self, action, get={}, post={}):        get['action'] = action        # Better use pyLoad User-Agent so we don't get blocked        self.req.http.c.setopt(pycurl.USERAGENT, ""pyLoad/%s"" % self.pyload.version)        json_data = self.load(self.API_URL, get=get, post=post)        return json.loads(json_data)",,"def api_response(self, action, get={}, post={}):        get['action'] = action        # Better use pyLoad User-Agent so we don't get blocked        self.req.http.c.setopt(pycurl.USERAGENT, ""pyLoad/%s"" % self.pyload.version)        json_data = self.load(self.API_URL, get=get, post=post)        return json.loads(json_data)",01e31449-f0c9-4a66-95c9-4e3343f1902c
accounts,AccioDebridCom.py,grab_hosters,43,50,"def grab_hosters(self, user, password, data):        res = self.api_response(""getHostsList"")        if res['success']:            return res['value']        else:            return []",,"def grab_hosters(self, user, password, data):        res = self.api_response(""getHostsList"")        if res['success']:            return res['value']        else:            return []",f3f99570-f527-4af0-9aec-bdeada774c1f
accounts,AccioDebridCom.py,grab_info,52,65,"def grab_info(self, user, password, data):        validuntil = None        trafficleft = None        premium = False        cache_info = data.get('cache_info', {})        if user in cache_info:            validuntil = float(cache_info[user]['vip_end'])            premium = validuntil > 0            trafficleft = -1        return {'validuntil': validuntil,                'trafficleft': trafficleft,                'premium': premium}",,"def grab_info(self, user, password, data):        validuntil = None        trafficleft = None        premium = False        cache_info = data.get('cache_info', {})        if user in cache_info:            validuntil = float(cache_info[user]['vip_end'])            premium = validuntil > 0            trafficleft = -1        return {'validuntil': validuntil,                'trafficleft': trafficleft,                'premium': premium}",11859dfd-d2a1-44fe-acb5-7318f6df38e7
accounts,AccioDebridCom.py,signin,67,106,"def signin(self, user, password, data):        cache_info = self.db.retrieve(""cache_info"", {})        if user in cache_info:            data['cache_info'] = cache_info            self.skip_login()        try:            res = self.api_response(""login"", args(login=user, password=password))        except BadHeader as exc:            if exc.code == 401:                self.fail_login()            elif exc.code == 405:                self.fail(self._(""Banned IP""))            else:                raise        if res['response_code'] != ""ok"":            cache_info.pop(user, None)            data['cache_info'] = cache_info            self.db.store(""cache_info"", cache_info)            if res['response_code'] == ""INCORRECT_PASSWORD"":                self.fail_login()            elif res['response_code'] == ""UNALLOWED_IP"":                self.fail_login(self._(""Banned IP""))            else:                self.log_error(res['response_text'])                self.fail_login(res['response_text'])        else:            cache_info[user] = {'vip_end': res['vip_end'],                                'token': res['token']}            data['cache_info'] = cache_info            self.db.store(""cache_info"", cache_info)",,"def signin(self, user, password, data):        cache_info = self.db.retrieve(""cache_info"", {})        if user in cache_info:            data['cache_info'] = cache_info            self.skip_login()        try:            res = self.api_response(""login"", args(login=user, password=password))        except BadHeader as exc:            if exc.code == 401:                self.fail_login()            elif exc.code == 405:                self.fail(self._(""Banned IP""))            else:                raise        if res['response_code'] != ""ok"":            cache_info.pop(user, None)            data['cache_info'] = cache_info            self.db.store(""cache_info"", cache_info)            if res['response_code'] == ""INCORRECT_PASSWORD"":                self.fail_login()            elif res['response_code'] == ""UNALLOWED_IP"":                self.fail_login(self._(""Banned IP""))            else:                self.log_error(res['response_text'])                self.fail_login(res['response_text'])        else:            cache_info[user] = {'vip_end': res['vip_end'],                                'token': res['token']}            data['cache_info'] = cache_info            self.db.store(""cache_info"", cache_info)",9c2fb20a-731d-4dd9-95a0-433de853fe9c
accounts,AccioDebridCom.py,relogin,108,116,"def relogin(self):        if self.req:            cache_info = self.info['data'].get('cache_info', {})            cache_info.pop(self.user, None)            self.info['data']['cache_info'] = cache_info            self.db.store(""cache_info"", cache_info)        return MultiAccount.relogin(self)",,"def relogin(self):        if self.req:            cache_info = self.info['data'].get('cache_info', {})            cache_info.pop(self.user, None)            self.info['data']['cache_info'] = cache_info            self.db.store(""cache_info"", cache_info)        return MultiAccount.relogin(self)",4ed5259a-8544-4d82-a2b7-1c91489834e1
accounts,AlldebridCom.py,api_request,38,46,"def api_request(self, method, get={}, post={}, multipart=False):        get.update({""agent"": ""pyLoad"", ""version"": self.pyload.version})        json_data = json.loads(            self.load(self.API_URL + method, get=get, post=post, multipart=multipart)        )        if json_data[""status""] == ""success"":            return json_data[""data""]        else:            return json_data",,"def api_request(self, method, get={}, post={}, multipart=False):        get.update({""agent"": ""pyLoad"", ""version"": self.pyload.version})        json_data = json.loads(            self.load(self.API_URL + method, get=get, post=post, multipart=multipart)        )        if json_data[""status""] == ""success"":            return json_data[""data""]        else:            return json_data",239d6bd1-6d4e-40a2-a276-e2207e95431d
accounts,AlldebridCom.py,grab_hosters,48,72,"def grab_hosters(self, user, password, data):        api_data = self.api_request(""user/hosts"", get={""apikey"": password})        if api_data.get(""error"", False):            self.log_error(api_data[""error""][""message""])            return []        else:            valid_statuses = (                (True, False) if self.config.get(""ignore_status"") is True else (True,)            )            valid_hosters = list(api_data[""hosts""].values()) + (                list(api_data[""streams""].values())                if self.config.get(""streams_also"") is True                else []            )            hosts = reduce(                lambda x, y: x + y,                [                    _h[""domains""]                    for _h in valid_hosters                    if _h.get(""status"", False) in valid_statuses                    or _h.get(""type"") == ""free""                ],            )            return hosts",,"def grab_hosters(self, user, password, data):        api_data = self.api_request(""user/hosts"", get={""apikey"": password})        if api_data.get(""error"", False):            self.log_error(api_data[""error""][""message""])            return []        else:            valid_statuses = (                (True, False) if self.config.get(""ignore_status"") is True else (True,)            )            valid_hosters = list(api_data[""hosts""].values()) + (                list(api_data[""streams""].values())                if self.config.get(""streams_also"") is True                else []            )            hosts = reduce(                lambda x, y: x + y,                [                    _h[""domains""]                    for _h in valid_hosters                    if _h.get(""status"", False) in valid_statuses                    or _h.get(""type"") == ""free""                ],            )            return hosts",954b1320-baa7-4219-bc14-f417c6f3eee2
accounts,AlldebridCom.py,grab_info,74,86,"def grab_info(self, user, password, data):        api_data = self.api_request(""user"", get={""apikey"": password})        if api_data.get(""error"", False):            self.log_error(api_data[""error""][""message""])            premium = False            validuntil = -1        else:            premium = api_data[""user""][""isPremium""]            validuntil = api_data[""user""][""premiumUntil""] or -1        return {""validuntil"": validuntil, ""trafficleft"": -1, ""premium"": premium}",,"def grab_info(self, user, password, data):        api_data = self.api_request(""user"", get={""apikey"": password})        if api_data.get(""error"", False):            self.log_error(api_data[""error""][""message""])            premium = False            validuntil = -1        else:            premium = api_data[""user""][""isPremium""]            validuntil = api_data[""user""][""premiumUntil""] or -1        return {""validuntil"": validuntil, ""trafficleft"": -1, ""premium"": premium}",919605f8-6e13-45b1-8778-7f31d346c2c5
accounts,AlldebridCom.py,signin,88,105,"def signin(self, user, password, data):        api_data = self.api_request(""user"", get={""apikey"": password})        if api_data.get(""error"", False):            self.log_error(                self._(                    ""Password for alldebrid.com should be the API token - use GetAlldebridTokenV4.py to get it: https://github.com/pyload/pyload/files/4489732/GetAlldebridTokenV4.zip""                )            )            self.fail_login(api_data[""error""][""message""])        elif api_data[""user""][""username""] != user:            self.log_error(                self._(                    ""username for alldebrid.com should be your alldebrid.com username""                )            )            self.fail_login()",,"def signin(self, user, password, data):        api_data = self.api_request(""user"", get={""apikey"": password})        if api_data.get(""error"", False):            self.log_error(                self._(                    ""Password for alldebrid.com should be the API token - use GetAlldebridTokenV4.py to get it: https://github.com/pyload/pyload/files/4489732/GetAlldebridTokenV4.zip""                )            )            self.fail_login(api_data[""error""][""message""])        elif api_data[""user""][""username""] != user:            self.log_error(                self._(                    ""username for alldebrid.com should be your alldebrid.com username""                )            )            self.fail_login()",55d20d3c-a0da-4adb-831e-ba81f755afb7
accounts,ArchiveOrg.py,grab_info,23,26,"def grab_info(self, user, password, data):        return {'validuntil': None,                'trafficleft': None,                'premium': False}",,"def grab_info(self, user, password, data):        return {'validuntil': None,                'trafficleft': None,                'premium': False}",4aa2cc75-d6b6-41bb-95d6-54f0c639a8cd
accounts,ArchiveOrg.py,signin,28,50,"def signin(self, user, password, data):        html = self.load(self.LOGIN_CHECK_URL)        if ""<title>cannot find account</title>"" not in html:            self.skip_login()        else:            self.load(self.LOGIN_URL)            try:                html = self.load(self.LOGIN_URL, post={                    ""username"": user,                    ""password"": password,                    ""remember"": ""true"",                    ""referer"": ""https://archive.org/"",                    ""login"": ""true"",                    ""submit_by_js"": ""true""                })            except BadHeader as exc:                self.fail_login(str(exc))            else:                json_data = json.loads(html)                if json_data[""status""] != ""ok"":                    self.fail_login()",,"def signin(self, user, password, data):        html = self.load(self.LOGIN_CHECK_URL)        if ""<title>cannot find account</title>"" not in html:            self.skip_login()        else:            self.load(self.LOGIN_URL)            try:                html = self.load(self.LOGIN_URL, post={                    ""username"": user,                    ""password"": password,                    ""remember"": ""true"",                    ""referer"": ""https://archive.org/"",                    ""login"": ""true"",                    ""submit_by_js"": ""true""                })            except BadHeader as exc:                self.fail_login(str(exc))            else:                json_data = json.loads(html)                if json_data[""status""] != ""ok"":                    self.fail_login()",031b0795-e0f3-414e-ab3d-78673582b24f
accounts,CloudzillaTo.py,grab_info,20,25,"def grab_info(self, user, password, data):        html = self.load(""http://www.cloudzilla.to/"")        premium = re.search(self.PREMIUM_PATTERN, html) is not None        return {""validuntil"": -1, ""trafficleft"": -1, ""premium"": premium}",,"def grab_info(self, user, password, data):        html = self.load(""http://www.cloudzilla.to/"")        premium = re.search(self.PREMIUM_PATTERN, html) is not None        return {""validuntil"": -1, ""trafficleft"": -1, ""premium"": premium}",9284baf1-c7c4-429c-9423-7cf65110306b
accounts,CloudzillaTo.py,signin,27,34,"def signin(self, user, password, data):        html = self.load(            ""https://www.cloudzilla.to/"",            post={""lusername"": user, ""lpassword"": password, ""w"": ""dologin""},        )        if ""ERROR"" in html:            self.fail_login()",,"def signin(self, user, password, data):        html = self.load(            ""https://www.cloudzilla.to/"",            post={""lusername"": user, ""lpassword"": password, ""w"": ""dologin""},        )        if ""ERROR"" in html:            self.fail_login()",623f6a74-f5c8-454d-8449-7c664fc1112f
accounts,CzshareCom.py,grab_info,26,50,"def grab_info(self, user, password, data):        premium = False        validuntil = None        trafficleft = None        html = self.load(""https://sdilej.cz/prehled_kreditu/"")        try:            m = re.search(self.CREDIT_LEFT_PATTERN, html, re.MULTILINE)            trafficleft = self.parse_traffic(m.group(1), m.group(2))            v = re.search(self.VALID_UNTIL_PATTERN, html, re.MULTILINE)            validuntil = time.mktime(time.strptime(v.group(1), ""%d.%m.%y %H:%M""))        except Exception as exc:            self.log_error(exc)        else:            premium = True        return {            ""premium"": premium,            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,        }",,"def grab_info(self, user, password, data):        premium = False        validuntil = None        trafficleft = None        html = self.load(""https://sdilej.cz/prehled_kreditu/"")        try:            m = re.search(self.CREDIT_LEFT_PATTERN, html, re.MULTILINE)            trafficleft = self.parse_traffic(m.group(1), m.group(2))            v = re.search(self.VALID_UNTIL_PATTERN, html, re.MULTILINE)            validuntil = time.mktime(time.strptime(v.group(1), ""%d.%m.%y %H:%M""))        except Exception as exc:            self.log_error(exc)        else:            premium = True        return {            ""premium"": premium,            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,        }",5782f2ba-0db5-451f-b02c-44d309864461
accounts,CzshareCom.py,signin,52,63,"def signin(self, user, password, data):        html = self.load(            ""https://sdilej.cz/index.php"",            post={                ""Prihlasit"": ""Prihlasit"",                ""login-password"": password,                ""login-name"": user,            },        )        if '<div class=""login' in html:            self.fail_login()",,"def signin(self, user, password, data):        html = self.load(            ""https://sdilej.cz/index.php"",            post={                ""Prihlasit"": ""Prihlasit"",                ""login-password"": password,                ""login-name"": user,            },        )        if '<div class=""login' in html:            self.fail_login()",66e84b4a-4049-46dd-8d27-fbf0dcd3615f
accounts,DatoidCz.py,grab_info,18,26,"def grab_info(self, user, password, data):        html = self.load(""https://datoid.cz/"")        m = re.search(r'""menu-bar-storage""></i> ([\d.,]+) ([\w^_]+)', html)        trafficleft = self.parse_traffic(m.group(1), m.group(2)) if m else 0        info = {""validuntil"": -1, ""trafficleft"": trafficleft, ""premium"": True}        return info",,"def grab_info(self, user, password, data):        html = self.load(""https://datoid.cz/"")        m = re.search(r'""menu-bar-storage""></i> ([\d.,]+) ([\w^_]+)', html)        trafficleft = self.parse_traffic(m.group(1), m.group(2)) if m else 0        info = {""validuntil"": -1, ""trafficleft"": trafficleft, ""premium"": True}        return info",3a83d05a-8f39-4045-ad39-23ea54aec11a
accounts,DatoidCz.py,signin,28,39,"def signin(self, user, password, data):        html = self.load(""https://datoid.cz/"")        if 'href=""/muj-ucet"">' in html:            self.skip_login()        html = self.load(            ""https://datoid.cz/prihlaseni?do=signInForm-submit"",            post={""username"": user, ""password"": password},        )        if 'href=""/muj-ucet"">' not in html:            self.fail_login()",,"def signin(self, user, password, data):        html = self.load(""https://datoid.cz/"")        if 'href=""/muj-ucet"">' in html:            self.skip_login()        html = self.load(            ""https://datoid.cz/prihlaseni?do=signInForm-submit"",            post={""username"": user, ""password"": password},        )        if 'href=""/muj-ucet"">' not in html:            self.fail_login()",fc4812e6-bf06-491b-953b-9fab12f429a1
accounts,DdownloadCom.py,setup,25,27,"def setup(self):        super(DdownloadCom, self).setup()        self.req.http.c.setopt(pycurl.USERAGENT, ""pyLoad/{}"".format(self.pyload.version))",,"def setup(self):        super(DdownloadCom, self).setup()        self.req.http.c.setopt(pycurl.USERAGENT, ""pyLoad/{}"".format(self.pyload.version))",efdcd365-cb5c-4fd9-87d4-027ab03ae5b3
accounts,DebridItaliaCom.py,api_request,29,31,"def api_request(self, method, **kwargs):        kwargs[method] = """"        return self.load(self.API_URL, get=kwargs)",,"def api_request(self, method, **kwargs):        kwargs[method] = """"        return self.load(self.API_URL, get=kwargs)",f1dfd471-83f3-4ea6-a123-f089acdc504b
accounts,DebridItaliaCom.py,grab_hosters,33,34,"def grab_hosters(self, user, password, data):        return self.api_request(""hosts"").replace('""', """").split("","")",,"def grab_hosters(self, user, password, data):        return self.api_request(""hosts"").replace('""', """").split("","")",8123696b-5ebd-4da1-896d-259c8dda623d
accounts,DebridItaliaCom.py,grab_info,36,48,"def grab_info(self, user, password, data):        validuntil = None        html = self.api_request(""check"", u=user, p=password)        m = re.search(r""<expiration>(.+?)</expiration>"", html)        if m is not None:            validuntil = int(m.group(1))        else:            self.log_error(self._(""Unable to retrieve account information""))        return {""validuntil"": validuntil, ""trafficleft"": -1, ""premium"": True}",,"def grab_info(self, user, password, data):        validuntil = None        html = self.api_request(""check"", u=user, p=password)        m = re.search(r""<expiration>(.+?)</expiration>"", html)        if m is not None:            validuntil = int(m.group(1))        else:            self.log_error(self._(""Unable to retrieve account information""))        return {""validuntil"": validuntil, ""trafficleft"": -1, ""premium"": True}",d509ad90-1341-4e07-bd01-24507863355b
accounts,DebridItaliaCom.py,signin,50,54,"def signin(self, user, password, data):        html = self.api_request(""check"", u=user, p=password)        if ""<status>valid</status>"" not in html:            self.fail_login()",,"def signin(self, user, password, data):        html = self.api_request(""check"", u=user, p=password)        if ""<status>valid</status>"" not in html:            self.fail_login()",49121506-ab81-4fd5-9b2b-b9337cc49613
accounts,DebridlinkFr.py,api_request,34,46,"def api_request(self, method, get={}, post={}):        api_token = self.info[""data""].get(""api_token"", None)        if api_token and method != ""oauth/token"":            self.req.http.c.setopt(                pycurl.HTTPHEADER, [""Authorization: Bearer "" + api_token]            )        self.req.http.c.setopt(pycurl.USERAGENT, ""pyLoad/{}"".format(self.pyload.version))        try:            json_data = self.load(self.API_URL + method, get=get, post=post)        except BadHeader as exc:            json_data = exc.content        return json.loads(json_data)",,"def api_request(self, method, get={}, post={}):        api_token = self.info[""data""].get(""api_token"", None)        if api_token and method != ""oauth/token"":            self.req.http.c.setopt(                pycurl.HTTPHEADER, [""Authorization: Bearer "" + api_token]            )        self.req.http.c.setopt(pycurl.USERAGENT, ""pyLoad/{}"".format(self.pyload.version))        try:            json_data = self.load(self.API_URL + method, get=get, post=post)        except BadHeader as exc:            json_data = exc.content        return json.loads(json_data)",68a9949b-1ef1-4a1e-82b8-f50147d42638
accounts,DebridlinkFr.py,_refresh_token,48,74,"def _refresh_token(self, client_id, refresh_token):        api_data = self.api_request(            ""oauth/token"",            post={                ""client_id"": client_id,                ""refresh_token"": refresh_token,                ""grant_type"": ""refresh_token"",            },        )        if ""error"" in api_data:            if api_data[""error""] == ""invalid_request"":                self.log_error(                    self._(                        ""You have to use GetDebridlinkToken.py to authorize pyLoad: ""                        ""https://github.com/pyload/pyload/files/9353788/GetDebridlinkToken.zip""                    )                )            else:                self.log_error(                    api_data.get(                        ""error_description"", error_description(api_data[""error""])                    )                )            self.fail_login()        return api_data[""access_token""], api_data[""expires_in""]",,"def _refresh_token(self, client_id, refresh_token):        api_data = self.api_request(            ""oauth/token"",            post={                ""client_id"": client_id,                ""refresh_token"": refresh_token,                ""grant_type"": ""refresh_token"",            },        )        if ""error"" in api_data:            if api_data[""error""] == ""invalid_request"":                self.log_error(                    self._(                        ""You have to use GetDebridlinkToken.py to authorize pyLoad: ""                        ""https://github.com/pyload/pyload/files/9353788/GetDebridlinkToken.zip""                    )                )            else:                self.log_error(                    api_data.get(                        ""error_description"", error_description(api_data[""error""])                    )                )            self.fail_login()        return api_data[""access_token""], api_data[""expires_in""]",c61854ee-760b-4767-be80-b86b7c29912f
accounts,DebridlinkFr.py,grab_hosters,76,83,"def grab_hosters(self, user, password, data):        api_data = self.api_request(""v2/downloader/hostnames"")        if api_data[""success""]:            return api_data[""value""]        else:            return []",,"def grab_hosters(self, user, password, data):        api_data = self.api_request(""v2/downloader/hostnames"")        if api_data[""success""]:            return api_data[""value""]        else:            return []",5362eec7-3251-4444-9f1a-b6cfd319ede1
accounts,DebridlinkFr.py,grab_info,85,100,"def grab_info(self, user, password, data):        api_data = self.api_request(""v2/account/infos"")        if api_data[""success""]:            premium = api_data[""value""][""premiumLeft""] > 0            validuntil = api_data[""value""][""premiumLeft""] + time.time()        else:            self.log_error(                self._(""Unable to retrieve account information""),                api_data.get(""error_description"", error_description(api_data[""error""])),            )            validuntil = None            premium = None        return {""validuntil"": validuntil, ""trafficleft"": -1, ""premium"": premium}",,"def grab_info(self, user, password, data):        api_data = self.api_request(""v2/account/infos"")        if api_data[""success""]:            premium = api_data[""value""][""premiumLeft""] > 0            validuntil = api_data[""value""][""premiumLeft""] + time.time()        else:            self.log_error(                self._(""Unable to retrieve account information""),                api_data.get(""error_description"", error_description(api_data[""error""])),            )            validuntil = None            premium = None        return {""validuntil"": validuntil, ""trafficleft"": -1, ""premium"": premium}",438a0cb4-a8f3-40e1-9d47-f7aa6dac3257
accounts,DebridlinkFr.py,signin,102,123,"def signin(self, user, password, data):        if ""token"" not in data:            api_token, timeout = self._refresh_token(user, password)            data[""api_token""] = api_token            self.timeout = timeout - 5 * 60  #: Five minutes less to be on the safe side        api_data = self.api_request(""v2/account/infos"")        if ""error"" in api_data:            if api_data[""error""] == ""badToken"":  #: Token expired? try to refresh                api_token, timeout = self._refresh_token(user, password)                data[""api_token""] = api_token                self.timeout = (                    timeout - 5 * 60                )  #: Five minutes less to be on the safe side            else:                self.log_error(                    api_data.get(                        ""error_description"", error_description(api_data[""error""])                    )                )                self.fail_login()",,"def signin(self, user, password, data):        if ""token"" not in data:            api_token, timeout = self._refresh_token(user, password)            data[""api_token""] = api_token            self.timeout = timeout - 5 * 60  #: Five minutes less to be on the safe side        api_data = self.api_request(""v2/account/infos"")        if ""error"" in api_data:            if api_data[""error""] == ""badToken"":  #: Token expired? try to refresh                api_token, timeout = self._refresh_token(user, password)                data[""api_token""] = api_token                self.timeout = (                    timeout - 5 * 60                )  #: Five minutes less to be on the safe side            else:                self.log_error(                    api_data.get(                        ""error_description"", error_description(api_data[""error""])                    )                )                self.fail_login()",3ee50e10-8c1a-4cd1-a6a6-a95da1061f9a
accounts,DebridplanetCom.py,api_request,31,38,"def api_request(self, method, **kwargs):        token = self.info[""data""].get(""token"")        if token is not None:            self.req.http.c.setopt(                pycurl.HTTPHEADER, [""Authorization: Bearer "" + token]            )        json_data = self.load(f""{self.API_URL}{method}.php"", post=json.dumps(kwargs))        return json.loads(json_data)",,"def api_request(self, method, **kwargs):        token = self.info[""data""].get(""token"")        if token is not None:            self.req.http.c.setopt(                pycurl.HTTPHEADER, [""Authorization: Bearer "" + token]            )        json_data = self.load(f""{self.API_URL}{method}.php"", post=json.dumps(kwargs))        return json.loads(json_data)",4cb16efe-c352-453a-9af2-d49f77932751
accounts,DebridplanetCom.py,grab_hosters,40,47,"def grab_hosters(self, user, password, data):        api_data = self.api_request(""supportedhosts"")        hosts = [            h[""host""]            for h in api_data[""supportedhosts""]            if h[""currently_working""]        ]        return hosts",,"def grab_hosters(self, user, password, data):        api_data = self.api_request(""supportedhosts"")        hosts = [            h[""host""]            for h in api_data[""supportedhosts""]            if h[""currently_working""]        ]        return hosts",bc84040d-5f1f-4d35-b0fe-da91e0f89b47
accounts,DebridplanetCom.py,grab_info,49,58,"def grab_info(self, user, password, data):        validuntil = None        premium = False        api_data = self.api_request(""user-info"")        if api_data.get(""success"", False):            premium = api_data[""user""][""account_type""] == ""premium""            validuntil = time.mktime(time.strptime(api_data[""user""][""expire""], ""%Y-%m-%dT%H:%M:%S""))        return {""validuntil"": validuntil, ""trafficleft"": -1, ""premium"": premium}",,"def grab_info(self, user, password, data):        validuntil = None        premium = False        api_data = self.api_request(""user-info"")        if api_data.get(""success"", False):            premium = api_data[""user""][""account_type""] == ""premium""            validuntil = time.mktime(time.strptime(api_data[""user""][""expire""], ""%Y-%m-%dT%H:%M:%S""))        return {""validuntil"": validuntil, ""trafficleft"": -1, ""premium"": premium}",ea20fc06-8beb-4e48-a2aa-1c4bb8f1fe2c
accounts,DebridplanetCom.py,signin,60,71,"def signin(self, user, password, data):        api_data = self.api_request(""user-info"")        if api_data.get(""success"", False):            self.skip_login()        data[""token""] = None        api_data = self.api_request(""login"", username=user, password=hashlib.sha256(to_bytes(password)).hexdigest())        if api_data.get(""success"", False):            data[""token""] = api_data[""token""]        else:            self.fail_login()",,"def signin(self, user, password, data):        api_data = self.api_request(""user-info"")        if api_data.get(""success"", False):            self.skip_login()        data[""token""] = None        api_data = self.api_request(""login"", username=user, password=hashlib.sha256(to_bytes(password)).hexdigest())        if api_data.get(""success"", False):            data[""token""] = api_data[""token""]        else:            self.fail_login()",9875b82c-3cd0-4cc9-8cdd-32be79a82d8c
accounts,DepositfilesCom.py,grab_info,23,31,"def grab_info(self, user, password, data):        html = self.load(""https://dfiles.eu/de/gold/"")        validuntil = re.search(            r""Sie haben Gold Zugang bis: <b>(.*?)</b></div>"", html        ).group(1)        validuntil = time.mktime(time.strptime(validuntil, ""%Y-%m-%d %H:%M:%S""))        return {""validuntil"": validuntil, ""trafficleft"": -1}",,"def grab_info(self, user, password, data):        html = self.load(""https://dfiles.eu/de/gold/"")        validuntil = re.search(            r""Sie haben Gold Zugang bis: <b>(.*?)</b></div>"", html        ).group(1)        validuntil = time.mktime(time.strptime(validuntil, ""%Y-%m-%d %H:%M:%S""))        return {""validuntil"": validuntil, ""trafficleft"": -1}",dc8d604e-9e25-4ff6-90cd-b78a1afec621
accounts,DepositfilesCom.py,signin,33,44,"def signin(self, user, password, data):        html = self.load(            ""https://dfiles.eu/de/login.php"",            get={""return"": ""/de/gold/payment.php""},            post={""login"": user, ""password"": password},        )        if (            r'<div class=""error_message"">Sie haben eine falsche Benutzername-Passwort-Kombination verwendet.</div>'            in html        ):            self.fail_login()",,"def signin(self, user, password, data):        html = self.load(            ""https://dfiles.eu/de/login.php"",            get={""return"": ""/de/gold/payment.php""},            post={""login"": user, ""password"": password},        )        if (            r'<div class=""error_message"">Sie haben eine falsche Benutzername-Passwort-Kombination verwendet.</div>'            in html        ):            self.fail_login()",ad1e4792-e2c0-4ad2-af4d-bc05e83f3501
accounts,DownsterNet.py,__init__,17,24,"def __init__(self, plugin):        self.plugin = plugin        if hasattr(self.plugin, ""account""):            self.account_plugin = self.plugin.account        else:            self.account_plugin = self.plugin",,"def __init__(self, plugin):        self.plugin = plugin        if hasattr(self.plugin, ""account""):            self.account_plugin = self.plugin.account        else:            self.account_plugin = self.plugin",6b210120-5cb8-4b47-9099-baddcc1cfd11
accounts,DownsterNet.py,request,26,52,"def request(self, method, get={}, **kwargs):        self.plugin.req.http.c.setopt(            pycurl.HTTPHEADER,            [                ""Accept: application/json, text/plain, */"",                ""Content-Type: application/json"",                ""X-Flow-ID: "" + self.flow_id(),            ],        )        self.plugin.req.http.c.setopt(            pycurl.USERAGENT,            ""User-Agent: pyLoad/""            + self.plugin.pyload.version            + "" DownsterNet/""            + self.account_plugin.__version__,        )        try:            res = self.plugin.load(                self.API_URL + method, get=get, post=json.dumps(kwargs)            )        except BadHeader as exc:            res = exc.content        res = json.loads(res)        return res",,"def request(self, method, get={}, **kwargs):        self.plugin.req.http.c.setopt(            pycurl.HTTPHEADER,            [                ""Accept: application/json, text/plain, */"",                ""Content-Type: application/json"",                ""X-Flow-ID: "" + self.flow_id(),            ],        )        self.plugin.req.http.c.setopt(            pycurl.USERAGENT,            ""User-Agent: pyLoad/""            + self.plugin.pyload.version            + "" DownsterNet/""            + self.account_plugin.__version__,        )        try:            res = self.plugin.load(                self.API_URL + method, get=get, post=json.dumps(kwargs)            )        except BadHeader as exc:            res = exc.content        res = json.loads(res)        return res",ffcf7fae-d7cc-42fc-8a07-f799ca014bf9
accounts,DownsterNet.py,rnd,54,57,"def rnd(self):        return """".join(            [random.choice(string.ascii_lowercase + string.digits) for n in range(5)]        )",,"def rnd(self):        return """".join(            [random.choice(string.ascii_lowercase + string.digits) for n in range(5)]        )",c6571926-dab4-44aa-9a28-ed0516bc4dd3
accounts,DownsterNet.py,flow_id,59,72,"def flow_id(self):        user_flow_id = self.account_plugin.info[""data""].get(""user_flow_id"")        self.plugin.log_debug(""User flow id: {}"".format(user_flow_id))        if not user_flow_id:            self.account_plugin.info[""data""][""user_flow_id""] = self.rnd()            self.plugin.log_info(                ""Created user flow id: {}"".format(                    self.account_plugin.info[""data""][""user_flow_id""]                )            )        return (            ""PYL_"" + self.account_plugin.info[""data""][""user_flow_id""] + ""_"" + self.rnd()        )",,"def flow_id(self):        user_flow_id = self.account_plugin.info[""data""].get(""user_flow_id"")        self.plugin.log_debug(""User flow id: {}"".format(user_flow_id))        if not user_flow_id:            self.account_plugin.info[""data""][""user_flow_id""] = self.rnd()            self.plugin.log_info(                ""Created user flow id: {}"".format(                    self.account_plugin.info[""data""][""user_flow_id""]                )            )        return (            ""PYL_"" + self.account_plugin.info[""data""][""user_flow_id""] + ""_"" + self.rnd()        )",0cce98b4-9b6e-46df-955d-e8b937bfb443
accounts,DownsterNet.py,grab_hosters,93,100,"def grab_hosters(self, user, password, data):        api_data = self.api.request(""download/usage"")        if not api_data[""success""]:            self.log_error(""Could not get hoster info: "" + api_data[""error""])            return []        else:            return [hoster[""hoster""] for hoster in api_data[""data""]]",,"def grab_hosters(self, user, password, data):        api_data = self.api.request(""download/usage"")        if not api_data[""success""]:            self.log_error(""Could not get hoster info: "" + api_data[""error""])            return []        else:            return [hoster[""hoster""] for hoster in api_data[""data""]]",53e87b19-008b-40ec-8081-c99fad537662
accounts,DownsterNet.py,grab_info,102,125,"def grab_info(self, user, password, data):        api_data = self.api.request(""user/info"")        if not api_data[""success""]:            validuntil = None            trafficleft = None            premium = False            self.log_error(""Could not get user info: "" + api_data[""error""])        else:            validuntil = time.mktime(                time.strptime(                    api_data[""data""][""premiumUntil""], ""%Y-%m-%dT%H:%M:%S.%f+00:00""                )            )            trafficleft = -1            premium = validuntil > time.time()        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""premium"": premium,        }",,"def grab_info(self, user, password, data):        api_data = self.api.request(""user/info"")        if not api_data[""success""]:            validuntil = None            trafficleft = None            premium = False            self.log_error(""Could not get user info: "" + api_data[""error""])        else:            validuntil = time.mktime(                time.strptime(                    api_data[""data""][""premiumUntil""], ""%Y-%m-%dT%H:%M:%S.%f+00:00""                )            )            trafficleft = -1            premium = validuntil > time.time()        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""premium"": premium,        }",c3c9acef-4cd1-48c7-8452-512b75fb7e1f
accounts,DownsterNet.py,signin,127,138,"def signin(self, user, password, data):        if self.api is None:            self.api = DownsterApi(self)        api_data = self.api.request(""user/info"")        if api_data[""success""]:            self.skip_login()        api_data = self.api.request(""user/authenticate"", email=user, password=password)        if not api_data[""success""]:            self.fail_login(api_data[""error""])",,"def signin(self, user, password, data):        if self.api is None:            self.api = DownsterApi(self)        api_data = self.api.request(""user/info"")        if api_data[""success""]:            self.skip_login()        api_data = self.api.request(""user/authenticate"", email=user, password=password)        if not api_data[""success""]:            self.fail_login(api_data[""error""])",96ef9e2a-81f0-4e60-bf5a-399584f0e180
accounts,EuroshareEu.py,grab_info,23,37,"def grab_info(self, user, password, data):        html = self.load(""http://euroshare.eu/"", get={""lang"": ""en""})        m = re.search(            r'<span class=""btn btn--nav green darken-3"">Premium account until: (\d+/\d+/\d+ \d+:\d+:\d+)<',            html,        )        if m is None:            premium = False            validuntil = -1        else:            premium = True            validuntil = time.mktime(time.strptime(m.group(1), ""%d/%m/%Y %H:%M:%S""))        return {""validuntil"": validuntil, ""trafficleft"": -1, ""premium"": premium}",,"def grab_info(self, user, password, data):        html = self.load(""http://euroshare.eu/"", get={""lang"": ""en""})        m = re.search(            r'<span class=""btn btn--nav green darken-3"">Premium account until: (\d+/\d+/\d+ \d+:\d+:\d+)<',            html,        )        if m is None:            premium = False            validuntil = -1        else:            premium = True            validuntil = time.mktime(time.strptime(m.group(1), ""%d/%m/%Y %H:%M:%S""))        return {""validuntil"": validuntil, ""trafficleft"": -1, ""premium"": premium}",04f7cfd5-257f-4ead-8dc5-c3744abf7c54
accounts,EuroshareEu.py,signin,39,58,"def signin(self, user, password, data):        html = self.load(""http://euroshare.eu/login.html"")        if r'href=""http://euroshare.eu/logout.html""' in html:            self.skip_login()        json_data = json.loads(            self.load(                ""http://euroshare.eu/ajax/_account_login.ajax.php"",                post={                    ""username"": user,                    ""password"": password,                    ""remember"": ""false"",                    ""backlink"": """",                },            )        )        if json_data.get(""login_status"") != ""success"":            self.fail_login()",,"def signin(self, user, password, data):        html = self.load(""http://euroshare.eu/login.html"")        if r'href=""http://euroshare.eu/logout.html""' in html:            self.skip_login()        json_data = json.loads(            self.load(                ""http://euroshare.eu/ajax/_account_login.ajax.php"",                post={                    ""username"": user,                    ""password"": password,                    ""remember"": ""false"",                    ""backlink"": """",                },            )        )        if json_data.get(""login_status"") != ""success"":            self.fail_login()",7a285127-be0a-4e43-9f4a-3c225f216713
accounts,ExtmatrixCom.py,grab_info,25,40,"def grab_info(self, user, password, data):        html = self.load(""https://www.extmatrix.com"")        premium = "">Premium Member<"" in html        m = re.search(self.VALID_UNTIL_PATTERN, html)        if m is not None:            validuntil = time.mktime(                time.strptime(m.group(1) + "" 23:59:59"", ""%Y-%m-%d %H:%M:%S"")            )        else:            self.log_error(self._(""VALID_UNTIL_PATTERN not found""))            validuntil = None        return {""validuntil"": validuntil, ""trafficleft"": None, ""premium"": premium}",,"def grab_info(self, user, password, data):        html = self.load(""https://www.extmatrix.com"")        premium = "">Premium Member<"" in html        m = re.search(self.VALID_UNTIL_PATTERN, html)        if m is not None:            validuntil = time.mktime(                time.strptime(m.group(1) + "" 23:59:59"", ""%Y-%m-%d %H:%M:%S"")            )        else:            self.log_error(self._(""VALID_UNTIL_PATTERN not found""))            validuntil = None        return {""validuntil"": validuntil, ""trafficleft"": None, ""premium"": premium}",6c716ddb-eb04-4beb-a695-cd8da5b4c726
accounts,ExtmatrixCom.py,signin,42,95,"def signin(self, user, password, data):        html = self.load(""https://www.extmatrix.com/login.php"")        if 'href=""./logout.php""' in html:            self.skip_login()        # dummy pyfile        pyfile = PyFile(            self.pyload.files,            -1,            ""https://www.extmatrix.com"",            ""https://www.extmatrix.com"",            0,            0,            """",            self.classname,            -1,            -1,        )        pyfile.plugin = self        for i in range(5):            m = re.search(r'<img src=""(.+?captcha\.php.+?)""', html)            if m is None:                self.fail_login(""Captcha pattern not found"")            captcha_url = urllib.parse.urljoin(""https://www.extmatrix.com/"", m.group(1))            self.captcha = BaseCaptcha(pyfile)            captcha_response = self.captcha.decrypt(captcha_url)            html = self.load(                ""https://www.extmatrix.com/login.php"",                post={                    ""user"": user,                    ""pass"": password,                    ""submit"": ""Login"",                    ""task"": ""dologin"",                    ""return="": ""./members/myfiles.php"",                    ""captcha"": captcha_response,                },            )            if ""Incorrect captcha code"" in html:                self.captcha.invalid()            else:                self.captcha.correct()                break        else:            self.fail_login(self._(""Max captcha retries reached""))        html = self.load(""https://www.extmatrix.com"")        if 'href=""./logout.php""' not in html:            self.fail_login()",,"def signin(self, user, password, data):        html = self.load(""https://www.extmatrix.com/login.php"")        if 'href=""./logout.php""' in html:            self.skip_login()        # dummy pyfile        pyfile = PyFile(            self.pyload.files,            -1,            ""https://www.extmatrix.com"",            ""https://www.extmatrix.com"",            0,            0,            """",            self.classname,            -1,            -1,        )        pyfile.plugin = self        for i in range(5):            m = re.search(r'<img src=""(.+?captcha\.php.+?)""', html)            if m is None:                self.fail_login(""Captcha pattern not found"")            captcha_url = urllib.parse.urljoin(""https://www.extmatrix.com/"", m.group(1))            self.captcha = BaseCaptcha(pyfile)            captcha_response = self.captcha.decrypt(captcha_url)            html = self.load(                ""https://www.extmatrix.com/login.php"",                post={                    ""user"": user,                    ""pass"": password,                    ""submit"": ""Login"",                    ""task"": ""dologin"",                    ""return="": ""./members/myfiles.php"",                    ""captcha"": captcha_response,                },            )            if ""Incorrect captcha code"" in html:                self.captcha.invalid()            else:                self.captcha.correct()                break        else:            self.fail_login(self._(""Max captcha retries reached""))        html = self.load(""https://www.extmatrix.com"")        if 'href=""./logout.php""' not in html:            self.fail_login()",f90c0fd9-98f2-4950-a83a-2af269ae550a
accounts,ExtmatrixCom.py,check_status,102,103,def check_status(self):        pass,,def check_status(self):        pass,c1b6abe1-27e4-429c-9bfa-0c9a0e6ef1b0
accounts,ExtmatrixCom.py,retry_captcha,105,107,"def retry_captcha(self, attempts=10, wait=1, msg=""Max captcha retries reached""):        self.captcha.invalid()        self.fail_login(msg=self._(""Invalid captcha""))",,"def retry_captcha(self, attempts=10, wait=1, msg=""Max captcha retries reached""):        self.captcha.invalid()        self.fail_login(msg=self._(""Invalid captcha""))",470555e5-ceea-4cc7-996a-f5b54aaeaad3
accounts,FastixRu.py,grab_hosters,24,34,"def grab_hosters(self, user, password, data):        html = self.load(            ""http://fastix.ru/api_v2"",            get={                ""apikey"": ""5182964c3f8f9a7f0b00000a_kelmFB4n1IrnCDYuIFn2y"",                ""sub"": ""allowed_sources"",            },        )        host_list = json.loads(html)        host_list = host_list[""allow""]        return host_list",,"def grab_hosters(self, user, password, data):        html = self.load(            ""http://fastix.ru/api_v2"",            get={                ""apikey"": ""5182964c3f8f9a7f0b00000a_kelmFB4n1IrnCDYuIFn2y"",                ""sub"": ""allowed_sources"",            },        )        host_list = json.loads(html)        host_list = host_list[""allow""]        return host_list",38a1cd89-cf37-4a84-bde0-881fe39272c7
accounts,FastixRu.py,grab_info,36,50,"def grab_info(self, user, password, data):        html = self.load(            ""http://fastix.ru/api_v2/"",            get={""apikey"": data[""apikey""], ""sub"": ""getaccountdetails""},        )        json_data = json.loads(html)        points = json_data[""points""]        trafficleft = float(points) * 1024 ** 2        if points > 0:            account_info = {""validuntil"": -1, ""trafficleft"": trafficleft}        else:            account_info = {""validuntil"": None, ""trafficleft"": None, ""premium"": False}        return account_info",,"def grab_info(self, user, password, data):        html = self.load(            ""http://fastix.ru/api_v2/"",            get={""apikey"": data[""apikey""], ""sub"": ""getaccountdetails""},        )        json_data = json.loads(html)        points = json_data[""points""]        trafficleft = float(points) * 1024 ** 2        if points > 0:            account_info = {""validuntil"": -1, ""trafficleft"": trafficleft}        else:            account_info = {""validuntil"": None, ""trafficleft"": None, ""premium"": False}        return account_info",e7706fc1-360f-43ce-ba70-c9e413223212
accounts,FastixRu.py,signin,52,63,"def signin(self, user, password, data):        html = self.load(            ""https://fastix.ru/api_v2/"",            get={""sub"": ""get_apikey"", ""email"": user, ""password"": password},        )        api = json.loads(html)        if ""error"" in api:            self.fail_login(api[""error_txt""])        else:            data[""apikey""] = api[""apikey""]",,"def signin(self, user, password, data):        html = self.load(            ""https://fastix.ru/api_v2/"",            get={""sub"": ""get_apikey"", ""email"": user, ""password"": password},        )        api = json.loads(html)        if ""error"" in api:            self.fail_login(api[""error_txt""])        else:            data[""apikey""] = api[""apikey""]",87f1c289-964b-4e8e-bdac-e45f759a050c
accounts,FastshareCz.py,grab_info,28,61,"def grab_info(self, user, password, data):        html = self.load(""https://fastshare.cz/user"")        m = re.search(self.VALID_UNTILL_PATTERN, html)        if m is not None:            validuntil = time.mktime(                time.strptime(m.group(1) + "" 23:59:59"", ""%d.%m.%Y %H:%M:%S"")            )            premium = True            trafficleft = -1        else:            validuntil = -1            m = re.search(self.TRAFFICLEFT_PATTERN, html)            if m is not None:                trafficleft = self.parse_traffic(m.group(1), m.group(2))                premium = bool(trafficleft)                if not premium:                    trafficleft = None            elif "">Unlimited downloading<"" in html:                premium = True                trafficleft = -1                validuntil = None            else:                premium = False                trafficleft = None        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""premium"": premium,        }",,"def grab_info(self, user, password, data):        html = self.load(""https://fastshare.cz/user"")        m = re.search(self.VALID_UNTILL_PATTERN, html)        if m is not None:            validuntil = time.mktime(                time.strptime(m.group(1) + "" 23:59:59"", ""%d.%m.%Y %H:%M:%S"")            )            premium = True            trafficleft = -1        else:            validuntil = -1            m = re.search(self.TRAFFICLEFT_PATTERN, html)            if m is not None:                trafficleft = self.parse_traffic(m.group(1), m.group(2))                premium = bool(trafficleft)                if not premium:                    trafficleft = None            elif "">Unlimited downloading<"" in html:                premium = True                trafficleft = -1                validuntil = None            else:                premium = False                trafficleft = None        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""premium"": premium,        }",cf87c422-1d6c-4df4-9256-fcaddfc5b3fb
accounts,FastshareCz.py,signin,63,76,"def signin(self, user, password, data):        set_cookie(self.req.cj, ""fastshare.cz"", ""lang"", ""en"")        html = self.load(""https://fastshare.cz/user"")        if 'href=""/logout.php""' in html:            self.skip_login()        html = self.load(            ""https://fastshare.cz/sql.php"",            post={""login"": user, ""heslo"": password},        )        if 'href=""/logout.php""' not in html:            self.fail_login()",,"def signin(self, user, password, data):        set_cookie(self.req.cj, ""fastshare.cz"", ""lang"", ""en"")        html = self.load(""https://fastshare.cz/user"")        if 'href=""/logout.php""' in html:            self.skip_login()        html = self.load(            ""https://fastshare.cz/sql.php"",            post={""login"": user, ""heslo"": password},        )        if 'href=""/logout.php""' not in html:            self.fail_login()",d2530d4a-c17d-43c2-ab7d-7c742ba8d050
accounts,FikperCom.py,api_request,24,36,"def api_request(self, method, api_key=None, **kwargs):        if api_key is not None:            self.req.http.c.setopt(pycurl.HTTPHEADER, [f""x-api-key: {api_key}""])        try:            json_data = self.load(self.API_URL + method, post=kwargs)            return json.loads(json_data)        except json.JSONDecodeError:            return json_data        except BadHeader as exc:            return json.loads(exc.content)",,"def api_request(self, method, api_key=None, **kwargs):        if api_key is not None:            self.req.http.c.setopt(pycurl.HTTPHEADER, [f""x-api-key: {api_key}""])        try:            json_data = self.load(self.API_URL + method, post=kwargs)            return json.loads(json_data)        except json.JSONDecodeError:            return json_data        except BadHeader as exc:            return json.loads(exc.content)",ad2afef4-bb07-4fc0-81e7-12eb8e883c06
accounts,FikperCom.py,grab_info,38,54,"def grab_info(self, user, password, data):        api_data = self.api_request(""api/account/info"", api_key=password)        premium = api_data[""accountType""] == ""premium""        if premium:            validuntil = api_data[""premiumExpire""] / 1000        else:            validuntil = -1        trafficleft = api_data[""totalBandwidth""] - api_data[""usedBandwidth""]        return {            ""premium"": premium,            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,        }",,"def grab_info(self, user, password, data):        api_data = self.api_request(""api/account/info"", api_key=password)        premium = api_data[""accountType""] == ""premium""        if premium:            validuntil = api_data[""premiumExpire""] / 1000        else:            validuntil = -1        trafficleft = api_data[""totalBandwidth""] - api_data[""usedBandwidth""]        return {            ""premium"": premium,            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,        }",c415efc1-82fa-4b02-987f-337d4d048d7c
accounts,FikperCom.py,signin,56,67,"def signin(self, user, password, data):        api_data = self.api_request(""api/account/info"", api_key=password)        if api_data.get(""code"") is not None:            self.log_error(self._(""Password for fikper.com should be the API token""))            self.log_error(self._(""API error""), api_data)            self.fail_login()        elif api_data[""email""] != user:            self.log_error(                self._(""username for fikper.com should be your fikper.com email"")            )            self.fail_login()",,"def signin(self, user, password, data):        api_data = self.api_request(""api/account/info"", api_key=password)        if api_data.get(""code"") is not None:            self.log_error(self._(""Password for fikper.com should be the API token""))            self.log_error(self._(""API error""), api_data)            self.fail_login()        elif api_data[""email""] != user:            self.log_error(                self._(""username for fikper.com should be your fikper.com email"")            )            self.fail_login()",208c009b-f931-447f-8ec3-296dff465728
accounts,FileboomMe.py,api_request,29,32,"def api_request(self, method, **kwargs):        html = self.load(self.API_URL + method,                         post=json.dumps(kwargs))        return json.loads(html)",,"def api_request(self, method, **kwargs):        html = self.load(self.API_URL + method,                         post=json.dumps(kwargs))        return json.loads(html)",ea3f832d-f6ef-4d1f-921f-c9179cd644e4
accounts,FileboomMe.py,grab_info,34,39,"def grab_info(self, user, password, data):        json_data = self.api_request(""AccountInfo"", auth_token=data['token'])        return {'validuntil': json_data['account_expires'],                'trafficleft': json_data['available_traffic'],                'premium': True if json_data['account_expires'] else False}",,"def grab_info(self, user, password, data):        json_data = self.api_request(""AccountInfo"", auth_token=data['token'])        return {'validuntil': json_data['account_expires'],                'trafficleft': json_data['available_traffic'],                'premium': True if json_data['account_expires'] else False}",16cf8c0a-a9b2-460b-8dcc-ab5a530ba2ee
accounts,FileboomMe.py,signin,41,157,"def signin(self, user, password, data):        if 'token' in data:            try:                json_data = self.api_request(""test"", auth_token=data['token'])            except BadHeader as exc:                if exc.code == 403:  #: Session expired                    pass                else:                    raise            else:                self.skip_login()        try:            json_data = self.api_request(""login"", username=user, password=password)        except BadHeader as exc:            if exc.code == 406:  #: Captcha needed                # dummy pyfile                pyfile = PyFile(self.pyload.files, -1, ""https://fileboom.me"", ""https://fileboom.me"", 0, 0, """", self.classname, -1, -1)                pyfile.plugin = self                errors = [json.loads(m.group(0)).get('errorCode', 0) for m in re.finditer(r'{[^}]+}', exc.content)]                if 33 in errors:  #: ERROR_RE_CAPTCHA_REQUIRED                    #: Recaptcha                    self.captcha = ReCaptcha(pyfile)                    for i in range(10):                        json_data = self.api_request(""RequestReCaptcha"")                        if json_data['code'] != 200:                            self.log_error(_(""Request reCAPTCHA API failed""))                            self.fail_login(_(""Request reCAPTCHA API failed""))                        re_captcha_response = self.captcha.challenge(self.RECAPTCHA_KEY, version=""2js"", secure_token=False)                        try:                            json_data = self.api_request(""login"",                                                          username=user,                                                          password=password,                                                          re_captcha_challenge=json_data['challenge'],                                                          re_captcha_response=re_captcha_response)                        except BadHeader as exc:                            if exc.code == 406:                                errors = [json.loads(m.group(0)).get('errorCode', 0) for m in re.finditer(r'{[^}]+}', exc.content)]                                if 31 in errors:  #: ERROR_CAPTCHA_INVALID                                    self.captcha.invalid()                                    continue                                else:                                    self.log_error(exc.content)                                    self.fail_login(exc.content)                            else:                                self.log_error(exc.content)                                self.fail_login(exc.content)                        else:                            self.captcha.correct()                            data['token'] = json_data['auth_token']                            break                    else:                        self.log_error(_(""Max captcha retries reached""))                        self.fail_login(_(""Max captcha retries reached""))                elif 30 in errors:  #: ERROR_CAPTCHA_REQUIRED                    #: Normal captcha                    self.captcha = BaseCaptcha(pyfile)                    for i in range(10):                        json_data = self.api_request(""RequestCaptcha"")                        if json_data['code'] != 200:                            self.log_error(self._(""Request captcha API failed""))                            self.fail_login(self._(""Request captcha API failed""))                        captcha_response = self.captcha.decrypt(json_data['captcha_url'])                        try:                            json_data = self.api_request(""login"",                                                          username=user,                                                          password=password,                                                          captcha_challenge=json_data['challenge'],                                                          captcha_response=captcha_response)                        except BadHeader as exc:                            if exc.code == 406:                                errors = [json.loads(m.group(0)).get('errorCode', 0) for m in re.finditer(r'{[^}]+}', exc.content)]                                if 31 in errors:  #: ERROR_CAPTCHA_INVALID                                    self.captcha.invalid()                                    continue                                else:                                    self.log_error(exc.content)                                    self.fail_login(exc.content)                            else:                                self.log_error(exc.content)                                self.fail_login(exc.content)                        else:                            self.captcha.correct()                            data['token'] = json_data['auth_token']                            break                    else:                        self.log_error(self._(""Max captcha retries reached""))                        self.fail_login(self._(""Max captcha retries reached""))                else:                    self.log_error(exc.content)                    self.fail_login(exc.content)            else:                self.log_error(exc.content)                self.fail_login(exc.content)        else:            #: No captcha            data['token'] = json_data['auth_token']",,"def signin(self, user, password, data):        if 'token' in data:            try:                json_data = self.api_request(""test"", auth_token=data['token'])            except BadHeader as exc:                if exc.code == 403:  #: Session expired                    pass                else:                    raise            else:                self.skip_login()        try:            json_data = self.api_request(""login"", username=user, password=password)        except BadHeader as exc:            if exc.code == 406:  #: Captcha needed                # dummy pyfile                pyfile = PyFile(self.pyload.files, -1, ""https://fileboom.me"", ""https://fileboom.me"", 0, 0, """", self.classname, -1, -1)                pyfile.plugin = self                errors = [json.loads(m.group(0)).get('errorCode', 0) for m in re.finditer(r'{[^}]+}', exc.content)]                if 33 in errors:  #: ERROR_RE_CAPTCHA_REQUIRED                    #: Recaptcha                    self.captcha = ReCaptcha(pyfile)                    for i in range(10):                        json_data = self.api_request(""RequestReCaptcha"")                        if json_data['code'] != 200:                            self.log_error(_(""Request reCAPTCHA API failed""))                            self.fail_login(_(""Request reCAPTCHA API failed""))                        re_captcha_response = self.captcha.challenge(self.RECAPTCHA_KEY, version=""2js"", secure_token=False)                        try:                            json_data = self.api_request(""login"",                                                          username=user,                                                          password=password,                                                          re_captcha_challenge=json_data['challenge'],                                                          re_captcha_response=re_captcha_response)                        except BadHeader as exc:                            if exc.code == 406:                                errors = [json.loads(m.group(0)).get('errorCode', 0) for m in re.finditer(r'{[^}]+}', exc.content)]                                if 31 in errors:  #: ERROR_CAPTCHA_INVALID                                    self.captcha.invalid()                                    continue                                else:                                    self.log_error(exc.content)                                    self.fail_login(exc.content)                            else:                                self.log_error(exc.content)                                self.fail_login(exc.content)                        else:                            self.captcha.correct()                            data['token'] = json_data['auth_token']                            break                    else:                        self.log_error(_(""Max captcha retries reached""))                        self.fail_login(_(""Max captcha retries reached""))                elif 30 in errors:  #: ERROR_CAPTCHA_REQUIRED                    #: Normal captcha                    self.captcha = BaseCaptcha(pyfile)                    for i in range(10):                        json_data = self.api_request(""RequestCaptcha"")                        if json_data['code'] != 200:                            self.log_error(self._(""Request captcha API failed""))                            self.fail_login(self._(""Request captcha API failed""))                        captcha_response = self.captcha.decrypt(json_data['captcha_url'])                        try:                            json_data = self.api_request(""login"",                                                          username=user,                                                          password=password,                                                          captcha_challenge=json_data['challenge'],                                                          captcha_response=captcha_response)                        except BadHeader as exc:                            if exc.code == 406:                                errors = [json.loads(m.group(0)).get('errorCode', 0) for m in re.finditer(r'{[^}]+}', exc.content)]                                if 31 in errors:  #: ERROR_CAPTCHA_INVALID                                    self.captcha.invalid()                                    continue                                else:                                    self.log_error(exc.content)                                    self.fail_login(exc.content)                            else:                                self.log_error(exc.content)                                self.fail_login(exc.content)                        else:                            self.captcha.correct()                            data['token'] = json_data['auth_token']                            break                    else:                        self.log_error(self._(""Max captcha retries reached""))                        self.fail_login(self._(""Max captcha retries reached""))                else:                    self.log_error(exc.content)                    self.fail_login(exc.content)            else:                self.log_error(exc.content)                self.fail_login(exc.content)        else:            #: No captcha            data['token'] = json_data['auth_token']",b8203d8d-e9ec-497d-a667-0fd812a06a25
accounts,FileboomMe.py,check_status,163,164,def check_status(self):        pass,,def check_status(self):        pass,9173e708-ee14-4a27-bc75-d23f29d29a71
accounts,FileboomMe.py,retry_captcha,166,168,"def retry_captcha(self, attempts=10, wait=1, msg=""Max captcha retries reached""):        self.captcha.invalid()        self.fail_login(msg=self._(""Invalid captcha""))",,"def retry_captcha(self, attempts=10, wait=1, msg=""Max captcha retries reached""):        self.captcha.invalid()        self.fail_login(msg=self._(""Invalid captcha""))",3fbe8a8b-528a-4795-ab8b-6a9d4ba8168d
accounts,FilecloudIo.py,grab_info,22,51,"def grab_info(self, user, password, data):        #: It looks like the first API request always fails, so we retry 5 times, it should work on the second try        for _ in range(5):            rep = self.load(                ""https://secure.filecloud.io/api-fetch_apikey.api"",                post={""username"": user, ""password"": password},            )            rep = json.loads(rep)            if rep[""status""] == ""ok"":                break            elif (                rep[""status""] == ""error""                and rep[""message""] == ""no such user or wrong password""            ):                self.log_error(self._(""Wrong username or password""))                return {""valid"": False, ""premium"": False}        else:            return {""premium"": False}        akey = rep[""akey""]        self.accounts[user][""akey""] = akey  #: Saved for hoster plugin        rep = self.load(            ""http://api.filecloud.io/api-fetch_account_details.api"", post={""akey"": akey}        )        rep = json.loads(rep)        if rep[""is_premium""] == 1:            return {""validuntil"": float(rep[""premium_until""]), ""trafficleft"": -1}        else:            return {""premium"": False}",,"def grab_info(self, user, password, data):        #: It looks like the first API request always fails, so we retry 5 times, it should work on the second try        for _ in range(5):            rep = self.load(                ""https://secure.filecloud.io/api-fetch_apikey.api"",                post={""username"": user, ""password"": password},            )            rep = json.loads(rep)            if rep[""status""] == ""ok"":                break            elif (                rep[""status""] == ""error""                and rep[""message""] == ""no such user or wrong password""            ):                self.log_error(self._(""Wrong username or password""))                return {""valid"": False, ""premium"": False}        else:            return {""premium"": False}        akey = rep[""akey""]        self.accounts[user][""akey""] = akey  #: Saved for hoster plugin        rep = self.load(            ""http://api.filecloud.io/api-fetch_account_details.api"", post={""akey"": akey}        )        rep = json.loads(rep)        if rep[""is_premium""] == 1:            return {""validuntil"": float(rep[""premium_until""]), ""trafficleft"": -1}        else:            return {""premium"": False}",f233f1a8-2e86-4928-987b-5dca8edf549f
accounts,FilecloudIo.py,signin,53,68,"def signin(self, user, password, data):        set_cookie(self.req.cj, ""secure.filecloud.io"", ""lang"", ""en"")        html = self.load(""https://secure.filecloud.io/user-login.html"")        if not hasattr(self, ""form_data""):            self.form_data = {}        self.form_data[""username""] = user        self.form_password = password        html = self.load(            ""https://secure.filecloud.io/user-login_p.html"", post=self.form_data        )        if ""you have successfully logged in"" not in html:            self.fail_login()",,"def signin(self, user, password, data):        set_cookie(self.req.cj, ""secure.filecloud.io"", ""lang"", ""en"")        html = self.load(""https://secure.filecloud.io/user-login.html"")        if not hasattr(self, ""form_data""):            self.form_data = {}        self.form_data[""username""] = user        self.form_password = password        html = self.load(            ""https://secure.filecloud.io/user-login_p.html"", post=self.form_data        )        if ""you have successfully logged in"" not in html:            self.fail_login()",bc2a170d-ecdd-4a43-b973-8c57346eb515
accounts,FilefactoryCom.py,grab_info,25,40,"def grab_info(self, user, password, data):        html = self.load(""http://www.filefactory.com/account/"")        m = re.search(self.VALID_UNTIL_PATTERN, html)        if m is not None:            premium = True            validuntil = re.sub(                self.VALID_UNTIL_PATTERN, r""\g<D> \g<M> \g<Y>"", m.group(0)            )            validuntil = time.mktime(time.strptime(validuntil, ""%d %b %Y""))        else:            premium = False            validuntil = -1        return {""premium"": premium, ""trafficleft"": -1, ""validuntil"": validuntil}",,"def grab_info(self, user, password, data):        html = self.load(""http://www.filefactory.com/account/"")        m = re.search(self.VALID_UNTIL_PATTERN, html)        if m is not None:            premium = True            validuntil = re.sub(                self.VALID_UNTIL_PATTERN, r""\g<D> \g<M> \g<Y>"", m.group(0)            )            validuntil = time.mktime(time.strptime(validuntil, ""%d %b %Y""))        else:            premium = False            validuntil = -1        return {""premium"": premium, ""trafficleft"": -1, ""validuntil"": validuntil}",fce359b6-8117-462c-bcb3-46ecd2034113
accounts,FilefactoryCom.py,signin,42,53,"def signin(self, user, password, data):        html = self.load(""https://www.filefactory.com/member/signin.php"")        if ""/member/signout.php"" in html:            self.skip_login()        html = self.load(            ""https://www.filefactory.com/member/signin.php"",            post={""loginEmail"": user, ""loginPassword"": password, ""Submit"": ""Sign In""},        )        if ""/member/signout.php"" not in html:            self.fail_login()",,"def signin(self, user, password, data):        html = self.load(""https://www.filefactory.com/member/signin.php"")        if ""/member/signout.php"" in html:            self.skip_login()        html = self.load(            ""https://www.filefactory.com/member/signin.php"",            post={""loginEmail"": user, ""loginPassword"": password, ""Submit"": ""Sign In""},        )        if ""/member/signout.php"" not in html:            self.fail_login()",7d57f43c-5666-4085-9eac-02e4c7cabcf9
accounts,FilejokerNet.py,api_request,21,24,"def api_request(self, op, **kwargs):        args = {""op"": op}        args.update(kwargs)        return json.loads(self.load(self.API_URL, get=args))",,"def api_request(self, op, **kwargs):        args = {""op"": op}        args.update(kwargs)        return json.loads(self.load(self.API_URL, get=args))",2f381210-1da5-42a9-846e-7e70d54d3e3e
accounts,FilejokerNet.py,grab_info,26,44,"def grab_info(self, user, password, data):        api_data = self.api_request(""my_account"", session=data[""session""])        premium_expire = api_data.get(""usr_premium_expire"")        validuntil = (            time.mktime(time.strptime(premium_expire, ""%Y-%m-%d %H:%M:%S""))            if premium_expire            else -1        )        trafficleft = (            int(api_data[""traffic_left""]) * 1024 ** 2 if ""traffic_left"" in api_data else None        )        premium = bool(premium_expire)        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""premium"": premium,        }",,"def grab_info(self, user, password, data):        api_data = self.api_request(""my_account"", session=data[""session""])        premium_expire = api_data.get(""usr_premium_expire"")        validuntil = (            time.mktime(time.strptime(premium_expire, ""%Y-%m-%d %H:%M:%S""))            if premium_expire            else -1        )        trafficleft = (            int(api_data[""traffic_left""]) * 1024 ** 2 if ""traffic_left"" in api_data else None        )        premium = bool(premium_expire)        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""premium"": premium,        }",084048a4-5ce9-44fb-9ce7-38e514548692
accounts,FilejokerNet.py,signin,46,55,"def signin(self, user, password, data):        session = data.get(""session"")        if session and ""error"" not in self.api_request(""my_account"", session=session):            self.skip_login()        api_data = self.api_request(""login"", **{""email"": user, ""pass"": password})        if ""error"" in api_data:            self.fail_login()        data[""session""] = api_data[""session""]",,"def signin(self, user, password, data):        session = data.get(""session"")        if session and ""error"" not in self.api_request(""my_account"", session=session):            self.skip_login()        api_data = self.api_request(""login"", **{""email"": user, ""pass"": password})        if ""error"" in api_data:            self.fail_login()        data[""session""] = api_data[""session""]",6179958d-8f7a-49b2-86ed-5dfbccbb0848
accounts,FilerNet.py,grab_info,27,50,"def grab_info(self, user, password, data):        html = self.load(""https://filer.net/profile"")        #: Free user        if re.search(self.FREE_PATTERN, html) is not None:            return {""premium"": False, ""validuntil"": None, ""trafficleft"": None}        until = re.search(self.VALID_UNTIL_PATTERN, html)        traffic = re.search(self.TRAFFIC_LEFT_PATTERN, html)        if until and traffic:            validuntil = time.mktime(                time.strptime(until.group(1), ""%d.%m.%Y, %H:%M:%S"")            )            trafficleft = self.parse_traffic(traffic.group(1), traffic.group(2))            return {                ""premium"": True,                ""validuntil"": validuntil,                ""trafficleft"": trafficleft,            }        else:            self.log_error(self._(""Unable to retrieve account information""))            return {""premium"": False, ""validuntil"": None, ""trafficleft"": None}",,"def grab_info(self, user, password, data):        html = self.load(""https://filer.net/profile"")        #: Free user        if re.search(self.FREE_PATTERN, html) is not None:            return {""premium"": False, ""validuntil"": None, ""trafficleft"": None}        until = re.search(self.VALID_UNTIL_PATTERN, html)        traffic = re.search(self.TRAFFIC_LEFT_PATTERN, html)        if until and traffic:            validuntil = time.mktime(                time.strptime(until.group(1), ""%d.%m.%Y, %H:%M:%S"")            )            trafficleft = self.parse_traffic(traffic.group(1), traffic.group(2))            return {                ""premium"": True,                ""validuntil"": validuntil,                ""trafficleft"": trafficleft,            }        else:            self.log_error(self._(""Unable to retrieve account information""))            return {""premium"": False, ""validuntil"": None, ""trafficleft"": None}",183c05d6-5150-4789-83da-fee929ce4fe6
accounts,FilerNet.py,signin,52,72,"def signin(self, user, password, data):        html = self.load(""https://filer.net/login"")        if re.search(self.LOGIN_SKIP_PATTERN, html) is not None:            self.skip_login()        token = re.search(self.TOKEN_PATTERN, html).group(1)        html = self.load(            ""https://filer.net/login_check"",            post={                ""_username"": user,                ""_password"": password,                ""_remember_me"": ""on"",                ""_csrf_token"": token,                ""_target_path"": ""https://filer.net/"",            },        )        if re.search(self.LOGIN_SKIP_PATTERN, html) is None:            self.fail_login()",,"def signin(self, user, password, data):        html = self.load(""https://filer.net/login"")        if re.search(self.LOGIN_SKIP_PATTERN, html) is not None:            self.skip_login()        token = re.search(self.TOKEN_PATTERN, html).group(1)        html = self.load(            ""https://filer.net/login_check"",            post={                ""_username"": user,                ""_password"": password,                ""_remember_me"": ""on"",                ""_csrf_token"": token,                ""_target_path"": ""https://filer.net/"",            },        )        if re.search(self.LOGIN_SKIP_PATTERN, html) is None:            self.fail_login()",ff0ad58f-af9a-4df8-8c3f-c0048b22b93a
accounts,FilesMailRu.py,grab_info,16,17,"def grab_info(self, user, password, data):        return {""validuntil"": None, ""trafficleft"": None}",,"def grab_info(self, user, password, data):        return {""validuntil"": None, ""trafficleft"": None}",cccee164-cdf4-4cf7-ba08-0fe0ba3b40e9
accounts,FilesMailRu.py,signin,19,33,"def signin(self, user, password, data):        user, domain = user.split(""@"")        html = self.load(            ""https://swa.mail.ru/cgi-bin/auth"",            post={                ""Domain"": domain,                ""Login"": user,                ""Password"": password,                ""Page"": ""http://files.mail.ru/"",            },        )        if ""Неверное имя пользователя или пароль"" in html:            self.fail_login()",,"def signin(self, user, password, data):        user, domain = user.split(""@"")        html = self.load(            ""https://swa.mail.ru/cgi-bin/auth"",            post={                ""Domain"": domain,                ""Login"": user,                ""Password"": password,                ""Page"": ""http://files.mail.ru/"",            },        )        if ""Неверное имя пользователя или пароль"" in html:            self.fail_login()",e6bb1647-e613-41da-8898-6eb73d676fd4
accounts,FileStoreTo.py,grab_info,22,32,"def grab_info(self, user, password, data):        premium = False        validuntil = None        html = self.load(""https://filestore.to/konto"")        m = re.search(self.VALID_UNTIL_PATTERN, html)        if m is not None:            validuntil = time.mktime(time.strptime(m.group(1), ""%d.%m.%Y - %H:%M""))            premium = validuntil > time.time()        return {""validuntil"": validuntil, ""trafficleft"": -1, ""premium"": premium}",,"def grab_info(self, user, password, data):        premium = False        validuntil = None        html = self.load(""https://filestore.to/konto"")        m = re.search(self.VALID_UNTIL_PATTERN, html)        if m is not None:            validuntil = time.mktime(time.strptime(m.group(1), ""%d.%m.%Y - %H:%M""))            premium = validuntil > time.time()        return {""validuntil"": validuntil, ""trafficleft"": -1, ""premium"": premium}",0ec41e4d-b950-414a-8720-44258a9ab107
accounts,FileStoreTo.py,signin,34,45,"def signin(self, user, password, data):        html = self.load(self.LOGIN_URL)        if 'href=""logout""' in html:            self.skip_login()        else:            html = self.load(                self.LOGIN_URL,                post={""Email"": user, ""Password"": password, ""Aktion"": ""Login""},            )            if 'href=""logout""' not in html:                self.fail_login()",,"def signin(self, user, password, data):        html = self.load(self.LOGIN_URL)        if 'href=""logout""' in html:            self.skip_login()        else:            html = self.load(                self.LOGIN_URL,                post={""Email"": user, ""Password"": password, ""Aktion"": ""Login""},            )            if 'href=""logout""' not in html:                self.fail_login()",a2026fc8-498b-4612-a3e6-be5693d74eb8
accounts,FourSharedCom.py,grab_info,20,22,"def grab_info(self, user, password, data):        #: Free mode only for now        return {""premium"": False}",,"def grab_info(self, user, password, data):        #: Free mode only for now        return {""premium"": False}",e3d8f173-bc8a-46e3-b534-e6607dd44e05
accounts,FourSharedCom.py,signin,24,39,"def signin(self, user, password, data):        set_cookie(self.req.cj, ""4shared.com"", ""4langcookie"", ""en"")        res = self.load(            ""https://www.4shared.com/web/login"",            post={                ""login"": user,                ""password"": password,                ""remember"": ""on"",                ""_remember"": ""on"",                ""returnTo"": ""http://www.4shared.com/account/home.jsp"",            },        )        if ""Please log in to access your 4shared account"" in res:            self.fail_login()",,"def signin(self, user, password, data):        set_cookie(self.req.cj, ""4shared.com"", ""4langcookie"", ""en"")        res = self.load(            ""https://www.4shared.com/web/login"",            post={                ""login"": user,                ""password"": password,                ""remember"": ""on"",                ""_remember"": ""on"",                ""returnTo"": ""http://www.4shared.com/account/home.jsp"",            },        )        if ""Please log in to access your 4shared account"" in res:            self.fail_login()",4049c1e7-b2c8-429c-8c18-a016769a3e75
accounts,FshareVn.py,api_request,29,52,"def api_request(self, method, session_id=None, **kwargs):        self.req.http.c.setopt(pycurl.USERAGENT, self.API_USERAGENT)        if len(kwargs) == 0:            json_data = self.load(                self.API_URL + method,                cookies=[(""fshare.vn"", ""session_id"", session_id)]                if session_id                else True,            )        else:            self.req.http.c.setopt(                pycurl.HTTPHEADER, [""Content-Type: application/json""]            )            json_data = self.load(                self.API_URL + method,                post=json.dumps(kwargs),                cookies=[(""fshare.vn"", ""session_id"", session_id)]                if session_id                else True,            )        return json.loads(json_data)",,"def api_request(self, method, session_id=None, **kwargs):        self.req.http.c.setopt(pycurl.USERAGENT, self.API_USERAGENT)        if len(kwargs) == 0:            json_data = self.load(                self.API_URL + method,                cookies=[(""fshare.vn"", ""session_id"", session_id)]                if session_id                else True,            )        else:            self.req.http.c.setopt(                pycurl.HTTPHEADER, [""Content-Type: application/json""]            )            json_data = self.load(                self.API_URL + method,                post=json.dumps(kwargs),                cookies=[(""fshare.vn"", ""session_id"", session_id)]                if session_id                else True,            )        return json.loads(json_data)",3404218c-96be-485c-8659-a64f50a99266
accounts,FshareVn.py,grab_info,54,70,"def grab_info(self, user, password, data):        trafficleft = None        premium = False        api_data = self.api_request(""user/get"", session_id=data[""session_id""])        expire_vip = api_data.get(""expire_vip"", """")        validuntil = float(expire_vip) if expire_vip.isnumeric() else None        if validuntil:            premium = True        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""premium"": premium,        }",,"def grab_info(self, user, password, data):        trafficleft = None        premium = False        api_data = self.api_request(""user/get"", session_id=data[""session_id""])        expire_vip = api_data.get(""expire_vip"", """")        validuntil = float(expire_vip) if expire_vip.isnumeric() else None        if validuntil:            premium = True        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""premium"": premium,        }",3fe377c6-a83f-4d65-a5c2-a33d550ff4e1
accounts,FshareVn.py,signin,72,117,"def signin(self, user, password, data):        user = user.lower()        fshare_session_cache = self.db.retrieve(""fshare_session_cache"") or {}        if user in fshare_session_cache:            data[""token""] = fshare_session_cache[user][""token""]            data[""session_id""] = fshare_session_cache[user][""session_id""]            try:                api_data = self.api_request(""user/get"", session_id=data[""session_id""])            except BadHeader as exc:                if exc.code == 401:                    del fshare_session_cache[user]                    self.db.store(""fshare_session_cache"", fshare_session_cache)            if api_data.get(""email"", """").lower() == user:                self.skip_login()            else:                del fshare_session_cache[user]                self.db.store(""fshare_session_cache"", fshare_session_cache)        data[""token""] = None        data[""session_id""] = None        try:            api_data = self.api_request(                ""user/login"", app_key=self.API_KEY, user_email=user, password=password            )        except BadHeader as exc:            self.log_error(self._(""Login failed, error code {}"").format(exc.code))            self.fail_login()        if api_data[""code""] != 200:            self.log_error(api_data[""msg""])            self.fail_login()        fshare_session_cache[user] = {            ""token"": api_data[""token""],            ""session_id"": api_data[""session_id""],        }        self.db.store(""fshare_session_cache"", fshare_session_cache)        data[""token""] = fshare_session_cache[user][""token""]        data[""session_id""] = fshare_session_cache[user][""session_id""]",,"def signin(self, user, password, data):        user = user.lower()        fshare_session_cache = self.db.retrieve(""fshare_session_cache"") or {}        if user in fshare_session_cache:            data[""token""] = fshare_session_cache[user][""token""]            data[""session_id""] = fshare_session_cache[user][""session_id""]            try:                api_data = self.api_request(""user/get"", session_id=data[""session_id""])            except BadHeader as exc:                if exc.code == 401:                    del fshare_session_cache[user]                    self.db.store(""fshare_session_cache"", fshare_session_cache)            if api_data.get(""email"", """").lower() == user:                self.skip_login()            else:                del fshare_session_cache[user]                self.db.store(""fshare_session_cache"", fshare_session_cache)        data[""token""] = None        data[""session_id""] = None        try:            api_data = self.api_request(                ""user/login"", app_key=self.API_KEY, user_email=user, password=password            )        except BadHeader as exc:            self.log_error(self._(""Login failed, error code {}"").format(exc.code))            self.fail_login()        if api_data[""code""] != 200:            self.log_error(api_data[""msg""])            self.fail_login()        fshare_session_cache[user] = {            ""token"": api_data[""token""],            ""session_id"": api_data[""session_id""],        }        self.db.store(""fshare_session_cache"", fshare_session_cache)        data[""token""] = fshare_session_cache[user][""token""]        data[""session_id""] = fshare_session_cache[user][""session_id""]",f8e3b1c2-07f5-4622-8294-000f9edd293e
accounts,GetTwentyFourOrg.py,api_request,24,29,"def api_request(self, method, **kwargs):        self.req.http.c.setopt(            pycurl.USERAGENT, ""pyLoad/{}"".format(self.pyload.version).encode()        )        json_data = self.load(self.API_URL + method, post=kwargs)        return json.loads(json_data)",,"def api_request(self, method, **kwargs):        self.req.http.c.setopt(            pycurl.USERAGENT, ""pyLoad/{}"".format(self.pyload.version).encode()        )        json_data = self.load(self.API_URL + method, post=kwargs)        return json.loads(json_data)",afae9658-8fbb-4def-816f-7868bcbd6fd1
accounts,GetTwentyFourOrg.py,grab_hosters,31,34,"def grab_hosters(self, user, password, data):        hosts = self.api_request(""hosts/enabled"")        self.log_debug(hosts)        return hosts",,"def grab_hosters(self, user, password, data):        hosts = self.api_request(""hosts/enabled"")        self.log_debug(hosts)        return hosts",15023a0d-ea80-41f8-9c69-47c3a73abea8
accounts,GetTwentyFourOrg.py,grab_info,36,48,"def grab_info(self, user, password, data):        rc = self.api_request(            ""login"", email=user, passwd_sha256=self.info[""data""][""passwd_sha256""]        )        self.log_debug(rc)        validuntil = time.mktime(time.strptime(rc[""date_expire""], ""%Y-%m-%d %H:%M:%S""))        return {            ""validuntil"": validuntil,            ""trafficleft"": rc[""transfer_left""] * 2 ** 30,  # gb -> b            ""premium"": rc[""status""] == ""premium"",        }",,"def grab_info(self, user, password, data):        rc = self.api_request(            ""login"", email=user, passwd_sha256=self.info[""data""][""passwd_sha256""]        )        self.log_debug(rc)        validuntil = time.mktime(time.strptime(rc[""date_expire""], ""%Y-%m-%d %H:%M:%S""))        return {            ""validuntil"": validuntil,            ""trafficleft"": rc[""transfer_left""] * 2 ** 30,  # gb -> b            ""premium"": rc[""status""] == ""premium"",        }",769a66c4-a40f-4a6a-9124-840695887681
accounts,GetTwentyFourOrg.py,signin,50,55,"def signin(self, user, password, data):        data[""passwd_sha256""] = sha256(password.encode(""ascii"")).hexdigest()        rc = self.api_request(""login"", email=user, passwd_sha256=data[""passwd_sha256""])        if rc.get(""ok"") is False:            self.log_error(rc[""reason""])            self.fail_login()",,"def signin(self, user, password, data):        data[""passwd_sha256""] = sha256(password.encode(""ascii"")).hexdigest()        rc = self.api_request(""login"", email=user, passwd_sha256=data[""passwd_sha256""])        if rc.get(""ok"") is False:            self.log_error(rc[""reason""])            self.fail_login()",df2ab1dc-0b31-4351-bd53-1a56b7cb76f8
accounts,HellshareCz.py,grab_info,22,61,"def grab_info(self, user, password, data):        html = self.load(""http://www.hellshare.com/"")        m = re.search(self.CREDIT_LEFT_PATTERN, html)        if m is None:            trafficleft = None            validuntil = None            premium = False        else:            credit = m.group(1)            premium = True            try:                if ""."" in credit:                    #: Time-based account                    vt = [int(x) for x in credit.split(""."")[:2]]                    lt = time.localtime()                    year = lt.tm_year + int(                        vt[1] < lt.tm_mon or (vt[1] == lt.tm_mon and vt[0] < lt.tm_mday)                    )                    validuntil = time.mktime(                        time.strptime(                            ""{}{} 23:59:59"".format(credit, year), ""%d.%m.%Y %H:%M:%S""                        )                    )                    trafficleft = -1                else:                    #: Traffic-based account                    trafficleft = self.parse_traffic(credit, ""MiB"")                    validuntil = -1            except Exception as exc:                self.log_error(self._(""Unable to parse credit info""), exc)                validuntil = -1                trafficleft = -1        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""premium"": premium,        }",,"def grab_info(self, user, password, data):        html = self.load(""http://www.hellshare.com/"")        m = re.search(self.CREDIT_LEFT_PATTERN, html)        if m is None:            trafficleft = None            validuntil = None            premium = False        else:            credit = m.group(1)            premium = True            try:                if ""."" in credit:                    #: Time-based account                    vt = [int(x) for x in credit.split(""."")[:2]]                    lt = time.localtime()                    year = lt.tm_year + int(                        vt[1] < lt.tm_mon or (vt[1] == lt.tm_mon and vt[0] < lt.tm_mday)                    )                    validuntil = time.mktime(                        time.strptime(                            ""{}{} 23:59:59"".format(credit, year), ""%d.%m.%Y %H:%M:%S""                        )                    )                    trafficleft = -1                else:                    #: Traffic-based account                    trafficleft = self.parse_traffic(credit, ""MiB"")                    validuntil = -1            except Exception as exc:                self.log_error(self._(""Unable to parse credit info""), exc)                validuntil = -1                trafficleft = -1        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""premium"": premium,        }",57d32681-44eb-4c99-8c76-b4b0f535bf6d
accounts,HellshareCz.py,signin,63,92,"def signin(self, user, password, data):        html = self.load(""http://www.hellshare.com/"")        if self.req.last_effective_url != ""http://www.hellshare.com/"":            #: Switch to English            self.log_debug(f""Switch lang - URL: {self.req.last_effective_url}"")            json = self.load(f""{self.req.last_effective_url}?do=locRouter-show"")            hash = re.search(r""(--[0-9a-f]+\-)"", json).group(1)            self.log_debug(f""Switch lang - HASH: {hash}"")            html = self.load(""http://www.hellshare.com/{}/"".format(hash))        if re.search(self.CREDIT_LEFT_PATTERN, html):            self.log_debug(""Already logged in"")            return        html = self.load(            ""https://www.hellshare.com/login"",            get={""do"": ""loginForm-submit""},            post={                ""login"": ""Log in"",                ""password"": password,                ""username"": user,                ""perm_login"": ""on"",            },        )        if ""<p>You input a wrong user name or wrong password</p>"" in html:            self.fail_login()",,"def signin(self, user, password, data):        html = self.load(""http://www.hellshare.com/"")        if self.req.last_effective_url != ""http://www.hellshare.com/"":            #: Switch to English            self.log_debug(f""Switch lang - URL: {self.req.last_effective_url}"")            json = self.load(f""{self.req.last_effective_url}?do=locRouter-show"")            hash = re.search(r""(--[0-9a-f]+\-)"", json).group(1)            self.log_debug(f""Switch lang - HASH: {hash}"")            html = self.load(""http://www.hellshare.com/{}/"".format(hash))        if re.search(self.CREDIT_LEFT_PATTERN, html):            self.log_debug(""Already logged in"")            return        html = self.load(            ""https://www.hellshare.com/login"",            get={""do"": ""loginForm-submit""},            post={                ""login"": ""Log in"",                ""password"": password,                ""username"": user,                ""perm_login"": ""on"",            },        )        if ""<p>You input a wrong user name or wrong password</p>"" in html:            self.fail_login()",75999441-2482-4aaf-bd8d-308c67f5d96e
accounts,HighWayMe.py,api_request,27,32,"def api_request(self, method, **kwargs):        post = dict([(k.lstrip('_'), v) for k, v in kwargs.items()])        json_data = self.load(self.API_URL,                              get={method: ''},                              post=post)        return json.loads(json_data)",,"def api_request(self, method, **kwargs):        post = dict([(k.lstrip('_'), v) for k, v in kwargs.items()])        json_data = self.load(self.API_URL,                              get={method: ''},                              post=post)        return json.loads(json_data)",78a4ca40-b6dd-45ba-b5fb-3bda9970fe90
accounts,HighWayMe.py,grab_hosters,34,36,"def grab_hosters(self, user, password, data):        json_data = self.api_request(""hoster"")        return [element[""name""] for element in json_data[""hoster""]]",,"def grab_hosters(self, user, password, data):        json_data = self.api_request(""hoster"")        return [element[""name""] for element in json_data[""hoster""]]",35c0b6c0-f4cd-4cbf-b18e-6db944ed8ab8
accounts,HighWayMe.py,grab_info,38,58,"def grab_info(self, user, password, data):        premium = False        validuntil = -1        trafficleft = None        json_data = self.api_request(""user"")        if ""premium"" in json_data[""user""] and json_data[""user""][""premium""]:            premium = True        if 'premium_bis' in json_data['user'] and json_data['user']['premium_bis']:            validuntil = float(json_data[""user""][""premium_bis""])        if 'premium_traffic' in json_data['user'] and json_data['user']['premium_traffic']:            trafficleft = int(json_data[""user""][""premium_traffic""])        return {            ""premium"": premium,            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,        }",,"def grab_info(self, user, password, data):        premium = False        validuntil = -1        trafficleft = None        json_data = self.api_request(""user"")        if ""premium"" in json_data[""user""] and json_data[""user""][""premium""]:            premium = True        if 'premium_bis' in json_data['user'] and json_data['user']['premium_bis']:            validuntil = float(json_data[""user""][""premium_bis""])        if 'premium_traffic' in json_data['user'] and json_data['user']['premium_traffic']:            trafficleft = int(json_data[""user""][""premium_traffic""])        return {            ""premium"": premium,            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,        }",20be0679-822e-45e6-adb3-25bf144c9928
accounts,HighWayMe.py,signin,60,64,"def signin(self, user, password, data):        json_data = self.api_request(""login"", user=user, _pass=password)        if not json_data.get('loggedin', False):            self.fail_login()",,"def signin(self, user, password, data):        json_data = self.api_request(""login"", user=user, _pass=password)        if not json_data.get('loggedin', False):            self.fail_login()",5d287c00-70be-4055-9347-bd6091ff0213
accounts,Http.py,grab_info,17,18,"def grab_info(self, user, password, data):        pass",,"def grab_info(self, user, password, data):        pass",5d784e35-413a-4f13-97be-e22ff59e9449
accounts,Http.py,signin,20,21,"def signin(self, user, password, data):        pass",,"def signin(self, user, password, data):        pass",aa3b9882-18f7-47e0-8eb2-0c4743696a49
accounts,IronfilesNet.py,api_request,21,23,"def api_request(self, method, **kwargs):        json_data = self.load(self.API_URL + method, get=kwargs)        return json.loads(json_data)",,"def api_request(self, method, **kwargs):        json_data = self.load(self.API_URL + method, get=kwargs)        return json.loads(json_data)",80560dce-22f8-4d87-9343-297eebf08f92
accounts,IronfilesNet.py,grab_info,25,37,"def grab_info(self, user, password, data):        json_data = self.api_request(""accountStatus"")        expires = json_data[""expires""].split(""T"", 1)        validuntil = time.mktime(            time.strptime(expires[0] + expires[1][:8], ""%Y-%m-%d%H:%M:%S"")        )        return {            ""validuntil"": validuntil,            ""trafficleft"": -1,            ""premium"": json_data[""premium""],        }",,"def grab_info(self, user, password, data):        json_data = self.api_request(""accountStatus"")        expires = json_data[""expires""].split(""T"", 1)        validuntil = time.mktime(            time.strptime(expires[0] + expires[1][:8], ""%Y-%m-%d%H:%M:%S"")        )        return {            ""validuntil"": validuntil,            ""trafficleft"": -1,            ""premium"": json_data[""premium""],        }",78374d71-36d4-475c-a239-5bac46f98518
accounts,IronfilesNet.py,signin,39,43,"def signin(self, user, password, data):        json_data = self.api_request(""auth"", login=user, password=password)        if not json_data[""result""]:            self.fail_login(json_data[""message""])",,"def signin(self, user, password, data):        json_data = self.api_request(""auth"", login=user, password=password)        if not json_data[""result""]:            self.fail_login(json_data[""message""])",ce9e3f15-2a51-4613-b38b-2843aa807014
accounts,Keep2ShareCc.py,api_request,33,35,"def api_request(self, method, **kwargs):        html = self.load(self.API_URL + method, post=json.dumps(kwargs))        return json.loads(html)",,"def api_request(self, method, **kwargs):        html = self.load(self.API_URL + method, post=json.dumps(kwargs))        return json.loads(html)",e65e12cc-dc4c-4816-8f93-c957722c5ff0
accounts,Keep2ShareCc.py,grab_info,37,44,"def grab_info(self, user, password, data):        json_data = self.api_request(""AccountInfo"", auth_token=data[""token""])        return {            ""validuntil"": json_data[""account_expires""],            ""trafficleft"": json_data[""available_traffic""],            ""premium"": True if json_data[""account_expires""] else False,        }",,"def grab_info(self, user, password, data):        json_data = self.api_request(""AccountInfo"", auth_token=data[""token""])        return {            ""validuntil"": json_data[""account_expires""],            ""trafficleft"": json_data[""available_traffic""],            ""premium"": True if json_data[""account_expires""] else False,        }",0403b670-01bb-49ed-9790-5f734cb5d0f7
accounts,Keep2ShareCc.py,signin,46,190,"def signin(self, user, password, data):        if ""token"" in data:            try:                json_data = self.api_request(""test"", auth_token=data[""token""])            except BadHeader as exc:                if exc.code == 403:  #: Session expired                    pass                else:                    raise            else:                self.skip_login()        try:            json_data = self.api_request(""login"", username=user, password=password)        except BadHeader as exc:            if exc.code == 406:  #: Captcha needed                # dummy pyfile                pyfile = PyFile(                    self.pyload.files,                    -1,                    ""https://k2s.cc"",                    ""https://k2s.cc"",                    0,                    0,                    """",                    self.classname,                    -1,                    -1,                )                pyfile.plugin = self                errors = [                    json.loads(m.group(0)).get(""errorCode"", 0)                    for m in re.finditer(r""{[^}]+}"", exc.content)                ]                if 33 in errors:  #: ERROR_RE_CAPTCHA_REQUIRED                    #: Recaptcha                    self.captcha = ReCaptcha(pyfile)                    for i in range(10):                        json_data = self.api_request(""RequestReCaptcha"")                        if json_data[""code""] != 200:                            self.log_error(_(""Request reCAPTCHA API failed""))                            self.fail_login(_(""Request reCAPTCHA API failed""))                        re_captcha_response = self.captcha.challenge(                            self.RECAPTCHA_KEY, version=""2js"", secure_token=False                        )                        try:                            json_data = self.api_request(                                ""login"",                                username=user,                                password=password,                                re_captcha_challenge=json_data[""challenge""],                                re_captcha_response=re_captcha_response,                            )                        except BadHeader as exc:                            if exc.code == 406:                                errors = [                                    json.loads(m.group(0)).get(""errorCode"", 0)                                    for m in re.finditer(r""{[^}]+}"", exc.content)                                ]                                if 31 in errors:  #: ERROR_CAPTCHA_INVALID                                    self.captcha.invalid()                                    continue                                else:                                    self.log_error(exc.content)                                    self.fail_login(exc.content)                            else:                                self.log_error(exc.content)                                self.fail_login(exc.content)                        else:                            self.captcha.correct()                            data[""token""] = json_data[""auth_token""]                            break                    else:                        self.log_error(_(""Max captcha retries reached""))                        self.fail_login(_(""Max captcha retries reached""))                elif 30 in errors:  #: ERROR_CAPTCHA_REQUIRED                    #: Normal captcha                    self.captcha = BaseCaptcha(pyfile)                    for i in range(10):                        json_data = self.api_request(""RequestCaptcha"")                        if json_data[""code""] != 200:                            self.log_error(self._(""Request captcha API failed""))                            self.fail_login(self._(""Request captcha API failed""))                        captcha_response = self.captcha.decrypt(                            json_data[""captcha_url""]                        )                        try:                            json_data = self.api_request(                                ""login"",                                username=user,                                password=password,                                captcha_challenge=json_data[""challenge""],                                captcha_response=captcha_response,                            )                        except BadHeader as exc:                            if exc.code == 406:                                errors = [                                    json.loads(m.group(0)).get(""errorCode"", 0)                                    for m in re.finditer(r""{[^}]+}"", exc.content)                                ]                                if 31 in errors:  #: ERROR_CAPTCHA_INVALID                                    self.captcha.invalid()                                    continue                                else:                                    self.log_error(exc.content)                                    self.fail_login(exc.content)                            else:                                self.log_error(exc.content)                                self.fail_login(exc.content)                        else:                            self.captcha.correct()                            data[""token""] = json_data[""auth_token""]                            break                    else:                        self.log_error(self._(""Max captcha retries reached""))                        self.fail_login(self._(""Max captcha retries reached""))                else:                    self.log_error(exc.content)                    self.fail_login(exc.content)            else:                self.log_error(exc.content)                self.fail_login(exc.content)        else:            #: No captcha            data[""token""] = json_data[""auth_token""]",,"def signin(self, user, password, data):        if ""token"" in data:            try:                json_data = self.api_request(""test"", auth_token=data[""token""])            except BadHeader as exc:                if exc.code == 403:  #: Session expired                    pass                else:                    raise            else:                self.skip_login()        try:            json_data = self.api_request(""login"", username=user, password=password)        except BadHeader as exc:            if exc.code == 406:  #: Captcha needed                # dummy pyfile                pyfile = PyFile(                    self.pyload.files,                    -1,                    ""https://k2s.cc"",                    ""https://k2s.cc"",                    0,                    0,                    """",                    self.classname,                    -1,                    -1,                )                pyfile.plugin = self                errors = [                    json.loads(m.group(0)).get(""errorCode"", 0)                    for m in re.finditer(r""{[^}]+}"", exc.content)                ]                if 33 in errors:  #: ERROR_RE_CAPTCHA_REQUIRED                    #: Recaptcha                    self.captcha = ReCaptcha(pyfile)                    for i in range(10):                        json_data = self.api_request(""RequestReCaptcha"")                        if json_data[""code""] != 200:                            self.log_error(_(""Request reCAPTCHA API failed""))                            self.fail_login(_(""Request reCAPTCHA API failed""))                        re_captcha_response = self.captcha.challenge(                            self.RECAPTCHA_KEY, version=""2js"", secure_token=False                        )                        try:                            json_data = self.api_request(                                ""login"",                                username=user,                                password=password,                                re_captcha_challenge=json_data[""challenge""],                                re_captcha_response=re_captcha_response,                            )                        except BadHeader as exc:                            if exc.code == 406:                                errors = [                                    json.loads(m.group(0)).get(""errorCode"", 0)                                    for m in re.finditer(r""{[^}]+}"", exc.content)                                ]                                if 31 in errors:  #: ERROR_CAPTCHA_INVALID                                    self.captcha.invalid()                                    continue                                else:                                    self.log_error(exc.content)                                    self.fail_login(exc.content)                            else:                                self.log_error(exc.content)                                self.fail_login(exc.content)                        else:                            self.captcha.correct()                            data[""token""] = json_data[""auth_token""]                            break                    else:                        self.log_error(_(""Max captcha retries reached""))                        self.fail_login(_(""Max captcha retries reached""))                elif 30 in errors:  #: ERROR_CAPTCHA_REQUIRED                    #: Normal captcha                    self.captcha = BaseCaptcha(pyfile)                    for i in range(10):                        json_data = self.api_request(""RequestCaptcha"")                        if json_data[""code""] != 200:                            self.log_error(self._(""Request captcha API failed""))                            self.fail_login(self._(""Request captcha API failed""))                        captcha_response = self.captcha.decrypt(                            json_data[""captcha_url""]                        )                        try:                            json_data = self.api_request(                                ""login"",                                username=user,                                password=password,                                captcha_challenge=json_data[""challenge""],                                captcha_response=captcha_response,                            )                        except BadHeader as exc:                            if exc.code == 406:                                errors = [                                    json.loads(m.group(0)).get(""errorCode"", 0)                                    for m in re.finditer(r""{[^}]+}"", exc.content)                                ]                                if 31 in errors:  #: ERROR_CAPTCHA_INVALID                                    self.captcha.invalid()                                    continue                                else:                                    self.log_error(exc.content)                                    self.fail_login(exc.content)                            else:                                self.log_error(exc.content)                                self.fail_login(exc.content)                        else:                            self.captcha.correct()                            data[""token""] = json_data[""auth_token""]                            break                    else:                        self.log_error(self._(""Max captcha retries reached""))                        self.fail_login(self._(""Max captcha retries reached""))                else:                    self.log_error(exc.content)                    self.fail_login(exc.content)            else:                self.log_error(exc.content)                self.fail_login(exc.content)        else:            #: No captcha            data[""token""] = json_data[""auth_token""]",bd4f3d9f-6dd4-4e14-8020-8b734fc2c64e
accounts,Keep2ShareCc.py,check_status,197,198,def check_status(self):        pass,,def check_status(self):        pass,3a12834a-c0d6-47ea-96bc-1f7a0a50b245
accounts,Keep2ShareCc.py,retry_captcha,200,202,"def retry_captcha(self, attempts=10, wait=1, msg=""Max captcha retries reached""):        self.captcha.invalid()        self.fail_login(msg=self._(""Invalid captcha""))",,"def retry_captcha(self, attempts=10, wait=1, msg=""Max captcha retries reached""):        self.captcha.invalid()        self.fail_login(msg=self._(""Invalid captcha""))",bc1e146d-860b-4d10-86b0-dba6ca7f5c82
accounts,LeechThreeHundreedSixtyCom.py,api_request,31,35,"def api_request(self, method, **kwargs):        if ""pass_"" in kwargs:            kwargs[""pass""] = kwargs.pop(""pass_"")        json_data = self.load(self.API_URL + method, get=kwargs)        return json.loads(json_data)",,"def api_request(self, method, **kwargs):        if ""pass_"" in kwargs:            kwargs[""pass""] = kwargs.pop(""pass_"")        json_data = self.load(self.API_URL + method, get=kwargs)        return json.loads(json_data)",47c52f7e-5857-4f6e-a492-ded7036508c5
accounts,LeechThreeHundreedSixtyCom.py,grab_hosters,37,44,"def grab_hosters(self, user, password, data):        api_data = self.api_request(""support"", token=data[""token""])        valid_status = (""online"", ""vip"") if self.info[""data""][""premium""] else (""online"")        return [            h[""hostname""]            for h in api_data[""data""].values()            if h[""status""] in valid_status        ]",,"def grab_hosters(self, user, password, data):        api_data = self.api_request(""support"", token=data[""token""])        valid_status = (""online"", ""vip"") if self.info[""data""][""premium""] else (""online"")        return [            h[""hostname""]            for h in api_data[""data""].values()            if h[""status""] in valid_status        ]",be04bc11-afe5-4d76-a8a8-1c207c1ef9b0
accounts,LeechThreeHundreedSixtyCom.py,grab_info,46,72,"def grab_info(self, user, password, data):        api_data = self.api_request(""userinfo"", token=data[""token""])        premium_expire = int(api_data[""data""].get(""premium_expire"", 0))        status = api_data[""data""][""status""]        if status == ""lifetime"":            premium = True            validuntil = -1        elif premium_expire > 0:            premium = True            validuntil = float(premium_expire)        else:            premium = False            validuntil = time.mktime(time.strptime(status, ""%b d %Y %I:%M %p""))        # TODO: Remove `>> 10` in 0.6.x        trafficleft = (            536_870_912_000 - int(api_data[""data""].get(""total_used"", 0))        )        return {            ""premium"": premium,            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,        }",,"def grab_info(self, user, password, data):        api_data = self.api_request(""userinfo"", token=data[""token""])        premium_expire = int(api_data[""data""].get(""premium_expire"", 0))        status = api_data[""data""][""status""]        if status == ""lifetime"":            premium = True            validuntil = -1        elif premium_expire > 0:            premium = True            validuntil = float(premium_expire)        else:            premium = False            validuntil = time.mktime(time.strptime(status, ""%b d %Y %I:%M %p""))        # TODO: Remove `>> 10` in 0.6.x        trafficleft = (            536_870_912_000 - int(api_data[""data""].get(""total_used"", 0))        )        return {            ""premium"": premium,            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,        }",2397f601-1f0b-487b-af52-a3cbff1bedc1
accounts,LeechThreeHundreedSixtyCom.py,signin,74,80,"def signin(self, user, password, data):        api_data = self.api_request(""token"", user=user, pass_=password)        if api_data[""error""]:            self.log_warning(api_data[""error_message""])            self.fail_login()        data[""token""] = api_data[""token""]",,"def signin(self, user, password, data):        api_data = self.api_request(""token"", user=user, pass_=password)        if api_data[""error""]:            self.log_warning(api_data[""error_message""])            self.fail_login()        data[""token""] = api_data[""token""]",07bd9e85-5d02-46b3-99ed-c9f69ff2bb98
accounts,LinkifierCom.py,api_request,30,44,"def api_request(self, method, user, password, **kwargs):        post = {            ""login"": user,            ""md5Pass"": hashlib.md5(password.encode()).hexdigest(),            ""apiKey"": self.API_KEY,        }        post.update(kwargs)        self.req.http.c.setopt(            pycurl.HTTPHEADER, [""Content-Type: application/json; charset=utf-8""]        )        res = json.loads(self.load(self.API_URL + method, post=json.dumps(post)))        self.req.http.c.setopt(            pycurl.HTTPHEADER, [""Content-Type: text/html; charset=utf-8""]        )        return res",,"def api_request(self, method, user, password, **kwargs):        post = {            ""login"": user,            ""md5Pass"": hashlib.md5(password.encode()).hexdigest(),            ""apiKey"": self.API_KEY,        }        post.update(kwargs)        self.req.http.c.setopt(            pycurl.HTTPHEADER, [""Content-Type: application/json; charset=utf-8""]        )        res = json.loads(self.load(self.API_URL + method, post=json.dumps(post)))        self.req.http.c.setopt(            pycurl.HTTPHEADER, [""Content-Type: text/html; charset=utf-8""]        )        return res",ce956623-033b-442e-9e79-29a726ba4eb0
accounts,LinkifierCom.py,grab_hosters,46,56,"def grab_hosters(self, user, password, data):        json_data = self.api_request(""hosters"", user, password)        if json_data[""hasErrors""]:            self.log_warning(json_data[""ErrorMSG""] or ""Unknown error"")            return []        return [            x[""hostername""]            for x in json_data[""hosters""]            if x[""hostername""] and x[""isActive""]        ]",,"def grab_hosters(self, user, password, data):        json_data = self.api_request(""hosters"", user, password)        if json_data[""hasErrors""]:            self.log_warning(json_data[""ErrorMSG""] or ""Unknown error"")            return []        return [            x[""hostername""]            for x in json_data[""hosters""]            if x[""hostername""] and x[""isActive""]        ]",10cdf7b2-e697-44e0-b3a8-e32dd9bfbfc8
accounts,LinkifierCom.py,grab_info,58,69,"def grab_info(self, user, password, data):        json_data = self.api_request(""user"", user, password)        trafficleft = json_data[""extraTraffic""]        validuntil = float(json_data[""expirydate""]) / 1000        return {            ""validuntil"": validuntil,            ""trafficleft"": -1            if trafficleft.lower() == ""unlimited""            else int(trafficleft) * 1024,            ""premium"": True,        }",,"def grab_info(self, user, password, data):        json_data = self.api_request(""user"", user, password)        trafficleft = json_data[""extraTraffic""]        validuntil = float(json_data[""expirydate""]) / 1000        return {            ""validuntil"": validuntil,            ""trafficleft"": -1            if trafficleft.lower() == ""unlimited""            else int(trafficleft) * 1024,            ""premium"": True,        }",e4b3237c-8b96-4fa0-90f7-c6254a7b8a47
accounts,LinkifierCom.py,signin,71,75,"def signin(self, user, password, data):        json_data = self.api_request(""user"", user, password)        if json_data.get(""hasErrors"", True) or not json_data.get(""isActive"", True):            self.log_warning(json_data[""ErrorMSG""] or ""Unknown error"")            self.fail_login()",,"def signin(self, user, password, data):        json_data = self.api_request(""user"", user, password)        if json_data.get(""hasErrors"", True) or not json_data.get(""isActive"", True):            self.log_warning(json_data[""ErrorMSG""] or ""Unknown error"")            self.fail_login()",52d9717b-44a3-463e-9511-d0f6e7d481b1
accounts,LinksnappyCom.py,api_request,29,30,"def api_request(self, method, **kwargs):        return json.loads(self.load(self.API_URL + method, get=kwargs))",,"def api_request(self, method, **kwargs):        return json.loads(self.load(self.API_URL + method, get=kwargs))",d3461eb7-6836-4041-9731-4a3eca9e314e
accounts,LinksnappyCom.py,grab_hosters,32,34,"def grab_hosters(self, user, password, data):        json_data = self.api_request(""FILEHOSTS"")        return [k for k, v in json_data[""return""].items() if v[""Status""] == ""1""]",,"def grab_hosters(self, user, password, data):        json_data = self.api_request(""FILEHOSTS"")        return [k for k, v in json_data[""return""].items() if v[""Status""] == ""1""]",39492395-2834-4f09-aa7c-18d279870eac
accounts,LinksnappyCom.py,grab_info,36,68,"def grab_info(self, user, password, data):        premium = True        validuntil = None        trafficleft = None        json_data = self.api_request(""USERDETAILS"", username=user, password=password)        if json_data[""status""] != ""OK"":            self.log_error(json_data[""error""])        else:            expire = json_data[""return""][""expire""]            if expire == ""lifetime"":                validuntil = -1            elif expire == ""expired"":                premium = False            else:                validuntil = float(expire)            if isinstance(json_data[""return""].get(""trafficleft"", """"), str):                trafficleft = -1            else:                trafficleft = float(json_data[""return""][""trafficleft""]) * 1024        return {            ""premium"": premium,            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,        }",,"def grab_info(self, user, password, data):        premium = True        validuntil = None        trafficleft = None        json_data = self.api_request(""USERDETAILS"", username=user, password=password)        if json_data[""status""] != ""OK"":            self.log_error(json_data[""error""])        else:            expire = json_data[""return""][""expire""]            if expire == ""lifetime"":                validuntil = -1            elif expire == ""expired"":                premium = False            else:                validuntil = float(expire)            if isinstance(json_data[""return""].get(""trafficleft"", """"), str):                trafficleft = -1            else:                trafficleft = float(json_data[""return""][""trafficleft""]) * 1024        return {            ""premium"": premium,            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,        }",8f6ee352-3544-42fa-aa65-23f113e0c37a
accounts,LinksnappyCom.py,signin,70,74,"def signin(self, user, password, data):        json_data = self.api_request(""AUTHENTICATE"", username=user, password=password)        if json_data[""status""] != ""OK"":            self.fail_login(json_data[""error""])",,"def signin(self, user, password, data):        json_data = self.api_request(""AUTHENTICATE"", username=user, password=password)        if json_data[""status""] != ""OK"":            self.fail_login(json_data[""error""])",26c1d0c3-1eff-458c-a369-46cb6838da20
accounts,MegaCoNz.py,grab_info,21,44,"def grab_info(self, user, password, data):        validuntil = -1        trafficleft = None        premium = False        mega = MegaClient(self, None)        res = mega.api_request(a=""uq"", xfer=1, pro=1)  #: user quota details        if isinstance(res, dict):            premium = res.get(""utype"", 0) > 0            if premium:                validuntil = res.get(""suntil"", None)                trafficleft = (                    res.get(""mxfer"", 0) - res.get(""caxfer"", 0) - res.get(""csxfer"", 0)                )            # if res['rtt']:            #     self.log_debug(f""Tranfare history:{res['tah']}"")        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""premium"": premium,        }",,"def grab_info(self, user, password, data):        validuntil = -1        trafficleft = None        premium = False        mega = MegaClient(self, None)        res = mega.api_request(a=""uq"", xfer=1, pro=1)  #: user quota details        if isinstance(res, dict):            premium = res.get(""utype"", 0) > 0            if premium:                validuntil = res.get(""suntil"", None)                trafficleft = (                    res.get(""mxfer"", 0) - res.get(""caxfer"", 0) - res.get(""csxfer"", 0)                )            # if res['rtt']:            #     self.log_debug(f""Tranfare history:{res['tah']}"")        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""premium"": premium,        }",266a3643-5d0e-4c49-a666-a35145e400e0
accounts,MegaCoNz.py,signin,46,141,"def signin(self, user, password, data):        user = user.lower()        mega = MegaClient(self, None)        mega_session_cache = self.db.retrieve(""mega_session_cache"") or {}        if user in mega_session_cache:            data[""mega_session_id""] = mega_session_cache[user]            res = mega.api_request(a=""ug"", xfer=1, pro=1)  #: ug is for user details            if isinstance(res, dict) and res.get(""email"", None) == user:                self.skip_login()            else:                del mega_session_cache[user]                self.db.store(""mega_session_cache"", mega_session_cache)        sid = None        data[""mega_session_id""] = sid        res = mega.api_request(a=""us0"", user=user)  #: us0 is `prelogin` command        if res[""v""] == 1:  #: v1 account            password_key = self.get_password_key(password)            user_hash = self.get_user_hash_v1(user, password_key)        elif res[""v""] == 2:  #: v2 account            salt = MegaCrypto.base64_decode(res[""s""])            pbkdf = hashlib.pbkdf2_hmac(""SHA512"", to_bytes(password, ""utf-8""), salt, 100_000, 32)            password_key = MegaCrypto.bytes_to_a32(pbkdf[:16])            user_hash = (                to_str(MegaCrypto.base64_encode(pbkdf[16:]), ""ascii"").replace(""="", """")            )        else:            self.log_error(                self._(""Unsupported user account version ({})"").format(res[""v""])            )            self.fail_login()        res = mega.api_request(a=""us"", user=user, uh=user_hash)  #: us if for user sign-in        if isinstance(res, int) or isinstance(res, dict) and ""e"" in res:            self.fail_login()        master_key = MegaCrypto.decrypt_key(res[""k""], password_key)        if ""tsid"" in res:            tsid = MegaCrypto.base64_decode(res[""tsid""])            if (                MegaCrypto.a32_to_bytes(                    MegaCrypto.encrypt_key(                        MegaCrypto.bytes_to_a32(tsid[:16]), master_key                    )                )                == tsid[-16:]            ):                sid = res[""tsid""]            else:                self.fail_login()        elif ""csid"" in res:            privk = MegaCrypto.a32_to_bytes(                MegaCrypto.decrypt_key(res[""privk""], master_key)            )            rsa_private_key = [0, 0, 0, 0]            for i in range(4):                l = ((privk[0] * 256 + privk[1] + 7) // 8) + 2                if l > len(privk):                    self.fail_login()                rsa_private_key[i] = self.mpi_to_int(privk[:l])                privk = privk[l:]            if len(privk) >= 16:                self.fail_login()            encrypted_sid = self.mpi_to_int(                MegaCrypto.base64_decode(res[""csid""])            )            sid = ""{:x}"".format(                pow(                    encrypted_sid,                    rsa_private_key[2],                    rsa_private_key[0] * rsa_private_key[1],                )            )            sid = ""0"" * (-len(sid) % 2) + sid            sid = bytes([(int(sid[i : i + 2], 16)) for i in range(0, len(sid), 2)])            sid = to_str(MegaCrypto.base64_encode(sid[:43]), ""ascii"").replace(""="", """")        else:            self.fail_login()        data[""mega_session_id""] = sid        mega_session_cache[user] = sid        self.db.store(""mega_session_cache"", mega_session_cache)",,"def signin(self, user, password, data):        user = user.lower()        mega = MegaClient(self, None)        mega_session_cache = self.db.retrieve(""mega_session_cache"") or {}        if user in mega_session_cache:            data[""mega_session_id""] = mega_session_cache[user]            res = mega.api_request(a=""ug"", xfer=1, pro=1)  #: ug is for user details            if isinstance(res, dict) and res.get(""email"", None) == user:                self.skip_login()            else:                del mega_session_cache[user]                self.db.store(""mega_session_cache"", mega_session_cache)        sid = None        data[""mega_session_id""] = sid        res = mega.api_request(a=""us0"", user=user)  #: us0 is `prelogin` command        if res[""v""] == 1:  #: v1 account            password_key = self.get_password_key(password)            user_hash = self.get_user_hash_v1(user, password_key)        elif res[""v""] == 2:  #: v2 account            salt = MegaCrypto.base64_decode(res[""s""])            pbkdf = hashlib.pbkdf2_hmac(""SHA512"", to_bytes(password, ""utf-8""), salt, 100_000, 32)            password_key = MegaCrypto.bytes_to_a32(pbkdf[:16])            user_hash = (                to_str(MegaCrypto.base64_encode(pbkdf[16:]), ""ascii"").replace(""="", """")            )        else:            self.log_error(                self._(""Unsupported user account version ({})"").format(res[""v""])            )            self.fail_login()        res = mega.api_request(a=""us"", user=user, uh=user_hash)  #: us if for user sign-in        if isinstance(res, int) or isinstance(res, dict) and ""e"" in res:            self.fail_login()        master_key = MegaCrypto.decrypt_key(res[""k""], password_key)        if ""tsid"" in res:            tsid = MegaCrypto.base64_decode(res[""tsid""])            if (                MegaCrypto.a32_to_bytes(                    MegaCrypto.encrypt_key(                        MegaCrypto.bytes_to_a32(tsid[:16]), master_key                    )                )                == tsid[-16:]            ):                sid = res[""tsid""]            else:                self.fail_login()        elif ""csid"" in res:            privk = MegaCrypto.a32_to_bytes(                MegaCrypto.decrypt_key(res[""privk""], master_key)            )            rsa_private_key = [0, 0, 0, 0]            for i in range(4):                l = ((privk[0] * 256 + privk[1] + 7) // 8) + 2                if l > len(privk):                    self.fail_login()                rsa_private_key[i] = self.mpi_to_int(privk[:l])                privk = privk[l:]            if len(privk) >= 16:                self.fail_login()            encrypted_sid = self.mpi_to_int(                MegaCrypto.base64_decode(res[""csid""])            )            sid = ""{:x}"".format(                pow(                    encrypted_sid,                    rsa_private_key[2],                    rsa_private_key[0] * rsa_private_key[1],                )            )            sid = ""0"" * (-len(sid) % 2) + sid            sid = bytes([(int(sid[i : i + 2], 16)) for i in range(0, len(sid), 2)])            sid = to_str(MegaCrypto.base64_encode(sid[:43]), ""ascii"").replace(""="", """")        else:            self.fail_login()        data[""mega_session_id""] = sid        mega_session_cache[user] = sid        self.db.store(""mega_session_cache"", mega_session_cache)",de3cd078-2b65-4ac9-aa32-3ff5514dd77a
accounts,MegaCoNz.py,get_password_key,143,156,"def get_password_key(self, password):        password_key = MegaCrypto.a32_to_bytes(            [0x93C467E3, 0x7DB0C7A4, 0xD1BE3F81, 0x0152CB56]        )        password_a32 = MegaCrypto.bytes_to_a32(to_bytes(password, ""utf-8""))        for c in range(0x10000):            for j in range(0, len(password_a32), 4):                key = [0, 0, 0, 0]                for i in range(4):                    if i + j < len(password_a32):                        key[i] = password_a32[i + j]                password_key = MegaCrypto.cbc_encrypt(password_key, key)        return MegaCrypto.bytes_to_a32(password_key)",,"def get_password_key(self, password):        password_key = MegaCrypto.a32_to_bytes(            [0x93C467E3, 0x7DB0C7A4, 0xD1BE3F81, 0x0152CB56]        )        password_a32 = MegaCrypto.bytes_to_a32(to_bytes(password, ""utf-8""))        for c in range(0x10000):            for j in range(0, len(password_a32), 4):                key = [0, 0, 0, 0]                for i in range(4):                    if i + j < len(password_a32):                        key[i] = password_a32[i + j]                password_key = MegaCrypto.cbc_encrypt(password_key, key)        return MegaCrypto.bytes_to_a32(password_key)",9c0b24e2-5039-4c05-9007-1da72cdf3d4a
accounts,MegaCoNz.py,get_user_hash_v1,158,170,"def get_user_hash_v1(self, user, password_key):        user_a32 = MegaCrypto.bytes_to_a32(to_bytes(user, ""utf-8""))        user_hash = [0, 0, 0, 0]        for i in range(len(user_a32)):            user_hash[i % 4] ^= user_a32[i]        user_hash = MegaCrypto.a32_to_bytes(user_hash)        for i in range(0x4000):            user_hash = MegaCrypto.cbc_encrypt(user_hash, password_key)        user_hash = MegaCrypto.bytes_to_a32(user_hash)        return to_str(MegaCrypto.a32_to_base64((user_hash[0], user_hash[2])), ""ascii"")",,"def get_user_hash_v1(self, user, password_key):        user_a32 = MegaCrypto.bytes_to_a32(to_bytes(user, ""utf-8""))        user_hash = [0, 0, 0, 0]        for i in range(len(user_a32)):            user_hash[i % 4] ^= user_a32[i]        user_hash = MegaCrypto.a32_to_bytes(user_hash)        for i in range(0x4000):            user_hash = MegaCrypto.cbc_encrypt(user_hash, password_key)        user_hash = MegaCrypto.bytes_to_a32(user_hash)        return to_str(MegaCrypto.a32_to_base64((user_hash[0], user_hash[2])), ""ascii"")",14bd064e-405b-4bfb-a653-b7c94ca15138
accounts,MegaCoNz.py,mpi_to_int,172,176,"def mpi_to_int(self, s):                return int("""".join(""{:02x}"".format(s[2:][x]) for x in range(len(s[2:]))), 16)",Convert GCRYMPI_FMT_PGP bignum format to integer.,"def mpi_to_int(self, s):        """"""        Convert GCRYMPI_FMT_PGP bignum format to integer.        """"""        return int("""".join(""{:02x}"".format(s[2:][x]) for x in range(len(s[2:]))), 16)

Convert GCRYMPI_FMT_PGP bignum format to integer.",46c902e8-8418-4064-b8d8-9f095f4fe260
accounts,MegaDebridEu.py,args,11,12,def args(**kwargs):    return kwargs,,def args(**kwargs):    return kwargs,0993867b-e843-442f-b585-40fdf3156931
accounts,MegaDebridEu.py,api_request,39,49,"def api_request(self, action, get={}, post={}):        get[""action""] = action        # Better use pyLoad User-Agent so we don't get blocked        self.req.http.c.setopt(            pycurl.USERAGENT, ""pyLoad/{}"".format(self.pyload.version).encode()        )        json_data = self.load(self.API_URL, get=get, post=post)        return json.loads(json_data)",,"def api_request(self, action, get={}, post={}):        get[""action""] = action        # Better use pyLoad User-Agent so we don't get blocked        self.req.http.c.setopt(            pycurl.USERAGENT, ""pyLoad/{}"".format(self.pyload.version).encode()        )        json_data = self.load(self.API_URL, get=get, post=post)        return json.loads(json_data)",4cbb7883-c482-46fc-b734-3589ef60c3dd
accounts,MegaDebridEu.py,grab_hosters,51,83,"def grab_hosters(self, user, password, data):        hosters = []        try:            res = self.api_request(""getHostersList"")        except BadHeader as exc:            if exc.code == 405:                self.log_error(self._(""Unable to retrieve hosters list: Banned IP""))            else:                self.log_error(                    self._(""Unable to retrieve hosters list: error {}""), exc.code                )        else:            if res[""response_code""] == ""ok"":                hosters = reduce(                    (lambda x, y: x + y),                    [                        h[""domains""]                        for h in res[""hosters""]                        if ""domains"" in h and isinstance(h[""domains""], list)                    ],                )            else:                self.log_error(                    self._(""Unable to retrieve hoster list: {}"").format(                        res[""response_text""]                    )                )        return hosters",,"def grab_hosters(self, user, password, data):        hosters = []        try:            res = self.api_request(""getHostersList"")        except BadHeader as exc:            if exc.code == 405:                self.log_error(self._(""Unable to retrieve hosters list: Banned IP""))            else:                self.log_error(                    self._(""Unable to retrieve hosters list: error {}""), exc.code                )        else:            if res[""response_code""] == ""ok"":                hosters = reduce(                    (lambda x, y: x + y),                    [                        h[""domains""]                        for h in res[""hosters""]                        if ""domains"" in h and isinstance(h[""domains""], list)                    ],                )            else:                self.log_error(                    self._(""Unable to retrieve hoster list: {}"").format(                        res[""response_text""]                    )                )        return hosters",a1ed268f-1a54-43cd-88df-81d5f7da9b58
accounts,MegaDebridEu.py,grab_info,85,100,"def grab_info(self, user, password, data):        validuntil = None        trafficleft = None        premium = False        cache_info = data.get(""cache_info"", {})        if user in cache_info:            validuntil = float(cache_info[user][""vip_end""])            premium = validuntil > 0            trafficleft = -1        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""premium"": premium,        }",,"def grab_info(self, user, password, data):        validuntil = None        trafficleft = None        premium = False        cache_info = data.get(""cache_info"", {})        if user in cache_info:            validuntil = float(cache_info[user][""vip_end""])            premium = validuntil > 0            trafficleft = -1        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""premium"": premium,        }",1a1ae44d-b731-4f2b-ba76-94d50af1520e
accounts,MegaDebridEu.py,signin,102,140,"def signin(self, user, password, data):        cache_info = self.db.retrieve(""cache_info"", {})        if user in cache_info:            data[""cache_info""] = cache_info            self.skip_login()        try:            res = self.api_request(""connectUser"", args(login=user, password=password))        except BadHeader as exc:            if exc.code == 401:                self.fail_login()            elif exc.code == 405:                self.fail(self._(""Banned IP""))            else:                raise        if res[""response_code""] != ""ok"":            cache_info.pop(user, None)            data[""cache_info""] = cache_info            self.db.store(""cache_info"", cache_info)            if res[""response_code""] == ""UNKNOWN_USER"":                self.fail_login()            elif res[""response_code""] == ""UNALLOWED_IP"":                self.fail_login(self._(""Banned IP""))            else:                self.log_error(res[""response_text""])                self.fail_login(res[""response_text""])        else:            cache_info[user] = {""vip_end"": res[""vip_end""], ""token"": res[""token""]}            data[""cache_info""] = cache_info            self.db.store(""cache_info"", cache_info)",,"def signin(self, user, password, data):        cache_info = self.db.retrieve(""cache_info"", {})        if user in cache_info:            data[""cache_info""] = cache_info            self.skip_login()        try:            res = self.api_request(""connectUser"", args(login=user, password=password))        except BadHeader as exc:            if exc.code == 401:                self.fail_login()            elif exc.code == 405:                self.fail(self._(""Banned IP""))            else:                raise        if res[""response_code""] != ""ok"":            cache_info.pop(user, None)            data[""cache_info""] = cache_info            self.db.store(""cache_info"", cache_info)            if res[""response_code""] == ""UNKNOWN_USER"":                self.fail_login()            elif res[""response_code""] == ""UNALLOWED_IP"":                self.fail_login(self._(""Banned IP""))            else:                self.log_error(res[""response_text""])                self.fail_login(res[""response_text""])        else:            cache_info[user] = {""vip_end"": res[""vip_end""], ""token"": res[""token""]}            data[""cache_info""] = cache_info            self.db.store(""cache_info"", cache_info)",395af201-4cb6-4425-aa6a-d3488fe8680f
accounts,MegaDebridEu.py,relogin,142,150,"def relogin(self):        if self.req:            cache_info = self.info[""data""].get(""cache_info"", {})            cache_info.pop(self.user, None)            self.info[""data""][""cache_info""] = cache_info            self.db.store(""cache_info"", cache_info)        return MultiAccount.relogin(self)",,"def relogin(self):        if self.req:            cache_info = self.info[""data""].get(""cache_info"", {})            cache_info.pop(self.user, None)            self.info[""data""][""cache_info""] = cache_info            self.db.store(""cache_info"", cache_info)        return MultiAccount.relogin(self)",a816a6cd-235a-4c23-b2d8-c3cebd199b2c
accounts,MegaRapidCz.py,grab_info,30,47,"def grab_info(self, user, password, data):        htmll = self.load(""http://megarapid.cz/mujucet/"")        m = re.search(self.LIMITDL_PATTERN, htmll)        if m is not None:            data[""options""][""limit_dl""] = [int(m.group(1))]        m = re.search(self.VALID_UNTIL_PATTERN, htmll)        if m is not None:            validuntil = time.mktime(time.strptime(m.group(1), ""%d.%m.%Y - %H:%M""))            return {""premium"": True, ""trafficleft"": -1, ""validuntil"": validuntil}        m = re.search(self.TRAFFIC_LEFT_PATTERN, htmll)        if m is not None:            trafficleft = float(m.group(1)) * (1 << 30)            return {""premium"": True, ""trafficleft"": trafficleft, ""validuntil"": -1}        return {""premium"": False, ""trafficleft"": None, ""validuntil"": None}",,"def grab_info(self, user, password, data):        htmll = self.load(""http://megarapid.cz/mujucet/"")        m = re.search(self.LIMITDL_PATTERN, htmll)        if m is not None:            data[""options""][""limit_dl""] = [int(m.group(1))]        m = re.search(self.VALID_UNTIL_PATTERN, htmll)        if m is not None:            validuntil = time.mktime(time.strptime(m.group(1), ""%d.%m.%Y - %H:%M""))            return {""premium"": True, ""trafficleft"": -1, ""validuntil"": validuntil}        m = re.search(self.TRAFFIC_LEFT_PATTERN, htmll)        if m is not None:            trafficleft = float(m.group(1)) * (1 << 30)            return {""premium"": True, ""trafficleft"": trafficleft, ""validuntil"": -1}        return {""premium"": False, ""trafficleft"": None, ""validuntil"": None}",45bb45aa-7dcd-4d9f-a780-19e802fd429a
accounts,MegaRapidCz.py,signin,49,65,"def signin(self, user, password, data):        html = self.load(""http://megarapid.cz/prihlaseni/"")        if ""Heslo:"" in html:            start = html.index('id=""inp_hash"" name=""hash"" value=""')            html = html[start + 33 :]            hashes = html[0:32]            html = self.load(                ""https://megarapid.cz/prihlaseni/"",                post={                    ""hash"": hashes,                    ""login"": user,                    ""pass1"": password,                    ""remember"": 1,                    ""sbmt"": ""Přihlásit"",                },            )",,"def signin(self, user, password, data):        html = self.load(""http://megarapid.cz/prihlaseni/"")        if ""Heslo:"" in html:            start = html.index('id=""inp_hash"" name=""hash"" value=""')            html = html[start + 33 :]            hashes = html[0:32]            html = self.load(                ""https://megarapid.cz/prihlaseni/"",                post={                    ""hash"": hashes,                    ""login"": user,                    ""pass1"": password,                    ""remember"": 1,                    ""sbmt"": ""Přihlásit"",                },            )",3a64f953-fd0f-4eb1-9fd7-d532fbeaacd6
accounts,MegaRapidoNet.py,grab_hosters,29,89,"def grab_hosters(self, user, password, data):        hosters = {            ""1fichier"": [],  #: leave it there are so many possible addresses?            ""1st-files"": [""1st-files.com""],            ""2shared"": [""2shared.com""],            ""4shared"": [""4shared.com"", ""4shared-china.com""],            ""asfile"": [""http://asfile.com/""],            ""bitshare"": [""bitshare.com""],            ""brupload"": [""brupload.net""],            ""crocko"": [""crocko.com"", ""easy-share.com""],            ""dailymotion"": [""dailymotion.com""],            ""depfile"": [""depfile.com""],            ""depositfiles"": [""depositfiles.com"", ""dfiles.eu""],            ""dizzcloud"": [""dizzcloud.com""],            ""dl.dropbox"": [],            ""extabit"": [""extabit.com""],            ""extmatrix"": [""extmatrix.com""],            ""facebook"": [],            ""file4go"": [""file4go.com""],            ""filecloud"": [""filecloud.io"", ""ifile.it"", ""mihd.net""],            ""filefactory"": [""filefactory.com""],            ""fileom"": [""fileom.com""],            ""fileparadox"": [""fileparadox.in""],            ""filepost"": [""filepost.com"", ""fp.io""],            ""filerio"": [""filerio.in"", ""filerio.com"", ""filekeen.com""],            ""filesflash"": [""filesflash.com""],            ""firedrive"": [""firedrive.com"", ""putlocker.com""],            ""flashx"": [],            ""freakshare"": [""freakshare.net"", ""freakshare.com""],            ""gigasize"": [""gigasize.com""],            ""hipfile"": [""hipfile.com""],            ""junocloud"": [""junocloud.me""],            ""letitbit"": [""letitbit.net"", ""shareflare.net""],            ""mediafire"": [""mediafire.com""],            ""mega"": [""mega.co.nz""],            ""megashares"": [""megashares.com""],            ""metacafe"": [""metacafe.com""],            ""netload"": [""netload.in""],            ""oboom"": [""oboom.com""],            ""rapidgator"": [""rapidgator.net""],            ""rapidshare"": [""rapidshare.com""],            ""rarefile"": [""rarefile.net""],            ""ryushare"": [""ryushare.com""],            ""sendspace"": [""sendspace.com""],            ""turbobit"": [""turbobit.net"", ""unextfiles.com""],            ""uploadable"": [""uploadable.ch""],            ""uploadbaz"": [""uploadbaz.com""],            ""uploaded"": [""uploaded.to"", ""uploaded.net"", ""ul.to""],            ""uploadhero"": [""uploadhero.com""],            ""uploading"": [""uploading.com""],            ""uptobox"": [""uptobox.com""],            ""xvideos"": [""xvideos.com""],            ""youtube"": [""youtube.com""],        }        hoster_list = []        for item in hosters.values():            hoster_list.extend(item)        return hoster_list",,"def grab_hosters(self, user, password, data):        hosters = {            ""1fichier"": [],  #: leave it there are so many possible addresses?            ""1st-files"": [""1st-files.com""],            ""2shared"": [""2shared.com""],            ""4shared"": [""4shared.com"", ""4shared-china.com""],            ""asfile"": [""http://asfile.com/""],            ""bitshare"": [""bitshare.com""],            ""brupload"": [""brupload.net""],            ""crocko"": [""crocko.com"", ""easy-share.com""],            ""dailymotion"": [""dailymotion.com""],            ""depfile"": [""depfile.com""],            ""depositfiles"": [""depositfiles.com"", ""dfiles.eu""],            ""dizzcloud"": [""dizzcloud.com""],            ""dl.dropbox"": [],            ""extabit"": [""extabit.com""],            ""extmatrix"": [""extmatrix.com""],            ""facebook"": [],            ""file4go"": [""file4go.com""],            ""filecloud"": [""filecloud.io"", ""ifile.it"", ""mihd.net""],            ""filefactory"": [""filefactory.com""],            ""fileom"": [""fileom.com""],            ""fileparadox"": [""fileparadox.in""],            ""filepost"": [""filepost.com"", ""fp.io""],            ""filerio"": [""filerio.in"", ""filerio.com"", ""filekeen.com""],            ""filesflash"": [""filesflash.com""],            ""firedrive"": [""firedrive.com"", ""putlocker.com""],            ""flashx"": [],            ""freakshare"": [""freakshare.net"", ""freakshare.com""],            ""gigasize"": [""gigasize.com""],            ""hipfile"": [""hipfile.com""],            ""junocloud"": [""junocloud.me""],            ""letitbit"": [""letitbit.net"", ""shareflare.net""],            ""mediafire"": [""mediafire.com""],            ""mega"": [""mega.co.nz""],            ""megashares"": [""megashares.com""],            ""metacafe"": [""metacafe.com""],            ""netload"": [""netload.in""],            ""oboom"": [""oboom.com""],            ""rapidgator"": [""rapidgator.net""],            ""rapidshare"": [""rapidshare.com""],            ""rarefile"": [""rarefile.net""],            ""ryushare"": [""ryushare.com""],            ""sendspace"": [""sendspace.com""],            ""turbobit"": [""turbobit.net"", ""unextfiles.com""],            ""uploadable"": [""uploadable.ch""],            ""uploadbaz"": [""uploadbaz.com""],            ""uploaded"": [""uploaded.to"", ""uploaded.net"", ""ul.to""],            ""uploadhero"": [""uploadhero.com""],            ""uploading"": [""uploading.com""],            ""uptobox"": [""uptobox.com""],            ""xvideos"": [""xvideos.com""],            ""youtube"": [""youtube.com""],        }        hoster_list = []        for item in hosters.values():            hoster_list.extend(item)        return hoster_list",f4fed77d-2f79-423d-b124-a163d6885b68
accounts,MegaRapidoNet.py,grab_info,91,115,"def grab_info(self, user, password, data):        validuntil = None        trafficleft = None        premium = False        html = self.load(""http://megarapido.net/gerador"")        validuntil = re.search(self.VALID_UNTIL_PATTERN, html)        if validuntil:            #: Hier weitermachen!!! (müssen umbedingt die zeit richtig machen damit! (sollte aber möglich))            validuntil = (                time.time()                + timedelta(hours=int(validuntil.group(1)) * 24).total_seconds()                + timedelta(hours=int(validuntil.group(2))).total_seconds()                + timedelta(minutes=int(validuntil.group(3))).total_seconds()                + int(validuntil.group(4))            )            trafficleft = -1            premium = True        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""premium"": premium,        }",,"def grab_info(self, user, password, data):        validuntil = None        trafficleft = None        premium = False        html = self.load(""http://megarapido.net/gerador"")        validuntil = re.search(self.VALID_UNTIL_PATTERN, html)        if validuntil:            #: Hier weitermachen!!! (müssen umbedingt die zeit richtig machen damit! (sollte aber möglich))            validuntil = (                time.time()                + timedelta(hours=int(validuntil.group(1)) * 24).total_seconds()                + timedelta(hours=int(validuntil.group(2))).total_seconds()                + timedelta(minutes=int(validuntil.group(3))).total_seconds()                + int(validuntil.group(4))            )            trafficleft = -1            premium = True        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""premium"": premium,        }",60b4affd-73a8-46c6-9733-b16ae724ab9f
accounts,MegaRapidoNet.py,signin,117,133,"def signin(self, user, password, data):        self.load(""http://megarapido.net/login"")        self.load(            ""http://megarapido.net/painel_user/ajax/logar.php"",            post={""login"": user, ""senha"": password},        )        html = self.load(""http://megarapido.net/gerador"")        if ""sair"" not in html.lower():            self.fail_login()        else:            m = re.search(self.USER_ID_PATTERN, html)            if m is not None:                data[""uid""] = m.group(1)            else:                self.fail_login(""Couldn't find the user ID"")",,"def signin(self, user, password, data):        self.load(""http://megarapido.net/login"")        self.load(            ""http://megarapido.net/painel_user/ajax/logar.php"",            post={""login"": user, ""senha"": password},        )        html = self.load(""http://megarapido.net/gerador"")        if ""sair"" not in html.lower():            self.fail_login()        else:            m = re.search(self.USER_ID_PATTERN, html)            if m is not None:                data[""uid""] = m.group(1)            else:                self.fail_login(""Couldn't find the user ID"")",be3a1fb3-3354-4be2-bf79-35055be23d7f
accounts,MegasharesCom.py,grab_info,23,39,"def grab_info(self, user, password, data):        html = self.load(""http://d01.megashares.com/myms.php"")        premium = "">Premium Upgrade<"" not in html        validuntil = trafficleft = -1        try:            timestr = re.search(self.VALID_UNTIL_PATTERN, html).group(1)            self.log_debug(timestr)            validuntil = time.mktime(time.strptime(timestr, ""%b %d, %Y""))        except Exception as exc:            self.log_error(                exc, exc_info=self.pyload.debug > 1, stack_info=self.pyload.debug > 2            )        return {""validuntil"": validuntil, ""trafficleft"": -1, ""premium"": premium}",,"def grab_info(self, user, password, data):        html = self.load(""http://d01.megashares.com/myms.php"")        premium = "">Premium Upgrade<"" not in html        validuntil = trafficleft = -1        try:            timestr = re.search(self.VALID_UNTIL_PATTERN, html).group(1)            self.log_debug(timestr)            validuntil = time.mktime(time.strptime(timestr, ""%b %d, %Y""))        except Exception as exc:            self.log_error(                exc, exc_info=self.pyload.debug > 1, stack_info=self.pyload.debug > 2            )        return {""validuntil"": validuntil, ""trafficleft"": -1, ""premium"": premium}",f69c7437-accf-4d51-a7e2-8a9c7eb90b4e
accounts,MegasharesCom.py,signin,41,53,"def signin(self, user, password, data):        html = self.load(            ""http://d01.megashares.com/myms_login.php"",            post={                ""httpref"": """",                ""myms_login"": ""Login"",                ""mymslogin_name"": user,                ""mymspassword"": password,            },        )        if '<span class=""b ml"">{}</span>'.format(user) not in html:            self.fail_login()",,"def signin(self, user, password, data):        html = self.load(            ""http://d01.megashares.com/myms_login.php"",            post={                ""httpref"": """",                ""myms_login"": ""Login"",                ""mymslogin_name"": user,                ""mymspassword"": password,            },        )        if '<span class=""b ml"">{}</span>'.format(user) not in html:            self.fail_login()",2853d6b8-e82f-466d-9ca4-8394cb9fe662
accounts,MultishareCz.py,api_request,33,45,"def api_request(self, method, **kwargs):        get = {""sub"": method}        get.update(kwargs)        self.req.http.c.setopt(pycurl.USERAGENT, ""JDownloader"")        json_data = self.load(self.API_URL, get=get)        if not json_data.startswith(""{""):            if json_data.startswith(""ERR:""):                json_data = json_data[4:].strip()            return {""err"": json_data}        else:            return json.loads(json_data)",,"def api_request(self, method, **kwargs):        get = {""sub"": method}        get.update(kwargs)        self.req.http.c.setopt(pycurl.USERAGENT, ""JDownloader"")        json_data = self.load(self.API_URL, get=get)        if not json_data.startswith(""{""):            if json_data.startswith(""ERR:""):                json_data = json_data[4:].strip()            return {""err"": json_data}        else:            return json.loads(json_data)",3f7798f1-da55-413c-aead-21b8d692f092
accounts,MultishareCz.py,grab_hosters,47,49,"def grab_hosters(self, user, password, data):        api_data = self.api_request(""supported-hosters"")        return api_data[""server""]",,"def grab_hosters(self, user, password, data):        api_data = self.api_request(""supported-hosters"")        return api_data[""server""]",5c8ccb98-8ac0-4950-8522-55043c022c6b
accounts,MultishareCz.py,grab_info,51,57,"def grab_info(self, user, password, data):        api_data = self.api_request(""account-details"", login=user, password=password)        trafficleft = self.parse_traffic(api_data[""credit""], ""MB"")        premium = True if trafficleft else False        return {""validuntil"": -1, ""trafficleft"": trafficleft, ""premium"": premium}",,"def grab_info(self, user, password, data):        api_data = self.api_request(""account-details"", login=user, password=password)        trafficleft = self.parse_traffic(api_data[""credit""], ""MB"")        premium = True if trafficleft else False        return {""validuntil"": -1, ""trafficleft"": trafficleft, ""premium"": premium}",f67038c0-9102-4bae-a9c4-512e3f1239a2
accounts,MultishareCz.py,signin,59,72,"def signin(self, user, password, data):        try:            api_data = self.api_request(                ""account-details"", login=user, password=password            )        except BadHeader as exc:            if exc.code == 403:                self.fail_login(_(""IP is banned""))            else:                raise        if ""err"" in api_data:            self.fail_login(api_data[""err""])",,"def signin(self, user, password, data):        try:            api_data = self.api_request(                ""account-details"", login=user, password=password            )        except BadHeader as exc:            if exc.code == 403:                self.fail_login(_(""IP is banned""))            else:                raise        if ""err"" in api_data:            self.fail_login(api_data[""err""])",abea6d3c-419b-4e2f-888e-1fbe7321b612
accounts,MyfastfileCom.py,grab_hosters,25,30,"def grab_hosters(self, user, password, data):        json_data = self.load(""http://myfastfile.com/api.php"", get={""hosts"": """"})        self.log_debug(""JSON data"", json_data)        json_data = json.loads(json_data)        return json_data[""hosts""]",,"def grab_hosters(self, user, password, data):        json_data = self.load(""http://myfastfile.com/api.php"", get={""hosts"": """"})        self.log_debug(""JSON data"", json_data)        json_data = json.loads(json_data)        return json_data[""hosts""]",52a86c50-a1ad-4cb2-8af1-88d924f9f103
accounts,MyfastfileCom.py,grab_info,32,39,"def grab_info(self, user, password, data):        if ""days_left"" in self.json_data:            validuntil = (                time.time() + timedelta(hours=self.json_data[""days_left""] * 24).total_seconds()            )            return {""premium"": True, ""validuntil"": validuntil, ""trafficleft"": -1}        else:            self.log_error(self._(""Unable to get account information""))",,"def grab_info(self, user, password, data):        if ""days_left"" in self.json_data:            validuntil = (                time.time() + timedelta(hours=self.json_data[""days_left""] * 24).total_seconds()            )            return {""premium"": True, ""validuntil"": validuntil, ""trafficleft"": -1}        else:            self.log_error(self._(""Unable to get account information""))",ac602c08-2afb-4be7-b2e9-c711b968d493
accounts,MyfastfileCom.py,signin,41,51,"def signin(self, user, password, data):        #: Password to use is the API-Password written in http://myfastfile.com/myaccount        html = self.load(            ""https://myfastfile.com/api.php"", get={""user"": user, ""pass"": password}        )        self.log_debug(""JSON data: "" + html)        self.json_data = json.loads(html)        if self.json_data[""status""] != ""ok"":            self.fail_login(self._(""Invalid username or password""))",,"def signin(self, user, password, data):        #: Password to use is the API-Password written in http://myfastfile.com/myaccount        html = self.load(            ""https://myfastfile.com/api.php"", get={""user"": user, ""pass"": password}        )        self.log_debug(""JSON data: "" + html)        self.json_data = json.loads(html)        if self.json_data[""status""] != ""ok"":            self.fail_login(self._(""Invalid username or password""))",dcc631e4-2cf3-45a6-b040-88265a232abc
accounts,NitrobitNet.py,grab_info,16,17,"def grab_info(self, user, password, data):        return {""premium"": True, ""validuntil"": None, ""trafficleft"": None}",,"def grab_info(self, user, password, data):        return {""premium"": True, ""validuntil"": None, ""trafficleft"": None}",12c70399-12f8-4b84-92fb-aec1e30c5cb8
accounts,NitrobitNet.py,signin,19,21,"def signin(self, user, password, data):        #: no way to sign in until we actually download something        self.skip_login()",,"def signin(self, user, password, data):        #: no way to sign in until we actually download something        self.skip_login()",053ea5d8-9ec6-4f62-8f07-059520b6c230
accounts,NitroflareCom.py,api_request,24,26,"def api_request(self, method, **kwargs):        json_data = self.load(self.API_URL + method, get=kwargs)        return json.loads(json_data)",,"def api_request(self, method, **kwargs):        json_data = self.load(self.API_URL + method, get=kwargs)        return json.loads(json_data)",f6d92440-97aa-488d-bf83-2493dc825ca9
accounts,NitroflareCom.py,grab_info,28,48,"def grab_info(self, user, password, data):        validuntil = -1        trafficleft = None        premium = False        api_data = self.api_request(""getKeyInfo"", user=user, premiumKey=password)        if api_data[""type""] == ""success"":            trafficleft = self.parse_traffic(api_data[""result""][""trafficLeft""], ""byte"")            premium = api_data[""result""][""status""] == ""active""            if premium:                validuntil = time.mktime(                    time.strptime(api_data[""result""][""expiryDate""], ""%Y-%m-%d %H:%M:%S"")                )        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""premium"": premium,        }",,"def grab_info(self, user, password, data):        validuntil = -1        trafficleft = None        premium = False        api_data = self.api_request(""getKeyInfo"", user=user, premiumKey=password)        if api_data[""type""] == ""success"":            trafficleft = self.parse_traffic(api_data[""result""][""trafficLeft""], ""byte"")            premium = api_data[""result""][""status""] == ""active""            if premium:                validuntil = time.mktime(                    time.strptime(api_data[""result""][""expiryDate""], ""%Y-%m-%d %H:%M:%S"")                )        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""premium"": premium,        }",102c9eb5-569b-4acf-8977-4663d6877c3d
accounts,NitroflareCom.py,signin,50,61,"def signin(self, user, password, data):        api_data = self.api_request(""getKeyInfo"", user=user, premiumKey=password)        if api_data[""type""] != ""success"":            error_code = api_data[""code""]            if error_code != 12:                self.log_error(api_data[""message""])                self.fail_login()            else:                self.fail_login(self._(""Account Login Requires Recaptcha""))",,"def signin(self, user, password, data):        api_data = self.api_request(""getKeyInfo"", user=user, premiumKey=password)        if api_data[""type""] != ""success"":            error_code = api_data[""code""]            if error_code != 12:                self.log_error(api_data[""message""])                self.fail_login()            else:                self.fail_login(self._(""Account Login Requires Recaptcha""))",da5f995b-3e15-4326-ae1d-8a4effa48b5f
accounts,NoPremiumPl.py,grab_hosters,40,50,"def grab_hosters(self, user, password, data):        html = self.load(""https://www.nopremium.pl/clipboard.php?json=3"").strip()        hostings = json.loads(html)        hostings_domains = [            domain            for row in hostings            for domain in row[""domains""]            if row[""sdownload""] == ""0""        ]        self.log_debug(hostings_domains)        return hostings_domains",,"def grab_hosters(self, user, password, data):        html = self.load(""https://www.nopremium.pl/clipboard.php?json=3"").strip()        hostings = json.loads(html)        hostings_domains = [            domain            for row in hostings            for domain in row[""domains""]            if row[""sdownload""] == ""0""        ]        self.log_debug(hostings_domains)        return hostings_domains",7204330a-6ca9-4581-9886-33bdcb30f742
accounts,NoPremiumPl.py,grab_info,52,73,"def grab_info(self, user, password, data):        try:            result = json.loads(self.run_auth_query())        except Exception:            # TODO: return or let it be thrown?            return        valid_untill = -1        if result.get(""expire""):            valid_untill = time.mktime(                datetime.datetime.fromtimestamp(int(result[""expire""])).timetuple()            )        traffic_left = result[""balance""] * 1024 ** 2        return {            ""validuntil"": valid_untill,            ""trafficleft"": traffic_left,            ""premium"": True,        }",,"def grab_info(self, user, password, data):        try:            result = json.loads(self.run_auth_query())        except Exception:            # TODO: return or let it be thrown?            return        valid_untill = -1        if result.get(""expire""):            valid_untill = time.mktime(                datetime.datetime.fromtimestamp(int(result[""expire""])).timetuple()            )        traffic_left = result[""balance""] * 1024 ** 2        return {            ""validuntil"": valid_untill,            ""trafficleft"": traffic_left,            ""premium"": True,        }",117a7421-fed7-48e2-92c4-27e777d7e190
accounts,NoPremiumPl.py,signin,75,87,"def signin(self, user, password, data):        data[""hash_password""] = hashlib.sha1(            hashlib.md5(password.encode()).hexdigest().encode()        ).hexdigest()        try:            response = json.loads(self.run_auth_query())        except Exception as exc:            self.fail_login(exc)        if ""errno"" in response.keys():            self.fail_login()",,"def signin(self, user, password, data):        data[""hash_password""] = hashlib.sha1(            hashlib.md5(password.encode()).hexdigest().encode()        ).hexdigest()        try:            response = json.loads(self.run_auth_query())        except Exception as exc:            self.fail_login(exc)        if ""errno"" in response.keys():            self.fail_login()",9bf81285-4312-4fae-870a-5b5d09a5c007
accounts,NoPremiumPl.py,create_auth_query,89,93,"def create_auth_query(self):        query = self.API_QUERY        query[""username""] = self.user        query[""password""] = self.info[""data""][""hash_password""]        return query",,"def create_auth_query(self):        query = self.API_QUERY        query[""username""] = self.user        query[""password""] = self.info[""data""][""hash_password""]        return query",751dd349-aed3-471f-b11b-90620d4702f0
accounts,NoPremiumPl.py,run_auth_query,95,96,"def run_auth_query(self):        return self.load(self.API_URL, post=self.create_auth_query(), redirect=20)",,"def run_auth_query(self):        return self.load(self.API_URL, post=self.create_auth_query(), redirect=20)",c8cf7fad-fc70-4769-a1b9-f024b6b565c3
accounts,NowVideoSx.py,grab_info,21,54,"def grab_info(self, user, password, data):        validuntil = None        trafficleft = -1        premium = None        html = self.load(""http://www.nowvideo.sx/premium.php"")        m = re.search(self.VALID_UNTIL_PATTERN, html)        if m is not None:            expiredate = m.group(1).strip()            self.log_debug(""Expire date: "" + expiredate)            try:                validuntil = time.mktime(time.strptime(expiredate, ""%Y-%b-%d""))            except Exception as exc:                self.log_error(                    exc,                    exc_info=self.pyload.debug > 1,                    stack_info=self.pyload.debug > 2,                )            else:                if validuntil > time.mktime(time.gmtime()):                    premium = True                else:                    premium = False                    validuntil = -1        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""premium"": premium,        }",,"def grab_info(self, user, password, data):        validuntil = None        trafficleft = -1        premium = None        html = self.load(""http://www.nowvideo.sx/premium.php"")        m = re.search(self.VALID_UNTIL_PATTERN, html)        if m is not None:            expiredate = m.group(1).strip()            self.log_debug(""Expire date: "" + expiredate)            try:                validuntil = time.mktime(time.strptime(expiredate, ""%Y-%b-%d""))            except Exception as exc:                self.log_error(                    exc,                    exc_info=self.pyload.debug > 1,                    stack_info=self.pyload.debug > 2,                )            else:                if validuntil > time.mktime(time.gmtime()):                    premium = True                else:                    premium = False                    validuntil = -1        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""premium"": premium,        }",5ac5efc1-412e-4e0e-9d6f-a291bdfede65
accounts,NowVideoSx.py,signin,56,62,"def signin(self, user, password, data):        html = self.load(            ""http://www.nowvideo.sx/login.php"", post={""user"": user, ""pass"": password}        )        if re.search(r"">Log In<"", html):            self.fail_login()",,"def signin(self, user, password, data):        html = self.load(            ""http://www.nowvideo.sx/login.php"", post={""user"": user, ""pass"": password}        )        if re.search(r"">Log In<"", html):            self.fail_login()",d3be40d1-9b8f-467f-a001-14a846efd690
accounts,OboomIo.py,grab_info,24,42,"def grab_info(self, user, password, data):        html = self.load(""https://oboom.io/dashboard"")        premium = re.search(self.PREMIUM_PATTERN, html) is not None        validuntil = None        m = re.search(self.VALID_UNTIL_PATTERN, html)        if m is not None:            previous_locale = locale.getlocale(locale.LC_TIME)            try:                locale.setlocale(locale.LC_TIME, ""en_US.UTF-8"")                validuntil = time.mktime(time.strptime(m.group(1).strip(), ""%d %b %Y, %H:%M""))            finally:                locale.setlocale(locale.LC_TIME, previous_locale)        else:            self.log_error(self._(""VALID_UNTIL_PATTERN not found""))        return {""validuntil"": validuntil, ""trafficleft"": -1, ""premium"": premium}",,"def grab_info(self, user, password, data):        html = self.load(""https://oboom.io/dashboard"")        premium = re.search(self.PREMIUM_PATTERN, html) is not None        validuntil = None        m = re.search(self.VALID_UNTIL_PATTERN, html)        if m is not None:            previous_locale = locale.getlocale(locale.LC_TIME)            try:                locale.setlocale(locale.LC_TIME, ""en_US.UTF-8"")                validuntil = time.mktime(time.strptime(m.group(1).strip(), ""%d %b %Y, %H:%M""))            finally:                locale.setlocale(locale.LC_TIME, previous_locale)        else:            self.log_error(self._(""VALID_UNTIL_PATTERN not found""))        return {""validuntil"": validuntil, ""trafficleft"": -1, ""premium"": premium}",1b3536bf-1390-4a74-b949-e637ef56a8dc
accounts,OboomIo.py,signin,44,59,"def signin(self, user, password, data):        html = self.load(""https://oboom.io/dashboard"")        if 'href=""/logout""' in html:            self.skip_login()        html = self.load(            ""https://oboom.io/api/1.0/apiGetUserLogin/"",            post={                ""email"": user,                ""pass"": password,                ""re"": ""0""            }        )        json_data = json.loads(html)        if json_data.get(""message"") != ""successUserLogin"":            self.fail_login()",,"def signin(self, user, password, data):        html = self.load(""https://oboom.io/dashboard"")        if 'href=""/logout""' in html:            self.skip_login()        html = self.load(            ""https://oboom.io/api/1.0/apiGetUserLogin/"",            post={                ""email"": user,                ""pass"": password,                ""re"": ""0""            }        )        json_data = json.loads(html)        if json_data.get(""message"") != ""successUserLogin"":            self.fail_login()",8ccf7063-d743-4f58-a52d-c4d926a0a773
accounts,OneFichierCom.py,grab_info,27,52,"def grab_info(self, user, password, data):        validuntil = None        trafficleft = -1        premium = False        html = self.load(""https://1fichier.com/console/abo.pl"")        m = re.search(self.VALID_UNTIL_PATTERN, html)        if m is not None:            expire_date = m.group(1)            self.log_debug(""Expire date: "" + expire_date)            try:                validuntil = time.mktime(time.strptime(expire_date, ""%Y-%m-%d""))            except Exception as exc:                self.log_error(exc)            else:                premium = True        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""premium"": premium,        }",,"def grab_info(self, user, password, data):        validuntil = None        trafficleft = -1        premium = False        html = self.load(""https://1fichier.com/console/abo.pl"")        m = re.search(self.VALID_UNTIL_PATTERN, html)        if m is not None:            expire_date = m.group(1)            self.log_debug(""Expire date: "" + expire_date)            try:                validuntil = time.mktime(time.strptime(expire_date, ""%Y-%m-%d""))            except Exception as exc:                self.log_error(exc)            else:                premium = True        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""premium"": premium,        }",f5861ef9-580e-4b17-b97d-05baa30051f5
accounts,OneFichierCom.py,signin,54,89,"def signin(self, user, password, data):        login_url = ""https://1fichier.com/login.pl?lg=en""        html = self.load(login_url)        if ""/logout.pl"" in html:            self.skip_login()        try:            html = self.load(                login_url,                ref=login_url,                post={                    ""mail"": user,                    ""pass"": password,                    ""lt"": ""on"",                    ""purge"": ""off"",                    ""valider"": ""OK"",                },            )            if any(                x in html                for x in (                    "">Invalid username or Password"",                    "">Invalid email address"",                    "">Invalid password"",                    "">Invalid username"",                )            ):                self.fail_login()        except BadHeader as exc:            if exc.code == 403:                self.fail_login()            else:                raise",,"def signin(self, user, password, data):        login_url = ""https://1fichier.com/login.pl?lg=en""        html = self.load(login_url)        if ""/logout.pl"" in html:            self.skip_login()        try:            html = self.load(                login_url,                ref=login_url,                post={                    ""mail"": user,                    ""pass"": password,                    ""lt"": ""on"",                    ""purge"": ""off"",                    ""valider"": ""OK"",                },            )            if any(                x in html                for x in (                    "">Invalid username or Password"",                    "">Invalid email address"",                    "">Invalid password"",                    "">Invalid username"",                )            ):                self.fail_login()        except BadHeader as exc:            if exc.code == 403:                self.fail_login()            else:                raise",37efd180-54b2-45a8-9412-8655d01ee755
accounts,OverLoadMe.py,grab_hosters,24,31,"def grab_hosters(self, user, password, data):        html = self.load(            ""https://api.over-load.me/hoster.php"",            get={                ""auth"": ""0001-cb1f24dadb3aa487bda5afd3b76298935329be7700cd7-5329be77-00cf-1ca0135f""            },        )        return [x.strip() for x in html.replace('""', """").split("","") if x.strip()]",,"def grab_hosters(self, user, password, data):        html = self.load(            ""https://api.over-load.me/hoster.php"",            get={                ""auth"": ""0001-cb1f24dadb3aa487bda5afd3b76298935329be7700cd7-5329be77-00cf-1ca0135f""            },        )        return [x.strip() for x in html.replace('""', """").split("","") if x.strip()]",5c3ef08b-93e3-4bd2-98e3-3c39b50cb9f7
accounts,OverLoadMe.py,grab_info,33,49,"def grab_info(self, user, password, data):        html = self.load(            ""https://api.over-load.me/account.php"", get={""user"": user, ""auth"": password}        ).strip()        data = json.loads(html)        self.log_debug(data)        #: Check for premium        if data[""membership""] == ""Free"":            return {""premium"": False, ""validuntil"": None, ""trafficleft"": None}        else:            return {                ""premium"": True,                ""validuntil"": data[""expirationunix""],                ""trafficleft"": -1,            }",,"def grab_info(self, user, password, data):        html = self.load(            ""https://api.over-load.me/account.php"", get={""user"": user, ""auth"": password}        ).strip()        data = json.loads(html)        self.log_debug(data)        #: Check for premium        if data[""membership""] == ""Free"":            return {""premium"": False, ""validuntil"": None, ""trafficleft"": None}        else:            return {                ""premium"": True,                ""validuntil"": data[""expirationunix""],                ""trafficleft"": -1,            }",f49d9093-b71e-42da-b287-d89c6a527396
accounts,OverLoadMe.py,signin,51,59,"def signin(self, user, password, data):        html = self.load(            ""https://api.over-load.me/account.php"", get={""user"": user, ""auth"": password}        ).strip()        data = json.loads(html)        if data[""err""] == 1:            self.fail_login()",,"def signin(self, user, password, data):        html = self.load(            ""https://api.over-load.me/account.php"", get={""user"": user, ""auth"": password}        ).strip()        data = json.loads(html)        if data[""err""] == 1:            self.fail_login()",86d7e78b-cdae-4ad5-8a1e-a499c2c304b1
accounts,PixeldrainCom.py,grab_info,24,30,"def grab_info(self, user, password, data):        # unfortunately, there is no method for account info, assume premium        return {            ""validuntil"": -1,            ""trafficleft"": -1,            ""premium"": True        }",,"def grab_info(self, user, password, data):        # unfortunately, there is no method for account info, assume premium        return {            ""validuntil"": -1,            ""trafficleft"": -1,            ""premium"": True        }",bb9b9ac0-821c-4edf-9926-f62954228a27
accounts,PixeldrainCom.py,signin,32,42,"def signin(self, user, password, data):        self.req.http.c.setopt(pycurl.USERPWD, f"":{password}"")        try:            json_data = self.load(f""{self.API_URL}/user/lists"")        except BadHeader as exc:            json_data = exc.content        api_data = json.loads(json_data)        if not api_data.get(""success"", True):            self.log_error(api_data[""message""])            self.fail_login()",,"def signin(self, user, password, data):        self.req.http.c.setopt(pycurl.USERPWD, f"":{password}"")        try:            json_data = self.load(f""{self.API_URL}/user/lists"")        except BadHeader as exc:            json_data = exc.content        api_data = json.loads(json_data)        if not api_data.get(""success"", True):            self.log_error(api_data[""message""])            self.fail_login()",14d8f031-d9d6-4f14-96fc-59528ef4ff18
accounts,PorntrexCom.py,grab_info,18,22,"def grab_info(self, user, password, data):        return {            ""validuntil"": -1,            ""trafficleft"": -1,        }",,"def grab_info(self, user, password, data):        return {            ""validuntil"": -1,            ""trafficleft"": -1,        }",317d90a6-4d92-423f-9333-9a4508af666b
accounts,PorntrexCom.py,signin,24,40,"def signin(self, user, password, data):        html = self.load(""https://www.porntrex.com"")        if "">Log out<"" in html:            self.skip_login()        url, inputs = parse_html_form(            'action=""https://www.porntrex.com/ajax-login/""', html        )        if inputs is None:            self.fail_login(""Login form not found"")        inputs[""username""] = user        inputs[""pass""] = password        html = self.load(url, post=inputs)        if "">Log out<"" not in html:            self.fail_login()",,"def signin(self, user, password, data):        html = self.load(""https://www.porntrex.com"")        if "">Log out<"" in html:            self.skip_login()        url, inputs = parse_html_form(            'action=""https://www.porntrex.com/ajax-login/""', html        )        if inputs is None:            self.fail_login(""Login form not found"")        inputs[""username""] = user        inputs[""pass""] = password        html = self.load(url, post=inputs)        if "">Log out<"" not in html:            self.fail_login()",c4e0a019-0938-40d4-ae58-f525fffe0c7b
accounts,PremiumizeMe.py,api_respond,30,33,"def api_respond(self, method, **kwargs):        json_data = self.load(self.API_URL + method, get=kwargs)        return json.loads(json_data)",,"def api_respond(self, method, **kwargs):        json_data = self.load(self.API_URL + method, get=kwargs)        return json.loads(json_data)",0a8f0d27-7aba-4700-b700-11c9a9d0ec95
accounts,PremiumizeMe.py,grab_hosters,35,42,"def grab_hosters(self, user, password, data):        res = self.api_respond(""services/list"", apikey=password)        hosters = []        for _h in res['directdl']:            hosters += res['aliases'][_h]        return hosters",,"def grab_hosters(self, user, password, data):        res = self.api_respond(""services/list"", apikey=password)        hosters = []        for _h in res['directdl']:            hosters += res['aliases'][_h]        return hosters",8a635735-56a0-47ca-b37d-7fd9c23b4d48
accounts,PremiumizeMe.py,grab_info,44,62,"def grab_info(self, user, password, data):        validuntil = None        trafficleft = None        premium = False        res = self.api_respond(""account/info"", apikey=password)        if res['status'] == ""success"":            premium = res['premium_until'] is not False            if premium:                validuntil = res['premium_until']                trafficleft = -1        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""premium"": premium,        }",,"def grab_info(self, user, password, data):        validuntil = None        trafficleft = None        premium = False        res = self.api_respond(""account/info"", apikey=password)        if res['status'] == ""success"":            premium = res['premium_until'] is not False            if premium:                validuntil = res['premium_until']                trafficleft = -1        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""premium"": premium,        }",d2934530-9742-41a2-af53-31b327f6324c
accounts,PremiumizeMe.py,signin,64,79,"def signin(self, user, password, data):        res = self.api_respond(""account/info"", apikey=password)        if res['status'] != ""success"":            self.log_error(                self._(""Password for premiumize.me should be the API token - get it from: https://www.premiumize.me/account"")            )            self.fail_login(res['message'])        elif res['customer_id'] != user:            self.log_error(                self._(""username for premiumize.me should be the Customer ID - get it from: https://www.premiumize.me/account"")            )            self.fail_login()",,"def signin(self, user, password, data):        res = self.api_respond(""account/info"", apikey=password)        if res['status'] != ""success"":            self.log_error(                self._(""Password for premiumize.me should be the API token - get it from: https://www.premiumize.me/account"")            )            self.fail_login(res['message'])        elif res['customer_id'] != user:            self.log_error(                self._(""username for premiumize.me should be the Customer ID - get it from: https://www.premiumize.me/account"")            )            self.fail_login()",b0564e11-1f57-4454-b49a-621f4315b836
accounts,PremiumTo.py,api_request,32,33,"def api_request(self, method, **kwargs):        return json.loads(self.load(self.API_URL + method + "".php"", get=kwargs))",,"def api_request(self, method, **kwargs):        return json.loads(self.load(self.API_URL + method + "".php"", get=kwargs))",c1e2e84e-d6f0-4193-bf09-cea8d4e13d1b
accounts,PremiumTo.py,grab_hosters,35,37,"def grab_hosters(self, user, password, data):        api_data = self.api_request(""hosts"", userid=user, apikey=password)        return api_data[""hosts""] if api_data.get(""code"") == 200 else []",,"def grab_hosters(self, user, password, data):        api_data = self.api_request(""hosts"", userid=user, apikey=password)        return api_data[""hosts""] if api_data.get(""code"") == 200 else []",969ea349-a4c4-4ab2-9bca-d0bf346d4de7
accounts,PremiumTo.py,grab_info,39,47,"def grab_info(self, user, password, data):        api_data = self.api_request(""traffic"", userid=user, apikey=password)        if api_data.get(""code"") == 200:            trafficleft = api_data[""traffic""] + api_data[""specialtraffic""]            return {""premium"": True, ""trafficleft"": trafficleft, ""validuntil"": -1}        else:            return {""premium"": False, ""trafficleft"": None, ""validuntil"": None}",,"def grab_info(self, user, password, data):        api_data = self.api_request(""traffic"", userid=user, apikey=password)        if api_data.get(""code"") == 200:            trafficleft = api_data[""traffic""] + api_data[""specialtraffic""]            return {""premium"": True, ""trafficleft"": trafficleft, ""validuntil"": -1}        else:            return {""premium"": False, ""trafficleft"": None, ""validuntil"": None}",a7462077-0de5-414f-8829-c856f0e381d8
accounts,PremiumTo.py,signin,49,59,"def signin(self, user, password, data):        api_data = self.api_request(""traffic"", userid=user, apikey=password)        if api_data[""code""] != 200:            self.log_warning(                self._(                    ""Username and password for PremiumTo should be the API userid & apikey""                )            )            self.log_warning(api_data[""message""])            self.fail_login()",,"def signin(self, user, password, data):        api_data = self.api_request(""traffic"", userid=user, apikey=password)        if api_data[""code""] != 200:            self.log_warning(                self._(                    ""Username and password for PremiumTo should be the API userid & apikey""                )            )            self.log_warning(api_data[""message""])            self.fail_login()",d85f090f-adbb-4a25-a135-d8508bc3a745
accounts,QuickshareCz.py,grab_info,20,31,"def grab_info(self, user, password, data):        html = self.load(""http://www.quickshare.cz/premium"")        m = re.search(self.TRAFFIC_LEFT_PATTERN, html)        if m is not None:            trafficleft = self.parse_traffic(m.group(1))            premium = True if trafficleft else False        else:            trafficleft = None            premium = False        return {""validuntil"": -1, ""trafficleft"": trafficleft, ""premium"": premium}",,"def grab_info(self, user, password, data):        html = self.load(""http://www.quickshare.cz/premium"")        m = re.search(self.TRAFFIC_LEFT_PATTERN, html)        if m is not None:            trafficleft = self.parse_traffic(m.group(1))            premium = True if trafficleft else False        else:            trafficleft = None            premium = False        return {""validuntil"": -1, ""trafficleft"": trafficleft, ""premium"": premium}",a9a6cecd-8c36-462d-8413-124adc5c8fb6
accounts,QuickshareCz.py,signin,33,40,"def signin(self, user, password, data):        html = self.load(            ""http://www.quickshare.cz/html/prihlaseni_process.php"",            post={""akce"": ""Přihlásit"", ""heslo"": password, ""jmeno"": user},        )        if "">Takový uživatel neexistuje.<"" in html or "">Špatné heslo.<"" in html:            self.fail_login()",,"def signin(self, user, password, data):        html = self.load(            ""http://www.quickshare.cz/html/prihlaseni_process.php"",            post={""akce"": ""Přihlásit"", ""heslo"": password, ""jmeno"": user},        )        if "">Takový uživatel neexistuje.<"" in html or "">Špatné heslo.<"" in html:            self.fail_login()",e6ca0e20-b060-4685-b223-9adae7c8f522
accounts,RapideoPl.py,grab_hosters,37,47,"def grab_hosters(self, user, password, data):        html = self.load(""https://www.rapideo.pl/clipboard.php?json=3"").strip()        hostings = json.loads(html)        hostings_domains = [            domain            for row in hostings            for domain in row[""domains""]            if row[""sdownload""] == ""0""        ]        self.log_debug(hostings_domains)        return hostings_domains",,"def grab_hosters(self, user, password, data):        html = self.load(""https://www.rapideo.pl/clipboard.php?json=3"").strip()        hostings = json.loads(html)        hostings_domains = [            domain            for row in hostings            for domain in row[""domains""]            if row[""sdownload""] == ""0""        ]        self.log_debug(hostings_domains)        return hostings_domains",3cc025eb-1e79-4a8a-aa07-5f7ce97542fb
accounts,RapideoPl.py,grab_info,49,72,"def grab_info(self, user, password, data):        try:            result = json.loads(self.run_auth_query())        except Exception:            # TODO: return or let it be thrown?            return        premium = False        valid_untill = -1        if ""expire"" in result.keys() and result[""expire""]:            premium = True            valid_untill = time.mktime(                datetime.datetime.fromtimestamp(int(result[""expire""])).timetuple()            )        traffic_left = result[""balance""]        return {            ""validuntil"": valid_untill,            ""trafficleft"": traffic_left,            ""premium"": premium,        }",,"def grab_info(self, user, password, data):        try:            result = json.loads(self.run_auth_query())        except Exception:            # TODO: return or let it be thrown?            return        premium = False        valid_untill = -1        if ""expire"" in result.keys() and result[""expire""]:            premium = True            valid_untill = time.mktime(                datetime.datetime.fromtimestamp(int(result[""expire""])).timetuple()            )        traffic_left = result[""balance""]        return {            ""validuntil"": valid_untill,            ""trafficleft"": traffic_left,            ""premium"": premium,        }",ecc79eec-4476-4b43-81e5-916f6293f388
accounts,RapideoPl.py,signin,74,85,"def signin(self, user, password, data):        data[""usr""] = user        data[""pwd""] = hashlib.md5(password.encode()).hexdigest()        try:            response = json.loads(self.run_auth_query())        except Exception:            self.fail_login()        if ""errno"" in response.keys():            self.fail_login()",,"def signin(self, user, password, data):        data[""usr""] = user        data[""pwd""] = hashlib.md5(password.encode()).hexdigest()        try:            response = json.loads(self.run_auth_query())        except Exception:            self.fail_login()        if ""errno"" in response.keys():            self.fail_login()",b0ac11f7-be15-4e53-b041-f0dd02c1acb9
accounts,RapideoPl.py,create_auth_query,87,91,"def create_auth_query(self):        query = self.API_QUERY        query[""username""] = self.info[""data""][""usr""]        query[""password""] = self.info[""data""][""pwd""]        return query",,"def create_auth_query(self):        query = self.API_QUERY        query[""username""] = self.info[""data""][""usr""]        query[""password""] = self.info[""data""][""pwd""]        return query",8bb19e03-f785-49ee-86ad-3b8fd3830a90
accounts,RapideoPl.py,run_auth_query,93,94,"def run_auth_query(self):        return self.load(self.API_URL, post=self.create_auth_query())",,"def run_auth_query(self):        return self.load(self.API_URL, post=self.create_auth_query())",4d44f5ce-76d6-4c9b-ae38-bbf2bd5de8cc
accounts,RapidgatorNet.py,api_request,25,27,"def api_request(self, method, **kwargs):        json_data = self.load(self.API_URL + method, get=kwargs)        return json.loads(json_data)",,"def api_request(self, method, **kwargs):        json_data = self.load(self.API_URL + method, get=kwargs)        return json.loads(json_data)",0db6a32f-f441-42e9-80b9-f882c4e183dd
accounts,RapidgatorNet.py,grab_info,29,54,"def grab_info(self, user, password, data):        validuntil = None        trafficleft = None        premium = False        try:            json_data = self.api_request(""info"", sid=data[""sid""])            if json_data[""response_status""] == 200:                validuntil = json_data[""response""][""expire_date""]                trafficleft = float(json_data[""response""][""traffic_left""])                premium = True            else:                self.log_error(json_data[""response_details""])        except Exception as exc:            self.log_error(                exc, exc_info=self.pyload.debug > 1, stack_info=self.pyload.debug > 2            )        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""premium"": premium,        }",,"def grab_info(self, user, password, data):        validuntil = None        trafficleft = None        premium = False        try:            json_data = self.api_request(""info"", sid=data[""sid""])            if json_data[""response_status""] == 200:                validuntil = json_data[""response""][""expire_date""]                trafficleft = float(json_data[""response""][""traffic_left""])                premium = True            else:                self.log_error(json_data[""response_details""])        except Exception as exc:            self.log_error(                exc, exc_info=self.pyload.debug > 1, stack_info=self.pyload.debug > 2            )        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""premium"": premium,        }",e952cc60-0923-4c77-8100-16b20723793c
accounts,RapidgatorNet.py,signin,56,80,"def signin(self, user, password, data):        try:            json_data = self.api_request(""login"", username=user, password=password)            if json_data[""response_status""] == 200:                data[""sid""] = str(json_data[""response""][""session_id""])                if ""reset_in"" in json_data[""response""]:                    self.timeout = float(json_data[""response""][""reset_in""])                    self.TUNE_TIMEOUT = False                else:                    self.TUNE_TIMEOUT = True                return            else:                self.log_error(json_data[""response_details""])        except Exception as exc:            self.log_error(                exc, exc_info=self.pyload.debug > 1, stack_info=self.pyload.debug > 2            )        self.fail_login()",,"def signin(self, user, password, data):        try:            json_data = self.api_request(""login"", username=user, password=password)            if json_data[""response_status""] == 200:                data[""sid""] = str(json_data[""response""][""session_id""])                if ""reset_in"" in json_data[""response""]:                    self.timeout = float(json_data[""response""][""reset_in""])                    self.TUNE_TIMEOUT = False                else:                    self.TUNE_TIMEOUT = True                return            else:                self.log_error(json_data[""response_details""])        except Exception as exc:            self.log_error(                exc, exc_info=self.pyload.debug > 1, stack_info=self.pyload.debug > 2            )        self.fail_login()",68e5589b-f01e-475e-93f3-02b7ad45484b
accounts,RapiduNet.py,api_request,26,28,"def api_request(self, method, **kwargs):        json_data = self.load(self.API_URL + method + ""/"", post=kwargs)        return json.loads(json_data)",,"def api_request(self, method, **kwargs):        json_data = self.load(self.API_URL + method + ""/"", post=kwargs)        return json.loads(json_data)",40fe82e0-2d1d-4599-8e9b-58d2817e0b89
accounts,RapiduNet.py,grab_info,30,47,"def grab_info(self, user, password, data):        validuntil = None        api_data = self.api_request(""getAccountDetails"", login=user, password=password)        premium = True if api_data[""userPremium""] == ""1"" else False        if premium:            validuntil = time.mktime(                time.strptime(api_data[""userPremiumDateEnd""], ""%Y-%m-%d %H:%M:%S"")            )        trafficleft = api_data[""userTraffic""]        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""premium"": premium,        }",,"def grab_info(self, user, password, data):        validuntil = None        api_data = self.api_request(""getAccountDetails"", login=user, password=password)        premium = True if api_data[""userPremium""] == ""1"" else False        if premium:            validuntil = time.mktime(                time.strptime(api_data[""userPremiumDateEnd""], ""%Y-%m-%d %H:%M:%S"")            )        trafficleft = api_data[""userTraffic""]        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""premium"": premium,        }",83cceb3c-f134-4d0d-a56c-265e9b8dd85d
accounts,RapiduNet.py,signin,49,54,"def signin(self, user, password, data):        api_data = self.api_request(""getAccountDetails"", login=user, password=password)        if ""message"" in api_data:            self.log_error(api_data[""message""][""error""])            self.fail_login()",,"def signin(self, user, password, data):        api_data = self.api_request(""getAccountDetails"", login=user, password=password)        if ""message"" in api_data:            self.log_error(api_data[""message""][""error""])            self.fail_login()",550f20ac-bc16-42ac-99c8-c116f194b64d
accounts,RealdebridCom.py,args,11,12,def args(**kwargs):    return kwargs,,def args(**kwargs):    return kwargs,9198f319-34b8-4b72-86b8-dcfa2ce48200
accounts,RealdebridCom.py,api_request,37,52,"def api_request(self, api_type, method, get={}, post={}):        if api_type == ""rest"":            endpoint = ""/rest/1.0""        elif api_type == ""oauth"":            endpoint = ""/oauth/v2""        else:            raise ValueError(""Illegal API call type"")        self.req.http.c.setopt(pycurl.USERAGENT, ""pyLoad/{}"".format(self.pyload.version))        try:            json_data = self.load(self.API_URL + endpoint + method, get=get, post=post)        except BadHeader as exc:            json_data = exc.content        return json.loads(json_data)",,"def api_request(self, api_type, method, get={}, post={}):        if api_type == ""rest"":            endpoint = ""/rest/1.0""        elif api_type == ""oauth"":            endpoint = ""/oauth/v2""        else:            raise ValueError(""Illegal API call type"")        self.req.http.c.setopt(pycurl.USERAGENT, ""pyLoad/{}"".format(self.pyload.version))        try:            json_data = self.load(self.API_URL + endpoint + method, get=get, post=post)        except BadHeader as exc:            json_data = exc.content        return json.loads(json_data)",7fef9eb6-30ab-4656-9564-2c696c12f7b3
accounts,RealdebridCom.py,_refresh_token,54,68,"def _refresh_token(self, client_id, client_secret, refresh_token):        res = self.api_request(""oauth"", ""/token"",                                post=args(client_id=client_id,                                          client_secret=client_secret,                                          code=refresh_token,                                          grant_type=""http://oauth.net/grant_type/device/1.0""))        if 'error' in res:            self.log_error(self._(                (""You have to use GetRealdebridToken.py to authorize pyLoad: ""                 ""https://github.com/pyload/pyload/files/4406037/GetRealdebridToken.zip"")            ))            self.fail_login()        return res['access_token'], res['expires_in']",,"def _refresh_token(self, client_id, client_secret, refresh_token):        res = self.api_request(""oauth"", ""/token"",                                post=args(client_id=client_id,                                          client_secret=client_secret,                                          code=refresh_token,                                          grant_type=""http://oauth.net/grant_type/device/1.0""))        if 'error' in res:            self.log_error(self._(                (""You have to use GetRealdebridToken.py to authorize pyLoad: ""                 ""https://github.com/pyload/pyload/files/4406037/GetRealdebridToken.zip"")            ))            self.fail_login()        return res['access_token'], res['expires_in']",62e0acd6-1ad2-41a4-80a4-fb8dc31d5aab
accounts,RealdebridCom.py,grab_hosters,70,73,"def grab_hosters(self, user, password, data):        api_data = self.api_request(""rest"", ""/hosts/status"", args(auth_token=data['api_token']))        hosters = [x[0] for x in api_data.items() if x[1]['supported'] == 1]        return hosters",,"def grab_hosters(self, user, password, data):        api_data = self.api_request(""rest"", ""/hosts/status"", args(auth_token=data['api_token']))        hosters = [x[0] for x in api_data.items() if x[1]['supported'] == 1]        return hosters",74e1b857-7e4d-4c41-b8e5-325af6bbe5d6
accounts,RealdebridCom.py,grab_info,75,82,"def grab_info(self, user, password, data):        api_data = self.api_request(""rest"", ""/user"", args(auth_token=data['api_token']))        premium_remain = api_data[""premium""]        premium = premium_remain > 0        validuntil = time.time() + premium_remain if premium else -1        return {""validuntil"": validuntil, ""trafficleft"": -1, ""premium"": premium}",,"def grab_info(self, user, password, data):        api_data = self.api_request(""rest"", ""/user"", args(auth_token=data['api_token']))        premium_remain = api_data[""premium""]        premium = premium_remain > 0        validuntil = time.time() + premium_remain if premium else -1        return {""validuntil"": validuntil, ""trafficleft"": -1, ""premium"": premium}",cc5f9768-10d9-453f-be62-46150a572629
accounts,RealdebridCom.py,signin,84,111,"def signin(self, user, password, data):        user = user.split('/')        if len(user) != 2:            self.log_error(self._(                (""You have to use GetRealdebridToken.py to authorize pyLoad: ""                 ""https://github.com/pyload/pyload/files/4406037/GetRealdebridToken.zip"")            ))            self.fail_login()        client_id, client_secret = user        if 'api_token' not in data:            api_token, timeout = self._refresh_token(client_id, client_secret, password)            data['api_token'] = api_token            self.timeout = timeout - 5 * 60  #: Five minutes less to be on the safe side        api_token = data['api_token']        api_data = self.api_request(""rest"", ""/user"", args(auth_token=api_token))        if api_data.get('error_code') == 8:  #: Token expired? try to refresh            api_token, timeout = self._refresh_token(client_id, client_secret, password)            data['api_token'] = api_token            self.timeout = timeout - 5 * 60  #: Five minutes less to be on the safe side        elif 'error' in api_data:            self.log_error(api_data['error'])            self.fail_login()",,"def signin(self, user, password, data):        user = user.split('/')        if len(user) != 2:            self.log_error(self._(                (""You have to use GetRealdebridToken.py to authorize pyLoad: ""                 ""https://github.com/pyload/pyload/files/4406037/GetRealdebridToken.zip"")            ))            self.fail_login()        client_id, client_secret = user        if 'api_token' not in data:            api_token, timeout = self._refresh_token(client_id, client_secret, password)            data['api_token'] = api_token            self.timeout = timeout - 5 * 60  #: Five minutes less to be on the safe side        api_token = data['api_token']        api_data = self.api_request(""rest"", ""/user"", args(auth_token=api_token))        if api_data.get('error_code') == 8:  #: Token expired? try to refresh            api_token, timeout = self._refresh_token(client_id, client_secret, password)            data['api_token'] = api_token            self.timeout = timeout - 5 * 60  #: Five minutes less to be on the safe side        elif 'error' in api_data:            self.log_error(api_data['error'])            self.fail_login()",71da0265-43ec-46b5-b2d5-d350be4ec02c
accounts,RehostTo.py,grab_hosters,23,28,"def grab_hosters(self, user, password, data):        html = self.load(            ""http://rehost.to/api.php"",            get={""cmd"": ""get_supported_och_dl"", ""long_ses"": data[""session""]},        )        return [x.strip() for x in html.replace('""', """").split("","") if x.strip()]",,"def grab_hosters(self, user, password, data):        html = self.load(            ""http://rehost.to/api.php"",            get={""cmd"": ""get_supported_och_dl"", ""long_ses"": data[""session""]},        )        return [x.strip() for x in html.replace('""', """").split("","") if x.strip()]",14dec52a-3ce8-44cb-a65a-9082d0abfa0d
accounts,RehostTo.py,grab_info,30,63,"def grab_info(self, user, password, data):        premium = False        trafficleft = None        validuntil = -1        session = """"        html = self.load(            ""https://rehost.to/api.php"",            get={""cmd"": ""login"", ""user"": user, ""pass"": password},        )        try:            session = html.split("","")[1].split(""="")[1]            html = self.load(                ""http://rehost.to/api.php"",                get={""cmd"": ""get_premium_credits"", ""long_ses"": session},            )            if html.strip() == ""0,0"" or ""ERROR"" in html:                self.log_debug(html)            else:                traffic, valid = html.split("","")                premium = True                trafficleft = self.parse_traffic(traffic, ""MiB"")                validuntil = float(valid)        finally:            return {                ""premium"": premium,                ""trafficleft"": trafficleft,                ""validuntil"": validuntil,                ""session"": session,            }",,"def grab_info(self, user, password, data):        premium = False        trafficleft = None        validuntil = -1        session = """"        html = self.load(            ""https://rehost.to/api.php"",            get={""cmd"": ""login"", ""user"": user, ""pass"": password},        )        try:            session = html.split("","")[1].split(""="")[1]            html = self.load(                ""http://rehost.to/api.php"",                get={""cmd"": ""get_premium_credits"", ""long_ses"": session},            )            if html.strip() == ""0,0"" or ""ERROR"" in html:                self.log_debug(html)            else:                traffic, valid = html.split("","")                premium = True                trafficleft = self.parse_traffic(traffic, ""MiB"")                validuntil = float(valid)        finally:            return {                ""premium"": premium,                ""trafficleft"": trafficleft,                ""validuntil"": validuntil,                ""session"": session,            }",62dd8f8c-a73a-478f-bd9c-b337b5b26e54
accounts,RehostTo.py,signin,65,73,"def signin(self, user, password, data):        html = self.load(            ""https://rehost.to/api.php"",            get={""cmd"": ""login"", ""user"": user, ""pass"": password},        )        if ""ERROR"" in html:            self.log_debug(html)            self.fail_login()",,"def signin(self, user, password, data):        html = self.load(            ""https://rehost.to/api.php"",            get={""cmd"": ""login"", ""user"": user, ""pass"": password},        )        if ""ERROR"" in html:            self.log_debug(html)            self.fail_login()",8487d9d5-da11-4783-8601-54dd4004ab0a
accounts,RPNetBiz.py,grab_hosters,24,36,"def grab_hosters(self, user, password, data):        res = self.load(            ""https://premium.rpnet.biz/client_api.php"",            get={""username"": user, ""password"": password, ""action"": ""showHosterList""},        )        hoster_list = json.loads(res)        #: If account is not valid thera are no hosters available        if ""error"" in hoster_list:            return []        #: Extract hosters from json file        return hoster_list[""hosters""]",,"def grab_hosters(self, user, password, data):        res = self.load(            ""https://premium.rpnet.biz/client_api.php"",            get={""username"": user, ""password"": password, ""action"": ""showHosterList""},        )        hoster_list = json.loads(res)        #: If account is not valid thera are no hosters available        if ""error"" in hoster_list:            return []        #: Extract hosters from json file        return hoster_list[""hosters""]",1fc88e99-4c3e-4bb9-9f5a-7aad93c56b8a
accounts,RPNetBiz.py,grab_info,38,60,"def grab_info(self, user, password, data):        #: Get account information from rpnet.biz        res = self.get_account_status(user, password)        try:            if res[""accountInfo""][""isPremium""]:                #: Parse account info. Change the trafficleft later to support per host info.                account_info = {                    ""validuntil"": float(res[""accountInfo""][""premiumExpiry""]),                    ""trafficleft"": -1,                    ""premium"": True,                }            else:                account_info = {                    ""validuntil"": None,                    ""trafficleft"": None,                    ""premium"": False,                }        except KeyError:            #: Handle wrong password exception            account_info = {""validuntil"": None, ""trafficleft"": None, ""premium"": False}        return account_info",,"def grab_info(self, user, password, data):        #: Get account information from rpnet.biz        res = self.get_account_status(user, password)        try:            if res[""accountInfo""][""isPremium""]:                #: Parse account info. Change the trafficleft later to support per host info.                account_info = {                    ""validuntil"": float(res[""accountInfo""][""premiumExpiry""]),                    ""trafficleft"": -1,                    ""premium"": True,                }            else:                account_info = {                    ""validuntil"": None,                    ""trafficleft"": None,                    ""premium"": False,                }        except KeyError:            #: Handle wrong password exception            account_info = {""validuntil"": None, ""trafficleft"": None, ""premium"": False}        return account_info",d6491ef6-eada-4ec0-9f1c-3e0537f1f7cf
accounts,RPNetBiz.py,signin,62,68,"def signin(self, user, password, data):        #: Get account information from rpnet.biz        res = self.get_account_status(user, password)        #: If we have an error in the res, we have wrong login information        if ""error"" in res:            self.fail_login()",,"def signin(self, user, password, data):        #: Get account information from rpnet.biz        res = self.get_account_status(user, password)        #: If we have an error in the res, we have wrong login information        if ""error"" in res:            self.fail_login()",c3afb9af-a8a0-4701-921a-f6896f02fda4
accounts,RPNetBiz.py,get_account_status,70,82,"def get_account_status(self, user, password):        #: Using the rpnet API, check if valid premium account        res = self.load(            ""https://premium.rpnet.biz/client_api.php"",            get={                ""username"": user,                ""password"": password,                ""action"": ""showAccountInformation"",            },        )        self.log_debug(f""JSON data: {res}"")        return json.loads(res)",,"def get_account_status(self, user, password):        #: Using the rpnet API, check if valid premium account        res = self.load(            ""https://premium.rpnet.biz/client_api.php"",            get={                ""username"": user,                ""password"": password,                ""action"": ""showAccountInformation"",            },        )        self.log_debug(f""JSON data: {res}"")        return json.loads(res)",d31be8eb-ab3a-4191-9197-4017c56c9aa3
accounts,SimplydebridCom.py,grab_hosters,27,29,"def grab_hosters(self, user, password, data):        html = self.load(""http://simply-debrid.com/api.php"", get={""list"": 1})        return [x for x in html.split("";"") if x]",,"def grab_hosters(self, user, password, data):        html = self.load(""http://simply-debrid.com/api.php"", get={""list"": 1})        return [x for x in html.split("";"") if x]",b12f1b95-1c5b-4b57-b0cd-c0e44af13e00
accounts,SimplydebridCom.py,grab_info,31,44,"def grab_info(self, user, password, data):        res = self.load(            ""http://simply-debrid.com/api.php"",            get={""login"": 2, ""u"": user, ""p"": password},        )        data = [x.strip() for x in res.split("";"")]        if str(data[0]) != ""1"":            return {""premium"": False}        else:            return {                ""premium"": True,                ""trafficleft"": -1,                ""validuntil"": time.mktime(time.strptime(str(data[2]), ""%d/%m/%Y"")),            }",,"def grab_info(self, user, password, data):        res = self.load(            ""http://simply-debrid.com/api.php"",            get={""login"": 2, ""u"": user, ""p"": password},        )        data = [x.strip() for x in res.split("";"")]        if str(data[0]) != ""1"":            return {""premium"": False}        else:            return {                ""premium"": True,                ""trafficleft"": -1,                ""validuntil"": time.mktime(time.strptime(str(data[2]), ""%d/%m/%Y"")),            }",2294e741-8de4-41c7-a927-31342d5c99a7
accounts,SimplydebridCom.py,signin,46,52,"def signin(self, user, password, data):        res = self.load(            ""https://simply-debrid.com/api.php"",            get={""login"": 1, ""u"": user, ""p"": password},        )        if res != ""02: loggin success"":            self.fail_login()",,"def signin(self, user, password, data):        res = self.load(            ""https://simply-debrid.com/api.php"",            get={""login"": 1, ""u"": user, ""p"": password},        )        if res != ""02: loggin success"":            self.fail_login()",1eeca5a1-c288-413e-b0ca-094e0083b8d2
accounts,SimplyPremiumCom.py,grab_hosters,25,34,"def grab_hosters(self, user, password, data):        json_data = self.load(            ""https://www.simply-premium.com/api/hosts.php"",            get={""format"": ""json"", ""online"": 1},        )        json_data = json.loads(json_data)        host_list = [element[""regex""] for element in json_data[""result""]]        return host_list",,"def grab_hosters(self, user, password, data):        json_data = self.load(            ""https://www.simply-premium.com/api/hosts.php"",            get={""format"": ""json"", ""online"": 1},        )        json_data = json.loads(json_data)        host_list = [element[""regex""] for element in json_data[""result""]]        return host_list",d1c1bcc9-abf0-4406-8d22-5167305222e8
accounts,SimplyPremiumCom.py,grab_info,36,63,"def grab_info(self, user, password, data):        premium = False        validuntil = -1        trafficleft = None        json_data = self.load(""https://www.simply-premium.com/api/user.php?format=json"")        self.log_debug(f""JSON data: {json_data}"")        json_data = json.loads(json_data)        if ""vip"" in json_data[""result""] and json_data[""result""][""vip""]:            premium = True        if ""timeend"" in json_data[""result""] and json_data[""result""][""timeend""]:            validuntil = float(json_data[""result""][""timeend""])        if (            ""remain_traffic"" in json_data[""result""]            and json_data[""result""][""remain_traffic""]        ):            trafficleft = float(json_data[""result""][""remain_traffic""])        return {            ""premium"": premium,            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,        }",,"def grab_info(self, user, password, data):        premium = False        validuntil = -1        trafficleft = None        json_data = self.load(""https://www.simply-premium.com/api/user.php?format=json"")        self.log_debug(f""JSON data: {json_data}"")        json_data = json.loads(json_data)        if ""vip"" in json_data[""result""] and json_data[""result""][""vip""]:            premium = True        if ""timeend"" in json_data[""result""] and json_data[""result""][""timeend""]:            validuntil = float(json_data[""result""][""timeend""])        if (            ""remain_traffic"" in json_data[""result""]            and json_data[""result""][""remain_traffic""]        ):            trafficleft = float(json_data[""result""][""remain_traffic""])        return {            ""premium"": premium,            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,        }",83fd4cb1-1ef8-45f0-8d20-e2796b5bbfe3
accounts,SimplyPremiumCom.py,signin,65,76,"def signin(self, user, password, data):        set_cookie(self.req.cj, ""simply-premium.com"", ""lang"", ""EN"")        html = self.load(            ""https://www.simply-premium.com/login.php"",            post={""key"": user}            if not password            else {""login_name"": user, ""login_pass"": password},        )        if ""logout"" not in html:            self.fail_login()",,"def signin(self, user, password, data):        set_cookie(self.req.cj, ""simply-premium.com"", ""lang"", ""EN"")        html = self.load(            ""https://www.simply-premium.com/login.php"",            post={""key"": user}            if not password            else {""login_name"": user, ""login_pass"": password},        )        if ""logout"" not in html:            self.fail_login()",f7e6d14f-1bf5-495b-831a-15314340933b
accounts,SmoozedCom.py,grab_hosters,26,27,"def grab_hosters(self, user, password, data):        return self.get_data(""hosters"")",,"def grab_hosters(self, user, password, data):        return self.get_data(""hosters"")",87102cd1-9307-4c31-b5eb-11d31f2e345c
accounts,SmoozedCom.py,grab_info,29,55,"def grab_info(self, user, password, data):        status = self.get_account_status(user, password)        self.log_debug(status)        if status[""state""] != ""ok"":            info = {""validuntil"": None, ""trafficleft"": None, ""premium"": False}        else:            #: Parse account info            info = {                ""validuntil"": float(status[""data""][""user""][""user_premium""]),                ""trafficleft"": max(                    0, status[""data""][""traffic""][1] - status[""data""][""traffic""][0]                ) << 10,                ""session"": status[""data""][""session_key""],                ""hosters"": [hoster[""name""] for hoster in status[""data""][""hoster""]],            }            if info[""validuntil""] < time.time():                if float(status[""data""][""user""].get(""user_trial"", 0)) > time.time():                    info[""premium""] = True                else:                    info[""premium""] = False            else:                info[""premium""] = True        return info",,"def grab_info(self, user, password, data):        status = self.get_account_status(user, password)        self.log_debug(status)        if status[""state""] != ""ok"":            info = {""validuntil"": None, ""trafficleft"": None, ""premium"": False}        else:            #: Parse account info            info = {                ""validuntil"": float(status[""data""][""user""][""user_premium""]),                ""trafficleft"": max(                    0, status[""data""][""traffic""][1] - status[""data""][""traffic""][0]                ) << 10,                ""session"": status[""data""][""session_key""],                ""hosters"": [hoster[""name""] for hoster in status[""data""][""hoster""]],            }            if info[""validuntil""] < time.time():                if float(status[""data""][""user""].get(""user_trial"", 0)) > time.time():                    info[""premium""] = True                else:                    info[""premium""] = False            else:                info[""premium""] = True        return info",12a8258b-ceb6-45a5-9993-b5bb0f0296b0
accounts,SmoozedCom.py,signin,57,63,"def signin(self, user, password, data):        #: Get user data from premiumize.me        status = self.get_account_status(user, password)        #: Check if user and password are valid        if status[""state""] != ""ok"":            self.fail_login()",,"def signin(self, user, password, data):        #: Get user data from premiumize.me        status = self.get_account_status(user, password)        #: Check if user and password are valid        if status[""state""] != ""ok"":            self.fail_login()",3526bdf7-c5df-4d1a-8721-54d112cac268
accounts,SmoozedCom.py,get_account_status,65,75,"def get_account_status(self, user, password):        b_password = password.encode()        encrypted = hashlib.pbkdf2_hmac(""sha256"", b_password, b_password, 1000).hex()[            32        ]        html = self.load(            ""http://www2.smoozed.com/api/login"",            get={""auth"": user, ""password"": encrypted},        )        return json.loads(html)",,"def get_account_status(self, user, password):        b_password = password.encode()        encrypted = hashlib.pbkdf2_hmac(""sha256"", b_password, b_password, 1000).hex()[            32        ]        html = self.load(            ""http://www2.smoozed.com/api/login"",            get={""auth"": user, ""password"": encrypted},        )        return json.loads(html)",97dd0ae4-0960-49a9-ac61-dc03e270d16c
accounts,TbSevenPl.py,grab_hosters,30,32,"def grab_hosters(self, user, password, data):        hosts = self.load(""https://tb7.pl/jdhostingi.txt"")        return hosts.splitlines()",,"def grab_hosters(self, user, password, data):        hosts = self.load(""https://tb7.pl/jdhostingi.txt"")        return hosts.splitlines()",eff377eb-fb89-4abe-abb5-86ffe5eb3c38
accounts,TbSevenPl.py,grab_info,34,58,"def grab_info(self, user, password, data):        premium = True        validuntil = None        trafficleft = None        html = self.load(""https://tb7.pl/"")        m = re.search(self.VALID_UNTIL_PATTERN, html)        if m is not None:            validuntil = time.mktime(time.strptime(m.group(1), ""%d.%m.%Y / %H:%M""))        else:            self.log_error(""VALID_UNTIL_PATTERN not found"")        m = re.search(self.TRAFFIC_LEFT_PATTERN, html)        if m is not None:            trafficleft = self.parse_traffic(m.group(""S""), m.group(""U""))        else:            self.log_error(""TRAFFIC_LEFT_PATTERN not found"")        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""premium"": premium,        }",,"def grab_info(self, user, password, data):        premium = True        validuntil = None        trafficleft = None        html = self.load(""https://tb7.pl/"")        m = re.search(self.VALID_UNTIL_PATTERN, html)        if m is not None:            validuntil = time.mktime(time.strptime(m.group(1), ""%d.%m.%Y / %H:%M""))        else:            self.log_error(""VALID_UNTIL_PATTERN not found"")        m = re.search(self.TRAFFIC_LEFT_PATTERN, html)        if m is not None:            trafficleft = self.parse_traffic(m.group(""S""), m.group(""U""))        else:            self.log_error(""TRAFFIC_LEFT_PATTERN not found"")        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""premium"": premium,        }",61a44b22-374e-4407-821f-03966677f399
accounts,TbSevenPl.py,signin,60,69,"def signin(self, user, password, data):        html = self.load(""https://tb7.pl/"")        if ""Wyloguj"" in html:            self.skip_login()        html = self.load(            ""https://tb7.pl/login"", post={""login"": user, ""password"": password}        )        if ""Wyloguj"" not in html:            self.fail_login()",,"def signin(self, user, password, data):        html = self.load(""https://tb7.pl/"")        if ""Wyloguj"" in html:            self.skip_login()        html = self.load(            ""https://tb7.pl/login"", post={""login"": user, ""password"": password}        )        if ""Wyloguj"" not in html:            self.fail_login()",eea13f0f-525c-43fe-9618-df76891d17a1
accounts,TenluaVn.py,api_request,22,31,"def api_request(self, method, **kwargs):        kwargs[""a""] = method        sid = kwargs.pop(""sid"", None)        return json.loads(            self.load(                self.API_URL,                get={""sid"": sid} if sid is not None else {},                post=json.dumps([kwargs]),            )        )",,"def api_request(self, method, **kwargs):        kwargs[""a""] = method        sid = kwargs.pop(""sid"", None)        return json.loads(            self.load(                self.API_URL,                get={""sid"": sid} if sid is not None else {},                post=json.dumps([kwargs]),            )        )",94629e2a-1b79-4e47-86ca-1d703a5913e8
accounts,TenluaVn.py,grab_info,33,39,"def grab_info(self, user, password, data):        user_info = self.api_request(""user_info"", sid=data[""sid""])[0]        validuntil = time.mktime(time.strptime(user_info[""endGold""], ""%d-%m-%Y""))        premium = user_info[""free_used""] != ""null""        return {""premium"": premium, ""trafficleft"": -1, ""validuntil"": validuntil}",,"def grab_info(self, user, password, data):        user_info = self.api_request(""user_info"", sid=data[""sid""])[0]        validuntil = time.mktime(time.strptime(user_info[""endGold""], ""%d-%m-%Y""))        premium = user_info[""free_used""] != ""null""        return {""premium"": premium, ""trafficleft"": -1, ""validuntil"": validuntil}",7f0fdbed-ae4e-4208-a500-532a2e464f2c
accounts,TenluaVn.py,signin,41,54,"def signin(self, user, password, data):        try:            login_info = self.api_request(                ""user_login"", user=user, password=password, permanent=False            )        except BadHeader as exc:            if exc.code == 401:                self.fail_login()            else:                self.fail_login(self._(""BadHeader {}"").format(exc.code))        data[""sid""] = login_info[0]",,"def signin(self, user, password, data):        try:            login_info = self.api_request(                ""user_login"", user=user, password=password, permanent=False            )        except BadHeader as exc:            if exc.code == 401:                self.fail_login()            else:                self.fail_login(self._(""BadHeader {}"").format(exc.code))        data[""sid""] = login_info[0]",7c5bde6f-f317-480c-bbb8-996bc924f165
accounts,TurbobitNet.py,grab_info,24,35,"def grab_info(self, user, password, data):        html = self.load(""https://turbobit.net/"")        m = re.search(r"">Turbo access till ([\d.]+)<"", html)        if m is not None:            premium = True            validuntil = time.mktime(time.strptime(m.group(1), ""%d.%m.%Y""))        else:            premium = False            validuntil = -1        return {""premium"": premium, ""trafficleft"": -1, ""validuntil"": validuntil}",,"def grab_info(self, user, password, data):        html = self.load(""https://turbobit.net/"")        m = re.search(r"">Turbo access till ([\d.]+)<"", html)        if m is not None:            premium = True            validuntil = time.mktime(time.strptime(m.group(1), ""%d.%m.%Y""))        else:            premium = False            validuntil = -1        return {""premium"": premium, ""trafficleft"": -1, ""validuntil"": validuntil}",c135645c-7fc9-495c-a73b-01d9f53ecd7c
accounts,TurbobitNet.py,signin,37,79,"def signin(self, user, password, data):        set_cookie(self.req.cj, ""turbobit.net"", ""user_lang"", ""en"")        self.data = self.load(""https://turbobit.net/login"")        if ""<a href='/user/logout'"" in self.data:            self.skip_login()        action, inputs = parse_html_form(            'class=""form-horizontal login mail""', self.data        )        if not inputs:            self.fail_login(self._(""Login form not found""))        inputs[""user[login]""] = user        inputs[""user[pass]""] = password        inputs[""user[submit]""] = ""Sign in""        inputs[""user[memory]""] = ""on""        if inputs.get(""user[captcha_type]""):            self.fail_login(                self._(                    ""Logging in with captcha is not supported, please disable catcha in turbobit's account settings""                )            )        self.data = self.load(""https://turbobit.net/user/login"", post=inputs)        if ""<a href='/user/logout'"" in self.data:            self.log_debug(""Login successful"")        elif re.search(self.LOGIN_FAIL_PATTERN, self.data):            self.fail_login()        elif "">Please enter the captcha code.</div>"" in self.data:            self.fail_login(                self._(                    ""Logging in with captcha is not supported, please disable catcha in turbobit's account settings""                )            )        else:            self.fail_login(self._(""Unknown response""))",,"def signin(self, user, password, data):        set_cookie(self.req.cj, ""turbobit.net"", ""user_lang"", ""en"")        self.data = self.load(""https://turbobit.net/login"")        if ""<a href='/user/logout'"" in self.data:            self.skip_login()        action, inputs = parse_html_form(            'class=""form-horizontal login mail""', self.data        )        if not inputs:            self.fail_login(self._(""Login form not found""))        inputs[""user[login]""] = user        inputs[""user[pass]""] = password        inputs[""user[submit]""] = ""Sign in""        inputs[""user[memory]""] = ""on""        if inputs.get(""user[captcha_type]""):            self.fail_login(                self._(                    ""Logging in with captcha is not supported, please disable catcha in turbobit's account settings""                )            )        self.data = self.load(""https://turbobit.net/user/login"", post=inputs)        if ""<a href='/user/logout'"" in self.data:            self.log_debug(""Login successful"")        elif re.search(self.LOGIN_FAIL_PATTERN, self.data):            self.fail_login()        elif "">Please enter the captcha code.</div>"" in self.data:            self.fail_login(                self._(                    ""Logging in with captcha is not supported, please disable catcha in turbobit's account settings""                )            )        else:            self.fail_login(self._(""Unknown response""))",775eb72b-a16f-412f-8eca-f3ba2bcff6fb
accounts,TwojlimitPl.py,grab_hosters,40,46,"def grab_hosters(self, user, password, data):        html = self.load(""https://www.twojlimit.pl/clipboard.php"", get={""json"": ""3""})        json_data = json.loads(html)        return [            h for row in json_data for h in row[""domains""] if row[""sdownload""] == ""0""        ]",,"def grab_hosters(self, user, password, data):        html = self.load(""https://www.twojlimit.pl/clipboard.php"", get={""json"": ""3""})        json_data = json.loads(html)        return [            h for row in json_data for h in row[""domains""] if row[""sdownload""] == ""0""        ]",09889c1d-5bf5-4b76-84b5-7f069bf067fc
accounts,TwojlimitPl.py,grab_info,48,73,"def grab_info(self, user, password, data):        premium = False        validuntil = -1        trafficleft = None        try:            json_data = json.loads(self.run_auth_query())            if json_data.get(""expire""):                premium = True                validuntil = time.mktime(                    datetime.datetime.fromtimestamp(                        int(json_data[""expire""])                    ).timetuple()                )            trafficleft = json_data[""balance""]        except Exception as exc:            self.log_error(exc)        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""premium"": premium,        }",,"def grab_info(self, user, password, data):        premium = False        validuntil = -1        trafficleft = None        try:            json_data = json.loads(self.run_auth_query())            if json_data.get(""expire""):                premium = True                validuntil = time.mktime(                    datetime.datetime.fromtimestamp(                        int(json_data[""expire""])                    ).timetuple()                )            trafficleft = json_data[""balance""]        except Exception as exc:            self.log_error(exc)        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""premium"": premium,        }",167b235c-ef4f-46e6-8b40-b67e098b0b42
accounts,TwojlimitPl.py,signin,75,87,"def signin(self, user, password, data):        data[""hash_password""] = hashlib.md5(password.encode()).hexdigest()        try:            response = json.loads(self.run_auth_query())        except Exception as exc:            self.log_error(exc)            self.fail_login()        else:            if ""errno"" in response:                self.fail_login()",,"def signin(self, user, password, data):        data[""hash_password""] = hashlib.md5(password.encode()).hexdigest()        try:            response = json.loads(self.run_auth_query())        except Exception as exc:            self.log_error(exc)            self.fail_login()        else:            if ""errno"" in response:                self.fail_login()",14344064-e059-482d-93f7-27cf7f4f19da
accounts,TwojlimitPl.py,run_auth_query,89,94,"def run_auth_query(self):        query = self.API_QUERY        query[""username""] = self.user        query[""password""] = self.info[""data""][""hash_password""]        return self.load(self.API_URL, post=query)",,"def run_auth_query(self):        query = self.API_QUERY        query[""username""] = self.user        query[""password""] = self.info[""data""][""hash_password""]        return self.load(self.API_URL, post=query)",5bdfcdd3-488a-4e8e-a3d4-9b40600f8510
accounts,UlozTo.py,grab_info,28,51,"def grab_info(self, user, password, data):        html = self.load(""https://ulozto.net/platby"")        if "">You don't have any credit at the moment.<"" in html:  #: Free account            validuntil = -1            trafficleft = -1            premium = False        else:            m = re.search(self.INFO_PATTERN, html)            if m is not None:                validuntil = time.mktime(time.strptime(m.group(3) + "" 23:59:59"", '%d.%m.%Y %H:%M:%S'))                trafficleft = self.parse_traffic(m.group(1), m.group(2))                premium = True if trafficleft else False            else:                self.log_error(self._(""Unable to retrieve account information, pattern not found""))                validuntil = None                trafficleft = None                premium = False        return {'validuntil': validuntil,                'trafficleft': trafficleft,                'premium': premium}",,"def grab_info(self, user, password, data):        html = self.load(""https://ulozto.net/platby"")        if "">You don't have any credit at the moment.<"" in html:  #: Free account            validuntil = -1            trafficleft = -1            premium = False        else:            m = re.search(self.INFO_PATTERN, html)            if m is not None:                validuntil = time.mktime(time.strptime(m.group(3) + "" 23:59:59"", '%d.%m.%Y %H:%M:%S'))                trafficleft = self.parse_traffic(m.group(1), m.group(2))                premium = True if trafficleft else False            else:                self.log_error(self._(""Unable to retrieve account information, pattern not found""))                validuntil = None                trafficleft = None                premium = False        return {'validuntil': validuntil,                'trafficleft': trafficleft,                'premium': premium}",5d95d0fc-9556-42c4-8300-5bc59ceef2b0
accounts,UlozTo.py,signin,53,68,"def signin(self, user, password, data):        html = self.load('https://ulozto.net/login')        if 'Log out' in html:            self.skip_login()        url, inputs = parse_html_form('action=""/login""', html)        if inputs is None:            self.fail_login(self._(""Login form not found""))        inputs['username'] = user        inputs['password'] = password        html = self.load(urllib.parse.urljoin(""https://ulozto.net/"", url),                         post=inputs)        if 'Log out' not in html:            self.fail_login()",,"def signin(self, user, password, data):        html = self.load('https://ulozto.net/login')        if 'Log out' in html:            self.skip_login()        url, inputs = parse_html_form('action=""/login""', html)        if inputs is None:            self.fail_login(self._(""Login form not found""))        inputs['username'] = user        inputs['password'] = password        html = self.load(urllib.parse.urljoin(""https://ulozto.net/"", url),                         post=inputs)        if 'Log out' not in html:            self.fail_login()",0c70bc2d-cc1d-49b6-8a4f-766a4e043b87
accounts,UpleaCom.py,grab_info,25,45,"def grab_info(self, user, password, data):        trafficleft = -1        html = self.load(""http://uplea.com/account"")        if re.search(self.PREMIUM_PATTERN, html):            premium = True        m = re.search(self.VALID_UNTIL_PATTERN, html)        if m is None:            premium = False            validuntil = -1        else:            premium = True            validuntil = time.mktime(time.strptime(m.group(1), ""%d/%m/%Y""))        return {            ""premium"": premium,            ""trafficleft"": trafficleft,            ""validuntil"": validuntil,        }",,"def grab_info(self, user, password, data):        trafficleft = -1        html = self.load(""http://uplea.com/account"")        if re.search(self.PREMIUM_PATTERN, html):            premium = True        m = re.search(self.VALID_UNTIL_PATTERN, html)        if m is None:            premium = False            validuntil = -1        else:            premium = True            validuntil = time.mktime(time.strptime(m.group(1), ""%d/%m/%Y""))        return {            ""premium"": premium,            ""trafficleft"": trafficleft,            ""validuntil"": validuntil,        }",11e06600-4fc5-41df-976c-1f3a194ad50a
accounts,UpleaCom.py,signin,47,59,"def signin(self, user, password, data):        html = self.load(""http://uplea.com"")        if self.LOGIN_SKIP_PATTERN in html:            self.skip_login()        html = self.load(            ""http://uplea.com"",            post={""login"": user, ""password"": password, ""remember"": 0, ""login-form"": """"},        )        if self.LOGIN_SKIP_PATTERN not in html:            self.fail_login()",,"def signin(self, user, password, data):        html = self.load(""http://uplea.com"")        if self.LOGIN_SKIP_PATTERN in html:            self.skip_login()        html = self.load(            ""http://uplea.com"",            post={""login"": user, ""password"": password, ""remember"": 0, ""login-form"": """"},        )        if self.LOGIN_SKIP_PATTERN not in html:            self.fail_login()",41c7028f-07d1-4663-93df-01dc94b69990
accounts,UploadgigCom.py,grab_info,32,57,"def grab_info(self, user, password, data):        html = self.load(""https://uploadgig.com/user/my_account"")        premium = re.search(self.PREMIUM_PATTERN, html) is not None        m = re.search(self.TRAFFIC_LEFT_PATTERN, html)        if m is None:            trafficleft = None        else:            trafficleft = self.parse_traffic(                m.group(""S2""), m.group(""U2"")            ) - self.parse_traffic(m.group(""S1""), m.group(""U1"") or m.group(""U2""))        m = re.search(self.VALID_UNTIL_PATTERN, html)        if m is None:            validuntil = None        else:            validuntil = time.mktime(time.strptime(m.group(1), ""%Y/%m/%d""))        return {            ""premium"": premium,            ""trafficleft"": trafficleft,            ""validuntil"": validuntil,        }",,"def grab_info(self, user, password, data):        html = self.load(""https://uploadgig.com/user/my_account"")        premium = re.search(self.PREMIUM_PATTERN, html) is not None        m = re.search(self.TRAFFIC_LEFT_PATTERN, html)        if m is None:            trafficleft = None        else:            trafficleft = self.parse_traffic(                m.group(""S2""), m.group(""U2"")            ) - self.parse_traffic(m.group(""S1""), m.group(""U1"") or m.group(""U2""))        m = re.search(self.VALID_UNTIL_PATTERN, html)        if m is None:            validuntil = None        else:            validuntil = time.mktime(time.strptime(m.group(1), ""%Y/%m/%d""))        return {            ""premium"": premium,            ""trafficleft"": trafficleft,            ""validuntil"": validuntil,        }",70e559c2-549e-45e7-8144-635c98c998dd
accounts,UploadgigCom.py,signin,59,105,"def signin(self, user, password, data):        html = self.load(""https://uploadgig.com/login/form"")        if self.LOGIN_SKIP_PATTERN in html:            self.skip_login()        url, inputs = parse_html_form('id=""login_form""', html)        if inputs is None:            self.fail_login(""Login form not found"")        inputs[""email""] = user        inputs[""pass""] = password        if '<div class=""row"" id=""parent_captcha_container"">' in html:            # dummy pyfile            pyfile = PyFile(                self.pyload.files,                -1,                ""https://uploadgig.com"",                ""https://uploadgig.com"",                0,                0,                """",                self.classname,                -1,                -1,            )            pyfile.plugin = self            recaptcha = ReCaptcha(pyfile)            captcha_key = recaptcha.detect_key(html)            if captcha_key:                self.captcha = recaptcha                response = recaptcha.challenge(captcha_key, html)                inputs[""g-recaptcha-response""] = response            else:                self.log_error(self._(""ReCaptcha key not found""))                self.fail_login(self._(""ReCaptcha key not found""))        html = self.load(url, post=inputs)        json_data = json.loads(html)        if json_data.get(""state"") != ""1"":            self.log_error(json_data[""msg""])            self.fail_login()",,"def signin(self, user, password, data):        html = self.load(""https://uploadgig.com/login/form"")        if self.LOGIN_SKIP_PATTERN in html:            self.skip_login()        url, inputs = parse_html_form('id=""login_form""', html)        if inputs is None:            self.fail_login(""Login form not found"")        inputs[""email""] = user        inputs[""pass""] = password        if '<div class=""row"" id=""parent_captcha_container"">' in html:            # dummy pyfile            pyfile = PyFile(                self.pyload.files,                -1,                ""https://uploadgig.com"",                ""https://uploadgig.com"",                0,                0,                """",                self.classname,                -1,                -1,            )            pyfile.plugin = self            recaptcha = ReCaptcha(pyfile)            captcha_key = recaptcha.detect_key(html)            if captcha_key:                self.captcha = recaptcha                response = recaptcha.challenge(captcha_key, html)                inputs[""g-recaptcha-response""] = response            else:                self.log_error(self._(""ReCaptcha key not found""))                self.fail_login(self._(""ReCaptcha key not found""))        html = self.load(url, post=inputs)        json_data = json.loads(html)        if json_data.get(""state"") != ""1"":            self.log_error(json_data[""msg""])            self.fail_login()",b24a2f38-aad3-4162-a193-fc626d45878d
accounts,UploadgigCom.py,logged,108,128,"def logged(self):                if not self.user:            return False        self.sync()        if (            self.info[""login""][""timestamp""] == 0            or self.timeout != -1            and self.info[""login""][""timestamp""] + self.timeout < time.time()            or self.req            and not self.req.cj.parse_cookie(""fs_secure"")        ):            self.log_debug(""Reached login timeout for user `%s`"" % self.user)            return False        else:            return True",Checks if user is still logged in,"def logged(self):        """"""        Checks if user is still logged in        """"""        if not self.user:            return False        self.sync()        if (            self.info[""login""][""timestamp""] == 0            or self.timeout != -1            and self.info[""login""][""timestamp""] + self.timeout < time.time()            or self.req            and not self.req.cj.parse_cookie(""fs_secure"")        ):            self.log_debug(""Reached login timeout for user `%s`"" % self.user)            return False        else:            return True

Checks if user is still logged in",8ceeaab1-ad0e-45f0-a37e-35e6051d8b96
accounts,UploadgigCom.py,check_status,135,136,def check_status(self):        pass,,def check_status(self):        pass,2fb73502-c36f-45dc-80f0-433098e31a8f
accounts,UploadgigCom.py,retry_captcha,138,140,"def retry_captcha(self, attempts=10, wait=1, msg=""Max captcha retries reached""):        self.captcha.invalid()        self.fail_login(msg=self._(""Invalid captcha""))",,"def retry_captcha(self, attempts=10, wait=1, msg=""Max captcha retries reached""):        self.captcha.invalid()        self.fail_login(msg=self._(""Invalid captcha""))",a62c427a-660a-4899-8181-64b6a2a219ea
accounts,UpstoreNet.py,grab_info,21,48,"def grab_info(self, user, password, data):        validuntil = None        trafficleft = None        premium = True        html = self.load(""https://upstore.net/stat/download"",                         get={'lang': ""en""})        m = re.search(r""Downloaded in last 24 hours: ([\d.,]+) of ([\d.,]+) GB"", html)        if m is not None:            trafficleft = self.parse_traffic(m.group(2), ""GB"") - self.parse_traffic(m.group(1), ""GB"")        if ""eternal premium"" in html:            validuntil = -1        else:            m = re.search(r'premium till\s*(\d{1,2}/\d{1,2}/\d{2})', html)            if m is not None:                validuntil = time.mktime(time.strptime(m.group(1) + "" 23:59:59"", '%m/%d/%y %H:%M:%S'))            else:                m = re.search(r'premium till\s*([a-zA-Z.]+\s*\d{1,2}\s*,\s*(\d{4}|\d{2}))', html)                if m is not None:                    validuntil = time.mktime(time.strptime(m.group(1) + "" 23:59:59"", '%B %d , %y %H:%M:%S'))        return {'validuntil': validuntil,                'trafficleft': trafficleft,                'premium': premium}",,"def grab_info(self, user, password, data):        validuntil = None        trafficleft = None        premium = True        html = self.load(""https://upstore.net/stat/download"",                         get={'lang': ""en""})        m = re.search(r""Downloaded in last 24 hours: ([\d.,]+) of ([\d.,]+) GB"", html)        if m is not None:            trafficleft = self.parse_traffic(m.group(2), ""GB"") - self.parse_traffic(m.group(1), ""GB"")        if ""eternal premium"" in html:            validuntil = -1        else:            m = re.search(r'premium till\s*(\d{1,2}/\d{1,2}/\d{2})', html)            if m is not None:                validuntil = time.mktime(time.strptime(m.group(1) + "" 23:59:59"", '%m/%d/%y %H:%M:%S'))            else:                m = re.search(r'premium till\s*([a-zA-Z.]+\s*\d{1,2}\s*,\s*(\d{4}|\d{2}))', html)                if m is not None:                    validuntil = time.mktime(time.strptime(m.group(1) + "" 23:59:59"", '%B %d , %y %H:%M:%S'))        return {'validuntil': validuntil,                'trafficleft': trafficleft,                'premium': premium}",0bb0729d-048f-4e6f-bfa2-9106d1903675
accounts,UpstoreNet.py,signin,50,63,"def signin(self, user, password, data):        login_url = ""https://upstore.net/account/login""        html = self.load(login_url)        if ""/account/logout"" in html:            self.skip_login()        html = self.load(login_url,                         post={'url': ""https://upstore.net"",                               'email': user,                               'password': password,                               'send': ""Login""})        if ""/account/logout"" not in html:            self.fail_login()",,"def signin(self, user, password, data):        login_url = ""https://upstore.net/account/login""        html = self.load(login_url)        if ""/account/logout"" in html:            self.skip_login()        html = self.load(login_url,                         post={'url': ""https://upstore.net"",                               'email': user,                               'password': password,                               'send': ""Login""})        if ""/account/logout"" not in html:            self.fail_login()",a5eccb3d-b0a5-4e92-b8bc-6fce6b053acf
accounts,UptoboxCom.py,grab_info,29,42,"def grab_info(self, user, password, data):        html = self.load(""https://uptobox.link/my_account"")        premium = re.search(self.PREMIUM_PATTERN, html) is not None        m = re.search(self.VALID_UNTIL_PATTERN, html)        if m is not None:            validuntil = time.mktime(time.strptime(m.group(1), ""%Y-%m-%d %H:%M:%S""))        else:            self.log_error(self._(""VALID_UNTIL_PATTERN not found""))            validuntil = None        return {""validuntil"": validuntil, ""trafficleft"": -1, ""premium"": premium}",,"def grab_info(self, user, password, data):        html = self.load(""https://uptobox.link/my_account"")        premium = re.search(self.PREMIUM_PATTERN, html) is not None        m = re.search(self.VALID_UNTIL_PATTERN, html)        if m is not None:            validuntil = time.mktime(time.strptime(m.group(1), ""%Y-%m-%d %H:%M:%S""))        else:            self.log_error(self._(""VALID_UNTIL_PATTERN not found""))            validuntil = None        return {""validuntil"": validuntil, ""trafficleft"": -1, ""premium"": premium}",4886f051-080d-4711-b82a-7f040da7bf28
accounts,UptoboxCom.py,signin,44,57,"def signin(self, user, password, data):        html = self.load(self.LOGIN_URL)        if re.search(self.LOGIN_SKIP_PATTERN, html) is not None:            self.skip_login()        html = self.load(            self.LOGIN_URL,            post={""login"": user, ""password"": password},            ref=self.LOGIN_URL,        )        if re.search(self.LOGIN_SKIP_PATTERN, html) is None:            self.fail_login()",,"def signin(self, user, password, data):        html = self.load(self.LOGIN_URL)        if re.search(self.LOGIN_SKIP_PATTERN, html) is not None:            self.skip_login()        html = self.load(            self.LOGIN_URL,            post={""login"": user, ""password"": password},            ref=self.LOGIN_URL,        )        if re.search(self.LOGIN_SKIP_PATTERN, html) is None:            self.fail_login()",6775cfcc-3330-4a51-8440-a6fb47a3d37a
accounts,WebshareCz.py,md5_crypt,14,78,"def md5_crypt(password, salt=None):    MAGIC = ""$1$""    BASE64_CHARS = ""./0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz""    if salt is None:        salt = random_string(8, valid_chars=string.ascii_letters + string.digits + ""./"")    else:        salt = salt[:8]    salt = salt.encode(""ascii"")    if isinstance(password, str):        password = password.encode(""utf-8"")    ctx_a = hashes.Hash(hashes.MD5(), backend=default_backend())    ctx_a.update(password + MAGIC.encode(""ascii"") + salt)    ctx_b = hashes.Hash(hashes.MD5(), backend=default_backend())    ctx_b.update(password + salt + password)    intermediate_hash = ctx_b.finalize()    for i in range(len(password), 0, -16):        ctx_a.update(intermediate_hash[:16 if i > 16 else i])    i = len(password)    while i:        if i & 1:            ctx_a.update(b""\0"")        else:            ctx_a.update(password[0:1])        i >>= 1    final_hash = ctx_a.finalize()    for i in range(1000):        ctx_c = hashes.Hash(hashes.MD5(), backend=default_backend())        if i & 1:            ctx_c.update(password)        else:            ctx_c.update(final_hash)        if i % 3:            ctx_c.update(salt)        if i % 7:            ctx_c.update(password)        if i & 1:            ctx_c.update(final_hash)        else:            ctx_c.update(password)        final_hash = ctx_c.finalize()    encoded_hash = """"    for a, b, c in ((0, 6, 12), (1, 7, 13), (2, 8, 14), (3, 9, 15), (4, 10, 5)):        t = (final_hash[a] << 16) | (final_hash[b] << 8) | final_hash[c]        for i in range(4):            encoded_hash += BASE64_CHARS[t & 0x3f]            t >>= 6    t = final_hash[11]    for i in range(2):        encoded_hash += BASE64_CHARS[t & 0x3f]        t >>= 6    return f""{MAGIC}{salt.decode()}${encoded_hash}""",,"def md5_crypt(password, salt=None):    MAGIC = ""$1$""    BASE64_CHARS = ""./0123456789ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz""    if salt is None:        salt = random_string(8, valid_chars=string.ascii_letters + string.digits + ""./"")    else:        salt = salt[:8]    salt = salt.encode(""ascii"")    if isinstance(password, str):        password = password.encode(""utf-8"")    ctx_a = hashes.Hash(hashes.MD5(), backend=default_backend())    ctx_a.update(password + MAGIC.encode(""ascii"") + salt)    ctx_b = hashes.Hash(hashes.MD5(), backend=default_backend())    ctx_b.update(password + salt + password)    intermediate_hash = ctx_b.finalize()    for i in range(len(password), 0, -16):        ctx_a.update(intermediate_hash[:16 if i > 16 else i])    i = len(password)    while i:        if i & 1:            ctx_a.update(b""\0"")        else:            ctx_a.update(password[0:1])        i >>= 1    final_hash = ctx_a.finalize()    for i in range(1000):        ctx_c = hashes.Hash(hashes.MD5(), backend=default_backend())        if i & 1:            ctx_c.update(password)        else:            ctx_c.update(final_hash)        if i % 3:            ctx_c.update(salt)        if i % 7:            ctx_c.update(password)        if i & 1:            ctx_c.update(final_hash)        else:            ctx_c.update(password)        final_hash = ctx_c.finalize()    encoded_hash = """"    for a, b, c in ((0, 6, 12), (1, 7, 13), (2, 8, 14), (3, 9, 15), (4, 10, 5)):        t = (final_hash[a] << 16) | (final_hash[b] << 8) | final_hash[c]        for i in range(4):            encoded_hash += BASE64_CHARS[t & 0x3f]            t >>= 6    t = final_hash[11]    for i in range(2):        encoded_hash += BASE64_CHARS[t & 0x3f]        t >>= 6    return f""{MAGIC}{salt.decode()}${encoded_hash}""",165b9ca7-ba88-4909-b4a2-a22ae4436d2f
accounts,WebshareCz.py,api_request,101,102,"def api_request(self, method, **kwargs):        return self.load(self.API_URL + method + ""/"", post=kwargs)",,"def api_request(self, method, **kwargs):        return self.load(self.API_URL + method + ""/"", post=kwargs)",406de033-812f-44f9-8128-12d9b3c3e425
accounts,WebshareCz.py,grab_info,104,118,"def grab_info(self, user, password, data):        user_data = self.api_request(""user_data"", wst=data[""wst""])        expire_date = re.search(self.VALID_UNTIL_PATTERN, user_data).group(1)        if expire_date:            validuntil = time.mktime(time.strptime(expire_date, ""%Y-%m-%d %H:%M:%S""))            premium = validuntil > time.time()        else:            validuntil = -1            premium = False        # trafficleft = self.parse_traffic(re.search(self.TRAFFIC_LEFT_PATTERN, user_data).group(1))        return {""validuntil"": validuntil, ""trafficleft"": -1, ""premium"": premium}",,"def grab_info(self, user, password, data):        user_data = self.api_request(""user_data"", wst=data[""wst""])        expire_date = re.search(self.VALID_UNTIL_PATTERN, user_data).group(1)        if expire_date:            validuntil = time.mktime(time.strptime(expire_date, ""%Y-%m-%d %H:%M:%S""))            premium = validuntil > time.time()        else:            validuntil = -1            premium = False        # trafficleft = self.parse_traffic(re.search(self.TRAFFIC_LEFT_PATTERN, user_data).group(1))        return {""validuntil"": validuntil, ""trafficleft"": -1, ""premium"": premium}",81c67cbe-5e13-4eef-aff0-8c358aab9dfb
accounts,WebshareCz.py,signin,120,146,"def signin(self, user, password, data):        salt = self.api_request(""salt"", username_or_email=user)        if ""<status>OK</status>"" not in salt:            message = re.search(r""<message>(.+?)</message>"", salt).group(1)            self.log_warning(message)            self.fail_login()        salt = re.search(""<salt>(.*?)</salt>"", salt).group(1)        salt_pw = salt + password        ctx_sha1 = hashes.Hash(hashes.SHA1(), backend=default_backend())        ctx_sha1.update(md5_crypt(password, salt=salt).encode())        password = ctx_sha1.finalize().hex()        login = self.api_request(            ""login"",            keep_logged_in=1,            username_or_email=user,            password=password,        )        if ""<status>OK</status>"" not in login:            message = re.search(r""<message>(.+?)</message>"", salt).group(1)            self.log_warning(message)            self.fail_login()        data[""wst""] = re.search(""<token>(.+?)</token>"", login).group(1)",,"def signin(self, user, password, data):        salt = self.api_request(""salt"", username_or_email=user)        if ""<status>OK</status>"" not in salt:            message = re.search(r""<message>(.+?)</message>"", salt).group(1)            self.log_warning(message)            self.fail_login()        salt = re.search(""<salt>(.*?)</salt>"", salt).group(1)        salt_pw = salt + password        ctx_sha1 = hashes.Hash(hashes.SHA1(), backend=default_backend())        ctx_sha1.update(md5_crypt(password, salt=salt).encode())        password = ctx_sha1.finalize().hex()        login = self.api_request(            ""login"",            keep_logged_in=1,            username_or_email=user,            password=password,        )        if ""<status>OK</status>"" not in login:            message = re.search(r""<message>(.+?)</message>"", salt).group(1)            self.log_warning(message)            self.fail_login()        data[""wst""] = re.search(""<token>(.+?)</token>"", login).group(1)",778b57ec-b516-46cf-b572-f77be225bd40
accounts,YibaishiwuCom.py,grab_info,20,30,"def grab_info(self, user, password, data):        html = self.load(""http://115.com/"")        m = re.search(self.ACCOUNT_INFO_PATTERN, html, re.S)        premium = m and ""is_vip: 1"" in m.group(1)        validuntil = trafficleft = -1 if m else 0        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""premium"": premium,        }",,"def grab_info(self, user, password, data):        html = self.load(""http://115.com/"")        m = re.search(self.ACCOUNT_INFO_PATTERN, html, re.S)        premium = m and ""is_vip: 1"" in m.group(1)        validuntil = trafficleft = -1 if m else 0        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""premium"": premium,        }",e995ed73-a5bd-4ffd-b74b-459627843c69
accounts,YibaishiwuCom.py,signin,32,44,"def signin(self, user, password, data):        html = self.load(            ""https://passport.115.com/?ac=login"",            post={                ""back"": ""http://www.115.com/"",                ""goto"": ""http://115.com/"",                ""login[account]"": user,                ""login[passwd]"": password,            },        )        if ""var USER_PERMISSION = {"" not in html:            self.fail_login()",,"def signin(self, user, password, data):        html = self.load(            ""https://passport.115.com/?ac=login"",            post={                ""back"": ""http://www.115.com/"",                ""goto"": ""http://115.com/"",                ""login[account]"": user,                ""login[passwd]"": password,            },        )        if ""var USER_PERMISSION = {"" not in html:            self.fail_login()",de0b1db3-4f78-46fd-bbdc-d6e66dc7b84e
accounts,ZeveraCom.py,api_request,32,41,"def api_request(self, method, api_key, **kwargs):        get_data = {""client_id"": ""452508742"", ""apikey"": api_key}        get_data.update(kwargs)        res = self.load(self.API_URL + method, get=get_data)        self.log_debug(res)        return json.loads(res)",,"def api_request(self, method, api_key, **kwargs):        get_data = {""client_id"": ""452508742"", ""apikey"": api_key}        get_data.update(kwargs)        res = self.load(self.API_URL + method, get=get_data)        self.log_debug(res)        return json.loads(res)",4d7ded44-97b7-4165-a8d5-788870941877
accounts,ZeveraCom.py,grab_hosters,43,45,"def grab_hosters(self, user, password, data):        res = self.api_request(""services/list"", password)        return res[""directdl""]",,"def grab_hosters(self, user, password, data):        res = self.api_request(""services/list"", password)        return res[""directdl""]",a7678854-5014-43d9-82d4-a64662cc37cc
accounts,ZeveraCom.py,grab_info,47,65,"def grab_info(self, user, password, data):        trafficleft = None        res = self.api_request(""account/info"", password)        premium = res[""premium_until""] is not False        validuntil = (            time.mktime(                datetime.datetime.fromtimestamp(res[""premium_until""]).timetuple()            )            if premium            else -1        )        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""premium"": premium,        }",,"def grab_info(self, user, password, data):        trafficleft = None        res = self.api_request(""account/info"", password)        premium = res[""premium_until""] is not False        validuntil = (            time.mktime(                datetime.datetime.fromtimestamp(res[""premium_until""]).timetuple()            )            if premium            else -1        )        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""premium"": premium,        }",1a8ee569-ddb3-4b12-bf9f-ad2a2e0b8e72
accounts,ZeveraCom.py,signin,67,75,"def signin(self, user, password, data):        res = self.api_request(""account/info"", password)        if res[""status""] != ""success"":            self.log_error(                self._(                    ""Password for Zevera should be the API token - get it from: https://www.zevera.com/account""                )            )            self.fail_login()",,"def signin(self, user, password, data):        res = self.api_request(""account/info"", password)        if res[""status""] != ""success"":            self.log_error(                self._(                    ""Password for Zevera should be the API token - get it from: https://www.zevera.com/account""                )            )            self.fail_login()",db069604-88d9-4a98-9108-28e6236ff9c5
addons,AndroidPhoneNotify.py,get_key,39,40,"def get_key(self):        return self.config.get(""apikey"")",,"def get_key(self):        return self.config.get(""apikey"")",6de4c36e-6fbf-4a27-9a7d-2fbf695f0ef0
addons,AndroidPhoneNotify.py,send,42,51,"def send(self, event, msg, key):        self.load(            ""http://www.notifymyandroid.com/publicapi/notify"",            get={                ""apikey"": key,                ""application"": ""pyLoad"",                ""event"": event,                ""description"": msg,            },        )",,"def send(self, event, msg, key):        self.load(            ""http://www.notifymyandroid.com/publicapi/notify"",            get={                ""apikey"": key,                ""application"": ""pyLoad"",                ""event"": event,                ""description"": msg,            },        )",fd3a8a44-19ee-4d26-af2b-57eec8a57dea
addons,AntiCaptcha.py,api_request,64,66,"def api_request(self, method, post):        json_data = self.load(self.API_URL + method, post=json.dumps(post))        return json.loads(json_data)",,"def api_request(self, method, post):        json_data = self.load(self.API_URL + method, post=json.dumps(post))        return json.loads(json_data)",aba61c99-e60a-4011-afe4-74c4afc5975c
addons,AntiCaptcha.py,get_credits,68,86,"def get_credits(self):        credits = self.db.retrieve(""credits"", {""balance"": 0, ""time"": 0})        #: Docs says: ""Please don't call this method more often than once in 30 seconds""        if time.time() - credits[""time""] >= 30:            api_data = self.api_request(                ""getBalance"", {""clientKey"": self.config.get(""passkey"")}            )            if api_data[""errorId""] != 0:                self.log_error(self._(""API error""), api_data[""errorDescription""])                return 0            credits = {""balance"": api_data[""balance""], ""time"": time.time()}            self.db.store(""credits"", credits)        balance = credits[""balance""]        self.log_info(self._(""Credits left: {:.2f}$"").format(balance))        return balance",,"def get_credits(self):        credits = self.db.retrieve(""credits"", {""balance"": 0, ""time"": 0})        #: Docs says: ""Please don't call this method more often than once in 30 seconds""        if time.time() - credits[""time""] >= 30:            api_data = self.api_request(                ""getBalance"", {""clientKey"": self.config.get(""passkey"")}            )            if api_data[""errorId""] != 0:                self.log_error(self._(""API error""), api_data[""errorDescription""])                return 0            credits = {""balance"": api_data[""balance""], ""time"": time.time()}            self.db.store(""credits"", credits)        balance = credits[""balance""]        self.log_info(self._(""Credits left: {:.2f}$"").format(balance))        return balance",53f81017-6b59-408a-abf5-fab3e5f74c4a
addons,AntiCaptcha.py,_process_captcha,89,172,"def _process_captcha(self, task):        url_p = urllib.parse.urlparse(task.captcha_params[""url""])        if task.is_interactive():            if url_p.scheme not in (""http"", ""https""):                self.log_error(self._(""Invalid url""))                return            api_data = self.api_request(                ""createTask"",                {                    ""clientKey"": self.config.get(""passkey""),                    ""softId"": 976,                    ""task"": {                        ""type"": self.TASK_TYPES[task.captcha_params[""captcha_plugin""]],                        ""websiteURL"": r""{}://{}/"".format(url_p.scheme, url_p.netloc),                        ""websiteKey"": task.captcha_params[""sitekey""],                        ""isInvisible"": task.is_invisible(),                    },                },            )        else:            try:                with open(task.captcha_params[""file""], mode=""rb"") as fp:                    data = fp.read()            except IOError as exc:                self.log_error(exc)                return            api_data = self.api_request(                ""createTask"",                {                    ""clientKey"": self.config.get(""passkey""),                    ""softId"": 976,                    ""task"": {                        ""type"": ""ImageToTextTask"",                        ""body"": to_str(base64.b64encode(data)),                        ""case"": True,                        ""websiteURL"": r""{}://{}/"".format(url_p.scheme, url_p.netloc),                    },                },            )        if api_data[""errorId""] != 0:            task.error = api_data[""errorDescription""]            self.log_error(self._(""API error""), api_data[""errorDescription""])            return        ticket = api_data[""taskId""]        self.log_debug(            f""NewCaptchaID ticket: {ticket}"",            task.captcha_params.get(""file"", """"),        )        task.data[""ticket""] = ticket        result = None        for _ in range(int(self.config.get(""timeout"") // 5)):            api_data = self.api_request(                ""getTaskResult"",                {""clientKey"": self.config.get(""passkey""), ""taskId"": ticket},            )            if api_data[""errorId""] != 0:                task.error = api_data[""errorDescription""]                self.log_error(self._(""API error""), api_data[""errorDescription""])                break            if api_data[""status""] == ""processing"":                time.sleep(5)            else:                captcha_plugin = task.captcha_params[""captcha_plugin""]                if captcha_plugin in (""HCaptcha"", ""ReCaptcha""):                    result = api_data[""solution""][""gRecaptchaResponse""]                elif task.is_textual():                    result = api_data[""solution""][""text""]                break        else:            self.log_debug(f""Could not get result: {ticket}"")        self.log_info(self._(""Captcha result for ticket {}: {}"").format(ticket, result))        task.set_result(result)",,"def _process_captcha(self, task):        url_p = urllib.parse.urlparse(task.captcha_params[""url""])        if task.is_interactive():            if url_p.scheme not in (""http"", ""https""):                self.log_error(self._(""Invalid url""))                return            api_data = self.api_request(                ""createTask"",                {                    ""clientKey"": self.config.get(""passkey""),                    ""softId"": 976,                    ""task"": {                        ""type"": self.TASK_TYPES[task.captcha_params[""captcha_plugin""]],                        ""websiteURL"": r""{}://{}/"".format(url_p.scheme, url_p.netloc),                        ""websiteKey"": task.captcha_params[""sitekey""],                        ""isInvisible"": task.is_invisible(),                    },                },            )        else:            try:                with open(task.captcha_params[""file""], mode=""rb"") as fp:                    data = fp.read()            except IOError as exc:                self.log_error(exc)                return            api_data = self.api_request(                ""createTask"",                {                    ""clientKey"": self.config.get(""passkey""),                    ""softId"": 976,                    ""task"": {                        ""type"": ""ImageToTextTask"",                        ""body"": to_str(base64.b64encode(data)),                        ""case"": True,                        ""websiteURL"": r""{}://{}/"".format(url_p.scheme, url_p.netloc),                    },                },            )        if api_data[""errorId""] != 0:            task.error = api_data[""errorDescription""]            self.log_error(self._(""API error""), api_data[""errorDescription""])            return        ticket = api_data[""taskId""]        self.log_debug(            f""NewCaptchaID ticket: {ticket}"",            task.captcha_params.get(""file"", """"),        )        task.data[""ticket""] = ticket        result = None        for _ in range(int(self.config.get(""timeout"") // 5)):            api_data = self.api_request(                ""getTaskResult"",                {""clientKey"": self.config.get(""passkey""), ""taskId"": ticket},            )            if api_data[""errorId""] != 0:                task.error = api_data[""errorDescription""]                self.log_error(self._(""API error""), api_data[""errorDescription""])                break            if api_data[""status""] == ""processing"":                time.sleep(5)            else:                captcha_plugin = task.captcha_params[""captcha_plugin""]                if captcha_plugin in (""HCaptcha"", ""ReCaptcha""):                    result = api_data[""solution""][""gRecaptchaResponse""]                elif task.is_textual():                    result = api_data[""solution""][""text""]                break        else:            self.log_debug(f""Could not get result: {ticket}"")        self.log_info(self._(""Captcha result for ticket {}: {}"").format(ticket, result))        task.set_result(result)",563a3130-6454-4e03-8511-46e40f7996f2
addons,AntiCaptcha.py,captcha_task,174,205,"def captcha_task(self, task):        if task.is_interactive():            captcha_plugin = task.captcha_params[""captcha_plugin""]            if captcha_plugin == ""ReCaptcha"" and not self.config.get(""solve_recaptcha""):                return            elif captcha_plugin == ""HCaptcha"" and not self.config.get(""solve_hcaptcha""):                return        else:            if not task.is_textual():                return            elif not self.config.get(""solve_image""):                return        if not self.config.get(""passkey""):            return        if self.pyload.is_client_connected() and self.config.get(""check_client""):            return        credits = self.get_credits()        if credits < 0.05:            self.log_error(                self._(""Your captcha anti-captcha.com account has not enough credits"")            )            return        timeout = min(max(self.config.get(""timeout""), 300), 3999)        task.handler.append(self)        task.set_waiting(timeout)        self._process_captcha(task)",,"def captcha_task(self, task):        if task.is_interactive():            captcha_plugin = task.captcha_params[""captcha_plugin""]            if captcha_plugin == ""ReCaptcha"" and not self.config.get(""solve_recaptcha""):                return            elif captcha_plugin == ""HCaptcha"" and not self.config.get(""solve_hcaptcha""):                return        else:            if not task.is_textual():                return            elif not self.config.get(""solve_image""):                return        if not self.config.get(""passkey""):            return        if self.pyload.is_client_connected() and self.config.get(""check_client""):            return        credits = self.get_credits()        if credits < 0.05:            self.log_error(                self._(""Your captcha anti-captcha.com account has not enough credits"")            )            return        timeout = min(max(self.config.get(""timeout""), 300), 3999)        task.handler.append(self)        task.set_waiting(timeout)        self._process_captcha(task)",9a2a09d4-49c5-4831-8870-3dbd226591fc
addons,AntiCaptcha.py,_captcha_response,207,244,"def _captcha_response(self, task, correct):        request_type = ""correct"" if correct else ""refund""        if ""ticket"" not in task.data:            self.log_debug(                ""No CaptchaID for {} request (task: {})"".format(request_type, task)            )            return        if not self.config.get(""refund"", False) or correct:            return        if task.captcha_params[""captcha_plugin""] == ""ReCaptcha"":            method = ""reportIncorrectRecaptcha""        elif task.is_textual():            method = ""reportIncorrectImageCaptcha""        else:            return        for _ in range(3):            api_data = self.api_request(                method,                {                    ""clientKey"": self.config.get(""passkey""),                    ""taskId"": task.data[""ticket""],                },            )            self.log_debug(f""Request {request_type}: {api_data}"")            if api_data[""errorId""] == 0:                break            time.sleep(5)        else:            self.log_debug(                ""Could not send {} request: {}"".format(                    request_type, api_data[""errorDescription""]                )            )",,"def _captcha_response(self, task, correct):        request_type = ""correct"" if correct else ""refund""        if ""ticket"" not in task.data:            self.log_debug(                ""No CaptchaID for {} request (task: {})"".format(request_type, task)            )            return        if not self.config.get(""refund"", False) or correct:            return        if task.captcha_params[""captcha_plugin""] == ""ReCaptcha"":            method = ""reportIncorrectRecaptcha""        elif task.is_textual():            method = ""reportIncorrectImageCaptcha""        else:            return        for _ in range(3):            api_data = self.api_request(                method,                {                    ""clientKey"": self.config.get(""passkey""),                    ""taskId"": task.data[""ticket""],                },            )            self.log_debug(f""Request {request_type}: {api_data}"")            if api_data[""errorId""] == 0:                break            time.sleep(5)        else:            self.log_debug(                ""Could not send {} request: {}"".format(                    request_type, api_data[""errorDescription""]                )            )",a1c1fee2-2930-4471-8161-9e289ba066b7
addons,AntiCaptcha.py,captcha_correct,246,247,"def captcha_correct(self, task):        self._captcha_response(task, True)",,"def captcha_correct(self, task):        self._captcha_response(task, True)",5d06ba65-5475-4a7f-85cd-28951f76c9b4
addons,AntiCaptcha.py,captcha_invalid,249,250,"def captcha_invalid(self, task):        self._captcha_response(task, False)",,"def captcha_invalid(self, task):        self._captcha_response(task, False)",94c5c2fd-c6bc-4c70-a1d1-fb9073449922
addons,AntiStandby.py,init,44,46,def init(self):        self.pid = None        self.mtime = 0,,def init(self):        self.pid = None        self.mtime = 0,f1adcbb8-0f3d-420b-885d-c0b6a0185ac5
addons,AntiStandby.py,activate,48,64,"def activate(self):        hdd = self.config.get(""hdd"")        system = not self.config.get(""system"")        display = not self.config.get(""display"")        if hdd:            print(""INTERVAL"", type(self.config.get(""interval"")))            self.periodical.start(self.config.get(""interval""), threaded=True)        if os.name == ""nt"":            self.win_standby(system, display)        elif sys.platform == ""darwin"":            self.osx_standby(system, display)        else:            self.linux_standby(system, display)",,"def activate(self):        hdd = self.config.get(""hdd"")        system = not self.config.get(""system"")        display = not self.config.get(""display"")        if hdd:            print(""INTERVAL"", type(self.config.get(""interval"")))            self.periodical.start(self.config.get(""interval""), threaded=True)        if os.name == ""nt"":            self.win_standby(system, display)        elif sys.platform == ""darwin"":            self.osx_standby(system, display)        else:            self.linux_standby(system, display)",536c06b9-4157-4fd7-b4cb-29815e41a0cb
addons,AntiStandby.py,deactivate,66,76,"def deactivate(self):        self.remove(self.TMP_FILE, try_trash=False)        if os.name == ""nt"":            self.win_standby(True)        elif sys.platform == ""darwin"":            self.osx_standby(True)        else:            self.linux_standby(True)",,"def deactivate(self):        self.remove(self.TMP_FILE, try_trash=False)        if os.name == ""nt"":            self.win_standby(True)        elif sys.platform == ""darwin"":            self.osx_standby(True)        else:            self.linux_standby(True)",67e8cd93-91a2-475b-8a8f-bcc4d42a4b8f
addons,AntiStandby.py,win_standby,79,97,"def win_standby(self, system=True, display=True):        import ctypes        set = ctypes.windll.kernel32.SetThreadExecutionState        if system:            if display:                set(Kernel32.ES_CONTINUOUS)            else:                set(Kernel32.ES_CONTINUOUS | Kernel32.ES_DISPLAY_REQUIRED)        else:            if display:                set(Kernel32.ES_CONTINUOUS | Kernel32.ES_SYSTEM_REQUIRED)            else:                set(                    Kernel32.ES_CONTINUOUS                    | Kernel32.ES_SYSTEM_REQUIRED                    | Kernel32.ES_DISPLAY_REQUIRED                )",,"def win_standby(self, system=True, display=True):        import ctypes        set = ctypes.windll.kernel32.SetThreadExecutionState        if system:            if display:                set(Kernel32.ES_CONTINUOUS)            else:                set(Kernel32.ES_CONTINUOUS | Kernel32.ES_DISPLAY_REQUIRED)        else:            if display:                set(Kernel32.ES_CONTINUOUS | Kernel32.ES_SYSTEM_REQUIRED)            else:                set(                    Kernel32.ES_CONTINUOUS                    | Kernel32.ES_SYSTEM_REQUIRED                    | Kernel32.ES_DISPLAY_REQUIRED                )",a5271334-ae78-4100-b3eb-66f732e802a5
addons,AntiStandby.py,osx_standby,100,113,"def osx_standby(self, system=True, display=True):        try:            if system:                caffeine.off()            else:                caffeine.on(display)        except NameError:            self.log_warning(                self._(""Unable to change power state""), self._(""caffeine lib not found"")            )        except Exception as exc:            self.log_warning(self._(""Unable to change power state""), exc)",,"def osx_standby(self, system=True, display=True):        try:            if system:                caffeine.off()            else:                caffeine.on(display)        except NameError:            self.log_warning(                self._(""Unable to change power state""), self._(""caffeine lib not found"")            )        except Exception as exc:            self.log_warning(self._(""Unable to change power state""), exc)",207b3984-b023-4410-a6c7-d15d44b19159
addons,AntiStandby.py,linux_standby,116,135,"def linux_standby(self, system=True, display=True):        try:            if system:                if self.pid:                    self.pid.kill()            elif not self.pid:                self.pid = subprocess.Popen([""caffeine""])        except Exception as exc:            self.log_warning(self._(""Unable to change system power state""), exc)        try:            if display:                subprocess.call([""xset"", ""+dpms"", ""s"", ""default""])            else:                subprocess.call([""xset"", ""-dpms"", ""s"", ""off""])        except Exception as exc:            self.log_warning(self._(""Unable to change display power state""), exc)",,"def linux_standby(self, system=True, display=True):        try:            if system:                if self.pid:                    self.pid.kill()            elif not self.pid:                self.pid = subprocess.Popen([""caffeine""])        except Exception as exc:            self.log_warning(self._(""Unable to change system power state""), exc)        try:            if display:                subprocess.call([""xset"", ""+dpms"", ""s"", ""default""])            else:                subprocess.call([""xset"", ""-dpms"", ""s"", ""off""])        except Exception as exc:            self.log_warning(self._(""Unable to change display power state""), exc)",3a7d920b-2d2b-4536-836a-cbb40959b336
addons,AntiStandby.py,touch,138,142,"def touch(self, path):        with open(path, mode=""w""):            os.utime(path, None)        self.mtime = time.time()",,"def touch(self, path):        with open(path, mode=""w""):            os.utime(path, None)        self.mtime = time.time()",50206648-553f-47b8-90ef-e33c3123e466
addons,AntiStandby.py,max_mtime,145,154,"def max_mtime(self, path):        return max(            0,            0,            *(                os.path.getmtime(os.path.join(root, file))                for root, dirs, files in os.walk(os.fsdecode(path), topdown=False)                for file in files            ),        )",,"def max_mtime(self, path):        return max(            0,            0,            *(                os.path.getmtime(os.path.join(root, file))                for root, dirs, files in os.walk(os.fsdecode(path), topdown=False)                for file in files            ),        )",168c8e25-9ed9-45bf-af0c-023c0379eebc
addons,AntiStandby.py,periodical_task,156,171,"def periodical_task(self):        if not self.config.get(""hdd""):            return        if (            self.pyload.thread_manager.pause            or not self.pyload.api.is_time_download()            or not self.pyload.thread_manager.get_active_files()        ):            return        dl_folder = self.pyload.config.get(""general"", ""storage_folder"")        if (self.max_mtime(dl_folder) - self.mtime) < self.periodical.interval:            return        self.touch(self.TMP_FILE)",,"def periodical_task(self):        if not self.config.get(""hdd""):            return        if (            self.pyload.thread_manager.pause            or not self.pyload.api.is_time_download()            or not self.pyload.thread_manager.get_active_files()        ):            return        dl_folder = self.pyload.config.get(""general"", ""storage_folder"")        if (self.max_mtime(dl_folder) - self.mtime) < self.periodical.interval:            return        self.touch(self.TMP_FILE)",589bfe44-a5fc-4a10-bd59-9adfa2555b2e
addons,AntiVirus.py,scan,47,144,"def scan(self, pyfile, thread):        avfile = os.fsdecode(self.config.get(""avfile""))        avargs = os.fsdecode(self.config.get(""avargs"").strip())        if not os.path.isfile(avfile):            self.fail(self._(""Antivirus executable not found""))        scanfolder = self.config.get(""avtarget"") == ""folder""        if scanfolder:            dl_folder = self.pyload.config.get(""general"", ""storage_folder"")            package_folder = (                pyfile.package().folder                if self.pyload.config.get(""general"", ""folder_per_package"")                else """"            )            target = os.path.join(dl_folder, package_folder, pyfile.name)            target_repr = ""Folder: "" + package_folder or dl_folder        else:            target = os.fsdecode(pyfile.plugin.last_download)            target_repr = ""File: "" + os.path.basename(pyfile.plugin.last_download)        if not exists(target):            return        thread.add_active(pyfile)        pyfile.set_custom_status(self._(""virus scanning""))        pyfile.set_progress(0)        try:            p = subprocess.Popen([avfile, avargs, target])            out, err = (to_str(x).strip() for x in p.communicate())            if out:                self.log_info(target_repr, out)            if err:                self.log_warning(target_repr, err)                if not self.config.get(""ignore-err""):                    self.log_debug(""Delete/Quarantine task aborted due scan error"")                    return            if p.returncode:                action = self.config.get(""action"")                if scanfolder:                    if action == ""Antivirus default"":                        self.log_warning(                            self._(""Delete/Quarantine task skipped in folder scan mode"")                        )                    return                pyfile.error = self._(""Infected file"")                try:                    if action == ""Delete"":                        if not self.config.get(""deltotrash""):                            os.remove(target)                        else:                            try:                                send2trash.send2trash(target)                            except NameError:                                self.log_warning(                                    self._(                                        ""Send2Trash lib not found, moving to quarantine instead""                                    )                                )                                pyfile.set_custom_status(self._(""file moving""))                                shutil.move(target, self.config.get(""quardir""))                            except Exception as exc:                                self.log_warning(                                    self._(                                        ""Unable to move file to trash: {}, moving to quarantine instead""                                    ).format(exc)                                )                                pyfile.set_custom_status(self._(""file moving""))                                shutil.move(target, self.config.get(""quardir""))                            else:                                self.log_debug(""Successfully moved file to trash"")                    elif action == ""Quarantine"":                        pyfile.set_custom_status(self._(""file moving""))                        shutil.move(target, self.config.get(""quardir""))                except (IOError, shutil.Error) as exc:                    self.log_error(target_repr, action + "" action failed!"", exc)            elif not err:                self.log_debug(target_repr, ""No infected file found"")        finally:            pyfile.set_progress(100)            thread.finish_file(pyfile)",,"def scan(self, pyfile, thread):        avfile = os.fsdecode(self.config.get(""avfile""))        avargs = os.fsdecode(self.config.get(""avargs"").strip())        if not os.path.isfile(avfile):            self.fail(self._(""Antivirus executable not found""))        scanfolder = self.config.get(""avtarget"") == ""folder""        if scanfolder:            dl_folder = self.pyload.config.get(""general"", ""storage_folder"")            package_folder = (                pyfile.package().folder                if self.pyload.config.get(""general"", ""folder_per_package"")                else """"            )            target = os.path.join(dl_folder, package_folder, pyfile.name)            target_repr = ""Folder: "" + package_folder or dl_folder        else:            target = os.fsdecode(pyfile.plugin.last_download)            target_repr = ""File: "" + os.path.basename(pyfile.plugin.last_download)        if not exists(target):            return        thread.add_active(pyfile)        pyfile.set_custom_status(self._(""virus scanning""))        pyfile.set_progress(0)        try:            p = subprocess.Popen([avfile, avargs, target])            out, err = (to_str(x).strip() for x in p.communicate())            if out:                self.log_info(target_repr, out)            if err:                self.log_warning(target_repr, err)                if not self.config.get(""ignore-err""):                    self.log_debug(""Delete/Quarantine task aborted due scan error"")                    return            if p.returncode:                action = self.config.get(""action"")                if scanfolder:                    if action == ""Antivirus default"":                        self.log_warning(                            self._(""Delete/Quarantine task skipped in folder scan mode"")                        )                    return                pyfile.error = self._(""Infected file"")                try:                    if action == ""Delete"":                        if not self.config.get(""deltotrash""):                            os.remove(target)                        else:                            try:                                send2trash.send2trash(target)                            except NameError:                                self.log_warning(                                    self._(                                        ""Send2Trash lib not found, moving to quarantine instead""                                    )                                )                                pyfile.set_custom_status(self._(""file moving""))                                shutil.move(target, self.config.get(""quardir""))                            except Exception as exc:                                self.log_warning(                                    self._(                                        ""Unable to move file to trash: {}, moving to quarantine instead""                                    ).format(exc)                                )                                pyfile.set_custom_status(self._(""file moving""))                                shutil.move(target, self.config.get(""quardir""))                            else:                                self.log_debug(""Successfully moved file to trash"")                    elif action == ""Quarantine"":                        pyfile.set_custom_status(self._(""file moving""))                        shutil.move(target, self.config.get(""quardir""))                except (IOError, shutil.Error) as exc:                    self.log_error(target_repr, action + "" action failed!"", exc)            elif not err:                self.log_debug(target_repr, ""No infected file found"")        finally:            pyfile.set_progress(100)            thread.finish_file(pyfile)",112d8967-aae5-4efb-895e-910ebe2d0873
addons,AntiVirus.py,download_finished,146,147,"def download_finished(self, pyfile):        return self.scan(pyfile)",,"def download_finished(self, pyfile):        return self.scan(pyfile)",fa04a555-2f02-4967-b7c7-1d0c8c6a3287
addons,AntiVirus.py,download_failed,149,152,"def download_failed(self, pyfile):        #: Check if pyfile is still ""failed"", maybe might has been restarted in meantime        if pyfile.status == 8 and self.config.get(""scanfailed""):            return self.scan(pyfile)",,"def download_failed(self, pyfile):        #: Check if pyfile is still ""failed"", maybe might has been restarted in meantime        if pyfile.status == 8 and self.config.get(""scanfailed""):            return self.scan(pyfile)",9f7c45f9-99da-4208-ba68-769773ab15f7
addons,AppriseNotify.py,get_key,36,37,"def get_key(self):        return self.config.get(""configs"").split("","")",,"def get_key(self):        return self.config.get(""configs"").split("","")",9be6f58f-27c2-4080-9185-b41bc8d7eff4
addons,AppriseNotify.py,send,39,60,"def send(self, event, msg, key):        if not check_module(""apprise""):            self.log_error(                self._(""Cannot send notification: apprise is not installed.""),                self._(""Install apprise by issuing 'pip install apprise' command.""),            )            return        import apprise        apprise_obj = apprise.Apprise()        apprise_config = apprise.AppriseConfig()        for c in key:            apprise_config.add(c)        apprise_obj.add(apprise_config)        apprise_obj.notify(            title=self.config.get(""title""),            body=""%s: %s"" % (event, msg) if msg else event,        )",,"def send(self, event, msg, key):        if not check_module(""apprise""):            self.log_error(                self._(""Cannot send notification: apprise is not installed.""),                self._(""Install apprise by issuing 'pip install apprise' command.""),            )            return        import apprise        apprise_obj = apprise.Apprise()        apprise_config = apprise.AppriseConfig()        for c in key:            apprise_config.add(c)        apprise_obj.add(apprise_config)        apprise_obj.notify(            title=self.config.get(""title""),            body=""%s: %s"" % (event, msg) if msg else event,        )",dd4c27e6-f740-4b29-8ff1-fa3d264944b2
addons,BypassCaptcha.py,__init__,12,13,"def __init__(self, err):        self.err = err",,"def __init__(self, err):        self.err = err",54070b9f-61e8-4151-9637-f061e3886796
addons,BypassCaptcha.py,get_code,15,16,def get_code(self):        return self.err,,def get_code(self):        return self.err,0c5c4d50-ccb7-4e17-b713-3baa3cf48eb1
addons,BypassCaptcha.py,__str__,18,19,"def __str__(self):        return ""<BypassCaptchaException {}>"".format(self.err)",,"def __str__(self):        return ""<BypassCaptchaException {}>"".format(self.err)",5f6fe228-60c3-4ea4-9454-408cbca5de9c
addons,BypassCaptcha.py,__repr__,21,22,"def __repr__(self):        return ""<BypassCaptchaException {}>"".format(self.err)",,"def __repr__(self):        return ""<BypassCaptchaException {}>"".format(self.err)",85c71717-03a3-48bd-b4da-9ea37db2dcc4
addons,BypassCaptcha.py,get_credits,51,55,"def get_credits(self):        res = self.load(self.GETCREDITS_URL, post={""key"": self.config.get(""passkey"")})        data = dict(x.split("" "", 1) for x in res.splitlines())        return int(data[""Left""])",,"def get_credits(self):        res = self.load(self.GETCREDITS_URL, post={""key"": self.config.get(""passkey"")})        data = dict(x.split("" "", 1) for x in res.splitlines())        return int(data[""Left""])",9116ccba-23d5-43e2-b2b9-d712b0f974dc
addons,BypassCaptcha.py,submit,57,82,"def submit(self, captcha, captcha_type=""file"", match=None):        with get_request() as req:            #: Raise timeout threshold            req.c.setopt(pycurl.LOW_SPEED_TIME, 80)            res = self.load(                self.SUBMIT_URL,                post={                    ""vendor_key"": self.PYLOAD_KEY,                    ""key"": self.config.get(""passkey""),                    ""gen_task_id"": ""1"",                    ""file"": (pycurl.FORM_FILE, captcha),                },                req=req,            )        data = dict(x.split("" "", 1) for x in res.splitlines())        if not data or ""Value"" not in data:            raise BypassCaptchaException(res)        result = data[""Value""]        ticket = data[""TaskId""]        self.log_debug(f""Result {ticket} : {result}"")        return ticket, result",,"def submit(self, captcha, captcha_type=""file"", match=None):        with get_request() as req:            #: Raise timeout threshold            req.c.setopt(pycurl.LOW_SPEED_TIME, 80)            res = self.load(                self.SUBMIT_URL,                post={                    ""vendor_key"": self.PYLOAD_KEY,                    ""key"": self.config.get(""passkey""),                    ""gen_task_id"": ""1"",                    ""file"": (pycurl.FORM_FILE, captcha),                },                req=req,            )        data = dict(x.split("" "", 1) for x in res.splitlines())        if not data or ""Value"" not in data:            raise BypassCaptchaException(res)        result = data[""Value""]        ticket = data[""TaskId""]        self.log_debug(f""Result {ticket} : {result}"")        return ticket, result",9bbf60f7-165c-4ce6-826c-bf12bacb9d0f
addons,BypassCaptcha.py,respond,84,95,"def respond(self, ticket, success):        try:            res = self.load(                self.RESPOND_URL,                post={                    ""task_id"": ticket,                    ""key"": self.config.get(""passkey""),                    ""cv"": 1 if success else 0,                },            )        except BadHeader as exc:            self.log_error(self._(""Could not send response""), exc)",,"def respond(self, ticket, success):        try:            res = self.load(                self.RESPOND_URL,                post={                    ""task_id"": ticket,                    ""key"": self.config.get(""passkey""),                    ""cv"": 1 if success else 0,                },            )        except BadHeader as exc:            self.log_error(self._(""Could not send response""), exc)",f324d3d3-8c51-4b13-b439-671f026a8e52
addons,BypassCaptcha.py,captcha_task,97,117,"def captcha_task(self, task):        if ""service"" in task.data:            return False        if not task.is_textual():            return False        if not self.config.get(""passkey""):            return False        if self.pyload.is_client_connected() and self.config.get(""check_client""):            return False        if self.get_credits() > 0:            task.handler.append(self)            task.data[""service""] = self.classname            task.set_waiting(100)            self._process_captcha(task)        else:            self.log_info(self._(""Your account has not enough credits""))",,"def captcha_task(self, task):        if ""service"" in task.data:            return False        if not task.is_textual():            return False        if not self.config.get(""passkey""):            return False        if self.pyload.is_client_connected() and self.config.get(""check_client""):            return False        if self.get_credits() > 0:            task.handler.append(self)            task.data[""service""] = self.classname            task.set_waiting(100)            self._process_captcha(task)        else:            self.log_info(self._(""Your account has not enough credits""))",afad08fc-ffe2-42c5-9969-62a1afc83ce3
addons,BypassCaptcha.py,captcha_correct,119,121,"def captcha_correct(self, task):        if task.data[""service""] == self.classname and ""ticket"" in task.data:            self.respond(task.data[""ticket""], True)",,"def captcha_correct(self, task):        if task.data[""service""] == self.classname and ""ticket"" in task.data:            self.respond(task.data[""ticket""], True)",3604d225-714a-485b-8a6d-97a9b10ec014
addons,BypassCaptcha.py,captcha_invalid,123,125,"def captcha_invalid(self, task):        if task.data[""service""] == self.classname and ""ticket"" in task.data:            self.respond(task.data[""ticket""], False)",,"def captcha_invalid(self, task):        if task.data[""service""] == self.classname and ""ticket"" in task.data:            self.respond(task.data[""ticket""], False)",2b0d8fa2-7a43-45a6-869e-0219c437f077
addons,BypassCaptcha.py,_process_captcha,128,137,"def _process_captcha(self, task):        c = task.captcha_params[""file""]        try:            ticket, result = self.submit(c)        except BypassCaptchaException as exc:            task.error = exc.get_code()            return        task.data[""ticket""] = ticket        task.set_result(result)",,"def _process_captcha(self, task):        c = task.captcha_params[""file""]        try:            ticket, result = self.submit(c)        except BypassCaptchaException as exc:            task.error = exc.get_code()            return        task.data[""ticket""] = ticket        task.set_result(result)",74b202e5-1ed8-44fb-96a1-1bacb9075435
addons,Captcha9Kw.py,get_credits,64,81,"def get_credits(self):        res = self.load(            self.API_URL,            get={                ""apikey"": self.config.get(""passkey""),                ""pyload"": ""1"",                ""source"": ""pyload"",                ""action"": ""usercaptchaguthaben"",            },        )        if res.isdigit():            self.log_info(self._(""{} credits left"").format(res))            credits = self.info[""credits""] = int(res)            return credits        else:            self.log_error(res)            return 0",,"def get_credits(self):        res = self.load(            self.API_URL,            get={                ""apikey"": self.config.get(""passkey""),                ""pyload"": ""1"",                ""source"": ""pyload"",                ""action"": ""usercaptchaguthaben"",            },        )        if res.isdigit():            self.log_info(self._(""{} credits left"").format(res))            credits = self.info[""credits""] = int(res)            return credits        else:            self.log_error(res)            return 0",9d5f813f-942e-4770-8960-0edd2ae6bef0
addons,Captcha9Kw.py,_process_captcha,84,225,"def _process_captcha(self, task):        pluginname = task.captcha_params[""plugin""]        if task.is_interactive() or task.is_invisible():            url_p = urllib.parse.urlparse(task.captcha_params[""url""])            if url_p.scheme not in (""http"", ""https""):                self.log_error(self._(""Invalid url""))                return            post_data = {                ""pageurl"": ""{}://{}/"".format(url_p.scheme, url_p.netloc),                ""oldsource"": self.INTERACTIVE_TYPES[                    task.captcha_params[""captcha_plugin""]                ],                ""captchachoice"": self.INTERACTIVE_TYPES[                    task.captcha_params[""captcha_plugin""]                ],                ""isInvisible"": ""INVISIBLE"" if task.is_invisible() else ""NORMAL"",                ""data-sitekey"": task.captcha_params[""sitekey""],                ""securetoken"": task.captcha_params.get(""securetoken"", """"),            }        else:            try:                with open(task.captcha_params[""file""], mode=""rb"") as fp:                    data = fp.read()            except IOError as exc:                self.log_error(exc)                return            post_data = {                ""file-upload-01"": base64.b64encode(data),                ""oldsource"": pluginname,            }        option = {            ""min"": 2,            ""max"": 50,            ""phrase"": 0,            ""numeric"": 0,            ""case_sensitive"": 0,            ""math"": 0,            ""prio"": min(max(self.config.get(""prio""), 0), 10),            ""confirm"": self.config.get(""confirm""),            ""timeout"": min(max(self.config.get(""timeout""), 300), 3999),            ""selfsolve"": self.config.get(""selfsolve""),            ""cph"": self.config.get(""captchaperhour""),            ""cpm"": self.config.get(""captchapermin""),        }        for opt in self.config.get(""hoster_options"", """").split(""|""):            if not opt:                continue            details = (x.strip() for x in opt.split("";""))            if not details or details[0].lower() != pluginname.lower():                continue            for d in details:                hosteroption = d.split("" "")                if len(hosteroption) < 2 or not hosteroption[1].isdigit():                    continue                o = hosteroption[0].lower()                if o in option:                    option[o] = hosteroption[1]            break        post_data.update(            {                ""apikey"": self.config.get(""passkey""),                ""prio"": option[""prio""],                ""confirm"": option[""confirm""],                ""maxtimeout"": option[""timeout""],                ""selfsolve"": option[""selfsolve""],                ""captchaperhour"": option[""cph""],                ""captchapermin"": option[""cpm""],                ""case-sensitive"": option[""case_sensitive""],                ""min_len"": option[""min""],                ""max_len"": option[""max""],                ""phrase"": option[""phrase""],                ""numeric"": option[""numeric""],                ""math"": option[""math""],                ""pyload"": 1,                ""source"": ""pyload"",                ""base64"": 0 if task.is_interactive() or task.is_invisible() else 1,                ""mouse"": 1 if task.is_positional() else 0,                ""interactive"": 1 if task.is_interactive() or task.is_invisible() else 0,                ""action"": ""usercaptchaupload"",            }        )        for _ in range(5):            try:                res = self.load(self.API_URL, post=post_data)            except BadHeader as exc:                res = exc.content                time.sleep(3)            else:                if res and res.isdigit():                    break        else:            self.log_error(self._(""Bad request: {}"").format(res))            return        self.log_debug(            ""NewCaptchaID ticket: {}"".format(res), task.captcha_params.get(""file"", """")        )        task.data[""ticket""] = res        for _ in range(int(self.config.get(""timeout"") // 5)):            result = self.load(                self.API_URL,                get={                    ""apikey"": self.config.get(""passkey""),                    ""id"": res,                    ""pyload"": ""1"",                    ""info"": ""1"",                    ""source"": ""pyload"",                    ""action"": ""usercaptchacorrectdata"",                },            )            if not result or result == ""NO DATA"":                time.sleep(5)            else:                break        else:            self.log_debug(f""Could not send request: {res}"")            result = None        self.log_info(self._(""Captcha result for ticket {}: {}"").format(res, result))        task.set_result(result)",,"def _process_captcha(self, task):        pluginname = task.captcha_params[""plugin""]        if task.is_interactive() or task.is_invisible():            url_p = urllib.parse.urlparse(task.captcha_params[""url""])            if url_p.scheme not in (""http"", ""https""):                self.log_error(self._(""Invalid url""))                return            post_data = {                ""pageurl"": ""{}://{}/"".format(url_p.scheme, url_p.netloc),                ""oldsource"": self.INTERACTIVE_TYPES[                    task.captcha_params[""captcha_plugin""]                ],                ""captchachoice"": self.INTERACTIVE_TYPES[                    task.captcha_params[""captcha_plugin""]                ],                ""isInvisible"": ""INVISIBLE"" if task.is_invisible() else ""NORMAL"",                ""data-sitekey"": task.captcha_params[""sitekey""],                ""securetoken"": task.captcha_params.get(""securetoken"", """"),            }        else:            try:                with open(task.captcha_params[""file""], mode=""rb"") as fp:                    data = fp.read()            except IOError as exc:                self.log_error(exc)                return            post_data = {                ""file-upload-01"": base64.b64encode(data),                ""oldsource"": pluginname,            }        option = {            ""min"": 2,            ""max"": 50,            ""phrase"": 0,            ""numeric"": 0,            ""case_sensitive"": 0,            ""math"": 0,            ""prio"": min(max(self.config.get(""prio""), 0), 10),            ""confirm"": self.config.get(""confirm""),            ""timeout"": min(max(self.config.get(""timeout""), 300), 3999),            ""selfsolve"": self.config.get(""selfsolve""),            ""cph"": self.config.get(""captchaperhour""),            ""cpm"": self.config.get(""captchapermin""),        }        for opt in self.config.get(""hoster_options"", """").split(""|""):            if not opt:                continue            details = (x.strip() for x in opt.split("";""))            if not details or details[0].lower() != pluginname.lower():                continue            for d in details:                hosteroption = d.split("" "")                if len(hosteroption) < 2 or not hosteroption[1].isdigit():                    continue                o = hosteroption[0].lower()                if o in option:                    option[o] = hosteroption[1]            break        post_data.update(            {                ""apikey"": self.config.get(""passkey""),                ""prio"": option[""prio""],                ""confirm"": option[""confirm""],                ""maxtimeout"": option[""timeout""],                ""selfsolve"": option[""selfsolve""],                ""captchaperhour"": option[""cph""],                ""captchapermin"": option[""cpm""],                ""case-sensitive"": option[""case_sensitive""],                ""min_len"": option[""min""],                ""max_len"": option[""max""],                ""phrase"": option[""phrase""],                ""numeric"": option[""numeric""],                ""math"": option[""math""],                ""pyload"": 1,                ""source"": ""pyload"",                ""base64"": 0 if task.is_interactive() or task.is_invisible() else 1,                ""mouse"": 1 if task.is_positional() else 0,                ""interactive"": 1 if task.is_interactive() or task.is_invisible() else 0,                ""action"": ""usercaptchaupload"",            }        )        for _ in range(5):            try:                res = self.load(self.API_URL, post=post_data)            except BadHeader as exc:                res = exc.content                time.sleep(3)            else:                if res and res.isdigit():                    break        else:            self.log_error(self._(""Bad request: {}"").format(res))            return        self.log_debug(            ""NewCaptchaID ticket: {}"".format(res), task.captcha_params.get(""file"", """")        )        task.data[""ticket""] = res        for _ in range(int(self.config.get(""timeout"") // 5)):            result = self.load(                self.API_URL,                get={                    ""apikey"": self.config.get(""passkey""),                    ""id"": res,                    ""pyload"": ""1"",                    ""info"": ""1"",                    ""source"": ""pyload"",                    ""action"": ""usercaptchacorrectdata"",                },            )            if not result or result == ""NO DATA"":                time.sleep(5)            else:                break        else:            self.log_debug(f""Could not send request: {res}"")            result = None        self.log_info(self._(""Captcha result for ticket {}: {}"").format(res, result))        task.set_result(result)",1ab0b492-2add-41e5-a0fe-1f46066c073a
addons,Captcha9Kw.py,captcha_task,227,291,"def captcha_task(self, task):        if task.is_interactive() or task.is_invisible():            if task.captcha_params[                ""captcha_plugin""            ] not in self.INTERACTIVE_TYPES.keys() or not self.config.get(                ""solve_interactive""            ):                return        else:            if not task.is_textual() and not task.is_positional():                return        if not self.config.get(""passkey""):            return        if self.pyload.is_client_connected() and self.config.get(""check_client""):            return        credits = self.get_credits()        if credits <= 0:            self.log_error(self._(""Your captcha 9kw.eu account has not enough credits""))            return        max_queue = min(self.config.get(""queue""), 999)        timeout = min(max(self.config.get(""timeout""), 300), 3999)        pluginname = task.captcha_params[""plugin""]        for _ in range(5):            servercheck = self.load(""http://www.9kw.eu/grafik/servercheck.txt"")            if max_queue > int(re.search(r""queue=(\d+)"", servercheck).group(1)):                break            time.sleep(10)        else:            self.log_error(self._(""Too many captchas in queue""))            return        for opt in self.config.get(""hoster_options"", """").split(""|""):            if not opt:                continue            details = [x.strip() for x in opt.split("":"")]            if not details or details[0].lower() != pluginname.lower():                continue            for d in details:                hosteroption = d.split(""="")                if (                    len(hosteroption) > 1                    and hosteroption[0].lower() == ""timeout""                    and hosteroption[1].isdigit()                ):                    timeout = int(hosteroption[1])            break        task.handler.append(self)        task.set_waiting(timeout)        self._process_captcha(task)",,"def captcha_task(self, task):        if task.is_interactive() or task.is_invisible():            if task.captcha_params[                ""captcha_plugin""            ] not in self.INTERACTIVE_TYPES.keys() or not self.config.get(                ""solve_interactive""            ):                return        else:            if not task.is_textual() and not task.is_positional():                return        if not self.config.get(""passkey""):            return        if self.pyload.is_client_connected() and self.config.get(""check_client""):            return        credits = self.get_credits()        if credits <= 0:            self.log_error(self._(""Your captcha 9kw.eu account has not enough credits""))            return        max_queue = min(self.config.get(""queue""), 999)        timeout = min(max(self.config.get(""timeout""), 300), 3999)        pluginname = task.captcha_params[""plugin""]        for _ in range(5):            servercheck = self.load(""http://www.9kw.eu/grafik/servercheck.txt"")            if max_queue > int(re.search(r""queue=(\d+)"", servercheck).group(1)):                break            time.sleep(10)        else:            self.log_error(self._(""Too many captchas in queue""))            return        for opt in self.config.get(""hoster_options"", """").split(""|""):            if not opt:                continue            details = [x.strip() for x in opt.split("":"")]            if not details or details[0].lower() != pluginname.lower():                continue            for d in details:                hosteroption = d.split(""="")                if (                    len(hosteroption) > 1                    and hosteroption[0].lower() == ""timeout""                    and hosteroption[1].isdigit()                ):                    timeout = int(hosteroption[1])            break        task.handler.append(self)        task.set_waiting(timeout)        self._process_captcha(task)",be5413a3-6054-40af-b263-3ff5883514d0
addons,Captcha9Kw.py,_captcha_response,293,325,"def _captcha_response(self, task, correct):        request_type = ""correct"" if correct else ""refund""        if ""ticket"" not in task.data:            self.log_debug(                ""No CaptchaID for {} request (task: {})"".format(request_type, task)            )            return        passkey = self.config.get(""passkey"")        for _ in range(3):            res = self.load(                self.API_URL,                get={                    ""action"": ""usercaptchacorrectback"",                    ""apikey"": passkey,                    ""api_key"": passkey,                    ""correct"": ""1"" if correct else ""2"",                    ""pyload"": ""1"",                    ""source"": ""pyload"",                    ""id"": task.data[""ticket""],                },            )            self.log_debug(f""Request {request_type}: {res}"")            if res == ""OK"":                break            time.sleep(5)        else:            self.log_debug(f""Could not send {request_type} request: {res}"")",,"def _captcha_response(self, task, correct):        request_type = ""correct"" if correct else ""refund""        if ""ticket"" not in task.data:            self.log_debug(                ""No CaptchaID for {} request (task: {})"".format(request_type, task)            )            return        passkey = self.config.get(""passkey"")        for _ in range(3):            res = self.load(                self.API_URL,                get={                    ""action"": ""usercaptchacorrectback"",                    ""apikey"": passkey,                    ""api_key"": passkey,                    ""correct"": ""1"" if correct else ""2"",                    ""pyload"": ""1"",                    ""source"": ""pyload"",                    ""id"": task.data[""ticket""],                },            )            self.log_debug(f""Request {request_type}: {res}"")            if res == ""OK"":                break            time.sleep(5)        else:            self.log_debug(f""Could not send {request_type} request: {res}"")",5ad45aa9-0cef-440a-9f14-d61b927cded2
addons,Captcha9Kw.py,captcha_correct,327,328,"def captcha_correct(self, task):        self._captcha_response(task, True)",,"def captcha_correct(self, task):        self._captcha_response(task, True)",56980502-8a3e-4ad8-b800-a4577e6b607f
addons,Captcha9Kw.py,captcha_invalid,330,331,"def captcha_invalid(self, task):        self._captcha_response(task, False)",,"def captcha_invalid(self, task):        self._captcha_response(task, False)",850d49f9-41d0-43ca-8658-75bd43c1ea10
addons,Checksum.py,compute_checksum,15,65,"def compute_checksum(local_file, algorithm, progress_notify=None, abort=None):    file_size = os.stat(local_file).st_size    processed = 0    if progress_notify:        progress_notify(0)    try:        if algorithm in getattr(            hashlib,            ""algorithms"",            (""md5"", ""sha1"", ""sha224"", ""sha256"", ""sha384"", ""sha512""),        ):            h = getattr(hashlib, algorithm)()            with open(local_file, mode=""rb"") as fp:                for chunk in iter(lambda: fp.read(128 * h.block_size), b""""):                    if abort and abort():                        return False                    h.update(chunk)                    processed += len(chunk)                    if progress_notify:                        progress_notify(processed * 100 // file_size)            return h.hexdigest()        elif algorithm in (""adler32"", ""crc32""):            hf = getattr(zlib, algorithm)            last = 0            with open(local_file, mode=""rb"") as fp:                for chunk in iter(lambda: fp.read(8192), """"):                    if abort and abort():                        return False                    last = hf(chunk, last)                    processed += len(chunk)                    if progress_notify:                        progress_notify(processed * 100 // file_size)            #: zlib sometimes return negative value            return ""{:x}"".format((2 ** 32 + last) & 0xFFFFFFFF)        else:            return None    finally:        if progress_notify:            progress_notify(100)",,"def compute_checksum(local_file, algorithm, progress_notify=None, abort=None):    file_size = os.stat(local_file).st_size    processed = 0    if progress_notify:        progress_notify(0)    try:        if algorithm in getattr(            hashlib,            ""algorithms"",            (""md5"", ""sha1"", ""sha224"", ""sha256"", ""sha384"", ""sha512""),        ):            h = getattr(hashlib, algorithm)()            with open(local_file, mode=""rb"") as fp:                for chunk in iter(lambda: fp.read(128 * h.block_size), b""""):                    if abort and abort():                        return False                    h.update(chunk)                    processed += len(chunk)                    if progress_notify:                        progress_notify(processed * 100 // file_size)            return h.hexdigest()        elif algorithm in (""adler32"", ""crc32""):            hf = getattr(zlib, algorithm)            last = 0            with open(local_file, mode=""rb"") as fp:                for chunk in iter(lambda: fp.read(8192), """"):                    if abort and abort():                        return False                    last = hf(chunk, last)                    processed += len(chunk)                    if progress_notify:                        progress_notify(processed * 100 // file_size)            #: zlib sometimes return negative value            return ""{:x}"".format((2 ** 32 + last) & 0xFFFFFFFF)        else:            return None    finally:        if progress_notify:            progress_notify(100)",baa4eb41-a8c2-4c15-bc46-26b2b6632d74
addons,Checksum.py,activate,106,110,"def activate(self):        if not self.config.get(""check_checksum""):            self.log_info(                self._(""Checksum validation is disabled in plugin configuration"")            )",,"def activate(self):        if not self.config.get(""check_checksum""):            self.log_info(                self._(""Checksum validation is disabled in plugin configuration"")            )",0ff1aa9c-6739-40d7-9412-b8f651c07ce9
addons,Checksum.py,init,112,126,"def init(self):        self.algorithms = sorted(            getattr(                hashlib,                ""algorithms"",                (""md5"", ""sha1"", ""sha224"", ""sha256"", ""sha384"", ""sha512""),            ),            reverse=True,        )        self.algorithms.extend([""crc32"", ""adler32""])        self.formats = self.algorithms + [""sfv"", ""crc"", ""hash""]        self.retries = {}",,"def init(self):        self.algorithms = sorted(            getattr(                hashlib,                ""algorithms"",                (""md5"", ""sha1"", ""sha224"", ""sha256"", ""sha384"", ""sha512""),            ),            reverse=True,        )        self.algorithms.extend([""crc32"", ""adler32""])        self.formats = self.algorithms + [""sfv"", ""crc"", ""hash""]        self.retries = {}",e50b6047-3401-40cd-908d-230f1fefd486
addons,Checksum.py,download_finished,128,243,"def download_finished(self, pyfile):                if hasattr(pyfile.plugin, ""check_data"") and isinstance(            pyfile.plugin.check_data, dict        ):            data = pyfile.plugin.check_data.copy()        elif hasattr(pyfile.plugin, ""api_data"") and isinstance(            pyfile.plugin.api_data, dict        ):            data = pyfile.plugin.api_data.copy()        elif hasattr(pyfile.plugin, ""info"") and isinstance(pyfile.plugin.info, dict):            data = pyfile.plugin.info.copy()            # NOTE: Don't check file size until a similarity matcher will be implemented            data.pop(""size"", None)        else:            return        pyfile.set_status(""processing"")        if not pyfile.plugin.last_download:            self.check_failed(pyfile, None, ""No file downloaded"")        local_file = os.fsdecode(pyfile.plugin.last_download)        if not os.path.isfile(local_file):            self.check_failed(pyfile, None, ""File does not exist"")        #: Validate file size        if ""size"" in data:            api_size = int(data[""size""])            file_size = os.path.getsize(local_file)            if api_size != file_size:                self.log_warning(                    self._(""File {} has incorrect size: {} B ({} expected)"").format(                        pyfile.name, file_size, api_size                    )                )                self.check_failed(pyfile, local_file, ""Incorrect file size"")            data.pop(""size"", None)        #: Validate checksum        if data and self.config.get(""check_checksum""):            data[""hash""] = data.get(""hash"", {})            for key in self.algorithms:                if data.get(key) and key not in data[""hash""]:                    data[""hash""][key] = data[key]                    break            if len(data[""hash""]) > 0:                for key in self.algorithms:                    if key in data[""hash""]:                        pyfile.set_custom_status(self._(""checksum verifying""))                        try:                            checksum = compute_checksum(                                local_file,                                key.replace(""-"", """").lower(),                                progress_notify=pyfile.set_progress,                                abort=lambda: pyfile.abort,                            )                        finally:                            pyfile.set_status(""processing"")                        if checksum is False:                            continue                        elif checksum is not None:                            if checksum.lower() == data[""hash""][key].lower():                                self.log_info(                                    self._(                                        'File integrity of ""{}"" verified by {} checksum ({})'                                    ).format(pyfile.name, key.upper(), checksum.lower())                                )                                pyfile.error = self._(""checksum verified"")                                break                            else:                                self.log_warning(                                    self._(                                        ""{} checksum for file {} does not match ({} != {})""                                    ).format(                                        key.upper(),                                        pyfile.name,                                        checksum,                                        data[""hash""][key].lower(),                                    )                                )                                self.check_failed(                                    pyfile, local_file, ""Checksums do not match""                                )                        else:                            self.log_warning(                                self._(""Unsupported hashing algorithm""), key.upper()                            )                else:                    self.log_warning(                        self._('Unable to validate checksum for file: ""{}""').format(                            pyfile.name                        )                    )","Compute checksum for the downloaded file and compare it with the hash provided
by the downloader.

pyfile.plugin.check_data should be a dictionary which can
contain: a) if known, the exact filesize in bytes (e.g. 'size':
123456789) b) hexadecimal hash string with algorithm name as key
(e.g. 'md5': ""d76505d0869f9f928a17d42d66326307"")","def download_finished(self, pyfile):        """"""        Compute checksum for the downloaded file and compare it with the hash provided        by the downloader.        pyfile.plugin.check_data should be a dictionary which can        contain: a) if known, the exact filesize in bytes (e.g. 'size':        123456789) b) hexadecimal hash string with algorithm name as key        (e.g. 'md5': ""d76505d0869f9f928a17d42d66326307"")        """"""        if hasattr(pyfile.plugin, ""check_data"") and isinstance(            pyfile.plugin.check_data, dict        ):            data = pyfile.plugin.check_data.copy()        elif hasattr(pyfile.plugin, ""api_data"") and isinstance(            pyfile.plugin.api_data, dict        ):            data = pyfile.plugin.api_data.copy()        elif hasattr(pyfile.plugin, ""info"") and isinstance(pyfile.plugin.info, dict):            data = pyfile.plugin.info.copy()            # NOTE: Don't check file size until a similarity matcher will be implemented            data.pop(""size"", None)        else:            return        pyfile.set_status(""processing"")        if not pyfile.plugin.last_download:            self.check_failed(pyfile, None, ""No file downloaded"")        local_file = os.fsdecode(pyfile.plugin.last_download)        if not os.path.isfile(local_file):            self.check_failed(pyfile, None, ""File does not exist"")        #: Validate file size        if ""size"" in data:            api_size = int(data[""size""])            file_size = os.path.getsize(local_file)            if api_size != file_size:                self.log_warning(                    self._(""File {} has incorrect size: {} B ({} expected)"").format(                        pyfile.name, file_size, api_size                    )                )                self.check_failed(pyfile, local_file, ""Incorrect file size"")            data.pop(""size"", None)        #: Validate checksum        if data and self.config.get(""check_checksum""):            data[""hash""] = data.get(""hash"", {})            for key in self.algorithms:                if data.get(key) and key not in data[""hash""]:                    data[""hash""][key] = data[key]                    break            if len(data[""hash""]) > 0:                for key in self.algorithms:                    if key in data[""hash""]:                        pyfile.set_custom_status(self._(""checksum verifying""))                        try:                            checksum = compute_checksum(                                local_file,                                key.replace(""-"", """").lower(),                                progress_notify=pyfile.set_progress,                                abort=lambda: pyfile.abort,                            )                        finally:                            pyfile.set_status(""processing"")                        if checksum is False:                            continue                        elif checksum is not None:                            if checksum.lower() == data[""hash""][key].lower():                                self.log_info(                                    self._(                                        'File integrity of ""{}"" verified by {} checksum ({})'                                    ).format(pyfile.name, key.upper(), checksum.lower())                                )                                pyfile.error = self._(""checksum verified"")                                break                            else:                                self.log_warning(                                    self._(                                        ""{} checksum for file {} does not match ({} != {})""                                    ).format(                                        key.upper(),                                        pyfile.name,                                        checksum,                                        data[""hash""][key].lower(),                                    )                                )                                self.check_failed(                                    pyfile, local_file, ""Checksums do not match""                                )                        else:                            self.log_warning(                                self._(""Unsupported hashing algorithm""), key.upper()                            )                else:                    self.log_warning(                        self._('Unable to validate checksum for file: ""{}""').format(                            pyfile.name                        )                    )

Compute checksum for the downloaded file and compare it with the hash provided
by the downloader.

pyfile.plugin.check_data should be a dictionary which can
contain: a) if known, the exact filesize in bytes (e.g. 'size':
123456789) b) hexadecimal hash string with algorithm name as key
(e.g. 'md5': ""d76505d0869f9f928a17d42d66326307"")",6506b773-caf6-4414-a3ac-cae2d6ce379e
addons,Checksum.py,check_failed,245,263,"def check_failed(self, pyfile, local_file, msg):        check_action = self.config.get(""check_action"")        if check_action == ""retry"":            max_tries = self.config.get(""max_tries"")            retry_action = self.config.get(""retry_action"")            if all(r < max_tries for _, r in pyfile.plugin.retries.items()):                if local_file:                    os.remove(local_file)                pyfile.plugin.retry(max_tries, self.config.get(""wait_time""), msg)            elif retry_action == ""nothing"":                return        elif check_action == ""nothing"":            return        os.remove(local_file)        pyfile.plugin.fail(msg)",,"def check_failed(self, pyfile, local_file, msg):        check_action = self.config.get(""check_action"")        if check_action == ""retry"":            max_tries = self.config.get(""max_tries"")            retry_action = self.config.get(""retry_action"")            if all(r < max_tries for _, r in pyfile.plugin.retries.items()):                if local_file:                    os.remove(local_file)                pyfile.plugin.retry(max_tries, self.config.get(""wait_time""), msg)            elif retry_action == ""nothing"":                return        elif check_action == ""nothing"":            return        os.remove(local_file)        pyfile.plugin.fail(msg)",867d8507-a90e-48c5-ae76-8a84e5078e55
addons,Checksum.py,package_finished,265,268,"def package_finished(self, pypack):        event_finished = Event()        self.verify_package(pypack, event_finished)        event_finished.wait()",,"def package_finished(self, pypack):        event_finished = Event()        self.verify_package(pypack, event_finished)        event_finished.wait()",dae90a1c-4c71-4cd1-93d8-1ecc24df634a
addons,Checksum.py,verify_package,271,375,"def verify_package(self, pypack, event_finished, thread=None):        try:            dl_folder = os.path.join(                self.pyload.config.get(""general"", ""storage_folder""), pypack.folder, """"            )            pdata = list(pypack.get_children().items())            files_ids = {fdata[""name""]: fdata[""id""] for fid, fdata in pdata}            failed_queue = []            for fid, fdata in pdata:                file_type = os.path.splitext(fdata[""name""])[1][1:].lower()                if file_type not in self.formats:                    continue                hash_file = os.fsdecode(os.path.join(dl_folder, fdata[""name""]))                if not os.path.isfile(hash_file):                    self.log_warning(self._(""File not found""), fdata[""name""])                    continue                with open(hash_file) as fp:                    text = fp.read()                failed = []                for m in re.finditer(                    self._regexmap.get(file_type, self._regexmap[""default""]), text, re.M                ):                    data = m.groupdict()                    self.log_debug(fdata[""name""], data)                    local_file = os.fsdecode(os.path.join(dl_folder, data[""NAME""]))                    algorithm = self._methodmap.get(file_type, file_type)                    pyfile = None                    fid = files_ids.get(data[""NAME""], None)                    if fid is not None:                        pyfile = self.pyload.files.get_file(fid)                        pyfile.set_custom_status(self._(""checksum verifying""))                        thread.add_active(pyfile)                        try:                            checksum = compute_checksum(                                local_file,                                algorithm,                                progress_notify=pyfile.set_progress,                                abort=lambda: pyfile.abort,                            )                        finally:                            thread.finish_file(pyfile)                    else:                        checksum = compute_checksum(local_file, algorithm)                    if checksum is False:                        continue                    elif checksum is not None:                        if checksum.lower() == data[""HASH""].lower():                            self.retries.pop(fid, 0)                            self.log_info(                                self._(                                    'File integrity of ""{}"" verified by {} checksum ({})'                                ).format(data[""NAME""], algorithm, checksum)                            )                            if pyfile is not None:                                pyfile.error = self._(""checksum verified"")                                pyfile.set_status(""finished"")                                pyfile.release()                        else:                            self.log_warning(                                self._(                                    ""{} checksum for file {} does not match ({} != {})""                                ).format(                                    algorithm.upper(),                                    data[""NAME""],                                    checksum.lower(),                                    data[""HASH""].lower(),                                )                            )                            if fid is not None:                                failed.append((fid, local_file))                    else:                        self.log_warning(                            self._(""Unsupported hashing algorithm""), algorithm.upper()                        )                if failed:                    failed_queue.extend(failed)                else:                    self.log_info(                        self._(                            'All files specified by ""{}"" verified successfully'                        ).format(fdata[""name""])                    )            if failed_queue:                self.package_check_failed(                    failed_queue, thread, ""Checksums do not match""                )        finally:            event_finished.set()",,"def verify_package(self, pypack, event_finished, thread=None):        try:            dl_folder = os.path.join(                self.pyload.config.get(""general"", ""storage_folder""), pypack.folder, """"            )            pdata = list(pypack.get_children().items())            files_ids = {fdata[""name""]: fdata[""id""] for fid, fdata in pdata}            failed_queue = []            for fid, fdata in pdata:                file_type = os.path.splitext(fdata[""name""])[1][1:].lower()                if file_type not in self.formats:                    continue                hash_file = os.fsdecode(os.path.join(dl_folder, fdata[""name""]))                if not os.path.isfile(hash_file):                    self.log_warning(self._(""File not found""), fdata[""name""])                    continue                with open(hash_file) as fp:                    text = fp.read()                failed = []                for m in re.finditer(                    self._regexmap.get(file_type, self._regexmap[""default""]), text, re.M                ):                    data = m.groupdict()                    self.log_debug(fdata[""name""], data)                    local_file = os.fsdecode(os.path.join(dl_folder, data[""NAME""]))                    algorithm = self._methodmap.get(file_type, file_type)                    pyfile = None                    fid = files_ids.get(data[""NAME""], None)                    if fid is not None:                        pyfile = self.pyload.files.get_file(fid)                        pyfile.set_custom_status(self._(""checksum verifying""))                        thread.add_active(pyfile)                        try:                            checksum = compute_checksum(                                local_file,                                algorithm,                                progress_notify=pyfile.set_progress,                                abort=lambda: pyfile.abort,                            )                        finally:                            thread.finish_file(pyfile)                    else:                        checksum = compute_checksum(local_file, algorithm)                    if checksum is False:                        continue                    elif checksum is not None:                        if checksum.lower() == data[""HASH""].lower():                            self.retries.pop(fid, 0)                            self.log_info(                                self._(                                    'File integrity of ""{}"" verified by {} checksum ({})'                                ).format(data[""NAME""], algorithm, checksum)                            )                            if pyfile is not None:                                pyfile.error = self._(""checksum verified"")                                pyfile.set_status(""finished"")                                pyfile.release()                        else:                            self.log_warning(                                self._(                                    ""{} checksum for file {} does not match ({} != {})""                                ).format(                                    algorithm.upper(),                                    data[""NAME""],                                    checksum.lower(),                                    data[""HASH""].lower(),                                )                            )                            if fid is not None:                                failed.append((fid, local_file))                    else:                        self.log_warning(                            self._(""Unsupported hashing algorithm""), algorithm.upper()                        )                if failed:                    failed_queue.extend(failed)                else:                    self.log_info(                        self._(                            'All files specified by ""{}"" verified successfully'                        ).format(fdata[""name""])                    )            if failed_queue:                self.package_check_failed(                    failed_queue, thread, ""Checksums do not match""                )        finally:            event_finished.set()",442bf590-0cf9-4549-9d4e-e261e89b97f6
addons,Checksum.py,package_check_failed,378,425,"def package_check_failed(self, failed_queue, parent_thread, msg):        parent_thread.join()  #: wait for calling thread to finish        time.sleep(1)        check_action = self.config.get(""check_action"")        retry_action = self.config.get(""retry_action"")        for fid, local_file in failed_queue:            pyfile = self.pyload.files.get_file(fid)            try:                if check_action == ""retry"":                    retry_count = self.retries.get(fid, 0)                    max_tries = self.config.get(""max_tries"")                    if retry_count < max_tries:                        if local_file:                            os.remove(local_file)                        self.retries[fid] = retry_count + 1                        wait_time = self.config.get(""wait_time"")                        self.log_info(                            self._(""Waiting {}..."").format(format.time(wait_time))                        )                        time.sleep(wait_time)                        pyfile.package().set_finished = (                            False  #: Force `package_finished` event again                        )                        self.pyload.files.restart_file(fid)                        continue                    else:                        self.retries.pop(fid, 0)                        if retry_action == ""nothing"":                            continue                else:                    self.retries.pop(fid, 0)                    if check_action == ""nothing"":                        continue                os.remove(local_file)                pyfile.error = msg                pyfile.set_status(""failed"")            finally:                pyfile.release()",,"def package_check_failed(self, failed_queue, parent_thread, msg):        parent_thread.join()  #: wait for calling thread to finish        time.sleep(1)        check_action = self.config.get(""check_action"")        retry_action = self.config.get(""retry_action"")        for fid, local_file in failed_queue:            pyfile = self.pyload.files.get_file(fid)            try:                if check_action == ""retry"":                    retry_count = self.retries.get(fid, 0)                    max_tries = self.config.get(""max_tries"")                    if retry_count < max_tries:                        if local_file:                            os.remove(local_file)                        self.retries[fid] = retry_count + 1                        wait_time = self.config.get(""wait_time"")                        self.log_info(                            self._(""Waiting {}..."").format(format.time(wait_time))                        )                        time.sleep(wait_time)                        pyfile.package().set_finished = (                            False  #: Force `package_finished` event again                        )                        self.pyload.files.restart_file(fid)                        continue                    else:                        self.retries.pop(fid, 0)                        if retry_action == ""nothing"":                            continue                else:                    self.retries.pop(fid, 0)                    if check_action == ""nothing"":                        continue                os.remove(local_file)                pyfile.error = msg                pyfile.set_status(""failed"")            finally:                pyfile.release()",cea581b1-67f3-4a26-b504-a520b50962e6
addons,ClickNLoad.py,init,36,45,"def init(self):        self.cnl_ip = """" if self.config.get(""extern"") else ""127.0.0.1""        self.cnl_port = self.config.get(""port"")        self.server_running = False        self.do_exit = False        self.exit_done = threading.Event()        self.backend_found = threading.Event()        self.pyload.scheduler.add_job(5, self._find_backend, threaded=False)",,"def init(self):        self.cnl_ip = """" if self.config.get(""extern"") else ""127.0.0.1""        self.cnl_port = self.config.get(""port"")        self.server_running = False        self.do_exit = False        self.exit_done = threading.Event()        self.backend_found = threading.Event()        self.pyload.scheduler.add_job(5, self._find_backend, threaded=False)",750ba917-6344-4d97-a08d-55c3925e5c66
addons,ClickNLoad.py,_find_backend,48,93,"def _find_backend(self):        if self.pyload.config.get(""webui"", ""enabled""):            web_host = self.pyload.config.get(""webui"", ""host"")            web_port = self.pyload.config.get(""webui"", ""port"")            if web_host in (""0.0.0.0"", ""::""):                web_host = ""127.0.0.1""            try:                addrinfo = socket.getaddrinfo(                    web_host, web_port, socket.AF_UNSPEC,                    socket.SOCK_STREAM, 0, socket.AI_PASSIVE,                )            except socket.gaierror:                self.log_error(                    self._(""Could not resolve backend server, ClickNLoad cannot start"")                )                return            for addr in addrinfo:                test_socket = socket.socket(addr[0], socket.SOCK_STREAM)                test_socket.settimeout(1)                try:                    test_socket.connect(addr[4])                except socket.error:                    continue                test_socket.shutdown(socket.SHUT_WR)                self.web_addr = addr[4]                self.web_af = addr[0]                self.log_debug(                    self._(""Backend found on {}://{}:{}"").format(                        ""https"" if self.pyload.webserver.use_ssl else ""http"",                        f""[{self.web_addr[0]}]"" if "":"" in self.web_addr[0] else self.web_addr[0],                        self.web_addr[1]                    )                )                self.backend_found.set()                break            else:                self.log_error(                    self._(""Could not connect to backend server, ClickNLoad cannot start"")                )",,"def _find_backend(self):        if self.pyload.config.get(""webui"", ""enabled""):            web_host = self.pyload.config.get(""webui"", ""host"")            web_port = self.pyload.config.get(""webui"", ""port"")            if web_host in (""0.0.0.0"", ""::""):                web_host = ""127.0.0.1""            try:                addrinfo = socket.getaddrinfo(                    web_host, web_port, socket.AF_UNSPEC,                    socket.SOCK_STREAM, 0, socket.AI_PASSIVE,                )            except socket.gaierror:                self.log_error(                    self._(""Could not resolve backend server, ClickNLoad cannot start"")                )                return            for addr in addrinfo:                test_socket = socket.socket(addr[0], socket.SOCK_STREAM)                test_socket.settimeout(1)                try:                    test_socket.connect(addr[4])                except socket.error:                    continue                test_socket.shutdown(socket.SHUT_WR)                self.web_addr = addr[4]                self.web_af = addr[0]                self.log_debug(                    self._(""Backend found on {}://{}:{}"").format(                        ""https"" if self.pyload.webserver.use_ssl else ""http"",                        f""[{self.web_addr[0]}]"" if "":"" in self.web_addr[0] else self.web_addr[0],                        self.web_addr[1]                    )                )                self.backend_found.set()                break            else:                self.log_error(                    self._(""Could not connect to backend server, ClickNLoad cannot start"")                )",fc92b11e-3ed9-4f79-b8fb-87783feb5f09
addons,ClickNLoad.py,_activate,96,99,def _activate(self):        self.backend_found.wait(20)        if self.backend_found.is_set():            self.proxy(),,def _activate(self):        self.backend_found.wait(20)        if self.backend_found.is_set():            self.proxy(),94dee2a7-0b20-49b0-baa2-3c65b86a730f
addons,ClickNLoad.py,activate,101,108,"def activate(self):        if not self.pyload.config.get(""webui"", ""enabled""):            self.log_warning(                self._(""pyLoad's Web interface is not active, ClickNLoad cannot start"")            )            return        self._activate()",,"def activate(self):        if not self.pyload.config.get(""webui"", ""enabled""):            self.log_warning(                self._(""pyLoad's Web interface is not active, ClickNLoad cannot start"")            )            return        self._activate()",311f18e8-37f9-4ad0-a21c-14298107663e
addons,ClickNLoad.py,deactivate,110,136,"def deactivate(self):        if self.server_running:            self.log_info(self._(""Shutting down proxy...""))            self.do_exit = True            try:                wakeup_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)                wakeup_socket.connect(                    (                        ""127.0.0.1""                        if any(ip == self.cnl_ip for ip in (""0.0.0.0"", """", ""::""))                        else self.cnl_ip,                        self.cnl_port,                    )                )                wakeup_socket.close()            except Exception:                pass            self.exit_done.wait(10)            if self.exit_done.is_set():                self.log_debug(""Server exited successfully"")            else:                self.log_warning(                    self._(""Server was not exited gracefully, shutdown forced"")                )",,"def deactivate(self):        if self.server_running:            self.log_info(self._(""Shutting down proxy...""))            self.do_exit = True            try:                wakeup_socket = socket.socket(socket.AF_INET, socket.SOCK_STREAM)                wakeup_socket.connect(                    (                        ""127.0.0.1""                        if any(ip == self.cnl_ip for ip in (""0.0.0.0"", """", ""::""))                        else self.cnl_ip,                        self.cnl_port,                    )                )                wakeup_socket.close()            except Exception:                pass            self.exit_done.wait(10)            if self.exit_done.is_set():                self.log_debug(""Server exited successfully"")            else:                self.log_warning(                    self._(""Server was not exited gracefully, shutdown forced"")                )",e2ea048b-faed-46df-a346-7bfde7bed991
addons,ClickNLoad.py,forward,140,153,"def forward(self, client_socket, backend_socket, queue=False):        if queue:            old_ids = set(pack.pid for pack in self.pyload.api.get_collector())        forward(client_socket, backend_socket, recv_timeout=0.5)        forward(backend_socket, client_socket)        if queue:            new_ids = set(pack.pid for pack in self.pyload.api.get_collector())            for id in new_ids - old_ids:                self.pyload.api.push_to_queue(id)        backend_socket.close()        client_socket.close()",,"def forward(self, client_socket, backend_socket, queue=False):        if queue:            old_ids = set(pack.pid for pack in self.pyload.api.get_collector())        forward(client_socket, backend_socket, recv_timeout=0.5)        forward(backend_socket, client_socket)        if queue:            new_ids = set(pack.pid for pack in self.pyload.api.get_collector())            for id in new_ids - old_ids:                self.pyload.api.push_to_queue(id)        backend_socket.close()        client_socket.close()",fd7df190-60d3-408e-9284-4240ae26c0a5
addons,ClickNLoad.py,proxy,156,162,"def proxy(self):        self.log_info(            self._(""Proxy listening on {}:{}"").format(                self.cnl_ip or ""0.0.0.0"", self.cnl_port            )        )        self._server()",,"def proxy(self):        self.log_info(            self._(""Proxy listening on {}:{}"").format(                self.cnl_ip or ""0.0.0.0"", self.cnl_port            )        )        self._server()",c7febbe8-1e93-467e-bef3-92ff0cde97ff
addons,ClickNLoad.py,_server,165,220,"def _server(self):        try:            self.exit_done.clear()            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as dock_socket:                dock_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)                dock_socket.bind((self.cnl_ip, self.cnl_port))                dock_socket.listen()                self.server_running = True                while True:                    client_socket, client_addr = dock_socket.accept()                    if not self.do_exit:                        host, port = client_addr                        self.log_debug(f""Connection from {host}:{port}"")                        backend_socket = socket.socket(                            self.web_af, socket.SOCK_STREAM                        )                        if self.pyload.webserver.use_ssl:                            try:                                context = ssl.create_default_context(ssl.Purpose.SERVER_AUTH)                                context.check_hostname = False                                context.verify_mode = ssl.CERT_NONE                                backend_socket = context.wrap_socket(backend_socket, server_hostname=self.web_addr[0])                            except Exception as exc:                                self.log_error(self._(""SSL error: {}"").format(exc))                                client_socket.close()                                continue                        backend_socket.connect(self.web_addr)                        self.forward(                            client_socket,                            backend_socket,                            self.config.get(""dest"") == ""queue"",                        )                    else:                        break            self.server_running = False            self.exit_done.set()        except socket.timeout:            self.log_debug(""Connection timed out, retrying..."")            return self._server()        except socket.error as exc:            self.log_error(exc)            time.sleep(240)            return self._server()",,"def _server(self):        try:            self.exit_done.clear()            with socket.socket(socket.AF_INET, socket.SOCK_STREAM) as dock_socket:                dock_socket.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)                dock_socket.bind((self.cnl_ip, self.cnl_port))                dock_socket.listen()                self.server_running = True                while True:                    client_socket, client_addr = dock_socket.accept()                    if not self.do_exit:                        host, port = client_addr                        self.log_debug(f""Connection from {host}:{port}"")                        backend_socket = socket.socket(                            self.web_af, socket.SOCK_STREAM                        )                        if self.pyload.webserver.use_ssl:                            try:                                context = ssl.create_default_context(ssl.Purpose.SERVER_AUTH)                                context.check_hostname = False                                context.verify_mode = ssl.CERT_NONE                                backend_socket = context.wrap_socket(backend_socket, server_hostname=self.web_addr[0])                            except Exception as exc:                                self.log_error(self._(""SSL error: {}"").format(exc))                                client_socket.close()                                continue                        backend_socket.connect(self.web_addr)                        self.forward(                            client_socket,                            backend_socket,                            self.config.get(""dest"") == ""queue"",                        )                    else:                        break            self.server_running = False            self.exit_done.set()        except socket.timeout:            self.log_debug(""Connection timed out, retrying..."")            return self._server()        except socket.error as exc:            self.log_error(exc)            time.sleep(240)            return self._server()",f0c57310-ff2b-4ae3-a871-8881dbba7815
addons,CloudFlareDdos.py,plugin_id,15,20,"def plugin_id(plugin):    return ""<{plugintype} {pluginname}{id}>"".format(        plugintype=plugin.__type__.upper(),        pluginname=plugin.__name__,        id=""[{}]"".format(plugin.pyfile.id if plugin.pyfile else """"),    )",,"def plugin_id(plugin):    return ""<{plugintype} {pluginname}{id}>"".format(        plugintype=plugin.__type__.upper(),        pluginname=plugin.__name__,        id=""[{}]"".format(plugin.pyfile.id if plugin.pyfile else """"),    )",8316cba4-edba-4fed-85bf-8ab6b41550a3
addons,CloudFlareDdos.py,is_simple_plugin,23,27,"def is_simple_plugin(obj):    return any(        k.__name__ in (""SimpleDownloader"", ""SimpleDecrypter"")        for k in inspect.getmro(type(obj))    )",,"def is_simple_plugin(obj):    return any(        k.__name__ in (""SimpleDownloader"", ""SimpleDecrypter"")        for k in inspect.getmro(type(obj))    )",ea15df87-bc47-4ffd-b982-74ea45e9025e
addons,CloudFlareDdos.py,get_plugin_last_header,30,32,"def get_plugin_last_header(plugin):    # NOTE: req can be a HTTPRequest or a Browser object    return plugin.req.http.response_header if hasattr(plugin.req, ""http"") else plugin.req.response_header",,"def get_plugin_last_header(plugin):    # NOTE: req can be a HTTPRequest or a Browser object    return plugin.req.http.response_header if hasattr(plugin.req, ""http"") else plugin.req.response_header",a03c176e-7bcf-4963-8828-c1da37f01f7d
addons,CloudFlareDdos.py,handle_function,37,101,"def handle_function(addon_plugin, owner_plugin, func_name, orig_func, args):        addon_plugin.log_debug(            ""Calling {}() of {}"".format(func_name, plugin_id(owner_plugin))        )        try:            data = orig_func(*args[0], **args[1])            addon_plugin.log_debug(f""{func_name}() returned successfully"")            return data        except BadHeader as exc:            addon_plugin.log_debug(                ""{}(): got BadHeader exception {}"".format(func_name, exc.code)            )            header = parse_html_header(exc.header)            if ""cloudflare"" in header.get(""server"", """"):                if exc.code == 403:                    data = CloudFlare._solve_cf_security_check(                        addon_plugin, owner_plugin, exc.content                    )                elif exc.code == 503:                    for _i in range(3):                        try:                            data = CloudFlare._solve_cf_ddos_challenge(addon_plugin, owner_plugin, exc.content)                            break                        except BadHeader as exc:  #: Possibly we got another ddos challenge                            addon_plugin.log_debug(f""{func_name}(): got BadHeader exception {exc.code}"")                            header = parse_html_header(exc.header)                            if exc.code == 503 and ""cloudflare"" in header.get(""server"", """"):                                continue  #: Yes, it's a ddos challenge again..                            else:                                data = None  # Tell the exception handler to re-throw the exception                                break                    else:                        addon_plugin.log_error(                            addon_plugin._(""{}(): Max solve retries reached"").format(                                func_name                            )                        )                        data = None  # Tell the exception handler to re-throw the exception                else:                    addon_plugin.log_warning(                        addon_plugin._(""Unknown CloudFlare response code {}"").format(                            exc.code                        )                    )                    raise                if data is None:                    raise exc                else:                    return data            else:                raise",,"def handle_function(addon_plugin, owner_plugin, func_name, orig_func, args):        addon_plugin.log_debug(            ""Calling {}() of {}"".format(func_name, plugin_id(owner_plugin))        )        try:            data = orig_func(*args[0], **args[1])            addon_plugin.log_debug(f""{func_name}() returned successfully"")            return data        except BadHeader as exc:            addon_plugin.log_debug(                ""{}(): got BadHeader exception {}"".format(func_name, exc.code)            )            header = parse_html_header(exc.header)            if ""cloudflare"" in header.get(""server"", """"):                if exc.code == 403:                    data = CloudFlare._solve_cf_security_check(                        addon_plugin, owner_plugin, exc.content                    )                elif exc.code == 503:                    for _i in range(3):                        try:                            data = CloudFlare._solve_cf_ddos_challenge(addon_plugin, owner_plugin, exc.content)                            break                        except BadHeader as exc:  #: Possibly we got another ddos challenge                            addon_plugin.log_debug(f""{func_name}(): got BadHeader exception {exc.code}"")                            header = parse_html_header(exc.header)                            if exc.code == 503 and ""cloudflare"" in header.get(""server"", """"):                                continue  #: Yes, it's a ddos challenge again..                            else:                                data = None  # Tell the exception handler to re-throw the exception                                break                    else:                        addon_plugin.log_error(                            addon_plugin._(""{}(): Max solve retries reached"").format(                                func_name                            )                        )                        data = None  # Tell the exception handler to re-throw the exception                else:                    addon_plugin.log_warning(                        addon_plugin._(""Unknown CloudFlare response code {}"").format(                            exc.code                        )                    )                    raise                if data is None:                    raise exc                else:                    return data            else:                raise",b8551e8b-1fdd-43e8-9d67-928fd67111a5
addons,CloudFlareDdos.py,_solve_cf_ddos_challenge,104,185,"def _solve_cf_ddos_challenge(addon_plugin, owner_plugin, data):        try:            addon_plugin.log_info(                addon_plugin._(""Detected CloudFlare's DDoS protection page"")            )            wait_time = (int(re.search(r""submit\(\);\r?\n\s*},\s*([0-9]+)"", data).group(1)) + 999) // 1000            owner_plugin.set_wait(wait_time)            last_url = owner_plugin.req.last_effective_url            urlp = urllib.parse.urlparse(last_url)            domain = urlp.netloc            submit_url = ""{}://{}/cdn-cgi/l/chk_jschl"".format(urlp.scheme, domain)            get_params = {}            try:                get_params[""jschl_vc""] = re.search(                    r'name=""jschl_vc"" value=""(\w+)""', data                ).group(1)                get_params[""pass""] = re.search(                    r'name=""pass"" value=""(.+?)""', data                ).group(1)                get_params['s'] = re.search(                    r'name=""s"" value=""(.+?)""', data                ).group(1)                # Extract the arithmetic operation                js = re.search(                    r""setTimeout\(function\(\){\s+(var s,t,o,p,b,r,e,a,k,i,n,g,f.+?\r?\n[\s\S]+?a\.value =.+?)\r?\n"",                    data,                ).group(1)                js = re.sub(r'a\.value = (.+\.toFixed\(10\);).+', r'\1', js)                solution_name = re.search(r's,t,o,p,b,r,e,a,k,i,n,g,f,\s*(.+)\s*=', js).group(1)                g = re.search(r'(.*};)\n\s*(t\s*=(.+))\n\s*(;%s.*)' % solution_name, js, re.M | re.I | re.S).groups()                js = g[0] + g[-1]                js = re.sub(r""[\n\\']"", """", js)            except Exception:                # Something is wrong with the page.                # This may indicate CloudFlare has changed their anti-bot                # technique.                owner_plugin.log_error(                    addon_plugin._(""Unable to parse CloudFlare's DDoS protection page"")                )                return None  #: Tell the exception handler to re-throw the exception            if ""toFixed"" not in js:                owner_plugin.log_error(owner_plugin._(""Unable to parse CloudFlare's DDoS protection page""))                return None  # Tell the exception handler to re-throw the exception            atob = 'var atob = function(str) {return Buffer.from(str, ""base64"").toString(""binary"");}'            try:                k = re.search(r'k\s*=\s*\'(.+?)\';', data).group(1)                v = re.search(r'<div(?:.*)id=""%s""(?:.*)>(.*)</div>' % k, data).group(1)                doc = 'var document= {getElementById: function(x) { return {innerHTML:""%s""};}}' % v            except (AttributeError, IndexError):                doc = """"            js = '%s;%s;var t=""%s"";%s' % (doc, atob, domain, js)            # Safely evaluate the Javascript expression            res = eval_js(js)            try:                get_params['jschl_answer'] = str(float(res))            except ValueError:                owner_plugin.log_error(owner_plugin._(""Unable to parse CloudFlare's DDoS protection page""))                return None  # Tell the exception handler to re-throw the exception            owner_plugin.wait()  #: Do the actual wait            return owner_plugin.load(submit_url, get=get_params, ref=last_url)        except BadHeader as exc:            raise exc  #: Huston, we have a BadHeader!        except Exception as exc:            addon_plugin.log_error(exc)            return None",,"def _solve_cf_ddos_challenge(addon_plugin, owner_plugin, data):        try:            addon_plugin.log_info(                addon_plugin._(""Detected CloudFlare's DDoS protection page"")            )            wait_time = (int(re.search(r""submit\(\);\r?\n\s*},\s*([0-9]+)"", data).group(1)) + 999) // 1000            owner_plugin.set_wait(wait_time)            last_url = owner_plugin.req.last_effective_url            urlp = urllib.parse.urlparse(last_url)            domain = urlp.netloc            submit_url = ""{}://{}/cdn-cgi/l/chk_jschl"".format(urlp.scheme, domain)            get_params = {}            try:                get_params[""jschl_vc""] = re.search(                    r'name=""jschl_vc"" value=""(\w+)""', data                ).group(1)                get_params[""pass""] = re.search(                    r'name=""pass"" value=""(.+?)""', data                ).group(1)                get_params['s'] = re.search(                    r'name=""s"" value=""(.+?)""', data                ).group(1)                # Extract the arithmetic operation                js = re.search(                    r""setTimeout\(function\(\){\s+(var s,t,o,p,b,r,e,a,k,i,n,g,f.+?\r?\n[\s\S]+?a\.value =.+?)\r?\n"",                    data,                ).group(1)                js = re.sub(r'a\.value = (.+\.toFixed\(10\);).+', r'\1', js)                solution_name = re.search(r's,t,o,p,b,r,e,a,k,i,n,g,f,\s*(.+)\s*=', js).group(1)                g = re.search(r'(.*};)\n\s*(t\s*=(.+))\n\s*(;%s.*)' % solution_name, js, re.M | re.I | re.S).groups()                js = g[0] + g[-1]                js = re.sub(r""[\n\\']"", """", js)            except Exception:                # Something is wrong with the page.                # This may indicate CloudFlare has changed their anti-bot                # technique.                owner_plugin.log_error(                    addon_plugin._(""Unable to parse CloudFlare's DDoS protection page"")                )                return None  #: Tell the exception handler to re-throw the exception            if ""toFixed"" not in js:                owner_plugin.log_error(owner_plugin._(""Unable to parse CloudFlare's DDoS protection page""))                return None  # Tell the exception handler to re-throw the exception            atob = 'var atob = function(str) {return Buffer.from(str, ""base64"").toString(""binary"");}'            try:                k = re.search(r'k\s*=\s*\'(.+?)\';', data).group(1)                v = re.search(r'<div(?:.*)id=""%s""(?:.*)>(.*)</div>' % k, data).group(1)                doc = 'var document= {getElementById: function(x) { return {innerHTML:""%s""};}}' % v            except (AttributeError, IndexError):                doc = """"            js = '%s;%s;var t=""%s"";%s' % (doc, atob, domain, js)            # Safely evaluate the Javascript expression            res = eval_js(js)            try:                get_params['jschl_answer'] = str(float(res))            except ValueError:                owner_plugin.log_error(owner_plugin._(""Unable to parse CloudFlare's DDoS protection page""))                return None  # Tell the exception handler to re-throw the exception            owner_plugin.wait()  #: Do the actual wait            return owner_plugin.load(submit_url, get=get_params, ref=last_url)        except BadHeader as exc:            raise exc  #: Huston, we have a BadHeader!        except Exception as exc:            addon_plugin.log_error(exc)            return None",183387df-ecfe-4f4d-b023-1e08425d5dcc
addons,CloudFlareDdos.py,_solve_cf_security_check,188,215,"def _solve_cf_security_check(addon_plugin, owner_plugin, data):        try:            last_url = owner_plugin.req.last_effective_url            captcha = ReCaptcha(owner_plugin.pyfile)            captcha_key = captcha.detect_key(data)            if captcha_key:                addon_plugin.log_info(                    addon_plugin._(""Detected CloudFlare's security check page"")                )                response = captcha.challenge(captcha_key, data)                return owner_plugin.load(                    owner_plugin.fixurl(""/cdn-cgi/l/chk_captcha""),                    get={""g-recaptcha-response"": response},                    ref=last_url,                )            else:                addon_plugin.log_warning(                    addon_plugin._(""Got unexpected CloudFlare html page"")                )                return None  #: Tell the exception handler to re-throw the exception        except Exception as exc:            addon_plugin.log_error(exc)            return None",,"def _solve_cf_security_check(addon_plugin, owner_plugin, data):        try:            last_url = owner_plugin.req.last_effective_url            captcha = ReCaptcha(owner_plugin.pyfile)            captcha_key = captcha.detect_key(data)            if captcha_key:                addon_plugin.log_info(                    addon_plugin._(""Detected CloudFlare's security check page"")                )                response = captcha.challenge(captcha_key, data)                return owner_plugin.load(                    owner_plugin.fixurl(""/cdn-cgi/l/chk_captcha""),                    get={""g-recaptcha-response"": response},                    ref=last_url,                )            else:                addon_plugin.log_warning(                    addon_plugin._(""Got unexpected CloudFlare html page"")                )                return None  #: Tell the exception handler to re-throw the exception        except Exception as exc:            addon_plugin.log_error(exc)            return None",27405d08-c4cb-49e3-886b-be41b7a6ab8c
addons,CloudFlareDdos.py,__init__,219,222,"def __init__(self, addon_plugin, owner_plugin):        self.addon_plugin = addon_plugin        self.owner_plugin = owner_plugin        self.old_preload = owner_plugin._preload",,"def __init__(self, addon_plugin, owner_plugin):        self.addon_plugin = addon_plugin        self.owner_plugin = owner_plugin        self.old_preload = owner_plugin._preload",efecb135-325b-4e63-842e-68cd1ea1ddb2
addons,CloudFlareDdos.py,my_preload,224,233,"def my_preload(self, *args, **kwargs):        data = CloudFlare.handle_function(            self.addon_plugin,            self.owner_plugin,            ""_preload"",            self.old_preload,            (args, kwargs),        )        if data is not None:            self.owner_plugin.data = data",,"def my_preload(self, *args, **kwargs):        data = CloudFlare.handle_function(            self.addon_plugin,            self.owner_plugin,            ""_preload"",            self.old_preload,            (args, kwargs),        )        if data is not None:            self.owner_plugin.data = data",91893999-3668-4e8b-a975-10158a19ae40
addons,CloudFlareDdos.py,__repr__,235,236,"def __repr__(self):        return ""<PreloadStub object at {}>"".format(hex(id(self)))",,"def __repr__(self):        return ""<PreloadStub object at {}>"".format(hex(id(self)))",b39686d6-9e06-46be-9973-f131aaf6bceb
addons,CloudFlareDdos.py,activate,251,253,def activate(self):        self.stubs = {}        self._override_get_url(),,def activate(self):        self.stubs = {}        self._override_get_url(),20a97f0f-7ef2-4922-a822-466a4f7a056c
addons,CloudFlareDdos.py,deactivate,255,260,def deactivate(self):        while len(self.stubs):            stub = next(iter(self.stubs.values()))            self._unoverride_preload(stub.owner_plugin)        self._unoverride_get_url(),,def deactivate(self):        while len(self.stubs):            stub = next(iter(self.stubs.values()))            self._unoverride_preload(stub.owner_plugin)        self._unoverride_get_url(),356feb96-f72d-4489-bbe8-7125d915409b
addons,CloudFlareDdos.py,_unoverride_preload,262,274,"def _unoverride_preload(self, plugin):        if id(plugin) in self.stubs:            self.log_debug(f""Unoverriding _preload() for {plugin_id(plugin)}"")            stub = self.stubs.pop(id(plugin))            stub.owner_plugin._preload = stub.old_preload        else:            self.log_warning(                self._(                    ""No _preload() override found for {}, cannot un-override>""                ).format(plugin_id(plugin))            )",,"def _unoverride_preload(self, plugin):        if id(plugin) in self.stubs:            self.log_debug(f""Unoverriding _preload() for {plugin_id(plugin)}"")            stub = self.stubs.pop(id(plugin))            stub.owner_plugin._preload = stub.old_preload        else:            self.log_warning(                self._(                    ""No _preload() override found for {}, cannot un-override>""                ).format(plugin_id(plugin))            )",5a97d583-668a-48c4-857d-187b9c726a48
addons,CloudFlareDdos.py,_override_preload,276,287,"def _override_preload(self, plugin):        if id(plugin) not in self.stubs:            stub = PreloadStub(self, plugin)            self.stubs[id(plugin)] = stub            self.log_debug(f""Overriding _preload() for {plugin_id(plugin)}"")            plugin._preload = stub.my_preload        else:            self.log_warning(                self._(""Already overrided _preload() for {}"").format(plugin_id(plugin))            )",,"def _override_preload(self, plugin):        if id(plugin) not in self.stubs:            stub = PreloadStub(self, plugin)            self.stubs[id(plugin)] = stub            self.log_debug(f""Overriding _preload() for {plugin_id(plugin)}"")            plugin._preload = stub.my_preload        else:            self.log_warning(                self._(""Already overrided _preload() for {}"").format(plugin_id(plugin))            )",4ef5a47e-2fd9-404b-80df-00ae8277f13e
addons,CloudFlareDdos.py,_override_get_url,289,293,"def _override_get_url(self):        self.log_debug(""Overriding get_url()"")        self.old_get_url = self.pyload.request_factory.get_url        self.pyload.request_factory.get_url = self.my_get_url",,"def _override_get_url(self):        self.log_debug(""Overriding get_url()"")        self.old_get_url = self.pyload.request_factory.get_url        self.pyload.request_factory.get_url = self.my_get_url",fc763092-7bf0-4dec-be7b-c77a9f2bd620
addons,CloudFlareDdos.py,_unoverride_get_url,295,298,"def _unoverride_get_url(self):        self.log_debug(""Unoverriding get_url()"")        self.pyload.request_factory.get_url = self.old_get_url",,"def _unoverride_get_url(self):        self.log_debug(""Unoverriding get_url()"")        self.pyload.request_factory.get_url = self.old_get_url",7c23c203-bd86-4165-abe4-4739f6c0e1d5
addons,CloudFlareDdos.py,_find_owner_plugin,300,318,"def _find_owner_plugin(self):                f = frame = inspect.currentframe()        try:            while True:                if f is None:                    return None                elif ""self"" in f.f_locals and is_simple_plugin(f.f_locals[""self""]):                    return f.f_locals[""self""]                else:                    f = f.f_back        finally:            del frame","Walk the callstack until we find SimpleDownloader or SimpleDecrypter class.
Dirty but works.","def _find_owner_plugin(self):        """"""        Walk the callstack until we find SimpleDownloader or SimpleDecrypter class.        Dirty but works.        """"""        f = frame = inspect.currentframe()        try:            while True:                if f is None:                    return None                elif ""self"" in f.f_locals and is_simple_plugin(f.f_locals[""self""]):                    return f.f_locals[""self""]                else:                    f = f.f_back        finally:            del frame

Walk the callstack until we find SimpleDownloader or SimpleDecrypter class.
Dirty but works.",8358de04-5d3f-4bba-9a36-d51bb8ebbebd
addons,CloudFlareDdos.py,download_preparing,320,335,"def download_preparing(self, pyfile):        #: Only SimpleDownloader and SimpleDecrypter based plugins are supported        if not is_simple_plugin(pyfile.plugin):            self.log_debug(f""Skipping plugin {plugin_id(pyfile.plugin)}"")            return        attr = getattr(pyfile.plugin, ""_preload"", None)        if not attr and not callable(attr):            self.log_error(                self._(""{} is missing _preload() function, cannot override!"").format(                    plugin_id(pyfile.plugin)                )            )            return        self._override_preload(pyfile.plugin)",,"def download_preparing(self, pyfile):        #: Only SimpleDownloader and SimpleDecrypter based plugins are supported        if not is_simple_plugin(pyfile.plugin):            self.log_debug(f""Skipping plugin {plugin_id(pyfile.plugin)}"")            return        attr = getattr(pyfile.plugin, ""_preload"", None)        if not attr and not callable(attr):            self.log_error(                self._(""{} is missing _preload() function, cannot override!"").format(                    plugin_id(pyfile.plugin)                )            )            return        self._override_preload(pyfile.plugin)",9485dea5-ea9a-4076-a162-67fb0792e397
addons,CloudFlareDdos.py,download_processed,337,339,"def download_processed(self, pyfile):        if id(pyfile.plugin) in self.stubs:            self._unoverride_preload(pyfile.plugin)",,"def download_processed(self, pyfile):        if id(pyfile.plugin) in self.stubs:            self._unoverride_preload(pyfile.plugin)",f2821d7c-1b54-491c-9578-ee49953ad3f1
addons,CloudFlareDdos.py,my_get_url,341,359,"def my_get_url(self, *args, **kwargs):        owner_plugin = self._find_owner_plugin()        if owner_plugin is None:            self.log_warning(self._(""Owner plugin not found, cannot process""))            return self.old_get_url(*args, **kwargs)        else:            # NOTE: Better use owner_plugin.load() instead of get_url() so cookies are saved and so captcha credits            # NOTE: Also that way we can use 'owner_plugin.req.header' to get the            # headers, otherwise we cannot get them            res = CloudFlare.handle_function(                self, owner_plugin, ""get_url"", owner_plugin.load, (args, kwargs)            )            if kwargs.get(""just_header"", False):                # NOTE: SimpleDownloader/SimpleDecrypter returns a dict while get_url() returns raw headers string,                # make sure we return a string for get_url('just_header'=True)                res = get_plugin_last_header(owner_plugin)            return res",,"def my_get_url(self, *args, **kwargs):        owner_plugin = self._find_owner_plugin()        if owner_plugin is None:            self.log_warning(self._(""Owner plugin not found, cannot process""))            return self.old_get_url(*args, **kwargs)        else:            # NOTE: Better use owner_plugin.load() instead of get_url() so cookies are saved and so captcha credits            # NOTE: Also that way we can use 'owner_plugin.req.header' to get the            # headers, otherwise we cannot get them            res = CloudFlare.handle_function(                self, owner_plugin, ""get_url"", owner_plugin.load, (args, kwargs)            )            if kwargs.get(""just_header"", False):                # NOTE: SimpleDownloader/SimpleDecrypter returns a dict while get_url() returns raw headers string,                # make sure we return a string for get_url('just_header'=True)                res = get_plugin_last_header(owner_plugin)            return res",7f653b7c-e1c7-407c-b26d-0c613c5d4649
addons,DeathByCaptcha.py,__init__,28,29,"def __init__(self, err):        self.err = err",,"def __init__(self, err):        self.err = err",0129ddb6-0b26-45fd-8bf6-e51b685d7e78
addons,DeathByCaptcha.py,get_code,31,32,def get_code(self):        return self.err,,def get_code(self):        return self.err,72b391b9-d60f-4dd9-9f2e-e0d4837ffa8f
addons,DeathByCaptcha.py,get_desc,34,38,def get_desc(self):        if self.err in self.DBC_ERRORS.keys():            return self.DBC_ERRORS[self.err]        else:            return self.err,,def get_desc(self):        if self.err in self.DBC_ERRORS.keys():            return self.DBC_ERRORS[self.err]        else:            return self.err,5ad101f6-14fc-4e1f-b858-cf0820328014
addons,DeathByCaptcha.py,__str__,40,41,"def __str__(self):        return ""<DeathByCaptchaException {}>"".format(self.err)",,"def __str__(self):        return ""<DeathByCaptchaException {}>"".format(self.err)",217a2c1d-6483-4302-aa8c-5ebfbc59ffd3
addons,DeathByCaptcha.py,__repr__,43,44,"def __repr__(self):        return ""<DeathByCaptchaException {}>"".format(self.err)",,"def __repr__(self):        return ""<DeathByCaptchaException {}>"".format(self.err)",817b12fa-786a-440c-8109-e8e384ff8c38
addons,DeathByCaptcha.py,api_request,66,119,"def api_request(self, api=""captcha"", post=False, multipart=False):        with get_request() as req:            req.c.setopt(                pycurl.HTTPHEADER,                [                    ""Accept: application/json"",                    f""User-Agent: pyLoad {self.pyload.version}"",                ],            )            if post:                if not isinstance(post, dict):                    post = {}                post.update(                    {                        ""username"": self.config.get(""username""),                        ""password"": self.config.get(""password""),                    }                )            res = None            try:                html = self.load(                    ""{}{}"".format(self.API_URL, api),                    post=post,                    multipart=multipart,                    req=req,                )                self.log_debug(html)                res = json.loads(html)                if ""error"" in res:                    raise DeathByCaptchaException(res[""error""])                elif ""status"" not in res:                    raise DeathByCaptchaException(str(res))            except BadHeader as exc:                if exc.code == 403:                    raise DeathByCaptchaException(""not-logged-in"")                elif exc.code == 413:                    raise DeathByCaptchaException(""invalid-captcha"")                elif exc.code == 503:                    raise DeathByCaptchaException(""service-overload"")                elif exc.code in (400, 405):                    raise DeathByCaptchaException(""invalid-request"")                else:                    raise        return res",,"def api_request(self, api=""captcha"", post=False, multipart=False):        with get_request() as req:            req.c.setopt(                pycurl.HTTPHEADER,                [                    ""Accept: application/json"",                    f""User-Agent: pyLoad {self.pyload.version}"",                ],            )            if post:                if not isinstance(post, dict):                    post = {}                post.update(                    {                        ""username"": self.config.get(""username""),                        ""password"": self.config.get(""password""),                    }                )            res = None            try:                html = self.load(                    ""{}{}"".format(self.API_URL, api),                    post=post,                    multipart=multipart,                    req=req,                )                self.log_debug(html)                res = json.loads(html)                if ""error"" in res:                    raise DeathByCaptchaException(res[""error""])                elif ""status"" not in res:                    raise DeathByCaptchaException(str(res))            except BadHeader as exc:                if exc.code == 403:                    raise DeathByCaptchaException(""not-logged-in"")                elif exc.code == 413:                    raise DeathByCaptchaException(""invalid-captcha"")                elif exc.code == 503:                    raise DeathByCaptchaException(""service-overload"")                elif exc.code in (400, 405):                    raise DeathByCaptchaException(""invalid-request"")                else:                    raise        return res",d2b1ee6a-e059-48e5-a20f-89bee172453e
addons,DeathByCaptcha.py,get_credits,121,129,"def get_credits(self):        res = self.api_request(""user"", True)        if ""is_banned"" in res and res[""is_banned""]:            raise DeathByCaptchaException(""banned"")        elif ""balance"" in res and ""rate"" in res:            self.info.update(res)        else:            raise DeathByCaptchaException(res)",,"def get_credits(self):        res = self.api_request(""user"", True)        if ""is_banned"" in res and res[""is_banned""]:            raise DeathByCaptchaException(""banned"")        elif ""balance"" in res and ""rate"" in res:            self.info.update(res)        else:            raise DeathByCaptchaException(res)",1644fa5c-3545-451c-8a94-018c17360fd8
addons,DeathByCaptcha.py,get_status,131,135,"def get_status(self):        res = self.api_request(""status"", False)        if ""is_service_overloaded"" in res and res[""is_service_overloaded""]:            raise DeathByCaptchaException(""service-overload"")",,"def get_status(self):        res = self.api_request(""status"", False)        if ""is_service_overloaded"" in res and res[""is_service_overloaded""]:            raise DeathByCaptchaException(""service-overload"")",5eb7cb30-727e-48a9-a665-f110f12f3cce
addons,DeathByCaptcha.py,submit,137,165,"def submit(self, captcha, captcha_type=""file"", match=None):        # NOTE: Workaround multipart-post bug in HTTPRequest.py        if re.match(r""^\w*$"", self.config.get(""password"")):            multipart = True            data = (pycurl.FORM_FILE, captcha)        else:            multipart = False            with open(captcha, mode=""rb"") as fp:                data = fp.read()            data = ""base64:"" + to_str(base64.b64encode(data))        res = self.api_request(""captcha"", {""captchafile"": data}, multipart)        if ""captcha"" not in res:            raise DeathByCaptchaException(res)        ticket = res[""captcha""]        for _ in range(24):            time.sleep(5)            res = self.api_request(""captcha/{}"".format(ticket), False)            if res[""text""] and res[""is_correct""]:                break        else:            raise DeathByCaptchaException(""timed-out"")        result = res[""text""]        self.log_debug(f""Result {ticket}: {result}"")        return ticket, result",,"def submit(self, captcha, captcha_type=""file"", match=None):        # NOTE: Workaround multipart-post bug in HTTPRequest.py        if re.match(r""^\w*$"", self.config.get(""password"")):            multipart = True            data = (pycurl.FORM_FILE, captcha)        else:            multipart = False            with open(captcha, mode=""rb"") as fp:                data = fp.read()            data = ""base64:"" + to_str(base64.b64encode(data))        res = self.api_request(""captcha"", {""captchafile"": data}, multipart)        if ""captcha"" not in res:            raise DeathByCaptchaException(res)        ticket = res[""captcha""]        for _ in range(24):            time.sleep(5)            res = self.api_request(""captcha/{}"".format(ticket), False)            if res[""text""] and res[""is_correct""]:                break        else:            raise DeathByCaptchaException(""timed-out"")        result = res[""text""]        self.log_debug(f""Result {ticket}: {result}"")        return ticket, result",27b87fcf-6340-495c-af6c-a7ae51196ad4
addons,DeathByCaptcha.py,captcha_task,167,199,"def captcha_task(self, task):        if ""service"" in task.data:            return False        if not task.is_textual():            return False        if not self.config.get(""username"") or not self.config.get(""password""):            return False        if self.pyload.is_client_connected() and self.config.get(""check_client""):            return False        try:            self.get_status()            self.get_credits()        except DeathByCaptchaException as exc:            self.log_error(exc)            return False        balance, rate = self.info[""balance""], self.info[""rate""]        self.log_info(            self._(""Account balance""),            self._(""US${:.3f} ({} captchas left at {:.2f} cents each)"").format(                balance // 100, balance // rate, rate            ),        )        if balance > rate:            task.handler.append(self)            task.data[""service""] = self.classname            task.set_waiting(180)            self._process_captcha(task)",,"def captcha_task(self, task):        if ""service"" in task.data:            return False        if not task.is_textual():            return False        if not self.config.get(""username"") or not self.config.get(""password""):            return False        if self.pyload.is_client_connected() and self.config.get(""check_client""):            return False        try:            self.get_status()            self.get_credits()        except DeathByCaptchaException as exc:            self.log_error(exc)            return False        balance, rate = self.info[""balance""], self.info[""rate""]        self.log_info(            self._(""Account balance""),            self._(""US${:.3f} ({} captchas left at {:.2f} cents each)"").format(                balance // 100, balance // rate, rate            ),        )        if balance > rate:            task.handler.append(self)            task.data[""service""] = self.classname            task.set_waiting(180)            self._process_captcha(task)",02e92007-4aab-4cbf-8cf5-91ec5229bdbe
addons,DeathByCaptcha.py,captcha_invalid,201,216,"def captcha_invalid(self, task):        if task.data[""service""] == self.classname and ""ticket"" in task.data:            try:                res = self.api_request(                    ""captcha/{}/report"".format(task.data[""ticket""]), True                )            except DeathByCaptchaException as exc:                self.log_error(exc)            except Exception as exc:                self.log_error(                    exc,                    exc_info=self.pyload.debug > 1,                    stack_info=self.pyload.debug > 2,                )",,"def captcha_invalid(self, task):        if task.data[""service""] == self.classname and ""ticket"" in task.data:            try:                res = self.api_request(                    ""captcha/{}/report"".format(task.data[""ticket""]), True                )            except DeathByCaptchaException as exc:                self.log_error(exc)            except Exception as exc:                self.log_error(                    exc,                    exc_info=self.pyload.debug > 1,                    stack_info=self.pyload.debug > 2,                )",72922e37-90fa-4e6f-afd2-72f14d853071
addons,DeathByCaptcha.py,_process_captcha,219,229,"def _process_captcha(self, task):        c = task.captcha_params[""file""]        try:            ticket, result = self.submit(c)        except DeathByCaptchaException as exc:            task.error = exc.get_code()            self.log_error(exc)            return        task.data[""ticket""] = ticket        task.set_result(result)",,"def _process_captcha(self, task):        c = task.captcha_params[""file""]        try:            ticket, result = self.submit(c)        except DeathByCaptchaException as exc:            task.error = exc.get_code()            self.log_error(exc)            return        task.data[""ticket""] = ticket        task.set_result(result)",8209c8af-ba09-49ed-8758-a90686589166
addons,DeleteFinished.py,periodical_task,29,41,"def periodical_task(self):        if not self.info[""sleep""]:            self.info[""sleep""] = True            delete_offline = self.config.get(""deloffline"")            mode = (0, 1, 4) if delete_offline else (0, 4)            mode_desc = self._(""including"") if delete_offline else self._(""excluding"")            self.log_info(                self._(                    ""delete all finished packages in queue list ({} packages with offline links)""                ).format(mode_desc)            )            self.delete_finished(mode)            self.m.add_event(""package_finished"", self.wakeup)",,"def periodical_task(self):        if not self.info[""sleep""]:            self.info[""sleep""] = True            delete_offline = self.config.get(""deloffline"")            mode = (0, 1, 4) if delete_offline else (0, 4)            mode_desc = self._(""including"") if delete_offline else self._(""excluding"")            self.log_info(                self._(                    ""delete all finished packages in queue list ({} packages with offline links)""                ).format(mode_desc)            )            self.delete_finished(mode)            self.m.add_event(""package_finished"", self.wakeup)",91763006-b91c-4d8d-af0e-a985d8f1e7da
addons,DeleteFinished.py,deactivate,43,44,"def deactivate(self):        self.m.remove_event(""package_finished"", self.wakeup)",,"def deactivate(self):        self.m.remove_event(""package_finished"", self.wakeup)",6fab7e96-bc06-483b-a9a8-278d9376cca3
addons,DeleteFinished.py,activate,46,49,"def activate(self):        self.info[""sleep""] = True        self.m.add_event(""package_finished"", self.wakeup)        self.periodical.start(timedelta(hours=self.config.get(""interval"")).total_seconds())",,"def activate(self):        self.info[""sleep""] = True        self.m.add_event(""package_finished"", self.wakeup)        self.periodical.start(timedelta(hours=self.config.get(""interval"")).total_seconds())",6de12488-03a5-46e3-b340-5edbe4fa6015
addons,DeleteFinished.py,delete_finished,52,59,"def delete_finished(self, mode):        self.c.execute(            f""DELETE FROM packages WHERE NOT EXISTS(SELECT 1 FROM links WHERE package=packages.id AND status NOT IN ({','.join('?' * len(mode))}))"",            mode,        )        self.c.execute(            ""DELETE FROM links WHERE NOT EXISTS(SELECT 1 FROM packages WHERE id=links.package)""        )",,"def delete_finished(self, mode):        self.c.execute(            f""DELETE FROM packages WHERE NOT EXISTS(SELECT 1 FROM links WHERE package=packages.id AND status NOT IN ({','.join('?' * len(mode))}))"",            mode,        )        self.c.execute(            ""DELETE FROM links WHERE NOT EXISTS(SELECT 1 FROM packages WHERE id=links.package)""        )",99cf8b21-903c-4d4a-b241-cbcae6845c6a
addons,DeleteFinished.py,wakeup,61,63,"def wakeup(self, pypack):        self.m.remove_event(""package_finished"", self.wakeup)        self.info[""sleep""] = False",,"def wakeup(self, pypack):        self.m.remove_event(""package_finished"", self.wakeup)        self.info[""sleep""] = False",66bd0cbc-16b4-4f50-9189-711a62aa613c
addons,DiscordNotifier.py,get_key,36,37,"def get_key(self):        return self.config.get(""webhookurl"")",,"def get_key(self):        return self.config.get(""webhookurl"")",f062be45-9ce5-4f1f-83ec-8734d8aa4040
addons,DiscordNotifier.py,send,39,42,"def send(self, event, msg, key):        req = get_request()        self.log_info(""Sending message to discord"")        self.load(self.get_key(), post={""content"": event + ""\n"" + msg}, req=req)",,"def send(self, event, msg, key):        req = get_request()        self.log_info(""Sending message to discord"")        self.load(self.get_key(), post={""content"": event + ""\n"" + msg}, req=req)",ef746f36-5f4e-4cf7-8a29-9261cfc59461
addons,DownloadScheduler.py,activate,38,40,def activate(self):        self.last_timetable = None        self.update_schedule(),,def activate(self):        self.last_timetable = None        self.update_schedule(),2c4ef0b9-8fe7-475a-99dd-8573a9c03105
addons,DownloadScheduler.py,config_changed,42,51,"def config_changed(self, category, option, value, section):                if (            category == self.__name__            and option == ""timetable""            and value != self.last_timetable        ):            self.update_schedule(schedule=value)","Listen for config changes, to trigger a schedule update.","def config_changed(self, category, option, value, section):        """"""        Listen for config changes, to trigger a schedule update.        """"""        if (            category == self.__name__            and option == ""timetable""            and value != self.last_timetable        ):            self.update_schedule(schedule=value)

Listen for config changes, to trigger a schedule update.",518c4eb8-e0e1-483b-a244-0ea57fd6efd9
addons,DownloadScheduler.py,update_schedule,53,92,"def update_schedule(self, schedule=None):        if schedule is None:            schedule = self.config.get(""timetable"")        self.last_timetable = schedule        schedule = re.findall(            r""(\d{1,2}):(\d{2})[\s]*(-?\d+)"",            schedule.lower().replace(""full"", ""-1"").replace(""none"", ""0""),        )        if not schedule:            self.log_error(self._(""Invalid schedule""))            return        t0 = time.localtime()        now = (t0.tm_hour, t0.tm_min, t0.tm_sec, ""X"")        schedule = sorted(            [(int(x[0]), int(x[1]), 0, int(x[2])) for x in schedule] + [now],            key=lambda a: (a[0], a[1], a[2], a[3] == ""X"")        )        self.log_debug(""Schedule"", schedule)        for i, v in enumerate(schedule):            if v[3] == ""X"":                last, next = schedule[i - 1], schedule[(i + 1) % len(schedule)]                self.log_debug(""Now/Last/Next"", now, last, next)                self.set_download_speed(last[3])                next_time = (                    ((24 + next[0] - now[0]) * 60 + next[1] - now[1]) * 60                    + next[2]                    - now[2]                ) % 86400                self.pyload.scheduler.remove_job(self.cb)                self.cb = self.pyload.scheduler.add_job(                    next_time, self.update_schedule, threaded=False                )                break",,"def update_schedule(self, schedule=None):        if schedule is None:            schedule = self.config.get(""timetable"")        self.last_timetable = schedule        schedule = re.findall(            r""(\d{1,2}):(\d{2})[\s]*(-?\d+)"",            schedule.lower().replace(""full"", ""-1"").replace(""none"", ""0""),        )        if not schedule:            self.log_error(self._(""Invalid schedule""))            return        t0 = time.localtime()        now = (t0.tm_hour, t0.tm_min, t0.tm_sec, ""X"")        schedule = sorted(            [(int(x[0]), int(x[1]), 0, int(x[2])) for x in schedule] + [now],            key=lambda a: (a[0], a[1], a[2], a[3] == ""X"")        )        self.log_debug(""Schedule"", schedule)        for i, v in enumerate(schedule):            if v[3] == ""X"":                last, next = schedule[i - 1], schedule[(i + 1) % len(schedule)]                self.log_debug(""Now/Last/Next"", now, last, next)                self.set_download_speed(last[3])                next_time = (                    ((24 + next[0] - now[0]) * 60 + next[1] - now[1]) * 60                    + next[2]                    - now[2]                ) % 86400                self.pyload.scheduler.remove_job(self.cb)                self.cb = self.pyload.scheduler.add_job(                    next_time, self.update_schedule, threaded=False                )                break",6229d578-cac1-4d13-a872-71b615dfc923
addons,DownloadScheduler.py,set_download_speed,94,123,"def set_download_speed(self, speed):        if speed == 0:            abort = self.config.get(""abort"")            self.log_info(                self._(""Stopping download server. (Running downloads will be aborted.)"")                if abort                else self._(                    ""Stopping download server. (Running downloads will not be aborted.)""                )            )            self.pyload.api.pause_server()            if abort:                self.pyload.api.stop_all_downloads()        else:            self.pyload.api.unpause_server()            if speed > 0:                self.log_info(self._(""Setting download speed to {} kB/s"").format(speed))                self.pyload.config.set(""download"", ""limit_speed"", True)                self.pyload.config.set(""download"", ""max_speed"", speed)            else:                self.log_info(self._(""Setting download speed to FULL""))                self.pyload.config.set(""download"", ""limit_speed"", False)                self.pyload.config.set(""download"", ""max_speed"", -1)            # Make new speed values take effect            self.pyload.request_factory.update_bucket()",,"def set_download_speed(self, speed):        if speed == 0:            abort = self.config.get(""abort"")            self.log_info(                self._(""Stopping download server. (Running downloads will be aborted.)"")                if abort                else self._(                    ""Stopping download server. (Running downloads will not be aborted.)""                )            )            self.pyload.api.pause_server()            if abort:                self.pyload.api.stop_all_downloads()        else:            self.pyload.api.unpause_server()            if speed > 0:                self.log_info(self._(""Setting download speed to {} kB/s"").format(speed))                self.pyload.config.set(""download"", ""limit_speed"", True)                self.pyload.config.set(""download"", ""max_speed"", speed)            else:                self.log_info(self._(""Setting download speed to FULL""))                self.pyload.config.set(""download"", ""limit_speed"", False)                self.pyload.config.set(""download"", ""max_speed"", -1)            # Make new speed values take effect            self.pyload.request_factory.update_bucket()",ecab945d-b9d5-43ef-a357-7d641514dd24
addons,ExpertDecoders.py,get_credits,30,41,"def get_credits(self):        res = self.load(            self.API_URL, post={""key"": self.config.get(""passkey""), ""action"": ""balance""}        )        if res.isdigit():            self.log_info(self._(""{} credits left"").format(res))            self.info[""credits""] = credits = int(res)            return credits        else:            self.log_error(res)            return 0",,"def get_credits(self):        res = self.load(            self.API_URL, post={""key"": self.config.get(""passkey""), ""action"": ""balance""}        )        if res.isdigit():            self.log_info(self._(""{} credits left"").format(res))            self.info[""credits""] = credits = int(res)            return credits        else:            self.log_error(res)            return 0",ddd0b5b6-cbb9-4d2b-9752-79cc71ac4a6b
addons,ExpertDecoders.py,_process_captcha,44,67,"def _process_captcha(self, task):        task.data[""ticket""] = ticket = uuid.uuid4()        result = None        with open(task.captcha_params[""file""], mode=""rb"") as fp:            data = fp.read()        with get_request() as req:            #: Raise timeout threshold            req.c.setopt(pycurl.LOW_SPEED_TIME, 80)            result = self.load(                self.API_URL,                post={                    ""action"": ""upload"",                    ""key"": self.config.get(""passkey""),                    ""file"": base64.b64encode(data),                    ""gen_task_id"": ticket,                },                req=req,            )        self.log_debug(f""Result {ticket}: {result}"")        task.set_result(result)",,"def _process_captcha(self, task):        task.data[""ticket""] = ticket = uuid.uuid4()        result = None        with open(task.captcha_params[""file""], mode=""rb"") as fp:            data = fp.read()        with get_request() as req:            #: Raise timeout threshold            req.c.setopt(pycurl.LOW_SPEED_TIME, 80)            result = self.load(                self.API_URL,                post={                    ""action"": ""upload"",                    ""key"": self.config.get(""passkey""),                    ""file"": base64.b64encode(data),                    ""gen_task_id"": ticket,                },                req=req,            )        self.log_debug(f""Result {ticket}: {result}"")        task.set_result(result)",292ec8d7-1248-4f05-aa59-181d86cd27ac
addons,ExpertDecoders.py,captcha_task,69,85,"def captcha_task(self, task):        if not task.is_textual():            return False        if not self.config.get(""passkey""):            return False        if self.pyload.is_client_connected() and self.config.get(""check_client""):            return False        if self.get_credits() > 0:            task.handler.append(self)            task.set_waiting(100)            self._process_captcha(task)        else:            self.log_info(self._(""Your ExpertDecoders Account has not enough credits""))",,"def captcha_task(self, task):        if not task.is_textual():            return False        if not self.config.get(""passkey""):            return False        if self.pyload.is_client_connected() and self.config.get(""check_client""):            return False        if self.get_credits() > 0:            task.handler.append(self)            task.set_waiting(100)            self._process_captcha(task)        else:            self.log_info(self._(""Your ExpertDecoders Account has not enough credits""))",4026bd0c-dee8-4afa-b432-2b19d2d0d084
addons,ExpertDecoders.py,captcha_invalid,87,102,"def captcha_invalid(self, task):        if ""ticket"" in task.data:            try:                res = self.load(                    self.API_URL,                    post={                        ""action"": ""refund"",                        ""key"": self.config.get(""passkey""),                        ""gen_task_id"": task.data[""ticket""],                    },                )                self.log_info(self._(""Request refund""), res)            except BadHeader as exc:                self.log_error(self._(""Could not send refund request""), exc)",,"def captcha_invalid(self, task):        if ""ticket"" in task.data:            try:                res = self.load(                    self.API_URL,                    post={                        ""action"": ""refund"",                        ""key"": self.config.get(""passkey""),                        ""gen_task_id"": task.data[""ticket""],                    },                )                self.log_info(self._(""Request refund""), res)            except BadHeader as exc:                self.log_error(self._(""Could not send refund request""), exc)",8920bd5a-b781-4ed4-957d-21c2b4adb723
addons,ExternalScripts.py,init,27,71,"def init(self):        self.scripts = {}        self.folders = [            ""pyload_start"",            ""pyload_restart"",            ""pyload_stop"",            ""before_reconnect"",            ""after_reconnect"",            ""download_preparing"",            ""download_failed"",            # TODO: Invert 'download_processed', 'download_finished' order            # in 0.6.x            ""download_finished"",            ""download_processed"",            ""archive_extract_failed"",            ""archive_extracted"",            ""archive_processed"",            # TODO: Invert 'package_finished', 'package_processed' order in            # 0.6.x            ""package_finished"",            ""package_processed"",            ""package_deleted"",            ""package_failed"",            ""package_extract_failed"",            ""package_extracted"",            ""all_downloads_processed"",            ""all_downloads_finished"",            ""all_archives_extracted"",            ""all_archives_processed"",        ]        self.event_map = {            ""archive_extract_failed"": ""archive_extract_failed"",            ""archive_extracted"": ""archive_extracted"",            ""archive_processed"": ""archive_processed"",            ""package_extract_failed"": ""package_extract_failed"",            ""package_extracted"": ""package_extracted"",            ""all_archives_extracted"": ""all_archives_extracted"",            ""all_archives_processed"": ""all_archives_processed"",            ""pyload_updated"": ""pyload_updated"",        }        self.periodical.start(60)        self.periodical_task()",,"def init(self):        self.scripts = {}        self.folders = [            ""pyload_start"",            ""pyload_restart"",            ""pyload_stop"",            ""before_reconnect"",            ""after_reconnect"",            ""download_preparing"",            ""download_failed"",            # TODO: Invert 'download_processed', 'download_finished' order            # in 0.6.x            ""download_finished"",            ""download_processed"",            ""archive_extract_failed"",            ""archive_extracted"",            ""archive_processed"",            # TODO: Invert 'package_finished', 'package_processed' order in            # 0.6.x            ""package_finished"",            ""package_processed"",            ""package_deleted"",            ""package_failed"",            ""package_extract_failed"",            ""package_extracted"",            ""all_downloads_processed"",            ""all_downloads_finished"",            ""all_archives_extracted"",            ""all_archives_processed"",        ]        self.event_map = {            ""archive_extract_failed"": ""archive_extract_failed"",            ""archive_extracted"": ""archive_extracted"",            ""archive_processed"": ""archive_processed"",            ""package_extract_failed"": ""package_extract_failed"",            ""package_extracted"": ""package_extracted"",            ""all_archives_extracted"": ""all_archives_extracted"",            ""all_archives_processed"": ""all_archives_processed"",            ""pyload_updated"": ""pyload_updated"",        }        self.periodical.start(60)        self.periodical_task()",5a9c00d4-4571-4b97-abea-8783cad0ced3
addons,ExternalScripts.py,activate,73,74,def activate(self):        self.pyload_start(),,def activate(self):        self.pyload_start(),ce137a3d-2818-4929-9315-f8873d65f2c3
addons,ExternalScripts.py,make_folders,76,83,"def make_folders(self):        for folder in self.folders:            dir = os.path.join(self.pyload.userdir, ""scripts"", folder)            if os.path.isdir(dir):                continue            os.makedirs(dir, exist_ok=True)",,"def make_folders(self):        for folder in self.folders:            dir = os.path.join(self.pyload.userdir, ""scripts"", folder)            if os.path.isdir(dir):                continue            os.makedirs(dir, exist_ok=True)",1b056d8f-3cbb-490e-b14a-297f99163572
addons,ExternalScripts.py,periodical_task,85,134,"def periodical_task(self):        self.make_folders()        for folder in self.folders:            scripts = []            dirname = os.path.join(self.pyload.userdir, ""scripts"", folder)            if folder not in self.scripts:                self.scripts[folder] = []            if os.path.isdir(dirname):                for entry in os.listdir(dirname):                    file = os.path.join(dirname, entry)                    if not os.path.isfile(file):                        continue                    if (                        file[0] in (""#"", ""_"")                        or file.endswith(""~"")                        or file.endswith("".swp"")                    ):                        continue                    if not os.access(file, os.X_OK):                        self.log_warning(                            self._(""Script `{}` is not executable"").format(entry)                        )                    scripts.append(file)            new_scripts = [s for s in scripts if s not in self.scripts[folder]]            if new_scripts:                self.log_info(                    self._(""Activated scripts in folder `{}`: {}"").format(                        folder, "", "".join(os.path.basename(x) for x in new_scripts)                    )                )            removed_scripts = [s for s in self.scripts[folder] if s not in scripts]            if removed_scripts:                self.log_info(                    self._(""Deactivated scripts in folder `{}`: {}"").format(                        folder, "", "".join(os.path.basename(x) for x in removed_scripts)                    )                )            self.scripts[folder] = scripts",,"def periodical_task(self):        self.make_folders()        for folder in self.folders:            scripts = []            dirname = os.path.join(self.pyload.userdir, ""scripts"", folder)            if folder not in self.scripts:                self.scripts[folder] = []            if os.path.isdir(dirname):                for entry in os.listdir(dirname):                    file = os.path.join(dirname, entry)                    if not os.path.isfile(file):                        continue                    if (                        file[0] in (""#"", ""_"")                        or file.endswith(""~"")                        or file.endswith("".swp"")                    ):                        continue                    if not os.access(file, os.X_OK):                        self.log_warning(                            self._(""Script `{}` is not executable"").format(entry)                        )                    scripts.append(file)            new_scripts = [s for s in scripts if s not in self.scripts[folder]]            if new_scripts:                self.log_info(                    self._(""Activated scripts in folder `{}`: {}"").format(                        folder, "", "".join(os.path.basename(x) for x in new_scripts)                    )                )            removed_scripts = [s for s in self.scripts[folder] if s not in scripts]            if removed_scripts:                self.log_info(                    self._(""Deactivated scripts in folder `{}`: {}"").format(                        folder, "", "".join(os.path.basename(x) for x in removed_scripts)                    )                )            self.scripts[folder] = scripts",16e7d45a-58aa-4a97-9cc9-1b17e8025452
addons,ExternalScripts.py,call_cmd,136,146,"def call_cmd(self, command, *args, **kwargs):        call = list(str(cmd) for cmd in [command] + list(args))        self.log_debug(            ""EXECUTE ""            + "" "".join('""' + arg + '""' if "" "" in arg else arg for arg in call)        )        p = subprocess.Popen(call)  # NOTE: output goes to pyload        return p",,"def call_cmd(self, command, *args, **kwargs):        call = list(str(cmd) for cmd in [command] + list(args))        self.log_debug(            ""EXECUTE ""            + "" "".join('""' + arg + '""' if "" "" in arg else arg for arg in call)        )        p = subprocess.Popen(call)  # NOTE: output goes to pyload        return p",370e43b8-c8f0-44c8-9f83-1e817a107ba7
addons,ExternalScripts.py,call_script,149,175,"def call_script(self, folder, *args, **kwargs):        scripts = self.scripts.get(folder)        if folder not in self.scripts:            self.log_debug(f""Folder `{folder}` not found"")            return        if not scripts:            self.log_debug(f""No script found under folder `{folder}`"")            return        self.log_info(self._(""Executing scripts in folder `{}`..."").format(folder))        for file in scripts:            try:                p = self.call_cmd(file, *args)            except Exception as exc:                self.log_error(                    self._(""Runtime error: {}"").format(file),                    exc or self._(""Unknown error""),                )            else:                lock = kwargs.get(""lock"", None)                if lock is not False and not self.config.get(""unlock""):                    p.communicate()",,"def call_script(self, folder, *args, **kwargs):        scripts = self.scripts.get(folder)        if folder not in self.scripts:            self.log_debug(f""Folder `{folder}` not found"")            return        if not scripts:            self.log_debug(f""No script found under folder `{folder}`"")            return        self.log_info(self._(""Executing scripts in folder `{}`..."").format(folder))        for file in scripts:            try:                p = self.call_cmd(file, *args)            except Exception as exc:                self.log_error(                    self._(""Runtime error: {}"").format(file),                    exc or self._(""Unknown error""),                )            else:                lock = kwargs.get(""lock"", None)                if lock is not False and not self.config.get(""unlock""):                    p.communicate()",125e4bcb-e7ff-432f-a302-bb0f7022b417
addons,ExternalScripts.py,pyload_updated,177,179,"def pyload_updated(self, etag):                self.call_script(""pyload_updated"", etag)",plugins were updated by UpdateManager,"def pyload_updated(self, etag):        """"""plugins were updated by UpdateManager""""""        self.call_script(""pyload_updated"", etag)

plugins were updated by UpdateManager",ffc1557d-b5fd-4fc5-b45d-ce0da8fc4440
addons,ExternalScripts.py,pyload_start,181,183,"def pyload_start(self):                self.call_script(""pyload_start"")",pyload was just started,"def pyload_start(self):        """"""pyload was just started""""""        self.call_script(""pyload_start"")

pyload was just started",8735574a-92c3-46cf-bfaa-43416cc6a5cc
addons,ExternalScripts.py,exit,185,188,"def exit(self):                event = ""restart"" if self.pyload._do_restart else ""stop""        self.call_script(""pyload_"" + event, lock=True)","deprecated method, use pyload_stop or pyload_restart instead","def exit(self):        """"""deprecated method, use pyload_stop or pyload_restart instead""""""        event = ""restart"" if self.pyload._do_restart else ""stop""        self.call_script(""pyload_"" + event, lock=True)

deprecated method, use pyload_stop or pyload_restart instead",88b969eb-6cc3-4cf2-9c5e-c875ce2b8f29
addons,ExternalScripts.py,before_reconnect,190,192,"def before_reconnect(self, ip):                self.call_script(""before_reconnect"", ip)",called before reconnecting,"def before_reconnect(self, ip):        """"""called before reconnecting""""""        self.call_script(""before_reconnect"", ip)

called before reconnecting",10604830-881c-4569-a158-c0c1f79435f5
addons,ExternalScripts.py,after_reconnect,194,196,"def after_reconnect(self, ip, oldip):                self.call_script(""after_reconnect"", ip, oldip)",called after reconnecting,"def after_reconnect(self, ip, oldip):        """"""called after reconnecting""""""        self.call_script(""after_reconnect"", ip, oldip)

called after reconnecting",f54a1c2a-4c1d-45fb-8496-231d72971a8d
addons,ExternalScripts.py,download_preparing,198,201,"def download_preparing(self, pyfile):                args = [pyfile.id, pyfile.name, None, pyfile.pluginname, pyfile.url]        self.call_script(""download_preparing"", *args)",a download was just queued and will be prepared now,"def download_preparing(self, pyfile):        """"""a download was just queued and will be prepared now""""""        args = [pyfile.id, pyfile.name, None, pyfile.pluginname, pyfile.url]        self.call_script(""download_preparing"", *args)

a download was just queued and will be prepared now",58d475b5-1cac-45cd-88e8-4dc999731f9e
addons,ExternalScripts.py,download_failed,203,207,"def download_failed(self, pyfile):                file = pyfile.plugin.last_download        args = [pyfile.id, pyfile.name, file, pyfile.pluginname, pyfile.url]        self.call_script(""download_failed"", *args)",download has failed,"def download_failed(self, pyfile):        """"""download has failed""""""        file = pyfile.plugin.last_download        args = [pyfile.id, pyfile.name, file, pyfile.pluginname, pyfile.url]        self.call_script(""download_failed"", *args)

download has failed",cee40dd7-7339-4c22-ae9a-b1256ffecfcb
addons,ExternalScripts.py,download_finished,209,213,"def download_finished(self, pyfile):                file = pyfile.plugin.last_download        args = [pyfile.id, pyfile.name, file, pyfile.pluginname, pyfile.url, pyfile.package().name]        self.call_script(""download_finished"", *args)",download successfully finished,"def download_finished(self, pyfile):        """"""download successfully finished""""""        file = pyfile.plugin.last_download        args = [pyfile.id, pyfile.name, file, pyfile.pluginname, pyfile.url, pyfile.package().name]        self.call_script(""download_finished"", *args)

download successfully finished",f122cad4-9a91-41aa-9057-a8380c4c7a30
addons,ExternalScripts.py,download_processed,215,219,"def download_processed(self, pyfile):                file = pyfile.plugin.last_download        args = [pyfile.id, pyfile.name, file, pyfile.pluginname, pyfile.url]        self.call_script(""download_processed"", *args)",download was precessed,"def download_processed(self, pyfile):        """"""download was precessed""""""        file = pyfile.plugin.last_download        args = [pyfile.id, pyfile.name, file, pyfile.pluginname, pyfile.url]        self.call_script(""download_processed"", *args)

download was precessed",82a69492-3739-456a-80ab-8d965620f268
addons,ExternalScripts.py,archive_extract_failed,221,224,"def archive_extract_failed(self, pyfile, archive):                args = [pyfile.id, pyfile.name, archive.filename, archive.out, archive.files]        self.call_script(""archive_extract_failed"", *args)",archive extraction failed,"def archive_extract_failed(self, pyfile, archive):        """"""archive extraction failed""""""        args = [pyfile.id, pyfile.name, archive.filename, archive.out, archive.files]        self.call_script(""archive_extract_failed"", *args)

archive extraction failed",cc85891b-5cd4-4a38-b2e5-98c257dbbf18
addons,ExternalScripts.py,archive_extracted,226,229,"def archive_extracted(self, pyfile, archive):                args = [pyfile.id, pyfile.name, archive.filename, archive.out, archive.files]        self.call_script(""archive_extracted"", *args)",archive was successfully extracted,"def archive_extracted(self, pyfile, archive):        """"""archive was successfully extracted""""""        args = [pyfile.id, pyfile.name, archive.filename, archive.out, archive.files]        self.call_script(""archive_extracted"", *args)

archive was successfully extracted",7517c2c6-bec7-4283-923c-554621d6bb6f
addons,ExternalScripts.py,archive_processed,231,239,"def archive_processed(self, pypack):                dl_folder = self.pyload.config.get(""general"", ""storage_folder"")        if self.pyload.config.get(""general"", ""folder_per_package""):            dl_folder = os.path.join(dl_folder, pypack.folder)        args = [pypack.id, pypack.name, dl_folder, pypack.password]        self.call_script(""archive_processed"", *args)",package was either extracted (successfully or not) or ignored because not an archive,"def archive_processed(self, pypack):        """"""package was either extracted (successfully or not) or ignored because not an archive""""""        dl_folder = self.pyload.config.get(""general"", ""storage_folder"")        if self.pyload.config.get(""general"", ""folder_per_package""):            dl_folder = os.path.join(dl_folder, pypack.folder)        args = [pypack.id, pypack.name, dl_folder, pypack.password]        self.call_script(""archive_processed"", *args)

package was either extracted (successfully or not) or ignored because not an archive",34fd6b67-1ccc-4537-94f1-a39c1317d9bc
addons,ExternalScripts.py,package_finished,241,249,"def package_finished(self, pypack):                dl_folder = self.pyload.config.get(""general"", ""storage_folder"")        if self.pyload.config.get(""general"", ""folder_per_package""):            dl_folder = os.path.join(dl_folder, pypack.folder)        args = [pypack.id, pypack.name, dl_folder, pypack.password]        self.call_script(""package_finished"", *args)",package finished successfully,"def package_finished(self, pypack):        """"""package finished successfully""""""        dl_folder = self.pyload.config.get(""general"", ""storage_folder"")        if self.pyload.config.get(""general"", ""folder_per_package""):            dl_folder = os.path.join(dl_folder, pypack.folder)        args = [pypack.id, pypack.name, dl_folder, pypack.password]        self.call_script(""package_finished"", *args)

package finished successfully",767d3c96-97c1-47f8-873e-0a0d83e34849
addons,ExternalScripts.py,package_processed,251,259,"def package_processed(self, pypack):                dl_folder = self.pyload.config.get(""general"", ""storage_folder"")        if self.pyload.config.get(""general"", ""folder_per_package""):            dl_folder = os.path.join(dl_folder, pypack.folder)        args = [pypack.id, pypack.name, dl_folder, pypack.password]        self.call_script(""package_processed"", *args)",package was processed,"def package_processed(self, pypack):        """"""package was processed""""""        dl_folder = self.pyload.config.get(""general"", ""storage_folder"")        if self.pyload.config.get(""general"", ""folder_per_package""):            dl_folder = os.path.join(dl_folder, pypack.folder)        args = [pypack.id, pypack.name, dl_folder, pypack.password]        self.call_script(""package_processed"", *args)

package was processed",f5f93a1b-0d86-4464-8da9-4e6cde4904f5
addons,ExternalScripts.py,package_deleted,261,270,"def package_deleted(self, pid):                dl_folder = self.pyload.config.get(""general"", ""storage_folder"")        pdata = self.pyload.api.get_package_info(pid)        if self.pyload.config.get(""general"", ""folder_per_package""):            dl_folder = os.path.join(dl_folder, pdata.folder)        args = [pdata.pid, pdata.name, dl_folder, pdata.password]        self.call_script(""package_deleted"", *args)",package wad deleted from the queue,"def package_deleted(self, pid):        """"""package wad deleted from the queue""""""        dl_folder = self.pyload.config.get(""general"", ""storage_folder"")        pdata = self.pyload.api.get_package_info(pid)        if self.pyload.config.get(""general"", ""folder_per_package""):            dl_folder = os.path.join(dl_folder, pdata.folder)        args = [pdata.pid, pdata.name, dl_folder, pdata.password]        self.call_script(""package_deleted"", *args)

package wad deleted from the queue",f8343a6d-cdf7-4e5d-b916-5b0bab234931
addons,ExternalScripts.py,package_failed,272,280,"def package_failed(self, pypack):                dl_folder = self.pyload.config.get(""general"", ""storage_folder"")        if self.pyload.config.get(""general"", ""folder_per_package""):            dl_folder = os.path.join(dl_folder, pypack.folder)        args = [pypack.id, pypack.name, dl_folder, pypack.password]        self.call_script(""package_failed"", *args)",package failed somehow,"def package_failed(self, pypack):        """"""package failed somehow""""""        dl_folder = self.pyload.config.get(""general"", ""storage_folder"")        if self.pyload.config.get(""general"", ""folder_per_package""):            dl_folder = os.path.join(dl_folder, pypack.folder)        args = [pypack.id, pypack.name, dl_folder, pypack.password]        self.call_script(""package_failed"", *args)

package failed somehow",ca375c1f-02ff-420b-8348-d04938900e83
addons,ExternalScripts.py,package_extract_failed,282,290,"def package_extract_failed(self, pypack):                dl_folder = self.pyload.config.get(""general"", ""storage_folder"")        if self.pyload.config.get(""general"", ""folder_per_package""):            dl_folder = os.path.join(dl_folder, pypack.folder)        args = [pypack.id, pypack.name, dl_folder, pypack.password]        self.call_script(""package_extract_failed"", *args)",package extraction failed,"def package_extract_failed(self, pypack):        """"""package extraction failed""""""        dl_folder = self.pyload.config.get(""general"", ""storage_folder"")        if self.pyload.config.get(""general"", ""folder_per_package""):            dl_folder = os.path.join(dl_folder, pypack.folder)        args = [pypack.id, pypack.name, dl_folder, pypack.password]        self.call_script(""package_extract_failed"", *args)

package extraction failed",53973c91-6702-44ad-83ab-5374bd973cc7
addons,ExternalScripts.py,package_extracted,292,300,"def package_extracted(self, pypack):                dl_folder = self.pyload.config.get(""general"", ""storage_folder"")        if self.pyload.config.get(""general"", ""folder_per_package""):            dl_folder = os.path.join(dl_folder, pypack.folder)        args = [pypack.id, pypack.name, dl_folder]        self.call_script(""package_extracted"", *args)",package was successfully extracted,"def package_extracted(self, pypack):        """"""package was successfully extracted""""""        dl_folder = self.pyload.config.get(""general"", ""storage_folder"")        if self.pyload.config.get(""general"", ""folder_per_package""):            dl_folder = os.path.join(dl_folder, pypack.folder)        args = [pypack.id, pypack.name, dl_folder]        self.call_script(""package_extracted"", *args)

package was successfully extracted",3035b1f4-f4db-4c05-ab3f-9a820520f50c
addons,ExternalScripts.py,all_downloads_finished,302,304,"def all_downloads_finished(self):                self.call_script(""all_downloads_finished"")",every download in queue is finished successfully,"def all_downloads_finished(self):        """"""every download in queue is finished successfully""""""        self.call_script(""all_downloads_finished"")

every download in queue is finished successfully",b166e267-6fe5-4ce5-bc2f-dfca43c33e36
addons,ExternalScripts.py,all_downloads_processed,306,308,"def all_downloads_processed(self):                self.call_script(""all_downloads_processed"")","every download was handled (successfully or not), pyload would idle afterwards","def all_downloads_processed(self):        """"""every download was handled (successfully or not), pyload would idle afterwards""""""        self.call_script(""all_downloads_processed"")

every download was handled (successfully or not), pyload would idle afterwards",804b20c6-2796-454e-bc80-b2c928da39ca
addons,ExternalScripts.py,all_archives_extracted,310,312,"def all_archives_extracted(self):                self.call_script(""all_archives_extracted"")",all archives were extracted,"def all_archives_extracted(self):        """"""all archives were extracted""""""        self.call_script(""all_archives_extracted"")

all archives were extracted",83865135-d0c7-4c18-a3bc-e7ec2e9c914a
addons,ExternalScripts.py,all_archives_processed,314,316,"def all_archives_processed(self):                self.call_script(""all_archives_processed"")",every archive was handled (successfully or not),"def all_archives_processed(self):        """"""every archive was handled (successfully or not)""""""        self.call_script(""all_archives_processed"")

every archive was handled (successfully or not)",29252afb-48b5-42d4-a2f4-cf243caacf06
addons,ExtractArchive.py,__init__,20,23,"def __init__(self, plugin, storage):        self.plugin = plugin        self.storage = storage        self.length = 0",,"def __init__(self, plugin, storage):        self.plugin = plugin        self.storage = storage        self.length = 0",e28a228b-eb95-4a7d-a66b-2095f0a66707
addons,ExtractArchive.py,__len__,25,26,def __len__(self):        return self.length,,def __len__(self):        return self.length,f12aae59-8efd-4038-977d-53e2f8695521
addons,ExtractArchive.py,get,28,29,"def get(self):        return self.plugin.db.retrieve(self.storage, default=[])",,"def get(self):        return self.plugin.db.retrieve(self.storage, default=[])",4e7a8f2c-ab87-488a-bdde-9de4fdeb3700
addons,ExtractArchive.py,set,31,33,"def set(self, value):        self.length = len(value)        return self.plugin.db.store(self.storage, value)",,"def set(self, value):        self.length = len(value)        return self.plugin.db.store(self.storage, value)",0f08f5fb-0c1e-4039-9e7e-cc8d8c59b173
addons,ExtractArchive.py,delete,35,37,def delete(self):        self.length = 0        return self.plugin.db.delete(self.storage),,def delete(self):        self.length = 0        return self.plugin.db.delete(self.storage),1838fb73-08ff-4513-ae42-ee349635b972
addons,ExtractArchive.py,add,39,44,"def add(self, item):        queue = self.get()        if item not in queue:            return self.set(queue + [item])        else:            return True",,"def add(self, item):        queue = self.get()        if item not in queue:            return self.set(queue + [item])        else:            return True",591b93b4-5bbe-4301-80bf-3a8f36e6dee8
addons,ExtractArchive.py,remove,46,57,"def remove(self, item):        queue = self.get()        try:            queue.remove(item)        except ValueError:            pass        if not queue:            return self.delete()        return self.set(queue)",,"def remove(self, item):        queue = self.get()        try:            queue.remove(item)        except ValueError:            pass        if not queue:            return self.delete()        return self.set(queue)",ea0f3b27-7d6c-4016-a38c-b62c3d84a2f3
addons,ExtractArchive.py,init,103,116,"def init(self):        self.event_map = {            ""all_downloads_processed"": ""all_downloads_processed"",            ""package_deleted"": ""package_deleted"",        }        self.queue = ArchiveQueue(self, ""Queue"")        self.extracting = False        self.extracted = 0        self.last_package = False        self.extractors = []        self.passwords = []        self.repair = False",,"def init(self):        self.event_map = {            ""all_downloads_processed"": ""all_downloads_processed"",            ""package_deleted"": ""package_deleted"",        }        self.queue = ArchiveQueue(self, ""Queue"")        self.extracting = False        self.extracted = 0        self.last_package = False        self.extractors = []        self.passwords = []        self.repair = False",9de4d686-109d-4b76-8ab6-bcd671c6b52c
addons,ExtractArchive.py,activate,118,145,"def activate(self):        for p in (""HjSplit"", ""UnRar"", ""SevenZip"", ""UnZip"", ""UnTar""):            try:                klass = self.pyload.plugin_manager.load_class(""extractor"", p)                if klass.find():                    self.extractors.append(klass)                if klass.REPAIR:                    self.repair = self.config.get(""repair"")            except OSError as exc:                if exc.errno == 2:                    self.log_warning(self._(""No {} installed"").format(p))                else:                    self.log_warning(self._(""Could not activate: {}"").format(p), exc)            except Exception as exc:                self.log_warning(self._(""Could not activate: {}"").format(p), exc)        if self.extractors:            self.log_debug(                *[                    ""Found {} {}"".format(Extractor.__name__, Extractor.VERSION)                    for Extractor in self.extractors                ]            )            self.extract_queued()  #: Resume unfinished extractions        else:            self.log_info(self._(""No Extract plugins activated""))",,"def activate(self):        for p in (""HjSplit"", ""UnRar"", ""SevenZip"", ""UnZip"", ""UnTar""):            try:                klass = self.pyload.plugin_manager.load_class(""extractor"", p)                if klass.find():                    self.extractors.append(klass)                if klass.REPAIR:                    self.repair = self.config.get(""repair"")            except OSError as exc:                if exc.errno == 2:                    self.log_warning(self._(""No {} installed"").format(p))                else:                    self.log_warning(self._(""Could not activate: {}"").format(p), exc)            except Exception as exc:                self.log_warning(self._(""Could not activate: {}"").format(p), exc)        if self.extractors:            self.log_debug(                *[                    ""Found {} {}"".format(Extractor.__name__, Extractor.VERSION)                    for Extractor in self.extractors                ]            )            self.extract_queued()  #: Resume unfinished extractions        else:            self.log_info(self._(""No Extract plugins activated""))",40e3ae4a-1156-41b3-9a71-64e62c61eb8c
addons,ExtractArchive.py,extract_queued,148,169,"def extract_queued(self, thread):        # NOTE: doing the check here for safety (called by core_ready)        if self.extracting:            return        self.extracting = True        packages = self.queue.get()        while packages:            if self.extract(packages, thread):                self.extracted += 1            if self.last_package and len(self.queue) == 0:  #: last_package is set by all_downloads_processed()                self.last_package = False                if self.extracted:                    self.extracted = 0                    self.m.dispatch_event(""all_archives_extracted"")                self.m.dispatch_event(""all_archives_processed"")            packages = self.queue.get()  #: Check for packages added during extraction        self.extracting = False",,"def extract_queued(self, thread):        # NOTE: doing the check here for safety (called by core_ready)        if self.extracting:            return        self.extracting = True        packages = self.queue.get()        while packages:            if self.extract(packages, thread):                self.extracted += 1            if self.last_package and len(self.queue) == 0:  #: last_package is set by all_downloads_processed()                self.last_package = False                if self.extracted:                    self.extracted = 0                    self.m.dispatch_event(""all_archives_extracted"")                self.m.dispatch_event(""all_archives_processed"")            packages = self.queue.get()  #: Check for packages added during extraction        self.extracting = False",75fcf8b7-13af-4b13-a2b0-9f3427c3025c
addons,ExtractArchive.py,extract_package,172,179,"def extract_package(self, *ids):                for id in ids:            self.queue.add(id)        if not self.config.get(""waitall"") and not self.extracting:            self.extract_queued()",Extract packages with given id.,"def extract_package(self, *ids):        """"""        Extract packages with given id.        """"""        for id in ids:            self.queue.add(id)        if not self.config.get(""waitall"") and not self.extracting:            self.extract_queued()

Extract packages with given id.",bbe9f4e5-ab18-4214-9e08-e46c0c673e42
addons,ExtractArchive.py,package_deleted,181,182,"def package_deleted(self, pid):        self.queue.remove(pid)",,"def package_deleted(self, pid):        self.queue.remove(pid)",c9b81918-6af7-412a-a2ed-4d7c1171312a
addons,ExtractArchive.py,package_finished,184,187,"def package_finished(self, pypack):        self.queue.add(pypack.id)        if not self.config.get(""waitall"") and not self.extracting:            self.extract_queued()",,"def package_finished(self, pypack):        self.queue.add(pypack.id)        if not self.config.get(""waitall"") and not self.extracting:            self.extract_queued()",6cef690b-a201-4b3d-acb3-e03180126d17
addons,ExtractArchive.py,all_downloads_processed,189,192,"def all_downloads_processed(self):        self.last_package = True        if self.config.get(""waitall"") and not self.extracting:            self.extract_queued()",,"def all_downloads_processed(self):        self.last_package = True        if self.config.get(""waitall"") and not self.extracting:            self.extract_queued()",ff5d5739-adf0-494b-924e-94a015c1656b
addons,ExtractArchive.py,extract,195,429,"def extract(        self, package_ids, thread=None    ):  # TODO: Use pypack, not pid to improve method usability        if not package_ids:            return False        extracted = []        failed = []        def to_list(value):            return value.replace("" "", """").replace("","", ""|"").replace("";"", ""|"").split(""|"")        destination = self.config.get(""destination"")        subfolder = self.config.get(""subfolder"")        fullpath = self.config.get(""fullpath"")        overwrite = self.config.get(""overwrite"")        priority = self.config.get(""priority"")        recursive = self.config.get(""recursive"")        keepbroken = self.config.get(""keepbroken"")        extensions = [            x.lstrip(""."").lower() for x in to_list(self.config.get(""extensions""))        ]        excludefiles = to_list(self.config.get(""excludefiles""))        if extensions:            self.log_debug(f""Use for extensions: .{'|.'.join(extensions)}"")        #: Reload from txt file        self.reload_passwords()        dl_folder = self.pyload.config.get(""general"", ""storage_folder"")        #: Iterate packages -> extractors -> targets        for package_id in package_ids:            pypack = self.pyload.files.get_package(package_id)            if not pypack:                self.queue.remove(package_id)                continue            self.log_info(self._(""Check package: {}"").format(pypack.name))            pack_dl_folder = os.path.join(                dl_folder, pypack.folder, """"            )  #: Force trailing slash            #: Determine output folder            extract_folder = os.path.join(                pack_dl_folder, destination, """"            )  #: Force trailing slash            if subfolder:                extract_folder = os.path.join(                    extract_folder,                    pypack.folder or safename(pypack.name.replace(""http://"", """")),                )            if not exists(extract_folder):                os.makedirs(extract_folder)                if subfolder:                    self.set_permissions(extract_folder)            matched = False            success = True            files_ids = list(                {                    fdata[""name""]: (                        fdata[""id""],                        (os.path.join(pack_dl_folder, fdata[""name""])),                        extract_folder,                    )                    for fdata in pypack.get_children().values()                }.values()            )  #: : Remove duplicates            #: Check as long there are unseen files            while files_ids:                new_files_ids = []                if extensions:  #: Include only specified archive types                    files_ids = [                        file_id                        for file_id in files_ids                        if any(                            [                                Extractor.archivetype(file_id[1]) in extensions                                for Extractor in self.extractors                            ]                        )                    ]                #: Sort by filename to ensure (or at least try) that a multi-volume archive is targeted by its first part                #: This is important because, for example, UnRar ignores preceding parts in listing mode                files_ids.sort(key=lambda file_id: file_id[1])                for Extractor in self.extractors:                    targets = Extractor.get_targets(files_ids)                    if targets:                        self.log_debug(                            ""Targets for {}: {}"".format(Extractor.__name__, targets)                        )                        matched = True                        for fid, fname, fout in targets:                            name = os.path.basename(fname)                            if not exists(fname):                                self.log_debug(name, ""File not found"")                                continue                            self.log_info(name, self._(""Extract to: {}"").format(fout))                            try:                                pyfile = self.pyload.files.get_file(fid)                                archive = Extractor(                                    pyfile,                                    fname,                                    fout,                                    fullpath,                                    overwrite,                                    excludefiles,                                    priority,                                    keepbroken,                                )                                thread.add_active(pyfile)                                archive.init()                                #: Save for removal from file processing list, which happens after deletion.                                #: So archive.chunks() would just return an empty list.                                chunks = archive.chunks()                                try:                                    new_files = self._extract(                                        pyfile, archive, pypack.password                                    )                                finally:                                    pyfile.set_progress(100)                                    thread.finish_file(pyfile)                            except Exception as exc:                                self.log_error(name, exc)                                success = False                                continue                            #: Remove processed file and related multi-parts from list                            files_ids = [                                (_fid, _fname, _fout)                                for _fid, _fname, _fout in files_ids                                if _fname not in chunks                            ]                            self.log_debug(f""Extracted files: {new_files}"")                            new_folders = []                            for _f in new_files:                                _d = os.path.dirname(_f)                                while extract_folder in _d:                                    if _d not in new_folders:                                        new_folders.append(_d)                                    _d = os.path.dirname(_d)                            for foldername in new_folders:                                self.set_permissions(foldername)                            for filename in new_files:                                self.set_permissions(filename)                            for filename in new_files:                                if not exists(filename):                                    self.log_debug(f""New file {filename} does not exists"")                                    continue                                if recursive and os.path.isfile(filename):                                    new_files_ids.append(                                        (fid, filename, os.path.dirname(filename))                                    )  #: Append as new target                            self.m.dispatch_event(""archive_extracted"", pyfile, archive)                files_ids = new_files_ids  #: Also check extracted files            if matched:                if success:                    #: Delete empty pack folder if extract_folder resides outside download folder                    if self.config.get(""delete"") and self.pyload.config.get(                        ""general"", ""folder_per_package""                    ):                        if not extract_folder.startswith(pack_dl_folder):                            if len(os.listdir(pack_dl_folder)) == 0:                                try:                                    os.rmdir(pack_dl_folder)                                    self.log_debug(                                        ""Successfully deleted pack folder {}"".format(                                            pack_dl_folder                                        )                                    )                                except OSError:                                    self.log_warning(                                        ""Unable to delete pack folder {}"".format(                                            pack_dl_folder                                        )                                    )                            else:                                self.log_warning(                                    ""Not deleting pack folder {}, folder not empty"".format(                                        pack_dl_folder                                    )                                )                    extracted.append(package_id)                    self.m.dispatch_event(""package_extracted"", pypack)                else:                    failed.append(package_id)                    self.m.dispatch_event(""package_extract_failed"", pypack)            else:                self.log_info(self._(""No files found to extract""))            if not matched or not success and subfolder:                try:                    os.rmdir(extract_folder)                except OSError:                    pass            self.queue.remove(package_id)            self.m.dispatch_event(""archive_processed"", pypack)        return True if extracted else False",,"def extract(        self, package_ids, thread=None    ):  # TODO: Use pypack, not pid to improve method usability        if not package_ids:            return False        extracted = []        failed = []        def to_list(value):            return value.replace("" "", """").replace("","", ""|"").replace("";"", ""|"").split(""|"")        destination = self.config.get(""destination"")        subfolder = self.config.get(""subfolder"")        fullpath = self.config.get(""fullpath"")        overwrite = self.config.get(""overwrite"")        priority = self.config.get(""priority"")        recursive = self.config.get(""recursive"")        keepbroken = self.config.get(""keepbroken"")        extensions = [            x.lstrip(""."").lower() for x in to_list(self.config.get(""extensions""))        ]        excludefiles = to_list(self.config.get(""excludefiles""))        if extensions:            self.log_debug(f""Use for extensions: .{'|.'.join(extensions)}"")        #: Reload from txt file        self.reload_passwords()        dl_folder = self.pyload.config.get(""general"", ""storage_folder"")        #: Iterate packages -> extractors -> targets        for package_id in package_ids:            pypack = self.pyload.files.get_package(package_id)            if not pypack:                self.queue.remove(package_id)                continue            self.log_info(self._(""Check package: {}"").format(pypack.name))            pack_dl_folder = os.path.join(                dl_folder, pypack.folder, """"            )  #: Force trailing slash            #: Determine output folder            extract_folder = os.path.join(                pack_dl_folder, destination, """"            )  #: Force trailing slash            if subfolder:                extract_folder = os.path.join(                    extract_folder,                    pypack.folder or safename(pypack.name.replace(""http://"", """")),                )            if not exists(extract_folder):                os.makedirs(extract_folder)                if subfolder:                    self.set_permissions(extract_folder)            matched = False            success = True            files_ids = list(                {                    fdata[""name""]: (                        fdata[""id""],                        (os.path.join(pack_dl_folder, fdata[""name""])),                        extract_folder,                    )                    for fdata in pypack.get_children().values()                }.values()            )  #: : Remove duplicates            #: Check as long there are unseen files            while files_ids:                new_files_ids = []                if extensions:  #: Include only specified archive types                    files_ids = [                        file_id                        for file_id in files_ids                        if any(                            [                                Extractor.archivetype(file_id[1]) in extensions                                for Extractor in self.extractors                            ]                        )                    ]                #: Sort by filename to ensure (or at least try) that a multi-volume archive is targeted by its first part                #: This is important because, for example, UnRar ignores preceding parts in listing mode                files_ids.sort(key=lambda file_id: file_id[1])                for Extractor in self.extractors:                    targets = Extractor.get_targets(files_ids)                    if targets:                        self.log_debug(                            ""Targets for {}: {}"".format(Extractor.__name__, targets)                        )                        matched = True                        for fid, fname, fout in targets:                            name = os.path.basename(fname)                            if not exists(fname):                                self.log_debug(name, ""File not found"")                                continue                            self.log_info(name, self._(""Extract to: {}"").format(fout))                            try:                                pyfile = self.pyload.files.get_file(fid)                                archive = Extractor(                                    pyfile,                                    fname,                                    fout,                                    fullpath,                                    overwrite,                                    excludefiles,                                    priority,                                    keepbroken,                                )                                thread.add_active(pyfile)                                archive.init()                                #: Save for removal from file processing list, which happens after deletion.                                #: So archive.chunks() would just return an empty list.                                chunks = archive.chunks()                                try:                                    new_files = self._extract(                                        pyfile, archive, pypack.password                                    )                                finally:                                    pyfile.set_progress(100)                                    thread.finish_file(pyfile)                            except Exception as exc:                                self.log_error(name, exc)                                success = False                                continue                            #: Remove processed file and related multi-parts from list                            files_ids = [                                (_fid, _fname, _fout)                                for _fid, _fname, _fout in files_ids                                if _fname not in chunks                            ]                            self.log_debug(f""Extracted files: {new_files}"")                            new_folders = []                            for _f in new_files:                                _d = os.path.dirname(_f)                                while extract_folder in _d:                                    if _d not in new_folders:                                        new_folders.append(_d)                                    _d = os.path.dirname(_d)                            for foldername in new_folders:                                self.set_permissions(foldername)                            for filename in new_files:                                self.set_permissions(filename)                            for filename in new_files:                                if not exists(filename):                                    self.log_debug(f""New file {filename} does not exists"")                                    continue                                if recursive and os.path.isfile(filename):                                    new_files_ids.append(                                        (fid, filename, os.path.dirname(filename))                                    )  #: Append as new target                            self.m.dispatch_event(""archive_extracted"", pyfile, archive)                files_ids = new_files_ids  #: Also check extracted files            if matched:                if success:                    #: Delete empty pack folder if extract_folder resides outside download folder                    if self.config.get(""delete"") and self.pyload.config.get(                        ""general"", ""folder_per_package""                    ):                        if not extract_folder.startswith(pack_dl_folder):                            if len(os.listdir(pack_dl_folder)) == 0:                                try:                                    os.rmdir(pack_dl_folder)                                    self.log_debug(                                        ""Successfully deleted pack folder {}"".format(                                            pack_dl_folder                                        )                                    )                                except OSError:                                    self.log_warning(                                        ""Unable to delete pack folder {}"".format(                                            pack_dl_folder                                        )                                    )                            else:                                self.log_warning(                                    ""Not deleting pack folder {}, folder not empty"".format(                                        pack_dl_folder                                    )                                )                    extracted.append(package_id)                    self.m.dispatch_event(""package_extracted"", pypack)                else:                    failed.append(package_id)                    self.m.dispatch_event(""package_extract_failed"", pypack)            else:                self.log_info(self._(""No files found to extract""))            if not matched or not success and subfolder:                try:                    os.rmdir(extract_folder)                except OSError:                    pass            self.queue.remove(package_id)            self.m.dispatch_event(""archive_processed"", pypack)        return True if extracted else False",5740613e-5ec3-4e16-a58b-ed126b25c620
addons,ExtractArchive.py,_extract,431,567,"def _extract(self, pyfile, archive, password):        name = os.path.basename(archive.filename)        pyfile.set_status(""processing"")        encrypted = False        try:            self.log_debug(f""Password: {password or None}"")            passwords = (                uniquify([password] + self.get_passwords(False))                if self.config.get(""usepasswordfile"")                else [password]            )            for pw in passwords:                try:                    pyfile.set_custom_status(self._(""archive testing""))                    pyfile.set_progress(0)                    self.log_debug(""Verifying using password: {}"".format(pw or ""None""))                    archive.verify(pw)                    pyfile.set_progress(100)                except PasswordError:                    if not encrypted:                        self.log_info(name, self._(""Password protected""))                        encrypted = True                    self.log_debug(""Password was wrong"")                except CRCError as exc:                    self.log_debug(name, exc)                    self.log_info(name, self._(""CRC Error""))                    if not self.repair:                        raise CRCError(""Archive damaged"")                    else:                        self.log_warning(name, self._(""Repairing...""))                        pyfile.set_custom_status(self._(""archive repairing""))                        pyfile.set_progress(0)                        repaired = archive.repair()                        pyfile.set_progress(100)                        if not repaired and not self.config.get(""keepbroken""):                            raise CRCError(""Archive damaged"")                        else:                            self.add_password(pw)                            password = pw                            break                except ArchiveError as exc:                    raise ArchiveError(exc)                else:                    self.add_password(pw)                    password = pw                    self.log_debug(""Password Correct"")                    break            else:                if encrypted:                    raise PasswordError            pyfile.set_custom_status(self._(""archive extracting""))            pyfile.set_progress(0)            self.log_debug(                ""Extracting using password: {}"".format(password or ""None"")            )            archive.extract(password)            pyfile.set_progress(100)            pyfile.set_status(""processing"")            extracted_files = archive.files or archive.list(password)            delfiles = archive.chunks()            self.log_debug(""Would delete: "" + "", "".join(delfiles))            if self.config.get(""delete""):                self.log_info(self._(""Deleting {} files"").format(len(delfiles)))                deltotrash = self.config.get(""deltotrash"")                for f in delfiles:                    file = os.fsdecode(f)                    if not exists(file):                        continue                    if not deltotrash:                        os.remove(file)                    else:                        try:                            send2trash.send2trash(file)                        except NameError:                            self.log_warning(                                self._(""Unable to move {} to trash"").format(                                    os.path.basename(f)                                ),                                self._(""Send2Trash lib not installed""),                            )                        except Exception as exc:                            self.log_warning(                                self._(""Unable to move {} to trash"").format(                                    os.path.basename(f)                                ),                                exc,                            )                        else:                            self.log_info(                                self._(""Moved {} to trash"").format(os.path.basename(f))                            )            self.log_info(name, self._(""Extracting finished""))            return extracted_files        except PasswordError:            self.log_error(                name, self._(""Wrong password"" if password else ""No password found"")            )        except CRCError as exc:            self.log_error(name, self._(""CRC mismatch""), exc)        except ArchiveError as exc:            self.log_error(name, self._(""Archive error""), exc)        except Exception as exc:            self.log_error(name, self._(""Unknown error""), exc)        self.m.dispatch_event(""archive_extract_failed"", pyfile, archive)        raise Exception(self._(""Extract failed""))",,"def _extract(self, pyfile, archive, password):        name = os.path.basename(archive.filename)        pyfile.set_status(""processing"")        encrypted = False        try:            self.log_debug(f""Password: {password or None}"")            passwords = (                uniquify([password] + self.get_passwords(False))                if self.config.get(""usepasswordfile"")                else [password]            )            for pw in passwords:                try:                    pyfile.set_custom_status(self._(""archive testing""))                    pyfile.set_progress(0)                    self.log_debug(""Verifying using password: {}"".format(pw or ""None""))                    archive.verify(pw)                    pyfile.set_progress(100)                except PasswordError:                    if not encrypted:                        self.log_info(name, self._(""Password protected""))                        encrypted = True                    self.log_debug(""Password was wrong"")                except CRCError as exc:                    self.log_debug(name, exc)                    self.log_info(name, self._(""CRC Error""))                    if not self.repair:                        raise CRCError(""Archive damaged"")                    else:                        self.log_warning(name, self._(""Repairing...""))                        pyfile.set_custom_status(self._(""archive repairing""))                        pyfile.set_progress(0)                        repaired = archive.repair()                        pyfile.set_progress(100)                        if not repaired and not self.config.get(""keepbroken""):                            raise CRCError(""Archive damaged"")                        else:                            self.add_password(pw)                            password = pw                            break                except ArchiveError as exc:                    raise ArchiveError(exc)                else:                    self.add_password(pw)                    password = pw                    self.log_debug(""Password Correct"")                    break            else:                if encrypted:                    raise PasswordError            pyfile.set_custom_status(self._(""archive extracting""))            pyfile.set_progress(0)            self.log_debug(                ""Extracting using password: {}"".format(password or ""None"")            )            archive.extract(password)            pyfile.set_progress(100)            pyfile.set_status(""processing"")            extracted_files = archive.files or archive.list(password)            delfiles = archive.chunks()            self.log_debug(""Would delete: "" + "", "".join(delfiles))            if self.config.get(""delete""):                self.log_info(self._(""Deleting {} files"").format(len(delfiles)))                deltotrash = self.config.get(""deltotrash"")                for f in delfiles:                    file = os.fsdecode(f)                    if not exists(file):                        continue                    if not deltotrash:                        os.remove(file)                    else:                        try:                            send2trash.send2trash(file)                        except NameError:                            self.log_warning(                                self._(""Unable to move {} to trash"").format(                                    os.path.basename(f)                                ),                                self._(""Send2Trash lib not installed""),                            )                        except Exception as exc:                            self.log_warning(                                self._(""Unable to move {} to trash"").format(                                    os.path.basename(f)                                ),                                exc,                            )                        else:                            self.log_info(                                self._(""Moved {} to trash"").format(os.path.basename(f))                            )            self.log_info(name, self._(""Extracting finished""))            return extracted_files        except PasswordError:            self.log_error(                name, self._(""Wrong password"" if password else ""No password found"")            )        except CRCError as exc:            self.log_error(name, self._(""CRC mismatch""), exc)        except ArchiveError as exc:            self.log_error(name, self._(""Archive error""), exc)        except Exception as exc:            self.log_error(name, self._(""Unknown error""), exc)        self.m.dispatch_event(""archive_extract_failed"", pyfile, archive)        raise Exception(self._(""Extract failed""))",b61ff671-dc43-4883-9fe2-7e6eaab5e6d9
addons,ExtractArchive.py,get_passwords,570,577,"def get_passwords(self, reload=True):                if reload:            self.reload_passwords()        return self.passwords",List of saved passwords.,"def get_passwords(self, reload=True):        """"""        List of saved passwords.        """"""        if reload:            self.reload_passwords()        return self.passwords

List of saved passwords.",bcc77072-df01-447f-9b12-45e955bc5131
addons,ExtractArchive.py,reload_passwords,579,597,"def reload_passwords(self):        try:            passwords = []            file = os.fsdecode(self.config.get(""passwordfile""))            with open(file) as fp:                for pw in fp.read().splitlines():                    passwords.append(pw)        except IOError as exc:            if exc.errno == 2:                fp = open(file, mode=""w"")                fp.close()            else:                self.log_error(exc)        else:            self.passwords = passwords",,"def reload_passwords(self):        try:            passwords = []            file = os.fsdecode(self.config.get(""passwordfile""))            with open(file) as fp:                for pw in fp.read().splitlines():                    passwords.append(pw)        except IOError as exc:            if exc.errno == 2:                fp = open(file, mode=""w"")                fp.close()            else:                self.log_error(exc)        else:            self.passwords = passwords",577ab4c5-e1a7-4a14-850c-fe833867e77e
addons,ExtractArchive.py,add_password,600,613,"def add_password(self, password):                try:            self.passwords = uniquify([password] + self.passwords)            file = os.fsdecode(self.config.get(""passwordfile""))            with open(file, mode=""w"") as fp:                for pw in self.passwords:                    fp.write(pw + ""\n"")        except IOError as exc:            self.log_error(exc)",Adds a password to saved list.,"def add_password(self, password):        """"""        Adds a password to saved list.        """"""        try:            self.passwords = uniquify([password] + self.passwords)            file = os.fsdecode(self.config.get(""passwordfile""))            with open(file, mode=""w"") as fp:                for pw in self.passwords:                    fp.write(pw + ""\n"")        except IOError as exc:            self.log_error(exc)

Adds a password to saved list.",8934f508-1a62-47bb-9c5c-01f8eb9804c0
addons,HotFolder.py,activate,37,47,"def activate(self):        self.extensions = None        if self.config.get(""enable_extension_filter""):            extension_filter = self.config.get(""extension_filter"")            self.extensions = [s.strip() for s in extension_filter.split("","")]            self.log_info(                self._(""Watching only for extensions {}"").format(self.extensions)            )        interval = max(self.config.get(""interval""), 20)        self.periodical.start(interval, threaded=True)",,"def activate(self):        self.extensions = None        if self.config.get(""enable_extension_filter""):            extension_filter = self.config.get(""extension_filter"")            self.extensions = [s.strip() for s in extension_filter.split("","")]            self.log_info(                self._(""Watching only for extensions {}"").format(self.extensions)            )        interval = max(self.config.get(""interval""), 20)        self.periodical.start(interval, threaded=True)",64791d82-bbba-4406-a14e-1309ba31704c
addons,HotFolder.py,periodical_task,49,113,"def periodical_task(self):        watch_folder = os.fsdecode(self.config.get(""folder""))        watch_file = os.fsdecode(self.config.get(""file""))        add_to = (            Destination.COLLECTOR            if self.config.get(""add_to"") == ""Packages""            else Destination.QUEUE        )        try:            if not os.path.isdir(os.path.join(watch_folder, ""finished"")):                os.makedirs(os.path.join(watch_folder, ""finished""), exist_ok=True)            if self.config.get(""watchfile""):                with open(watch_file, mode=""a+"") as fp:                    fp.seek(0)                    content = fp.read().strip()                if content:                    fp = open(watch_file, mode=""w"")                    fp.close()                    name = ""{}_{}.txt"".format(                        watch_file, time.strftime(""%H-%M-%S_%d%b%Y"")                    )                    with open(                        os.path.join(watch_folder, ""finished"", name), mode=""w""                    ) as fp:                        fp.write(content)                    self.pyload.api.add_package(name, [fp.name], add_to)            for entry in os.listdir(watch_folder):                entry_file = os.path.join(watch_folder, entry)                if (                    not os.path.isfile(entry_file)                    or entry.endswith(""~"")                    or entry.startswith(""#"")                    or entry.startswith(""."")                    or os.path.realpath(watch_file) == os.path.realpath(entry_file)                ):                    continue                if self.extensions is not None:                    extension = os.path.splitext(entry)[1]                    # Note that extension contains the leading dot                    if len(extension) == 0 or extension[1:] not in self.extensions:                        continue                new_path = os.path.join(                    watch_folder,                    ""finished"",                    ""tmp_"" + entry if self.config.get(""delete"") else entry,                )                shutil.move(entry_file, new_path)                self.log_info(self._(""Added {} from HotFolder"").format(entry))                self.pyload.api.add_package(entry, [new_path], add_to)        except (IOError, OSError) as exc:            self.log_error(                exc, exc_info=self.pyload.debug > 1, stack_info=self.pyload.debug > 2            )",,"def periodical_task(self):        watch_folder = os.fsdecode(self.config.get(""folder""))        watch_file = os.fsdecode(self.config.get(""file""))        add_to = (            Destination.COLLECTOR            if self.config.get(""add_to"") == ""Packages""            else Destination.QUEUE        )        try:            if not os.path.isdir(os.path.join(watch_folder, ""finished"")):                os.makedirs(os.path.join(watch_folder, ""finished""), exist_ok=True)            if self.config.get(""watchfile""):                with open(watch_file, mode=""a+"") as fp:                    fp.seek(0)                    content = fp.read().strip()                if content:                    fp = open(watch_file, mode=""w"")                    fp.close()                    name = ""{}_{}.txt"".format(                        watch_file, time.strftime(""%H-%M-%S_%d%b%Y"")                    )                    with open(                        os.path.join(watch_folder, ""finished"", name), mode=""w""                    ) as fp:                        fp.write(content)                    self.pyload.api.add_package(name, [fp.name], add_to)            for entry in os.listdir(watch_folder):                entry_file = os.path.join(watch_folder, entry)                if (                    not os.path.isfile(entry_file)                    or entry.endswith(""~"")                    or entry.startswith(""#"")                    or entry.startswith(""."")                    or os.path.realpath(watch_file) == os.path.realpath(entry_file)                ):                    continue                if self.extensions is not None:                    extension = os.path.splitext(entry)[1]                    # Note that extension contains the leading dot                    if len(extension) == 0 or extension[1:] not in self.extensions:                        continue                new_path = os.path.join(                    watch_folder,                    ""finished"",                    ""tmp_"" + entry if self.config.get(""delete"") else entry,                )                shutil.move(entry_file, new_path)                self.log_info(self._(""Added {} from HotFolder"").format(entry))                self.pyload.api.add_package(entry, [new_path], add_to)        except (IOError, OSError) as exc:            self.log_error(                exc, exc_info=self.pyload.debug > 1, stack_info=self.pyload.debug > 2            )",2a80c676-1f5c-4c26-941f-e95d987773be
addons,ImageTyperz.py,__init__,12,13,"def __init__(self, err):        self.err = err",,"def __init__(self, err):        self.err = err",d9e42ef4-f8e7-4674-aa5e-4fde22d14881
addons,ImageTyperz.py,get_code,15,16,def get_code(self):        return self.err,,def get_code(self):        return self.err,85bd6f2f-8746-4198-89e7-cc4a46153c05
addons,ImageTyperz.py,__str__,18,19,"def __str__(self):        return ""<ImageTyperzException {}>"".format(self.err)",,"def __str__(self):        return ""<ImageTyperzException {}>"".format(self.err)",e8878bfe-96ab-451a-a6dc-d3661ece9618
addons,ImageTyperz.py,__repr__,21,22,"def __repr__(self):        return ""<ImageTyperzException {}>"".format(self.err)",,"def __repr__(self):        return ""<ImageTyperzException {}>"".format(self.err)",d1918892-7fe2-4877-b0cb-91960b431114
addons,ImageTyperz.py,get_credits,46,66,"def get_credits(self):        res = self.load(            self.GETCREDITS_URL,            post={                ""action"": ""REQUESTBALANCE"",                ""username"": self.config.get(""username""),                ""password"": self.config.get(""password""),            },        )        if res.startswith(""ERROR""):            raise ImageTyperzException(res)        try:            balance = float(res)        except Exception:            raise ImageTyperzException(""Invalid response"")        self.log_info(self._(""Account balance: ${} left"").format(res))        return balance",,"def get_credits(self):        res = self.load(            self.GETCREDITS_URL,            post={                ""action"": ""REQUESTBALANCE"",                ""username"": self.config.get(""username""),                ""password"": self.config.get(""password""),            },        )        if res.startswith(""ERROR""):            raise ImageTyperzException(res)        try:            balance = float(res)        except Exception:            raise ImageTyperzException(""Invalid response"")        self.log_info(self._(""Account balance: ${} left"").format(res))        return balance",9d65293d-48f5-43bb-a226-bf2fed05da96
addons,ImageTyperz.py,submit,68,104,"def submit(self, captcha, captcha_type=""file"", match=None):        with get_request() as req:            #: Raise timeout threshold            req.c.setopt(pycurl.LOW_SPEED_TIME, 80)            # NOTE: Workaround multipart-post bug in HTTPRequest.py            if re.match(r""^\w*$"", self.config.get(""password"")):                multipart = True                data = (pycurl.FORM_FILE, captcha)            else:                multipart = False                with open(captcha, mode=""rb"") as fp:                    data = fp.read()                data = base64.b64encode(data)            res = self.load(                self.SUBMIT_URL,                post={                    ""action"": ""UPLOADCAPTCHA"",                    ""username"": self.config.get(""username""),                    ""password"": self.config.get(""password""),                    ""file"": data,                },                multipart=multipart,                req=req,            )        if res.startswith(""ERROR""):            raise ImageTyperzException(res)        else:            data = res.split(""|"")            if len(data) == 2:                ticket, result = data            else:                raise ImageTyperzException(""Unknown response: {}"".format(res))        return ticket, result",,"def submit(self, captcha, captcha_type=""file"", match=None):        with get_request() as req:            #: Raise timeout threshold            req.c.setopt(pycurl.LOW_SPEED_TIME, 80)            # NOTE: Workaround multipart-post bug in HTTPRequest.py            if re.match(r""^\w*$"", self.config.get(""password"")):                multipart = True                data = (pycurl.FORM_FILE, captcha)            else:                multipart = False                with open(captcha, mode=""rb"") as fp:                    data = fp.read()                data = base64.b64encode(data)            res = self.load(                self.SUBMIT_URL,                post={                    ""action"": ""UPLOADCAPTCHA"",                    ""username"": self.config.get(""username""),                    ""password"": self.config.get(""password""),                    ""file"": data,                },                multipart=multipart,                req=req,            )        if res.startswith(""ERROR""):            raise ImageTyperzException(res)        else:            data = res.split(""|"")            if len(data) == 2:                ticket, result = data            else:                raise ImageTyperzException(""Unknown response: {}"".format(res))        return ticket, result",5520608e-bf12-489c-93b9-e131c317cbb0
addons,ImageTyperz.py,captcha_task,106,126,"def captcha_task(self, task):        if ""service"" in task.data:            return False        if not task.is_textual():            return False        if not self.config.get(""username"") or not self.config.get(""password""):            return False        if self.pyload.is_client_connected() and self.config.get(""check_client""):            return False        if self.get_credits() > 0:            task.handler.append(self)            task.data[""service""] = self.classname            task.set_waiting(100)            self._process_captcha(task)        else:            self.log_info(self._(""Your account has not enough credits""))",,"def captcha_task(self, task):        if ""service"" in task.data:            return False        if not task.is_textual():            return False        if not self.config.get(""username"") or not self.config.get(""password""):            return False        if self.pyload.is_client_connected() and self.config.get(""check_client""):            return False        if self.get_credits() > 0:            task.handler.append(self)            task.data[""service""] = self.classname            task.set_waiting(100)            self._process_captcha(task)        else:            self.log_info(self._(""Your account has not enough credits""))",0c5d1afd-201c-45c7-b580-d022bd24231d
addons,ImageTyperz.py,captcha_invalid,128,145,"def captcha_invalid(self, task):        if task.data[""service""] == self.classname and ""ticket"" in task.data:            res = self.load(                self.RESPOND_URL,                post={                    ""action"": ""SETBADIMAGE"",                    ""username"": self.config.get(""username""),                    ""password"": self.config.get(""password""),                    ""imageid"": task.data[""ticket""],                },            )            if res == ""SUCCESS"":                self.log_info(self._(""Bad captcha solution received, requested refund""))            else:                self.log_error(                    self._(""Bad captcha solution received, refund request failed""), res                )",,"def captcha_invalid(self, task):        if task.data[""service""] == self.classname and ""ticket"" in task.data:            res = self.load(                self.RESPOND_URL,                post={                    ""action"": ""SETBADIMAGE"",                    ""username"": self.config.get(""username""),                    ""password"": self.config.get(""password""),                    ""imageid"": task.data[""ticket""],                },            )            if res == ""SUCCESS"":                self.log_info(self._(""Bad captcha solution received, requested refund""))            else:                self.log_error(                    self._(""Bad captcha solution received, refund request failed""), res                )",5d6a0eab-4244-487a-9567-18daf097dbb7
addons,ImageTyperz.py,_process_captcha,148,157,"def _process_captcha(self, task):        c = task.captcha_params[""file""]        try:            ticket, result = self.submit(c)        except ImageTyperzException as exc:            task.error = exc.get_code()            return        task.data[""ticket""] = ticket        task.set_result(result)",,"def _process_captcha(self, task):        c = task.captcha_params[""file""]        try:            ticket, result = self.submit(c)        except ImageTyperzException as exc:            task.error = exc.get_code()            return        task.data[""ticket""] = ticket        task.set_result(result)",6be701ef-ab1f-4649-a908-5764df0142c2
addons,IRC.py,parse_irc_msg,15,36,"def parse_irc_msg(line):        origin = ''    if not line:        return None, None, None    if line[0:1] == b':':        origin, line = line[1:].split(b' ', 1)    if line.find(b' :') != -1:        line, trailing = line.split(b' :', 1)        args = line.split()        args.append(trailing)    else:        args = line.split()    command = args.pop(0)    return to_str(origin), to_str(command), [to_str(arg) for arg in args]","Breaks a message from an IRC server into its origin, command, and arguments.","def parse_irc_msg(line):    """"""    Breaks a message from an IRC server into its origin, command, and arguments.    """"""    origin = ''    if not line:        return None, None, None    if line[0:1] == b':':        origin, line = line[1:].split(b' ', 1)    if line.find(b' :') != -1:        line, trailing = line.split(b' :', 1)        args = line.split()        args.append(trailing)    else:        args = line.split()    command = args.pop(0)    return to_str(origin), to_str(command), [to_str(arg) for arg in args]

Breaks a message from an IRC server into its origin, command, and arguments.",fa1d54e3-d75a-4249-9d38-8fbb0ce43401
addons,IRC.py,activate,72,75,def activate(self):        self.abort = False        super().activate(),,def activate(self):        self.abort = False        super().activate(),a1628be8-9f03-441a-9374-d0228b0ede65
addons,IRC.py,package_finished,77,83,"def package_finished(self, pypack):        try:            if self.config.get(""info_pack""):                self.response(self._(""Package finished: {}"").format(pypack.name))        except Exception:            pass",,"def package_finished(self, pypack):        try:            if self.config.get(""info_pack""):                self.response(self._(""Package finished: {}"").format(pypack.name))        except Exception:            pass",ca6d6594-10a7-421b-9826-b489caa23aa2
addons,IRC.py,download_finished,85,95,"def download_finished(self, pyfile):        try:            if self.config.get(""info_file""):                self.response(                    self._(""Download finished: {name} @ {plugin} "").format(                        name=pyfile.name, plugin=pyfile.pluginname                    )                )        except Exception:            pass",,"def download_finished(self, pyfile):        try:            if self.config.get(""info_file""):                self.response(                    self._(""Download finished: {name} @ {plugin} "").format(                        name=pyfile.name, plugin=pyfile.pluginname                    )                )        except Exception:            pass",e08cf121-2c61-4375-83a9-76569027f978
addons,IRC.py,captcha_task,97,111,"def captcha_task(self, task):        if self.config.get(""captcha"") and task.is_textual():            task.handler.append(self)            task.set_waiting(60)            html = self.load(                ""http://www.freeimagehosting.net/upl.php"",                post={""file"": (pycurl.FORM_FILE, task.captcha_params[""file""])},            )            url = re.search(r""src='([^']+)'"", html).group(1)            self.response(self._(""New Captcha Request: {}"").format(url))            self.response(                self._(""Answer with 'ca {} text on the captcha'"").format(task.id)            )",,"def captcha_task(self, task):        if self.config.get(""captcha"") and task.is_textual():            task.handler.append(self)            task.set_waiting(60)            html = self.load(                ""http://www.freeimagehosting.net/upl.php"",                post={""file"": (pycurl.FORM_FILE, task.captcha_params[""file""])},            )            url = re.search(r""src='([^']+)'"", html).group(1)            self.response(self._(""New Captcha Request: {}"").format(url))            self.response(                self._(""Answer with 'ca {} text on the captcha'"").format(task.id)            )",b8bf3e44-2d84-4084-a385-d15e5efa4b01
addons,IRC.py,run,113,139,"def run(self):        #: Connect to IRC etc.        self.sock = socket.socket()        host = self.config.get(""host"")        self.sock.connect((host, self.config.get(""port"")))        if self.config.get(""ssl""):            self.sock = ssl.wrap_socket(                self.sock, cert_reqs=ssl.CERT_NONE            )  # TODO: support certificate        nick = self.config.get(""nick"")        self.log_info(self._(""Connecting as""), nick)        self.sock.send(to_bytes(""NICK {}\r\n"".format(nick)))        self.sock.send(to_bytes(""USER {} {} bla :{}\r\n"".format(nick, host, nick)))        self.log_info(self._(""Connected to""), host)        for t in self.config.get(""owner"").split():            if t.startswith(""#""):                self.sock.send(to_bytes(""JOIN {}\r\n"".format(t)))                self.log_info(self._(""Joined channel {}"").format(to_str(t)))        self.log_info(self._(""Switching to listening mode!""))        try:            self.main_loop()        except IRCError:            self.sock.send(b""QUIT :byebye\r\n"")            self.sock.close()",,"def run(self):        #: Connect to IRC etc.        self.sock = socket.socket()        host = self.config.get(""host"")        self.sock.connect((host, self.config.get(""port"")))        if self.config.get(""ssl""):            self.sock = ssl.wrap_socket(                self.sock, cert_reqs=ssl.CERT_NONE            )  # TODO: support certificate        nick = self.config.get(""nick"")        self.log_info(self._(""Connecting as""), nick)        self.sock.send(to_bytes(""NICK {}\r\n"".format(nick)))        self.sock.send(to_bytes(""USER {} {} bla :{}\r\n"".format(nick, host, nick)))        self.log_info(self._(""Connected to""), host)        for t in self.config.get(""owner"").split():            if t.startswith(""#""):                self.sock.send(to_bytes(""JOIN {}\r\n"".format(t)))                self.log_info(self._(""Joined channel {}"").format(to_str(t)))        self.log_info(self._(""Switching to listening mode!""))        try:            self.main_loop()        except IRCError:            self.sock.send(b""QUIT :byebye\r\n"")            self.sock.close()",5546e46d-5a62-478d-a8b9-c3f6628aed41
addons,IRC.py,main_loop,141,173,"def main_loop(self):        readbuffer = b""""        while True:            time.sleep(1)            fdset = select.select([self.sock], [], [], 0)            if self.sock not in fdset[0]:                continue            if self.abort:                raise IRCError(""quit"")            readbuffer += self.sock.recv(1 << 10)            temp = readbuffer.split(b""\n"")            readbuffer = temp.pop()            for line in temp:                line = line.rstrip()                origin, command, args = parse_irc_msg(line)                if command == ""PING"":                    self.log_debug(""[{}] Ping? Pong!"".format(args[0]))                    self.sock.send(to_bytes(""PONG :{}\r\n"".format(args[0])))                if command == ""ERROR"":                    raise IRCError(line)                msg = {                    ""origin"": origin,                    ""command"": command,                    ""args"": args,                }                self.handle_events(msg)",,"def main_loop(self):        readbuffer = b""""        while True:            time.sleep(1)            fdset = select.select([self.sock], [], [], 0)            if self.sock not in fdset[0]:                continue            if self.abort:                raise IRCError(""quit"")            readbuffer += self.sock.recv(1 << 10)            temp = readbuffer.split(b""\n"")            readbuffer = temp.pop()            for line in temp:                line = line.rstrip()                origin, command, args = parse_irc_msg(line)                if command == ""PING"":                    self.log_debug(""[{}] Ping? Pong!"".format(args[0]))                    self.sock.send(to_bytes(""PONG :{}\r\n"".format(args[0])))                if command == ""ERROR"":                    raise IRCError(line)                msg = {                    ""origin"": origin,                    ""command"": command,                    ""args"": args,                }                self.handle_events(msg)",6c96dd27-12e1-460b-a9f2-058575469d7a
addons,IRC.py,handle_events,175,229,"def handle_events(self, msg):        if msg[""command""] != ""PRIVMSG"" or not msg[""origin""]:            return        sender_nick = msg[""origin""].split('@')[0].split('!')[0]        recipient = msg[""args""][0]        text = msg[""args""][1]        if recipient != self.config.get(""nick""):            return        #: HANDLE CTCP ANTI FLOOD/BOT PROTECTION        if text[0] == '\x01' and text[-1] == '\x01':  #: CTCP            ctcp_data = text[1:-1].split(' ', 1)            ctcp_command = ctcp_data[0]            ctcp_args = ctcp_data[1] if len(ctcp_data) > 1 else """"            if ctcp_command == ""VERSION"":                self.log_debug(""Sending CTCP VERSION"")                self.sock.send(                    to_bytes(""NOTICE {} :{}\r\n"".format(msg[""origin""], ""pyLoad! IRC Interface""))                )                return            elif ctcp_command == ""TIME"":                self.log_debug(""Sending CTCP TIME"")                self.sock.send(to_bytes(""NOTICE {} :{}\r\n"".format(msg[""origin""], time.time())))                return            elif ctcp_command == ""PING"":                self.log_debug(""[{}] Ping? Pong!"".format(sender_nick))                self.sock.send(to_bytes(""NOTICE {} :\x01PING {}\x01\r\n"".format(sender_nick, ctcp_args)))  #@NOTE: PING is not a typo            elif ctcp_command == ""LAG"":                self.log_debug(""Received CTCP LAG"")  #: don't know how to answer                return        if sender_nick not in self.config.get(""owner"").split():            return        temp = text.split()        try:            command = temp[0]            args = text.split()[1:]        except IndexError:            command = ""error""            args = []        try:            res = self.do_bot_command(command, args)            for line in res:                self.response(line, msg[""origin""])                time.sleep(1)  #: avoid Excess Flood        except Exception as exc:            self.log_error(exc)",,"def handle_events(self, msg):        if msg[""command""] != ""PRIVMSG"" or not msg[""origin""]:            return        sender_nick = msg[""origin""].split('@')[0].split('!')[0]        recipient = msg[""args""][0]        text = msg[""args""][1]        if recipient != self.config.get(""nick""):            return        #: HANDLE CTCP ANTI FLOOD/BOT PROTECTION        if text[0] == '\x01' and text[-1] == '\x01':  #: CTCP            ctcp_data = text[1:-1].split(' ', 1)            ctcp_command = ctcp_data[0]            ctcp_args = ctcp_data[1] if len(ctcp_data) > 1 else """"            if ctcp_command == ""VERSION"":                self.log_debug(""Sending CTCP VERSION"")                self.sock.send(                    to_bytes(""NOTICE {} :{}\r\n"".format(msg[""origin""], ""pyLoad! IRC Interface""))                )                return            elif ctcp_command == ""TIME"":                self.log_debug(""Sending CTCP TIME"")                self.sock.send(to_bytes(""NOTICE {} :{}\r\n"".format(msg[""origin""], time.time())))                return            elif ctcp_command == ""PING"":                self.log_debug(""[{}] Ping? Pong!"".format(sender_nick))                self.sock.send(to_bytes(""NOTICE {} :\x01PING {}\x01\r\n"".format(sender_nick, ctcp_args)))  #@NOTE: PING is not a typo            elif ctcp_command == ""LAG"":                self.log_debug(""Received CTCP LAG"")  #: don't know how to answer                return        if sender_nick not in self.config.get(""owner"").split():            return        temp = text.split()        try:            command = temp[0]            args = text.split()[1:]        except IndexError:            command = ""error""            args = []        try:            res = self.do_bot_command(command, args)            for line in res:                self.response(line, msg[""origin""])                time.sleep(1)  #: avoid Excess Flood        except Exception as exc:            self.log_error(exc)",f047f4d3-0ad5-4a94-8f16-28a021aed6dc
addons,IRC.py,response,231,236,"def response(self, msg, origin=""""):        if origin == """":            for t in self.config.get(""owner"").split():                self.sock.send(to_bytes(""PRIVMSG {} :{}\r\n"".format(t.strip(), msg)))        else:            self.sock.send(to_bytes(""PRIVMSG {} :{}\r\n"".format(origin.split(""!"", 1)[0], msg)))",,"def response(self, msg, origin=""""):        if origin == """":            for t in self.config.get(""owner"").split():                self.sock.send(to_bytes(""PRIVMSG {} :{}\r\n"".format(t.strip(), msg)))        else:            self.sock.send(to_bytes(""PRIVMSG {} :{}\r\n"".format(origin.split(""!"", 1)[0], msg)))",18ecc824-3fed-40db-9426-0ac7a0df9ebc
addons,IRC.py,exit,238,240,"def exit(self):        self.sock.send(b""QUIT :byebye\r\n"")        self.sock.close()",,"def exit(self):        self.sock.send(b""QUIT :byebye\r\n"")        self.sock.close()",88ed6518-d0f8-481d-b4b4-e51dd681d7fb
addons,IRC.py,__init__,244,245,"def __init__(self, value):        self.value = value",,"def __init__(self, value):        self.value = value",96dbd67c-5d8b-4e1b-b6e1-11cc7cacd116
addons,IRC.py,__str__,247,248,def __str__(self):        return repr(self.value),,def __str__(self):        return repr(self.value),07816d1d-d875-4bce-a83e-68535c490605
addons,JustPremium.py,init,27,28,"def init(self):        self.event_map = {""links_added"": ""links_added""}",,"def init(self):        self.event_map = {""links_added"": ""links_added""}",2adc0fa8-c0cc-48c2-9b6f-8e58d82a4e30
addons,JustPremium.py,links_added,30,83,"def links_added(self, links, pid):        hosterdict = self.pyload.plugin_manager.downloader_plugins        linkdict = self.pyload.api.check_urls(links)        premiumplugins = set(            account.type            for account in self.pyload.api.get_accounts(False)            if account.valid and account.premium        )        multihosters = set(            hoster            for hoster in self.pyload.plugin_manager.downloader_plugins            if ""new_name"" in hosterdict[hoster]            and hosterdict[hoster][""new_name""] in premiumplugins        )        excluded = [            """".join(                part.capitalize()                for part in re.split(r""(\.|\d+)"", domain)                if part != "".""            )            for domain in self.config.get(""excluded"")            .replace("" "", """")            .replace("","", ""|"")            .replace("";"", ""|"")            .split(""|"")        ]        included = [            """".join(                part.capitalize()                for part in re.split(r""(\.|\d+)"", domain)                if part != "".""            )            for domain in self.config.get(""included"")            .replace("" "", """")            .replace("","", ""|"")            .replace("";"", ""|"")            .split(""|"")        ]        hosterlist = (            (premiumplugins | multihosters).union(excluded).difference(included)        )        #: Found at least one hoster with account or multihoster        if not any(True for pluginname in linkdict if pluginname in hosterlist):            return        for pluginname in set(linkdict.keys()) - hosterlist:            self.log_info(self._(""Remove links of plugin: {}"").format(pluginname))            for link in linkdict[pluginname]:                self.log_debug(f""Remove link: {link}"")                links.remove(link)",,"def links_added(self, links, pid):        hosterdict = self.pyload.plugin_manager.downloader_plugins        linkdict = self.pyload.api.check_urls(links)        premiumplugins = set(            account.type            for account in self.pyload.api.get_accounts(False)            if account.valid and account.premium        )        multihosters = set(            hoster            for hoster in self.pyload.plugin_manager.downloader_plugins            if ""new_name"" in hosterdict[hoster]            and hosterdict[hoster][""new_name""] in premiumplugins        )        excluded = [            """".join(                part.capitalize()                for part in re.split(r""(\.|\d+)"", domain)                if part != "".""            )            for domain in self.config.get(""excluded"")            .replace("" "", """")            .replace("","", ""|"")            .replace("";"", ""|"")            .split(""|"")        ]        included = [            """".join(                part.capitalize()                for part in re.split(r""(\.|\d+)"", domain)                if part != "".""            )            for domain in self.config.get(""included"")            .replace("" "", """")            .replace("","", ""|"")            .replace("";"", ""|"")            .split(""|"")        ]        hosterlist = (            (premiumplugins | multihosters).union(excluded).difference(included)        )        #: Found at least one hoster with account or multihoster        if not any(True for pluginname in linkdict if pluginname in hosterlist):            return        for pluginname in set(linkdict.keys()) - hosterlist:            self.log_info(self._(""Remove links of plugin: {}"").format(pluginname))            for link in linkdict[pluginname]:                self.log_debug(f""Remove link: {link}"")                links.remove(link)",cb7faee7-2143-4172-95f0-d4bedeac953b
addons,LinkFilter.py,activate,29,30,"def activate(self):        self.m.add_event(""links_added"", self.filter_links)",,"def activate(self):        self.m.add_event(""links_added"", self.filter_links)",ebe9063e-6932-4e24-a4e0-f6ed6d53209a
addons,LinkFilter.py,deactivate,32,33,"def deactivate(self):        self.m.remove_event(""links_added"", self.filter_links)",,"def deactivate(self):        self.m.remove_event(""links_added"", self.filter_links)",40c9ce5f-c862-4fc1-877e-d2ca78f9cbec
addons,LinkFilter.py,filter_links,35,43,"def filter_links(self, links, pid):        filters = self.config.get(""filter"").replace("" "", """")        if filters == """":            return        filters = filters.split("","")        if self.config.get(""list_type"", ""unlisted"") == ""listed"":            self.whitelist(links, filters)        else:            self.blacklist(links, filters)",,"def filter_links(self, links, pid):        filters = self.config.get(""filter"").replace("" "", """")        if filters == """":            return        filters = filters.split("","")        if self.config.get(""list_type"", ""unlisted"") == ""listed"":            self.whitelist(links, filters)        else:            self.blacklist(links, filters)",243c6779-6c6c-486e-bf0f-d8dd1d075251
addons,LinkFilter.py,whitelist,45,64,"def whitelist(self, links, filters):        plugin_dict = dict(self.pyload.plugin_manager.parse_urls(links))        link_count = len(links)        links[:] = [            link            for link in links            if any(link.find(fltr) != -1 for fltr in filters)            or not self.is_downloader_link(link)            and plugin_dict[link] != ""DefaultPlugin""        ]        link_count -= len(links)        if link_count > 0:            link_type = """" if self.config.get(""filter_all"") else ""downloader ""            link_type += ""link"" if link_count == 1 else ""links""            self.log_warning(                self._(""Whitelist filter removed {} {} not containing ({})"").format(                    link_count, link_type, "", "".join(filters)                )            )",,"def whitelist(self, links, filters):        plugin_dict = dict(self.pyload.plugin_manager.parse_urls(links))        link_count = len(links)        links[:] = [            link            for link in links            if any(link.find(fltr) != -1 for fltr in filters)            or not self.is_downloader_link(link)            and plugin_dict[link] != ""DefaultPlugin""        ]        link_count -= len(links)        if link_count > 0:            link_type = """" if self.config.get(""filter_all"") else ""downloader ""            link_type += ""link"" if link_count == 1 else ""links""            self.log_warning(                self._(""Whitelist filter removed {} {} not containing ({})"").format(                    link_count, link_type, "", "".join(filters)                )            )",9cdd676a-06a6-4d13-8ce0-d3d192adab3c
addons,LinkFilter.py,blacklist,66,83,"def blacklist(self, links, filters):        for fltr in filters:            link_count = len(links)            links[:] = [                link                for link in links                if link.find(fltr) == -1 or not self.is_downloader_link(link)            ]            link_count -= len(links)            if link_count > 0:                link_type = """" if self.config.get(""filter_all"") else ""hoster ""                link_type += ""link"" if link_count == 1 else ""links""                self.log_warning(                    ""Blacklist filter removed {} {} containing {}"".format(                        link_count, link_type, fltr                    )                )",,"def blacklist(self, links, filters):        for fltr in filters:            link_count = len(links)            links[:] = [                link                for link in links                if link.find(fltr) == -1 or not self.is_downloader_link(link)            ]            link_count -= len(links)            if link_count > 0:                link_type = """" if self.config.get(""filter_all"") else ""hoster ""                link_type += ""link"" if link_count == 1 else ""links""                self.log_warning(                    ""Blacklist filter removed {} {} containing {}"".format(                        link_count, link_type, fltr                    )                )",a7c13d70-4e66-4d2e-b02e-9e4a557e425d
addons,LinkFilter.py,is_downloader_link,85,92,"def is_downloader_link(self, link):        if self.config.get(""filter_all""):            # declare all links as downloader links so the filter will work on all links            return True        for item in self.pyload.plugin_manager.downloader_plugins.items():            if item[1][""re""].match(link):                return True        return False",,"def is_downloader_link(self, link):        if self.config.get(""filter_all""):            # declare all links as downloader links so the filter will work on all links            return True        for item in self.pyload.plugin_manager.downloader_plugins.items():            if item[1][""re""].match(link):                return True        return False",9e48ca80-9716-4d07-9437-c3df00622b4c
addons,LogMarker.py,activated,27,30,"def activated(self):        self.periodical.start(            timedelta(hours=1).total_seconds() - 1, delay=seconds.to_nexthour(strict=True) - 1        )",,"def activated(self):        self.periodical.start(            timedelta(hours=1).total_seconds() - 1, delay=seconds.to_nexthour(strict=True) - 1        )",cb5afa70-de42-4913-98e5-8a0b92035ae0
addons,LogMarker.py,periodical_task,32,41,"def periodical_task(self):        if self.config.get(""mark_day"") and datetime.datetime.today().hour == 0:            self.log_info(""------------------------------------------------"")            self.log_info(self._(""------------------- DAY MARK -------------------""))            self.log_info(""------------------------------------------------"")        elif self.config.get(""mark_hour""):            self.log_info(""------------------------------------------------"")            self.log_info(self._(""------------------- HOUR MARK ------------------""))            self.log_info(""------------------------------------------------"")",,"def periodical_task(self):        if self.config.get(""mark_day"") and datetime.datetime.today().hour == 0:            self.log_info(""------------------------------------------------"")            self.log_info(self._(""------------------- DAY MARK -------------------""))            self.log_info(""------------------------------------------------"")        elif self.config.get(""mark_hour""):            self.log_info(""------------------------------------------------"")            self.log_info(self._(""------------------- HOUR MARK ------------------""))            self.log_info(""------------------------------------------------"")",3e07de9f-0d78-4944-9da9-916881002d68
addons,MergeFiles.py,package_finished,23,82,"def package_finished(self, pack):        files = {}        fid_dict = {}        for fid, data in pack.get_children().items():            if re.search(r""\.\d{3}$"", data[""name""]):                if data[""name""][:-4] not in files:                    files[data[""name""][:-4]] = []                files[data[""name""][:-4]].append(data[""name""])                files[data[""name""][:-4]].sort()                fid_dict[data[""name""]] = fid        dl_folder = self.pyload.config.get(""general"", ""storage_folder"")        if self.pyload.config.get(""general"", ""folder_per_package""):            dl_folder = os.path.join(dl_folder, pack.folder)        for name, file_list in files.items():            self.log_info(self._(""Starting merging of""), name)            with open(os.path.join(dl_folder, name), mode=""wb"") as final_file:                for splitted_file in file_list:                    self.log_debug(""Merging part"", splitted_file)                    pyfile = self.pyload.files.get_file(fid_dict[splitted_file])                    pyfile.set_status(""processing"")                    try:                        with open(                            os.path.join(dl_folder, splitted_file), ""rb""                        ) as s_file:                            size_written = 0                            s_file_size = int(                                os.path.getsize(os.path.join(dl_folder, splitted_file))                            )                            while True:                                f_buffer = s_file.read(self.BUFFER_SIZE)                                if f_buffer:                                    final_file.write(f_buffer)                                    size_written += self.BUFFER_SIZE                                    pyfile.set_progress(                                        (size_written * 100) // s_file_size                                    )                                else:                                    break                        self.log_debug(""Finished merging part"", splitted_file)                    except Exception as exc:                        self.log_error(                            exc,                            exc_info=self.pyload.debug > 1,                            stack_info=self.pyload.debug > 2,                        )                    finally:                        pyfile.set_progress(100)                        pyfile.set_status(""finished"")                        pyfile.release()            self.log_info(self._(""Finished merging of""), name)",,"def package_finished(self, pack):        files = {}        fid_dict = {}        for fid, data in pack.get_children().items():            if re.search(r""\.\d{3}$"", data[""name""]):                if data[""name""][:-4] not in files:                    files[data[""name""][:-4]] = []                files[data[""name""][:-4]].append(data[""name""])                files[data[""name""][:-4]].sort()                fid_dict[data[""name""]] = fid        dl_folder = self.pyload.config.get(""general"", ""storage_folder"")        if self.pyload.config.get(""general"", ""folder_per_package""):            dl_folder = os.path.join(dl_folder, pack.folder)        for name, file_list in files.items():            self.log_info(self._(""Starting merging of""), name)            with open(os.path.join(dl_folder, name), mode=""wb"") as final_file:                for splitted_file in file_list:                    self.log_debug(""Merging part"", splitted_file)                    pyfile = self.pyload.files.get_file(fid_dict[splitted_file])                    pyfile.set_status(""processing"")                    try:                        with open(                            os.path.join(dl_folder, splitted_file), ""rb""                        ) as s_file:                            size_written = 0                            s_file_size = int(                                os.path.getsize(os.path.join(dl_folder, splitted_file))                            )                            while True:                                f_buffer = s_file.read(self.BUFFER_SIZE)                                if f_buffer:                                    final_file.write(f_buffer)                                    size_written += self.BUFFER_SIZE                                    pyfile.set_progress(                                        (size_written * 100) // s_file_size                                    )                                else:                                    break                        self.log_debug(""Finished merging part"", splitted_file)                    except Exception as exc:                        self.log_error(                            exc,                            exc_info=self.pyload.debug > 1,                            stack_info=self.pyload.debug > 2,                        )                    finally:                        pyfile.set_progress(100)                        pyfile.set_status(""finished"")                        pyfile.release()            self.log_info(self._(""Finished merging of""), name)",b07fdd29-f294-4265-aa95-12c0c86a32ef
addons,MultiHome.py,__init__,9,11,"def __init__(self, address):        self.address = address        self.history = {}",,"def __init__(self, address):        self.address = address        self.history = {}",48f96f21-4708-4b51-9a64-a130785db331
addons,MultiHome.py,last_plugin_access,13,17,"def last_plugin_access(self, plugin_name, account):        if (plugin_name, account) in self.history:            return self.history[(plugin_name, account)]        else:            return 0",,"def last_plugin_access(self, plugin_name, account):        if (plugin_name, account) in self.history:            return self.history[(plugin_name, account)]        else:            return 0",afe28591-3572-4082-b2a9-e7758829e7b6
addons,MultiHome.py,use_for,19,20,"def use_for(self, plugin_name, account):        self.history[(plugin_name, account)] = time.time()",,"def use_for(self, plugin_name, account):        self.history[(plugin_name, account)] = time.time()",93fcf36d-e723-4968-ba93-bacc49b75652
addons,MultiHome.py,__repr__,22,23,"def __repr__(self):        return ""<Interface - {}>"".format(self.address)",,"def __repr__(self):        return ""<Interface - {}>"".format(self.address)",0d2d2128-848f-4595-aeb1-d813e25e33f4
addons,MultiHome.py,init,44,54,"def init(self):        self.interfaces = []        self.old_get_request = None        self.parse_interfaces(self.config.get(""interfaces"").split("";""))        if not self.interfaces:            self.parse_interfaces([self.pyload.config.get(""download"", ""interface"")])            self.pyload.config.set_plugin(                self.__name__, ""interfaces"", self.to_config()            )",,"def init(self):        self.interfaces = []        self.old_get_request = None        self.parse_interfaces(self.config.get(""interfaces"").split("";""))        if not self.interfaces:            self.parse_interfaces([self.pyload.config.get(""download"", ""interface"")])            self.pyload.config.set_plugin(                self.__name__, ""interfaces"", self.to_config()            )",b8a827c4-a229-44a9-8290-e5c006fbb6d0
addons,MultiHome.py,to_config,56,57,"def to_config(self):        return "";"".join(i.address for i in self.interfaces)",,"def to_config(self):        return "";"".join(i.address for i in self.interfaces)",8e0e0d04-5e79-4ddd-aed7-364390cc20a7
addons,MultiHome.py,parse_interfaces,59,63,"def parse_interfaces(self, interfaces):        for interface in interfaces:            if not interface or str(interface).lower() == ""none"":                continue            self.interfaces.append(Interface(interface))",,"def parse_interfaces(self, interfaces):        for interface in interfaces:            if not interface or str(interface).lower() == ""none"":                continue            self.interfaces.append(Interface(interface))",9aab2d2e-8bd8-4662-ba72-ad15e3d641fa
addons,MultiHome.py,activate,65,69,def activate(self):        self.old_get_request = self.pyload.request_factory.get_request        new_get_request = self.build_get_request()        self.pyload.request_factory.get_request = lambda *args: new_get_request(*args),,def activate(self):        self.old_get_request = self.pyload.request_factory.get_request        new_get_request = self.build_get_request()        self.pyload.request_factory.get_request = lambda *args: new_get_request(*args),b6aa9224-bd88-4e69-ba36-e92a3bbb9336
addons,MultiHome.py,best_interface,71,80,"def best_interface(self, plugin_name, account):        best = None        for interface in self.interfaces:            if not best or interface.last_plugin_access(                plugin_name, account            ) < best.last_plugin_access(plugin_name, account):                best = interface        return best",,"def best_interface(self, plugin_name, account):        best = None        for interface in self.interfaces:            if not best or interface.last_plugin_access(                plugin_name, account            ) < best.last_plugin_access(plugin_name, account):                best = interface        return best",020b16bc-7224-4405-bf8b-31c11db869c0
addons,MultiHome.py,get_request,82,92,"def get_request(self, plugin_name, account=None):        iface = self.best_interface(plugin_name, account)        if iface is None:            self.log_warning(self._(""Best interface not found""))            return self.old_get_request(plugin_name, account)        iface.use_for(plugin_name, account)        self.pyload.request_factory.iface = lambda: iface.address        self.log_debug(""Using address"", iface.address)        return self.old_get_request(plugin_name, account)",,"def get_request(self, plugin_name, account=None):        iface = self.best_interface(plugin_name, account)        if iface is None:            self.log_warning(self._(""Best interface not found""))            return self.old_get_request(plugin_name, account)        iface.use_for(plugin_name, account)        self.pyload.request_factory.iface = lambda: iface.address        self.log_debug(""Using address"", iface.address)        return self.old_get_request(plugin_name, account)",36905fc9-d9aa-4d90-8c56-ff97ada66884
addons,MultiHome.py,build_get_request,94,98,def build_get_request(self):        def resfunc(*args):            return self.get_request(*args)        return resfunc,,def build_get_request(self):        def resfunc(*args):            return self.get_request(*args)        return resfunc,ac19eecc-8c46-4a46-ab66-3d638f19d2af
addons,PushBullet.py,get_key,38,39,"def get_key(self):        return self.config.get(""tokenkey"")",,"def get_key(self):        return self.config.get(""tokenkey"")",9bd4d3ad-ac14-4c11-a3f3-3be70012ef0d
addons,PushBullet.py,send,41,49,"def send(self, event, msg, key):        req = get_request()        req.c.setopt(pycurl.HTTPHEADER, [""Access-Token: {}"".format(str(key))])        self.load(            ""https://api.pushbullet.com/v2/pushes"",            post={""type"": ""note"", ""title"": event, ""message"": msg},            req=req,        )",,"def send(self, event, msg, key):        req = get_request()        req.c.setopt(pycurl.HTTPHEADER, [""Access-Token: {}"".format(str(key))])        self.load(            ""https://api.pushbullet.com/v2/pushes"",            post={""type"": ""note"", ""title"": event, ""message"": msg},            req=req,        )",6798ec6e-7687-41ca-a80a-0ebad1e0950d
addons,PushOver.py,get_key,35,36,"def get_key(self):        return self.config.get(""tokenkey""), self.config.get(""userkey"")",,"def get_key(self):        return self.config.get(""tokenkey""), self.config.get(""userkey"")",cae49ed8-7c5d-42d5-a1b6-6e5ddf8d5f4b
addons,PushOver.py,send,38,48,"def send(self, event, msg, key):        token, user = key        self.load(            ""https://api.pushover.net/1/messages.json"",            post={                ""token"": token,                ""user"": user,                ""title"": event,                ""message"": msg or event,            },        )",,"def send(self, event, msg, key):        token, user = key        self.load(            ""https://api.pushover.net/1/messages.json"",            post={                ""token"": token,                ""user"": user,                ""title"": event,                ""message"": msg or event,            },        )",137d08c3-eb8e-45d2-ab04-2ee5810288dc
addons,RestartFailed.py,periodical_task,22,24,"def periodical_task(self):        self.log_info(self._(""Restarting all failed downloads...""))        self.pyload.api.restart_failed()",,"def periodical_task(self):        self.log_info(self._(""Restarting all failed downloads...""))        self.pyload.api.restart_failed()",b0b55d81-1ade-489b-bbbe-323545a6c4e2
addons,RestartFailed.py,activate,26,27,"def activate(self):        self.periodical.start(self.config.get(""interval"") * 60)",,"def activate(self):        self.periodical.start(self.config.get(""interval"") * 60)",c89213c6-7664-409c-b3c6-90795d34779e
addons,SkipRev.py,_name,25,26,"def _name(self, pyfile):        return pyfile.plugin.get_info(pyfile.url)[""name""]",,"def _name(self, pyfile):        return pyfile.plugin.get_info(pyfile.url)[""name""]",61abfd9d-4c73-495c-aa1a-f13f18198dcc
addons,SkipRev.py,_create_pyfile,28,41,"def _create_pyfile(self, data):        pylink = self.pyload.api._convert_py_file(data)        return PyFile(            self.pyload.files,            pylink.fid,            pylink.url,            pylink.name,            pylink.size,            pylink.status,            pylink.error,            pylink.plugin,            pylink.package_id,            pylink.order,        )",,"def _create_pyfile(self, data):        pylink = self.pyload.api._convert_py_file(data)        return PyFile(            self.pyload.files,            pylink.fid,            pylink.url,            pylink.name,            pylink.size,            pylink.status,            pylink.error,            pylink.plugin,            pylink.package_id,            pylink.order,        )",d7f723e7-30dd-46f8-97a8-8529bc8f70a2
addons,SkipRev.py,download_preparing,43,71,"def download_preparing(self, pyfile):        name = self._name(pyfile)        if (            pyfile.statusname == ""unskipped""            or not name.endswith("".rev"")            or "".part"" not in name        ):            return        revtokeep = (            -1 if self.config.get(""mode"") == ""Auto"" else self.config.get(""revtokeep"")        )        if revtokeep:            status_list = (1, 4, 8, 9, 14) if revtokeep < 0 else (1, 3, 4, 8, 9, 14)            basename = name.rsplit(""."", 2)[0].replace(""."", r""\."")            pyname = re.compile(rf""{basename}\.part\d+\.rev$"")            queued = [                True                for fid, fdata in pyfile.package().get_children().items()                if fdata[""status""] not in status_list and pyname.match(fdata[""name""])            ].count(True)            if not queued or queued < revtokeep:  #: Keep one rev at least in auto mode                return        pyfile.set_custom_status(""SkipRev"", ""skipped"")",,"def download_preparing(self, pyfile):        name = self._name(pyfile)        if (            pyfile.statusname == ""unskipped""            or not name.endswith("".rev"")            or "".part"" not in name        ):            return        revtokeep = (            -1 if self.config.get(""mode"") == ""Auto"" else self.config.get(""revtokeep"")        )        if revtokeep:            status_list = (1, 4, 8, 9, 14) if revtokeep < 0 else (1, 3, 4, 8, 9, 14)            basename = name.rsplit(""."", 2)[0].replace(""."", r""\."")            pyname = re.compile(rf""{basename}\.part\d+\.rev$"")            queued = [                True                for fid, fdata in pyfile.package().get_children().items()                if fdata[""status""] not in status_list and pyname.match(fdata[""name""])            ].count(True)            if not queued or queued < revtokeep:  #: Keep one rev at least in auto mode                return        pyfile.set_custom_status(""SkipRev"", ""skipped"")",d2115f0f-3e60-4e9c-9afa-3130f66f3ec2
addons,SkipRev.py,download_failed,73,98,"def download_failed(self, pyfile):        if pyfile.name.rsplit(""."", 1)[-1].strip() not in (""rar"", ""rev""):            return        revtokeep = (            -1 if self.config.get(""mode"") == ""Auto"" else self.config.get(""revtokeep"")        )        if not revtokeep:            return        basename = pyfile.name.rsplit(""."", 2)[0].replace(""."", r""\."")        pyname = re.compile(rf""{basename}\.part\d+\.rev$"")        for fid, fdata in pyfile.package().get_children().items():            if fdata[""status""] == 4 and pyname.match(fdata[""name""]):                pyfile_new = self._create_pyfile(fdata)                if revtokeep > -1 or pyfile.name.endswith("".rev""):                    pyfile_new.set_status(""queued"")                else:                    pyfile_new.set_custom_status(self._(""unskipped""), ""queued"")                self.pyload.files.save()                pyfile_new.release()                return",,"def download_failed(self, pyfile):        if pyfile.name.rsplit(""."", 1)[-1].strip() not in (""rar"", ""rev""):            return        revtokeep = (            -1 if self.config.get(""mode"") == ""Auto"" else self.config.get(""revtokeep"")        )        if not revtokeep:            return        basename = pyfile.name.rsplit(""."", 2)[0].replace(""."", r""\."")        pyname = re.compile(rf""{basename}\.part\d+\.rev$"")        for fid, fdata in pyfile.package().get_children().items():            if fdata[""status""] == 4 and pyname.match(fdata[""name""]):                pyfile_new = self._create_pyfile(fdata)                if revtokeep > -1 or pyfile.name.endswith("".rev""):                    pyfile_new.set_status(""queued"")                else:                    pyfile_new.set_custom_status(self._(""unskipped""), ""queued"")                self.pyload.files.save()                pyfile_new.release()                return",2b4b1f8a-f352-414a-9e13-495fb3287b7b
addons,TORRENT.py,activate,22,26,"def activate(self):        self.pyload.addon_manager.add_event(""plugin_updated"", self.plugins_updated)        self.torrent_plugin = self.config.get(""torrent_plugin"")        self._associate(self.torrent_plugin)        self._report_status()",,"def activate(self):        self.pyload.addon_manager.add_event(""plugin_updated"", self.plugins_updated)        self.torrent_plugin = self.config.get(""torrent_plugin"")        self._associate(self.torrent_plugin)        self._report_status()",bd2970a1-6631-4e20-8429-8e5a6a07d41a
addons,TORRENT.py,deactivate,28,33,"def deactivate(self):        self.pyload.addon_manager.remove_event(""plugin_updated"", self.plugins_updated)        self._remove_association(self.torrent_plugin)        self.torrent_plugin = ""None""        if self.pyload.exiting is False:            self._report_status()",,"def deactivate(self):        self.pyload.addon_manager.remove_event(""plugin_updated"", self.plugins_updated)        self._remove_association(self.torrent_plugin)        self.torrent_plugin = ""None""        if self.pyload.exiting is False:            self._report_status()",2f76d0d3-6adc-4795-ba43-c5e3df0daa1f
addons,TORRENT.py,plugins_updated,35,38,"def plugins_updated(self, updated_plugins):        if self.torrent_plugin != ""None"":            self._remove_association(self.torrent_plugin)            self._associate(self.torrent_plugin)",,"def plugins_updated(self, updated_plugins):        if self.torrent_plugin != ""None"":            self._remove_association(self.torrent_plugin)            self._associate(self.torrent_plugin)",48c11f38-9287-4c2d-a5aa-790f754e5402
addons,TORRENT.py,config_changed,40,45,"def config_changed(self, *args):        if args[3] == ""plugin"" and args[0] == ""TORRENT"" and args[1] == ""torrent_plugin"" and args[2] != self.torrent_plugin:            self._remove_association(self.torrent_plugin)            self.torrent_plugin = args[2]            self._associate(self.torrent_plugin)            self._report_status()",,"def config_changed(self, *args):        if args[3] == ""plugin"" and args[0] == ""TORRENT"" and args[1] == ""torrent_plugin"" and args[2] != self.torrent_plugin:            self._remove_association(self.torrent_plugin)            self.torrent_plugin = args[2]            self._associate(self.torrent_plugin)            self._report_status()",e6bc37f4-2caf-44d9-b463-c81c50abd7d5
addons,TORRENT.py,_report_status,47,51,"def _report_status(self):        if self.torrent_plugin == ""None"":            self.log_warning(self._(""torrents / magnets are not associated with any plugin""))        else:            self.log_info(self._(""Using {} to handle torrents / magnets"").format(self.torrent_plugin.split("":"")[1]))",,"def _report_status(self):        if self.torrent_plugin == ""None"":            self.log_warning(self._(""torrents / magnets are not associated with any plugin""))        else:            self.log_info(self._(""Using {} to handle torrents / magnets"").format(self.torrent_plugin.split("":"")[1]))",f5374101-0141-41ca-b4d7-a4fac6960047
addons,TORRENT.py,_associate,53,64,"def _associate(self, plugin):        if plugin != ""None"":            plugin_type, plugin_name = plugin.split("":"")            plugin_type = ""decrypter"" if plugin_type == ""c"" else ""downloader""            hdict = self.pyload.plugin_manager.plugins[""container""][""TORRENT""]            hdict[""pattern""] = r""(?!(?:file|https?)://).+\.(?:torrent|magnet)""            hdict[""re""] = re.compile(hdict[""pattern""])            hdict = self.pyload.plugin_manager.plugins[plugin_type][plugin_name]            hdict[""pattern""] = r""(?:file|https?)://.+\.torrent|magnet:\?.+""            hdict[""re""] = re.compile(hdict[""pattern""])",,"def _associate(self, plugin):        if plugin != ""None"":            plugin_type, plugin_name = plugin.split("":"")            plugin_type = ""decrypter"" if plugin_type == ""c"" else ""downloader""            hdict = self.pyload.plugin_manager.plugins[""container""][""TORRENT""]            hdict[""pattern""] = r""(?!(?:file|https?)://).+\.(?:torrent|magnet)""            hdict[""re""] = re.compile(hdict[""pattern""])            hdict = self.pyload.plugin_manager.plugins[plugin_type][plugin_name]            hdict[""pattern""] = r""(?:file|https?)://.+\.torrent|magnet:\?.+""            hdict[""re""] = re.compile(hdict[""pattern""])",35098935-03fd-425b-9be3-98c710d0a60e
addons,TORRENT.py,_remove_association,66,77,"def _remove_association(self, plugin):        if plugin != ""None"":            plugin_type, plugin_name = plugin.split("":"")            plugin_type = ""decrypter"" if plugin_type == ""c"" else ""downloader""            hdict = self.pyload.plugin_manager.plugins[plugin_type][plugin_name]            hdict[""pattern""] = r""^unmatchable$""            hdict[""re""] = re.compile(hdict[""pattern""])            hdict = self.pyload.plugin_manager.plugins[""container""][""TORRENT""]            hdict[""pattern""] = r""(?:file|https?)://.+\.torrent|magnet:\?.+|(?!(?:file|https?)://).+\.(?:torrent|magnet)""            hdict[""re""] = re.compile(hdict[""pattern""])",,"def _remove_association(self, plugin):        if plugin != ""None"":            plugin_type, plugin_name = plugin.split("":"")            plugin_type = ""decrypter"" if plugin_type == ""c"" else ""downloader""            hdict = self.pyload.plugin_manager.plugins[plugin_type][plugin_name]            hdict[""pattern""] = r""^unmatchable$""            hdict[""re""] = re.compile(hdict[""pattern""])            hdict = self.pyload.plugin_manager.plugins[""container""][""TORRENT""]            hdict[""pattern""] = r""(?:file|https?)://.+\.torrent|magnet:\?.+|(?!(?:file|https?)://).+\.(?:torrent|magnet)""            hdict[""re""] = re.compile(hdict[""pattern""])",27c2cded-dc01-4588-a65d-e06bb69bf919
addons,TransmissionRPC.py,init,37,38,"def init(self):        self.event_map = {""links_added"": ""links_added""}",,"def init(self):        self.event_map = {""links_added"": ""links_added""}",836dd4b9-1147-449f-b51d-44d69d39f8e4
addons,TransmissionRPC.py,links_added,40,46,"def links_added(self, links, pid):        _re_link = re.compile(self.__pattern__)        urls = [link for link in links if _re_link.match(link)]        for url in urls:            self.log_debug(f""Sending link: {url}"")            self.send_to_transmission(url)            links.remove(url)",,"def links_added(self, links, pid):        _re_link = re.compile(self.__pattern__)        urls = [link for link in links if _re_link.match(link)]        for url in urls:            self.log_debug(f""Sending link: {url}"")            self.send_to_transmission(url)            links.remove(url)",0b4849ee-c8a2-4caf-ab36-de093909c7a4
addons,TransmissionRPC.py,send_to_transmission,48,97,"def send_to_transmission(self, url):        transmission_rpc_url = self.config.get(""rpc_url"")        client_request_id = self.classname + """".join(            random.choice(""0123456789ABCDEF"") for _ in range(4)        )        req = get_request()        try:            response = self.load(                transmission_rpc_url,                post=json.dumps(                    {                        ""arguments"": {""filename"": url},                        ""method"": ""torrent-add"",                        ""tag"": client_request_id,                    }                ),                req=req,            )        except Exception as exc:            if isinstance(exc, BadHeader) and exc.code == 409:                headers = parse_html_header(exc.header)                session_id = headers[""X-Transmission-Session-Id""]                req.c.setopt(                    pycurl.HTTPHEADER, [f""X-Transmission-Session-Id: {session_id}""]                )                try:                    response = self.load(                        transmission_rpc_url,                        post=json.dumps(                            {                                ""arguments"": {""filename"": url},                                ""method"": ""torrent-add"",                                ""tag"": client_request_id,                            }                        ),                        req=req,                    )                    res = json.loads(response)                    if ""result"" in res:                        self.log_debug(f""Result: {res['result']}"")                except Exception as exc:                    self.log_error(exc)            else:                self.log_error(exc)",,"def send_to_transmission(self, url):        transmission_rpc_url = self.config.get(""rpc_url"")        client_request_id = self.classname + """".join(            random.choice(""0123456789ABCDEF"") for _ in range(4)        )        req = get_request()        try:            response = self.load(                transmission_rpc_url,                post=json.dumps(                    {                        ""arguments"": {""filename"": url},                        ""method"": ""torrent-add"",                        ""tag"": client_request_id,                    }                ),                req=req,            )        except Exception as exc:            if isinstance(exc, BadHeader) and exc.code == 409:                headers = parse_html_header(exc.header)                session_id = headers[""X-Transmission-Session-Id""]                req.c.setopt(                    pycurl.HTTPHEADER, [f""X-Transmission-Session-Id: {session_id}""]                )                try:                    response = self.load(                        transmission_rpc_url,                        post=json.dumps(                            {                                ""arguments"": {""filename"": url},                                ""method"": ""torrent-add"",                                ""tag"": client_request_id,                            }                        ),                        req=req,                    )                    res = json.loads(response)                    if ""result"" in res:                        self.log_debug(f""Result: {res['result']}"")                except Exception as exc:                    self.log_error(exc)            else:                self.log_error(exc)",ac10d348-e121-416c-b4af-6a66ffc8581c
addons,UnSkipOnFail.py,download_failed,21,48,"def download_failed(self, pyfile):        msg = self._(""Looking for skipped duplicates of: {} (pid:{})"")        self.log_info(msg.format(pyfile.name, pyfile.package().id))        link = self.find_duplicate(pyfile)        if link:            self.log_info(                self._(""Queue found duplicate: {} (pid:{})"").format(                    link.name, link.package_id                )            )            #: Change status of ""link"" to ""new_status"".            #: ""link"" has to be a valid FileData object,            #: ""new_status"" has to be a valid status name            #: (i.e. ""queued"" for this Plugin)            #: It creates a temporary PyFile object using            #: ""link"" data, changes its status, and tells            #: The pyload.files-manager to save its data.            pyfile_new = self._create_pyfile(link)            pyfile_new.set_custom_status(self._(""unskipped""), ""queued"")            self.pyload.files.save()            pyfile_new.release()        else:            self.log_info(self._(""No duplicates found""))",,"def download_failed(self, pyfile):        msg = self._(""Looking for skipped duplicates of: {} (pid:{})"")        self.log_info(msg.format(pyfile.name, pyfile.package().id))        link = self.find_duplicate(pyfile)        if link:            self.log_info(                self._(""Queue found duplicate: {} (pid:{})"").format(                    link.name, link.package_id                )            )            #: Change status of ""link"" to ""new_status"".            #: ""link"" has to be a valid FileData object,            #: ""new_status"" has to be a valid status name            #: (i.e. ""queued"" for this Plugin)            #: It creates a temporary PyFile object using            #: ""link"" data, changes its status, and tells            #: The pyload.files-manager to save its data.            pyfile_new = self._create_pyfile(link)            pyfile_new.set_custom_status(self._(""unskipped""), ""queued"")            self.pyload.files.save()            pyfile_new.release()        else:            self.log_info(self._(""No duplicates found""))",786e86d7-9ece-43ab-8427-387b75d11c20
addons,UnSkipOnFail.py,find_duplicate,50,75,"def find_duplicate(self, pyfile):                for pinfo in self.pyload.api.get_queue():            #: Check if package-folder equals pyfile's package folder            if pinfo.folder != pyfile.package().folder:                continue            #: Now get packaged data w/ files/links            pdata = self.pyload.api.get_package_data(pinfo.pid)            for link in pdata.links:                #: Check if link == ""skipped""                if link.status != 4:                    continue                #: Check if link name collides with pdata's name                #: and at last check if it is not pyfile itself                if link.name == pyfile.name and link.fid != pyfile.id:                    return link","Search all packages for duplicate links to ""pyfile"".

Duplicates are links that would overwrite ""pyfile"". To test on duplicity
the package-folder and link-name of twolinks are compared (link.name). So
this method returns a list of all links with equal package-folders and
filenames as ""pyfile"", but except the data for ""pyfile"" iotselöf. It does
MOT check the link's status.","def find_duplicate(self, pyfile):        """"""        Search all packages for duplicate links to ""pyfile"".        Duplicates are links that would overwrite ""pyfile"". To test on duplicity        the package-folder and link-name of twolinks are compared (link.name). So        this method returns a list of all links with equal package-folders and        filenames as ""pyfile"", but except the data for ""pyfile"" iotselöf. It does        MOT check the link's status.        """"""        for pinfo in self.pyload.api.get_queue():            #: Check if package-folder equals pyfile's package folder            if pinfo.folder != pyfile.package().folder:                continue            #: Now get packaged data w/ files/links            pdata = self.pyload.api.get_package_data(pinfo.pid)            for link in pdata.links:                #: Check if link == ""skipped""                if link.status != 4:                    continue                #: Check if link name collides with pdata's name                #: and at last check if it is not pyfile itself                if link.name == pyfile.name and link.fid != pyfile.id:                    return link

Search all packages for duplicate links to ""pyfile"".

Duplicates are links that would overwrite ""pyfile"". To test on duplicity
the package-folder and link-name of twolinks are compared (link.name). So
this method returns a list of all links with equal package-folders and
filenames as ""pyfile"", but except the data for ""pyfile"" iotselöf. It does
MOT check the link's status.",2167478a-24e8-431c-add3-4e1b87dd4aa7
addons,UnSkipOnFail.py,_create_pyfile,77,89,"def _create_pyfile(self, pylink):        return PyFile(            self.pyload.files,            pylink.fid,            pylink.url,            pylink.name,            pylink.size,            pylink.status,            pylink.error,            pylink.plugin,            pylink.package_id,            pylink.order,        )",,"def _create_pyfile(self, pylink):        return PyFile(            self.pyload.files,            pylink.fid,            pylink.url,            pylink.name,            pylink.size,            pylink.status,            pylink.error,            pylink.plugin,            pylink.package_id,            pylink.order,        )",ced69a54-4100-435f-b07a-5c2d292605c6
addons,UpdateManager.py,activate,43,51,def activate(self):        if self.checkonstart:            self.pyload.api.pause_server()            self.update()            if not self.do_restart:                self.pyload.api.unpause_server()        self.periodical.start(10),,def activate(self):        if self.checkonstart:            self.pyload.api.pause_server()            self.update()            if not self.do_restart:                self.pyload.api.unpause_server()        self.periodical.start(10),2c251725-1a92-4bab-8576-b890cd690d16
addons,UpdateManager.py,init,53,64,"def init(self):        self.info.update({""pyload"": False, ""plugins"": False, ""last_check"": time.time()})        self.mtimes = {}  #: Store modification time for each plugin        self.event_map = {""all_downloads_processed"": ""all_downloads_processed""}        if self.config.get(""checkonstart""):            self.pyload.api.pause_server()            self.checkonstart = True        else:            self.checkonstart = False        self.do_restart = False",,"def init(self):        self.info.update({""pyload"": False, ""plugins"": False, ""last_check"": time.time()})        self.mtimes = {}  #: Store modification time for each plugin        self.event_map = {""all_downloads_processed"": ""all_downloads_processed""}        if self.config.get(""checkonstart""):            self.pyload.api.pause_server()            self.checkonstart = True        else:            self.checkonstart = False        self.do_restart = False",315fd906-499d-4a7e-b16b-9e5318a0cfe0
addons,UpdateManager.py,all_downloads_processed,66,68,def all_downloads_processed(self):        if self.do_restart:            self.pyload.api.restart(),,def all_downloads_processed(self):        if self.do_restart:            self.pyload.api.restart(),a818c54e-25e5-47d7-ab9c-325169d8c0dd
addons,UpdateManager.py,periodical_task,70,94,"def periodical_task(self):        if self.pyload.debug:            if self.config.get(""reloadplugins""):                self.autoreload_plugins()            if self.config.get(""nodebugupdate""):                return        if (            self.config.get(""checkperiod"")            and time.time()            - max(                self.MIN_CHECK_INTERVAL,                timedelta(hours=self.config.get(""checkinterval"")).total_seconds(),            )            > self.info[""last_check""]        ):            self.update()        if self.do_restart:            if (                self.pyload.thread_manager.pause                and not self.pyload.api.status_downloads()            ):                self.pyload.api.restart()",,"def periodical_task(self):        if self.pyload.debug:            if self.config.get(""reloadplugins""):                self.autoreload_plugins()            if self.config.get(""nodebugupdate""):                return        if (            self.config.get(""checkperiod"")            and time.time()            - max(                self.MIN_CHECK_INTERVAL,                timedelta(hours=self.config.get(""checkinterval"")).total_seconds(),            )            > self.info[""last_check""]        ):            self.update()        if self.do_restart:            if (                self.pyload.thread_manager.pause                and not self.pyload.api.status_downloads()            ):                self.pyload.api.restart()",fe1ac469-6ebd-48d1-b53a-6f3936d837d2
addons,UpdateManager.py,autoreload_plugins,97,129,"def autoreload_plugins(self):                reloads = []        modules = [            m            for m in sys.modules.values()            if m            and (                m.__name__.startswith(""pyload.plugins."")                or m.__name__.startswith(""userplugins."")            )            and m.__name__.count(""."") >= 2        ]        for m in modules:            root, plugin_type, plugin_name = m.__name__.rsplit(""."", 2)            plugin_id = (plugin_type, plugin_name)            if plugin_type in self.pyload.plugin_manager.plugins:                f = m.__file__.replace("".pyc"", "".py"")                if not os.path.isfile(f):                    continue                mtime = os.path.getmtime(f)                if plugin_id not in self.mtimes:                    self.mtimes[plugin_id] = mtime                elif self.mtimes[plugin_id] < mtime:                    reloads.append(plugin_id)                    self.mtimes[plugin_id] = mtime        return True if self.pyload.plugin_manager.reload_plugins(reloads) else False",Reload and reindex all modified plugins.,"def autoreload_plugins(self):        """"""        Reload and reindex all modified plugins.        """"""        reloads = []        modules = [            m            for m in sys.modules.values()            if m            and (                m.__name__.startswith(""pyload.plugins."")                or m.__name__.startswith(""userplugins."")            )            and m.__name__.count(""."") >= 2        ]        for m in modules:            root, plugin_type, plugin_name = m.__name__.rsplit(""."", 2)            plugin_id = (plugin_type, plugin_name)            if plugin_type in self.pyload.plugin_manager.plugins:                f = m.__file__.replace("".pyc"", "".py"")                if not os.path.isfile(f):                    continue                mtime = os.path.getmtime(f)                if plugin_id not in self.mtimes:                    self.mtimes[plugin_id] = mtime                elif self.mtimes[plugin_id] < mtime:                    reloads.append(plugin_id)                    self.mtimes[plugin_id] = mtime        return True if self.pyload.plugin_manager.reload_plugins(reloads) else False

Reload and reindex all modified plugins.",f3298e45-3fa5-47ce-ac03-b8acf721b0a6
addons,UpdateManager.py,server_response,131,151,"def server_response(self, line=None):        try:            html = self.load(                self.SERVER_URL, get={""v"": self.pyload.api.get_server_version()}            )        except Exception:            self.log_warning(                self._(""Unable to connect to the server to retrieve updates"")            )        else:            res = html.splitlines()            if line is not None:                try:                    res = res[line]                except IndexError:                    res = None            return res",,"def server_response(self, line=None):        try:            html = self.load(                self.SERVER_URL, get={""v"": self.pyload.api.get_server_version()}            )        except Exception:            self.log_warning(                self._(""Unable to connect to the server to retrieve updates"")            )        else:            res = html.splitlines()            if line is not None:                try:                    res = res[line]                except IndexError:                    res = None            return res",52037ed3-6c32-430d-bca7-0fb874f8459c
addons,UpdateManager.py,update,155,172,"def update(self):                if self._update() != 2 or not self.config.get(""autorestart""):            return        if not self.pyload.api.status_downloads():            self.pyload.api.restart()        else:            self.log_warning(                self._(""pyLoad restart scheduled""),                self._(                    ""Downloads are active, pyLoad restart postponed once the download is done""                ),            )            self.pyload.api.pause_server()            self.do_restart = True",Check for updates.,"def update(self):        """"""        Check for updates.        """"""        if self._update() != 2 or not self.config.get(""autorestart""):            return        if not self.pyload.api.status_downloads():            self.pyload.api.restart()        else:            self.log_warning(                self._(""pyLoad restart scheduled""),                self._(                    ""Downloads are active, pyLoad restart postponed once the download is done""                ),            )            self.pyload.api.pause_server()            self.do_restart = True

Check for updates.",da1794c2-8c10-4da4-a4af-fe3772bca740
addons,UpdateManager.py,_update,174,207,"def _update(self):        newversion = self.server_response(0)        self.info[""pyload""] = False        self.info[""last_check""] = time.time()        if not newversion:            exitcode = 0        elif newversion == self.pyload.api.get_server_version():            self.log_info(self._(""pyLoad is up to date!""))            exitcode = self.update_plugins()        elif re.search(r""^\d+(?:\.\d+){0,3}[a-z]?$"", newversion):            self.log_info(                self._(""***  New pyLoad {} available  ***"").format(newversion)            )            self.log_info(                self._(                    ""***  Get it here: https://github.com/pyload/pyload/releases  ***""                )            )            self.info[""pyload""] = True            exitcode = 3        else:            exitcode = 0        #: Exit codes:        #: -1 = No plugin updated, new pyLoad version available        #:  0 = No plugin updated        #:  1 = Plugins updated        #:  2 = Plugins updated, but restart required        return exitcode",,"def _update(self):        newversion = self.server_response(0)        self.info[""pyload""] = False        self.info[""last_check""] = time.time()        if not newversion:            exitcode = 0        elif newversion == self.pyload.api.get_server_version():            self.log_info(self._(""pyLoad is up to date!""))            exitcode = self.update_plugins()        elif re.search(r""^\d+(?:\.\d+){0,3}[a-z]?$"", newversion):            self.log_info(                self._(""***  New pyLoad {} available  ***"").format(newversion)            )            self.log_info(                self._(                    ""***  Get it here: https://github.com/pyload/pyload/releases  ***""                )            )            self.info[""pyload""] = True            exitcode = 3        else:            exitcode = 0        #: Exit codes:        #: -1 = No plugin updated, new pyLoad version available        #:  0 = No plugin updated        #:  1 = Plugins updated        #:  2 = Plugins updated, but restart required        return exitcode",632c607c-1670-45d4-adf1-051f8d4b26ef
addons,UpdateManager.py,update_plugins,210,243,"def update_plugins(self):        server_data = self.server_response()        if not server_data or server_data[0] != self.pyload.api.get_server_version():            return 0        updated = self._update_plugins(server_data)        if updated:            self.log_info(self._(""*** Plugins updated ***""))            if self.pyload.plugin_manager.reload_plugins(updated):                exitcode = 1            else:                self.log_warning(                    self._(""You have to restart pyLoad to use the updated plugins"")                )                self.info[""plugins""] = True                exitcode = 2            paused = self.pyload.thread_manager.pause            self.pyload.api.pause_server()            self.m.dispatch_event(""plugin_updated"", updated)            if not paused:                self.pyload.api.unpause_server()        else:            self.log_info(self._(""All plugins are up to date!""))            exitcode = 0        #: Exit codes:        #: 0 = No plugin updated        #: 1 = Plugins updated        #: 2 = Plugins updated, but restart required        return exitcode",,"def update_plugins(self):        server_data = self.server_response()        if not server_data or server_data[0] != self.pyload.api.get_server_version():            return 0        updated = self._update_plugins(server_data)        if updated:            self.log_info(self._(""*** Plugins updated ***""))            if self.pyload.plugin_manager.reload_plugins(updated):                exitcode = 1            else:                self.log_warning(                    self._(""You have to restart pyLoad to use the updated plugins"")                )                self.info[""plugins""] = True                exitcode = 2            paused = self.pyload.thread_manager.pause            self.pyload.api.pause_server()            self.m.dispatch_event(""plugin_updated"", updated)            if not paused:                self.pyload.api.unpause_server()        else:            self.log_info(self._(""All plugins are up to date!""))            exitcode = 0        #: Exit codes:        #: 0 = No plugin updated        #: 1 = Plugins updated        #: 2 = Plugins updated, but restart required        return exitcode",e16fd87b-4c6b-48f6-92b2-545f6d9e265b
addons,UpdateManager.py,parse_updates,245,266,"def parse_updates(self, server_data):        schema = server_data[2].split(""|"")        if ""BLACKLIST"" in server_data:            blacklist = server_data[server_data.index(""BLACKLIST"") + 1 :]            updatelist = server_data[3 : server_data.index(""BLACKLIST"")]        else:            blacklist = []            updatelist = server_data[3:]        for l in updatelist, blacklist:            nl = []            for line in l:                d = dict(zip(schema, line.split(""|"")))                d[""name""] = d[""name""].rsplit("".py"", 1)[0]                nl.append(d)            l[:] = nl        updatelist = sorted(updatelist, key=operator.itemgetter(""type"", ""name""))        blacklist = sorted(blacklist, key=operator.itemgetter(""type"", ""name""))        return updatelist, blacklist",,"def parse_updates(self, server_data):        schema = server_data[2].split(""|"")        if ""BLACKLIST"" in server_data:            blacklist = server_data[server_data.index(""BLACKLIST"") + 1 :]            updatelist = server_data[3 : server_data.index(""BLACKLIST"")]        else:            blacklist = []            updatelist = server_data[3:]        for l in updatelist, blacklist:            nl = []            for line in l:                d = dict(zip(schema, line.split(""|"")))                d[""name""] = d[""name""].rsplit("".py"", 1)[0]                nl.append(d)            l[:] = nl        updatelist = sorted(updatelist, key=operator.itemgetter(""type"", ""name""))        blacklist = sorted(blacklist, key=operator.itemgetter(""type"", ""name""))        return updatelist, blacklist",3f8e3d29-b150-4574-b77d-3130cea1f117
addons,UpdateManager.py,_update_plugins,268,395,"def _update_plugins(self, server_data):                updated = []        updatelist, blacklist = self.parse_updates(server_data)        url = server_data[1]        req = self.pyload.request_factory.get_request(self.classname)        if blacklist:            # NOTE: Protect UpdateManager from self-removing            if os.name == ""nt"":                # NOTE: Windows filesystem is case insensitive, make sure we do not                # delete legitimate plugins                whitelisted_plugins = [                    (plugin[""type""], plugin[""name""].upper()) for plugin in updatelist                ]                blacklisted_plugins = [                    (plugin[""type""], plugin[""name""])                    for plugin in blacklist                    if not (                        plugin[""name""] == self.classname                        and plugin[""type""] == self.__type__                    )                    and (plugin[""type""], plugin[""name""].upper())                    not in whitelisted_plugins                ]            else:                blacklisted_plugins = [                    (plugin[""type""], plugin[""name""])                    for plugin in blacklist                    if not (                        plugin[""name""] == self.classname                        and plugin[""type""] == self.__type__                    )                ]            c = 1            l = len(blacklisted_plugins)            for idx, plugin in enumerate(updatelist):                if c > l:                    break                plugin_name = plugin[""name""]                plugin_type = plugin[""type""]                for t, n in blacklisted_plugins:                    if n != plugin_name or t != plugin_type:                        continue                    updatelist.pop(idx)                    c += 1                    break            for t, n in self.remove_plugins(blacklisted_plugins):                self.log_info(                    self._(""Removed blacklisted plugin: {type} {name}"").format(                        type=t.upper(), name=n                    )                )        userplugins = os.path.join(self.pyload.userdir, ""userplugins"")        for plugin in updatelist:            plugin_name = plugin[""name""]            plugin_type = plugin[""type""]            plugin_version = plugin[""version""]            plugins = getattr(                self.pyload.plugin_manager, ""{}Plugins"".format(plugin_type.rstrip(""s""))            )  # TODO: Remove rstrip in 0.6.x)            oldver = (                float(plugins[plugin_name][""v""]) if plugin_name in plugins else None            )            try:                newver = float(plugin_version)            except ValueError:                self.log_error(                    self._(""Error updating plugin: {} {}"").format(                        plugin_type.rstrip(""s"").upper(), plugin_name                    ),                    self._(""Bad version number on the server""),                )                continue            if not oldver:                msg = ""New plugin: {type} {name} (v{newver:.2f})""            elif newver > oldver:                msg = ""New version of plugin: {type} {name} (v{oldver:.2f} -> v{newver:.2f})""            else:                continue            self.log_info(                msg.format(                    type=plugin_type.rstrip(                        ""s""                    ).upper(),  # TODO: Remove rstrip in 0.6.x                    name=plugin_name,                    oldver=oldver,                    newver=newver,                )            )            try:                content = self.load(url.format(plugin + "".py""), decode=False, req=req)                if req.code == 404:                    raise Exception(self._(""URL not found""))                m = self._VERSION.search(content)                if m is not None and m.group(2) == plugin_version:                    with open(                        os.path.join(userplugins, plugin_type, plugin_name + "".py""),                        ""wb"",                    ) as fp:                        fp.write(content.encode())                    updated.append((plugin_type, plugin_name))                else:                    raise Exception(self._(""Version mismatch""))            except Exception as exc:                self.log_error(                    self._(""Error updating plugin: {} {}"").format(                        plugin_type.rstrip(""s"").upper(), plugin_name                    ),                    exc,                )  # TODO: Remove rstrip in 0.6.x        return updated",Check for plugin updates.,"def _update_plugins(self, server_data):        """"""        Check for plugin updates.        """"""        updated = []        updatelist, blacklist = self.parse_updates(server_data)        url = server_data[1]        req = self.pyload.request_factory.get_request(self.classname)        if blacklist:            # NOTE: Protect UpdateManager from self-removing            if os.name == ""nt"":                # NOTE: Windows filesystem is case insensitive, make sure we do not                # delete legitimate plugins                whitelisted_plugins = [                    (plugin[""type""], plugin[""name""].upper()) for plugin in updatelist                ]                blacklisted_plugins = [                    (plugin[""type""], plugin[""name""])                    for plugin in blacklist                    if not (                        plugin[""name""] == self.classname                        and plugin[""type""] == self.__type__                    )                    and (plugin[""type""], plugin[""name""].upper())                    not in whitelisted_plugins                ]            else:                blacklisted_plugins = [                    (plugin[""type""], plugin[""name""])                    for plugin in blacklist                    if not (                        plugin[""name""] == self.classname                        and plugin[""type""] == self.__type__                    )                ]            c = 1            l = len(blacklisted_plugins)            for idx, plugin in enumerate(updatelist):                if c > l:                    break                plugin_name = plugin[""name""]                plugin_type = plugin[""type""]                for t, n in blacklisted_plugins:                    if n != plugin_name or t != plugin_type:                        continue                    updatelist.pop(idx)                    c += 1                    break            for t, n in self.remove_plugins(blacklisted_plugins):                self.log_info(                    self._(""Removed blacklisted plugin: {type} {name}"").format(                        type=t.upper(), name=n                    )                )        userplugins = os.path.join(self.pyload.userdir, ""userplugins"")        for plugin in updatelist:            plugin_name = plugin[""name""]            plugin_type = plugin[""type""]            plugin_version = plugin[""version""]            plugins = getattr(                self.pyload.plugin_manager, ""{}Plugins"".format(plugin_type.rstrip(""s""))            )  # TODO: Remove rstrip in 0.6.x)            oldver = (                float(plugins[plugin_name][""v""]) if plugin_name in plugins else None            )            try:                newver = float(plugin_version)            except ValueError:                self.log_error(                    self._(""Error updating plugin: {} {}"").format(                        plugin_type.rstrip(""s"").upper(), plugin_name                    ),                    self._(""Bad version number on the server""),                )                continue            if not oldver:                msg = ""New plugin: {type} {name} (v{newver:.2f})""            elif newver > oldver:                msg = ""New version of plugin: {type} {name} (v{oldver:.2f} -> v{newver:.2f})""            else:                continue            self.log_info(                msg.format(                    type=plugin_type.rstrip(                        ""s""                    ).upper(),  # TODO: Remove rstrip in 0.6.x                    name=plugin_name,                    oldver=oldver,                    newver=newver,                )            )            try:                content = self.load(url.format(plugin + "".py""), decode=False, req=req)                if req.code == 404:                    raise Exception(self._(""URL not found""))                m = self._VERSION.search(content)                if m is not None and m.group(2) == plugin_version:                    with open(                        os.path.join(userplugins, plugin_type, plugin_name + "".py""),                        ""wb"",                    ) as fp:                        fp.write(content.encode())                    updated.append((plugin_type, plugin_name))                else:                    raise Exception(self._(""Version mismatch""))            except Exception as exc:                self.log_error(                    self._(""Error updating plugin: {} {}"").format(                        plugin_type.rstrip(""s"").upper(), plugin_name                    ),                    exc,                )  # TODO: Remove rstrip in 0.6.x        return updated

Check for plugin updates.",457f0158-2f4e-48ff-963f-f6afbeaa5a22
addons,UpdateManager.py,remove_plugins,398,445,"def remove_plugins(self, plugin_ids):                if not plugin_ids:            return        removed = set()        self.log_debug(f""Requested deletion of plugins: {plugin_ids}"")        for plugin_type, plugin_name in plugin_ids:            userplugins = os.path.join(self.pyload.userdir, ""plugins"")            rootplugins = os.path.join(PKGDIR, ""plugins"")            for basedir in (userplugins, rootplugins):                py_filename = os.path.join(basedir, plugin_type, plugin_name + "".py"")                pyc_filename = py_filename + ""c""                if plugin_type == ""addon"":                    try:                        self.m.deactivate_addon(plugin_name)                    except Exception as exc:                        self.log_debug(                            exc,                            exc_info=self.pyload.debug > 1,                            stack_info=self.pyload.debug > 2,                        )                for filename in (py_filename, pyc_filename):                    if not exists(filename):                        continue                    try:                        os.remove(filename)                    except OSError as exc:                        self.log_warning(                            self._(""Error removing `{}`"").format(filename), exc                        )                    else:                        plugin_id = (plugin_type, plugin_name)                        removed.add(plugin_id)        #: Return a list of the plugins successfully removed        return list(removed)",Delete plugins from disk.,"def remove_plugins(self, plugin_ids):        """"""        Delete plugins from disk.        """"""        if not plugin_ids:            return        removed = set()        self.log_debug(f""Requested deletion of plugins: {plugin_ids}"")        for plugin_type, plugin_name in plugin_ids:            userplugins = os.path.join(self.pyload.userdir, ""plugins"")            rootplugins = os.path.join(PKGDIR, ""plugins"")            for basedir in (userplugins, rootplugins):                py_filename = os.path.join(basedir, plugin_type, plugin_name + "".py"")                pyc_filename = py_filename + ""c""                if plugin_type == ""addon"":                    try:                        self.m.deactivate_addon(plugin_name)                    except Exception as exc:                        self.log_debug(                            exc,                            exc_info=self.pyload.debug > 1,                            stack_info=self.pyload.debug > 2,                        )                for filename in (py_filename, pyc_filename):                    if not exists(filename):                        continue                    try:                        os.remove(filename)                    except OSError as exc:                        self.log_warning(                            self._(""Error removing `{}`"").format(filename), exc                        )                    else:                        plugin_id = (plugin_type, plugin_name)                        removed.add(plugin_id)        #: Return a list of the plugins successfully removed        return list(removed)

Delete plugins from disk.",97a6c74b-9c13-4a5b-9d26-6f4e774f5f4b
addons,UserAgentSwitcher.py,download_preparing,32,54,"def download_preparing(self, pyfile):        if not isinstance(pyfile.plugin.req, HTTPRequest) and not isinstance(            pyfile.plugin.req, Browser        ):            return        connecttimeout = self.config.get(""connecttimeout"")        maxredirs = self.config.get(""maxredirs"")        useragent = self.config.get(""useragent"")        if connecttimeout:            self.log_debug(                ""Setting connection timeout to {} seconds"".format(connecttimeout)            )            pyfile.plugin.req.http.c.setopt(pycurl.CONNECTTIMEOUT, connecttimeout)        if maxredirs:            self.log_debug(f""Setting maximum redirections to {maxredirs}"")            pyfile.plugin.req.http.c.setopt(pycurl.MAXREDIRS, maxredirs)        if useragent:            self.log_debug(f""Use custom user-agent string `{useragent}`"")            pyfile.plugin.req.http.c.setopt(pycurl.USERAGENT, useragent.encode())",,"def download_preparing(self, pyfile):        if not isinstance(pyfile.plugin.req, HTTPRequest) and not isinstance(            pyfile.plugin.req, Browser        ):            return        connecttimeout = self.config.get(""connecttimeout"")        maxredirs = self.config.get(""maxredirs"")        useragent = self.config.get(""useragent"")        if connecttimeout:            self.log_debug(                ""Setting connection timeout to {} seconds"".format(connecttimeout)            )            pyfile.plugin.req.http.c.setopt(pycurl.CONNECTTIMEOUT, connecttimeout)        if maxredirs:            self.log_debug(f""Setting maximum redirections to {maxredirs}"")            pyfile.plugin.req.http.c.setopt(pycurl.MAXREDIRS, maxredirs)        if useragent:            self.log_debug(f""Use custom user-agent string `{useragent}`"")            pyfile.plugin.req.http.c.setopt(pycurl.USERAGENT, useragent.encode())",364663ec-1c08-4019-9f97-986f5c2f7c13
addons,WindowsPhoneNotify.py,get_key,41,42,"def get_key(self):        return self.config.get(""pushid""), self.config.get(""pushurl"")",,"def get_key(self):        return self.config.get(""pushid""), self.config.get(""pushurl"")",04b2d761-191d-4e32-ab5a-13fcb63bc8d4
addons,WindowsPhoneNotify.py,format_request,44,49,"def format_request(self, msg):        return (            ""<?xml version='1.0' encoding='utf-8'?> <wp:Notification xmlns:wp='WPNotification'> ""            ""<wp:Toast> <wp:Text1>pyLoad</wp:Text1> <wp:Text2>{}</wp:Text2> ""            ""</wp:Toast> </wp:Notification>"".format(msg)        )",,"def format_request(self, msg):        return (            ""<?xml version='1.0' encoding='utf-8'?> <wp:Notification xmlns:wp='WPNotification'> ""            ""<wp:Toast> <wp:Text1>pyLoad</wp:Text1> <wp:Text2>{}</wp:Text2> ""            ""</wp:Toast> </wp:Notification>"".format(msg)        )",16651587-d72d-446d-a22d-a709ca286540
addons,WindowsPhoneNotify.py,send,51,62,"def send(self, event, msg, key):        id, url = key        request = self.format_request(""{}: {}"".format(event, msg) if msg else event)        with closing(http.client.HTTPConnection(url)) as webservice:            webservice.putrequest(""POST"", id)            webservice.putheader(""Host"", url)            webservice.putheader(""Content-type"", ""text/xml"")            webservice.putheader(""X-NotificationClass"", ""2"")            webservice.putheader(""X-WindowsPhone-Target"", ""toast"")            webservice.putheader(""Content-length"", ""{}"".format(len(request)))            webservice.endheaders()            webservice.send(request)",,"def send(self, event, msg, key):        id, url = key        request = self.format_request(""{}: {}"".format(event, msg) if msg else event)        with closing(http.client.HTTPConnection(url)) as webservice:            webservice.putrequest(""POST"", id)            webservice.putheader(""Host"", url)            webservice.putheader(""Content-type"", ""text/xml"")            webservice.putheader(""X-NotificationClass"", ""2"")            webservice.putheader(""X-WindowsPhone-Target"", ""toast"")            webservice.putheader(""Content-length"", ""{}"".format(len(request)))            webservice.endheaders()            webservice.send(request)",01e2ac3d-744f-47f2-a955-54de1abb5504
addons,XFileSharing.py,activate,87,92,"def activate(self):        for type, plugin in (            (""downloader"", ""XFileSharing""),            (""decrypter"", ""XFileSharingFolder""),        ):            self._load(type, plugin)",,"def activate(self):        for type, plugin in (            (""downloader"", ""XFileSharing""),            (""decrypter"", ""XFileSharingFolder""),        ):            self._load(type, plugin)",1dbe5591-ac05-4229-bd18-e327362e43ea
addons,XFileSharing.py,deactivate,94,99,"def deactivate(self):        for type, plugin in (            (""downloader"", ""XFileSharing""),            (""decrypter"", ""XFileSharingFolder""),        ):            self._unload(type, plugin)",,"def deactivate(self):        for type, plugin in (            (""downloader"", ""XFileSharing""),            (""decrypter"", ""XFileSharingFolder""),        ):            self._unload(type, plugin)",701175be-44c9-4924-94bb-0ce8fcbda5e9
addons,XFileSharing.py,get_pattern,101,161,"def get_pattern(self, type, plugin):        if self.config.get(""use_{}_list"".format(type)):            plugin_list = self.config.get(""{}_list"".format(type))            plugin_list = plugin_list.replace("" "", """").replace(""\\"", """")            plugin_list = plugin_list.replace(""|"", "","").replace("";"", "","")            plugin_list = plugin_list.lower().split("","")            plugin_set = set(plugin_list)            if self.config.get(""use_builtin_list""):                builtin_list = getattr(self, ""BUILTIN_{}S"".format(type.upper()))                plugin_set.update(builtin_list)            plugin_set.difference_update(("""", """"))            if not plugin_set:                self.log_info(self._(""No {} to handle"").format(type))                return            match_list = ""|"".join(sorted(plugin_set)).replace(""."", r""\."")            pattern = self._regexmap[type][1].format(match_list)            self.log_info(                self._(""Handle {} {}{}: {}"").format(                    len(plugin_set),                    type,                    """" if len(plugin_set) == 1 else ""s"",                    match_list.replace(r""\."", ""."").replace(""|"", "", ""),                )            )        else:            plugin_list = []            is_xfs = lambda klass: any(                k.__name__.startswith(""XFS"") for k in inspect.getmro(klass)            )            for p in self.pyload.plugin_manager.plugins[type].values():                try:                    klass = self.pyload.plugin_manager.load_class(type, p[""name""])                except AttributeError as exc:                    self.log_debug(                        exc,                        exc_info=self.pyload.debug > 1,                        stack_info=self.pyload.debug > 2,                    )                    continue                if (                    hasattr(klass, ""PLUGIN_DOMAIN"")                    and klass.PLUGIN_DOMAIN                    and is_xfs(klass)                ):                    plugin_list.append(klass.PLUGIN_DOMAIN)            unmatch_list = ""|"".join(sorted(plugin_list)).replace(""."", r""\."")            pattern = self._regexmap[type][0].format(unmatch_list)            self.log_info(self._(""Auto-discover new {}s"").format(type))        return pattern",,"def get_pattern(self, type, plugin):        if self.config.get(""use_{}_list"".format(type)):            plugin_list = self.config.get(""{}_list"".format(type))            plugin_list = plugin_list.replace("" "", """").replace(""\\"", """")            plugin_list = plugin_list.replace(""|"", "","").replace("";"", "","")            plugin_list = plugin_list.lower().split("","")            plugin_set = set(plugin_list)            if self.config.get(""use_builtin_list""):                builtin_list = getattr(self, ""BUILTIN_{}S"".format(type.upper()))                plugin_set.update(builtin_list)            plugin_set.difference_update(("""", """"))            if not plugin_set:                self.log_info(self._(""No {} to handle"").format(type))                return            match_list = ""|"".join(sorted(plugin_set)).replace(""."", r""\."")            pattern = self._regexmap[type][1].format(match_list)            self.log_info(                self._(""Handle {} {}{}: {}"").format(                    len(plugin_set),                    type,                    """" if len(plugin_set) == 1 else ""s"",                    match_list.replace(r""\."", ""."").replace(""|"", "", ""),                )            )        else:            plugin_list = []            is_xfs = lambda klass: any(                k.__name__.startswith(""XFS"") for k in inspect.getmro(klass)            )            for p in self.pyload.plugin_manager.plugins[type].values():                try:                    klass = self.pyload.plugin_manager.load_class(type, p[""name""])                except AttributeError as exc:                    self.log_debug(                        exc,                        exc_info=self.pyload.debug > 1,                        stack_info=self.pyload.debug > 2,                    )                    continue                if (                    hasattr(klass, ""PLUGIN_DOMAIN"")                    and klass.PLUGIN_DOMAIN                    and is_xfs(klass)                ):                    plugin_list.append(klass.PLUGIN_DOMAIN)            unmatch_list = ""|"".join(sorted(plugin_list)).replace(""."", r""\."")            pattern = self._regexmap[type][0].format(unmatch_list)            self.log_info(self._(""Auto-discover new {}s"").format(type))        return pattern",9f887972-a4a6-4f28-9526-29d37b7f0a70
addons,XFileSharing.py,_load,163,173,"def _load(self, type, plugin):        dict = self.pyload.plugin_manager.plugins[type][plugin]        pattern = self.get_pattern(type, plugin)        if not pattern:            return        dict[""pattern""] = pattern        dict[""re""] = re.compile(pattern)        self.log_debug(f""Pattern for {type}: {pattern}"")",,"def _load(self, type, plugin):        dict = self.pyload.plugin_manager.plugins[type][plugin]        pattern = self.get_pattern(type, plugin)        if not pattern:            return        dict[""pattern""] = pattern        dict[""re""] = re.compile(pattern)        self.log_debug(f""Pattern for {type}: {pattern}"")",f772c418-2f9d-4bbc-b88c-b4181151cb89
addons,XFileSharing.py,_unload,175,178,"def _unload(self, type, plugin):        dict = self.pyload.plugin_manager.plugins[type][plugin]        dict[""pattern""] = r""^unmatchable$""        dict[""re""] = re.compile(dict[""pattern""])",,"def _unload(self, type, plugin):        dict = self.pyload.plugin_manager.plugins[type][plugin]        dict[""pattern""] = r""^unmatchable$""        dict[""re""] = re.compile(dict[""pattern""])",d0a2b0dd-e427-4250-ac38-61a9d52c44d3
addons,XMPP.py,activate,50,56,"def activate(self):        self.log_debug(""activate"")        self.jid = slixmpp.jid.JID(self.config.get(""jid""))        self.jid.resource = ""PyLoadNotifyBot""        self.log_debug(self.jid)        super().activate()",,"def activate(self):        self.log_debug(""activate"")        self.jid = slixmpp.jid.JID(self.config.get(""jid""))        self.jid.resource = ""PyLoadNotifyBot""        self.log_debug(self.jid)        super().activate()",77d48972-001e-408f-854e-8e91e8c0ed73
addons,XMPP.py,run,58,104,"def run(self):        self.log_debug(""def run"")        if os.name == ""nt"":            asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())        loop = asyncio.new_event_loop()        asyncio.set_event_loop(loop)        xmpp = XMPPClient(            self.jid,            self.config.get(""pw""),            self.log_info,            self.log_debug,        )        self.log_debug(""activate xmpp"")        xmpp.use_ipv6 = self.config.get(""use_ipv6"")        xmpp.register_plugin(""xep_0030"")  # Service Discovery        xmpp.register_plugin(""xep_0004"")  # Data Forms        xmpp.register_plugin(""xep_0060"")  # PubSub        xmpp.register_plugin(""xep_0199"")  # XMPP Ping        xmpp.ssl_version = ssl.PROTOCOL_TLSv1_2        # The message event is triggered whenever a message        # stanza is received. Be aware that that includes        # MUC messages and error messages.        xmpp.add_event_handler(""message"", self.message)        xmpp.add_event_handler(""connected"", self.connected)        xmpp.add_event_handler(""connection_failed"", self.connection_failed)        xmpp.add_event_handler(""disconnected"", self.disconnected)        xmpp.add_event_handler(""failed_auth"", self.failed_auth)        xmpp.add_event_handler(""changed_status"", self.changed_status)        xmpp.add_event_handler(""presence_error"", self.presence_error)        xmpp.add_event_handler(""presence_unavailable"", self.presence_unavailable)        xmpp.register_handler(            Callback(                ""Stream Error"",                MatchXPath(f""{{{xmpp.stream_ns}}}error""),                self.stream_error,            )        )        self.xmpp = xmpp        self.xmpp.connect(            use_ssl=self.config.get(""use_ssl""),            force_starttls=self.config.get(""tls""),        )        self.xmpp.process(forever=True)",,"def run(self):        self.log_debug(""def run"")        if os.name == ""nt"":            asyncio.set_event_loop_policy(asyncio.WindowsSelectorEventLoopPolicy())        loop = asyncio.new_event_loop()        asyncio.set_event_loop(loop)        xmpp = XMPPClient(            self.jid,            self.config.get(""pw""),            self.log_info,            self.log_debug,        )        self.log_debug(""activate xmpp"")        xmpp.use_ipv6 = self.config.get(""use_ipv6"")        xmpp.register_plugin(""xep_0030"")  # Service Discovery        xmpp.register_plugin(""xep_0004"")  # Data Forms        xmpp.register_plugin(""xep_0060"")  # PubSub        xmpp.register_plugin(""xep_0199"")  # XMPP Ping        xmpp.ssl_version = ssl.PROTOCOL_TLSv1_2        # The message event is triggered whenever a message        # stanza is received. Be aware that that includes        # MUC messages and error messages.        xmpp.add_event_handler(""message"", self.message)        xmpp.add_event_handler(""connected"", self.connected)        xmpp.add_event_handler(""connection_failed"", self.connection_failed)        xmpp.add_event_handler(""disconnected"", self.disconnected)        xmpp.add_event_handler(""failed_auth"", self.failed_auth)        xmpp.add_event_handler(""changed_status"", self.changed_status)        xmpp.add_event_handler(""presence_error"", self.presence_error)        xmpp.add_event_handler(""presence_unavailable"", self.presence_unavailable)        xmpp.register_handler(            Callback(                ""Stream Error"",                MatchXPath(f""{{{xmpp.stream_ns}}}error""),                self.stream_error,            )        )        self.xmpp = xmpp        self.xmpp.connect(            use_ssl=self.config.get(""use_ssl""),            force_starttls=self.config.get(""tls""),        )        self.xmpp.process(forever=True)",c72f0f92-145b-4b73-9f0a-158322c07739
addons,XMPP.py,changed_status,109,110,"def changed_status(self, stanza=None):        self.log_debug(""changed_status"", stanza, stanza.get_type())",,"def changed_status(self, stanza=None):        self.log_debug(""changed_status"", stanza, stanza.get_type())",a1db65b2-f263-474c-90c8-9d70a29cb5df
addons,XMPP.py,connection_failed,112,113,"def connection_failed(self, stanza=None):        self.log_error(""Unable to connect"", stanza)",,"def connection_failed(self, stanza=None):        self.log_error(""Unable to connect"", stanza)",d26eea8a-c0fe-4309-beb7-e0bcae04b53b
addons,XMPP.py,connected,115,116,"def connected(self, event=None):        self.log_info(""Client was connected"", event)",,"def connected(self, event=None):        self.log_info(""Client was connected"", event)",a1d5b8c7-68b4-4d92-989c-2f8e062b8acf
addons,XMPP.py,disconnected,118,119,"def disconnected(self, event=None):        self.log_info(""Client was disconnected"", event)",,"def disconnected(self, event=None):        self.log_info(""Client was disconnected"", event)",062b7bf5-4f38-416d-941f-df100f7dd770
addons,XMPP.py,presence_error,121,122,"def presence_error(self, stanza=None):        self.log_debug(""presence_error"", stanza)",,"def presence_error(self, stanza=None):        self.log_debug(""presence_error"", stanza)",0325cf45-2ae4-48fc-88be-f1e1c190aa0f
addons,XMPP.py,presence_unavailable,124,125,"def presence_unavailable(self, stanza=None):        self.log_debug(""presence_unavailable"", stanza)",,"def presence_unavailable(self, stanza=None):        self.log_debug(""presence_unavailable"", stanza)",78ee7173-2eb7-45a9-bcb7-8ffd0e7e4b13
addons,XMPP.py,failed_auth,127,128,"def failed_auth(self, event=None):        self.log_info(""Failed to authenticate"")",,"def failed_auth(self, event=None):        self.log_info(""Failed to authenticate"")",d6554f71-d981-4c06-b5f5-b9747c240a4e
addons,XMPP.py,stream_error,130,131,"def stream_error(self, err=None):        self.log_debug(""Stream Error"", err)",,"def stream_error(self, err=None):        self.log_debug(""Stream Error"", err)",d4d2ef77-2ab6-47be-98dd-496a6bb55501
addons,XMPP.py,message,134,183,"def message(self, stanza):                self.log_debug(""message"", stanza)        subject = stanza[""subject""]        body = stanza[""body""]        msg_type = stanza[""type""]        sender_jid = stanza[""from""]        names = self.config.get(""owners"").split("";"")        self.log_debug(f""Message from {sender_jid} received."")        self.log_debug(f""Body: {body} Subject: {subject} Type: {msg_type}"")        if msg_type == ""headline"":            #: 'headline' messages should never be replied to            return True        if subject:            subject = ""Re: "" + subject        if not (sender_jid.username in names or sender_jid.bare in names):            return True        temp = body.split()        try:            command = temp[0]            args = temp[1:]        except IndexError:            command = ""error""            args = []        ret = False        try:            res = self.do_bot_command(command, args)            if res:                msg_reply = ""\n"".join(res)            else:                msg_reply = ""ERROR: invalid command, enter: help""            self.log_debug(""Send response"")            ret = stanza.reply(msg_reply).send()        except Exception as exc:            self.log_error(exc)            stanza.reply(""ERROR: "" + str(exc)).send()        return ret",Message handler for the component.,"def message(self, stanza):        """"""        Message handler for the component.        """"""        self.log_debug(""message"", stanza)        subject = stanza[""subject""]        body = stanza[""body""]        msg_type = stanza[""type""]        sender_jid = stanza[""from""]        names = self.config.get(""owners"").split("";"")        self.log_debug(f""Message from {sender_jid} received."")        self.log_debug(f""Body: {body} Subject: {subject} Type: {msg_type}"")        if msg_type == ""headline"":            #: 'headline' messages should never be replied to            return True        if subject:            subject = ""Re: "" + subject        if not (sender_jid.username in names or sender_jid.bare in names):            return True        temp = body.split()        try:            command = temp[0]            args = temp[1:]        except IndexError:            command = ""error""            args = []        ret = False        try:            res = self.do_bot_command(command, args)            if res:                msg_reply = ""\n"".join(res)            else:                msg_reply = ""ERROR: invalid command, enter: help""            self.log_debug(""Send response"")            ret = stanza.reply(msg_reply).send()        except Exception as exc:            self.log_error(exc)            stanza.reply(""ERROR: "" + str(exc)).send()        return ret

Message handler for the component.",5e3813b6-145d-437c-93b9-8d64f1dd0202
addons,XMPP.py,announce,188,198,"def announce(self, message):                self.log_debug(""Announce, message:"", message)        for user in self.config.get(""owners"").split("";""):            self.log_debug(""Send message to"", user)            to_jid = slixmpp.jid.JID(user)            self.xmpp.sendMessage(                mfrom=self.jid, mto=to_jid, mtype=""chat"", mbody=str(message)            )",Send message to all owners,"def announce(self, message):        """"""        Send message to all owners        """"""        self.log_debug(""Announce, message:"", message)        for user in self.config.get(""owners"").split("";""):            self.log_debug(""Send message to"", user)            to_jid = slixmpp.jid.JID(user)            self.xmpp.sendMessage(                mfrom=self.jid, mto=to_jid, mtype=""chat"", mbody=str(message)            )

Send message to all owners",30a81a26-88a1-41b7-ad42-cb78316ec559
addons,XMPP.py,exit,203,204,def exit(self):        self.xmpp.disconnect(),,def exit(self):        self.xmpp.disconnect(),6a118d22-627b-41b3-8263-090b349c7759
addons,XMPP.py,before_reconnect,206,208,"def before_reconnect(self, ip):        self.log_debug(""before_reconnect"")        self.xmpp.disconnect()",,"def before_reconnect(self, ip):        self.log_debug(""before_reconnect"")        self.xmpp.disconnect()",9c149636-1581-4b68-a392-e8da548b7a89
addons,XMPP.py,after_reconnect,210,212,"def after_reconnect(self, ip, oldip):        self.log_debug(""after_reconnect"")        self.xmpp.connect()",,"def after_reconnect(self, ip, oldip):        self.log_debug(""after_reconnect"")        self.xmpp.connect()",08e6cf34-4f75-4272-a1b3-cda8b673d34c
addons,XMPP.py,download_failed,215,230,"def download_failed(self, pyfile):        self.log_debug(""download_failed"", pyfile, pyfile.error)        try:            if self.config.get(""download_failed""):                self.announce(                    self._(""Download failed: {} (#{}) in #{} @ {}: {}"").format(                        pyfile.name,                        pyfile.id,                        pyfile.packageid,                        pyfile.pluginname,                        pyfile.error,                    )                )        except Exception as exc:            self.log_error(exc)",,"def download_failed(self, pyfile):        self.log_debug(""download_failed"", pyfile, pyfile.error)        try:            if self.config.get(""download_failed""):                self.announce(                    self._(""Download failed: {} (#{}) in #{} @ {}: {}"").format(                        pyfile.name,                        pyfile.id,                        pyfile.packageid,                        pyfile.pluginname,                        pyfile.error,                    )                )        except Exception as exc:            self.log_error(exc)",081389ab-3dfb-483e-af2b-2b05300da54d
addons,XMPP.py,package_failed,232,241,"def package_failed(self, pypack):        self.log_debug(""package_failed"", pypack)        try:            if self.config.get(""package_failed""):                self.announce(                    self._(""Package failed: {} ({})."").format(pypack.name, pypack.id)                )        except Exception as exc:            self.log_error(exc)",,"def package_failed(self, pypack):        self.log_debug(""package_failed"", pypack)        try:            if self.config.get(""package_failed""):                self.announce(                    self._(""Package failed: {} ({})."").format(pypack.name, pypack.id)                )        except Exception as exc:            self.log_error(exc)",34a9b023-cd88-4f47-b4a7-bcae23dd9dff
addons,XMPP.py,package_finished,243,252,"def package_finished(self, pypack):        self.log_debug(""package_finished"")        try:            if self.config.get(""info_pack""):                self.announce(                    self._(""Package finished: {} ({})."").format(pypack.name, pypack.id)                )        except Exception as exc:            self.log_error(exc)",,"def package_finished(self, pypack):        self.log_debug(""package_finished"")        try:            if self.config.get(""info_pack""):                self.announce(                    self._(""Package finished: {} ({})."").format(pypack.name, pypack.id)                )        except Exception as exc:            self.log_error(exc)",b5175618-55f7-42b8-9520-5c686c7988a1
addons,XMPP.py,download_finished,254,265,"def download_finished(self, pyfile):        self.log_debug(""download_finished"")        try:            if self.config.get(""info_file""):                self.announce(                    self._(""Download finished: {} (#{}) in #{} @ {}"").format(                        pyfile.name, pyfile.id, pyfile.packageid, pyfile.pluginname                    )                )        except Exception as exc:            self.log_error(exc)",,"def download_finished(self, pyfile):        self.log_debug(""download_finished"")        try:            if self.config.get(""info_file""):                self.announce(                    self._(""Download finished: {} (#{}) in #{} @ {}"").format(                        pyfile.name, pyfile.id, pyfile.packageid, pyfile.pluginname                    )                )        except Exception as exc:            self.log_error(exc)",63f7a5d0-1b79-4a4c-9fab-45d2bef4b852
addons,XMPP.py,all_downloads_processed,267,274,"def all_downloads_processed(self):        self.log_debug(""all_downloads_processed"")        try:            if self.config.get(""all_download""):                self.announce(self._(""All download finished.""))        except Exception:            pass",,"def all_downloads_processed(self):        self.log_debug(""all_downloads_processed"")        try:            if self.config.get(""all_download""):                self.announce(self._(""All download finished.""))        except Exception:            pass",ed9416dc-05b6-4213-98d7-7de56b0473f4
addons,XMPP.py,download_start,276,286,"def download_start(self, pyfile, url, filename):        self.log_debug(""download_start"", pyfile, url, filename)        try:            if self.config.get(""download_start""):                self.announce(                    self._(""Download start: {} (#{}) in (#{}) @ {}."").format(                        pyfile.name, pyfile.id, pyfile.packageid, pyfile.pluginname                    )                )        except Exception:            pass",,"def download_start(self, pyfile, url, filename):        self.log_debug(""download_start"", pyfile, url, filename)        try:            if self.config.get(""download_start""):                self.announce(                    self._(""Download start: {} (#{}) in (#{}) @ {}."").format(                        pyfile.name, pyfile.id, pyfile.packageid, pyfile.pluginname                    )                )        except Exception:            pass",ad22dc81-64be-4df5-bd5b-64059432b695
addons,XMPP.py,__init__,293,298,"def __init__(self, jid, password, log_info, log_debug):        self.log_debug = log_debug        self.log_info = log_info        slixmpp.ClientXMPP.__init__(self, jid, password)        self.add_event_handler(""session_start"", self.start)",,"def __init__(self, jid, password, log_info, log_debug):        self.log_debug = log_debug        self.log_info = log_info        slixmpp.ClientXMPP.__init__(self, jid, password)        self.add_event_handler(""session_start"", self.start)",2f72ca44-a9bc-4b4e-85b4-d5196d30704c
addons,XMPP.py,start,300,303,"def start(self, event):        self.log_debug(""Session started"")        self.send_presence()        self.get_roster(timeout=60)",,"def start(self, event):        self.log_debug(""Session started"")        self.send_presence()        self.get_roster(timeout=60)",14b5aaf9-6dcb-43ac-8761-fc6ad7e7d386
anticaptchas,CircleCaptcha.py,__init__,19,20,"def __init__(self, im):        self.im = im",,"def __init__(self, im):        self.im = im",cadcf4c5-e1a5-4ac2-938a-3c54afb346ff
anticaptchas,CircleCaptcha.py,__getitem__,22,28,"def __getitem__(self, ix):        try:            if ix:                self.im.seek(ix)            return self.im        except EOFError:            raise IndexError",,"def __getitem__(self, ix):        try:            if ix:                self.im.seek(ix)            return self.im        except EOFError:            raise IndexError",53eccca5-d4dc-4fb5-8756-0ccb2cd22878
anticaptchas,CircleCaptcha.py,clean_image,47,101,"def clean_image(self, im, pix):        cleandeep = 1        imageheight = list(range(1, int(im.size[1])))        imagewidth = list(range(1, int(im.size[0])))        howmany = 0        for y in imageheight:            howmany = 0            for x in imagewidth:                curpix = pix[x, y]                if curpix > self.BACKGROUND:                    if howmany <= cleandeep and howmany > 0:                        #: Clean pixel                        for ic in range(1, cleandeep + 1):                            if x - ic > 0:                                pix[x - ic, y] = self.BACKGROUND                    howmany = 0                    # self.log_debug(x, y, jump, 2)                else:                    if howmany == 0:                        #: Found pixel                        howmany = howmany + 1                        # self.log_debug(x, y, jump, 2)                    else:                        howmany = howmany + 1            if howmany == 1:                #: Clean pixel                pix[x - 1, y] = self.BACKGROUND        for x in imagewidth:            howmany = 0            for y in imageheight:                curpix = pix[x, y]                # if jump is True:                if curpix > self.BACKGROUND:                    if howmany <= cleandeep and howmany > 0:                        #: Clean pixel                        for ic in range(1, cleandeep + 1):                            #: input('2'+str(ic))                            if y - ic > 0:                                pix[x, y - ic] = self.BACKGROUND                    howmany = 0                    # self.log_debug(x, y, jump)                else:                    if howmany == 0:                        #: Found pixel                        howmany = howmany + 1                        # self.log_debug(x, y, jump)                    else:                        howmany = howmany + 1            if howmany == 1:                #: Clean pixel                pix[x - 1, y] = self.BACKGROUND",,"def clean_image(self, im, pix):        cleandeep = 1        imageheight = list(range(1, int(im.size[1])))        imagewidth = list(range(1, int(im.size[0])))        howmany = 0        for y in imageheight:            howmany = 0            for x in imagewidth:                curpix = pix[x, y]                if curpix > self.BACKGROUND:                    if howmany <= cleandeep and howmany > 0:                        #: Clean pixel                        for ic in range(1, cleandeep + 1):                            if x - ic > 0:                                pix[x - ic, y] = self.BACKGROUND                    howmany = 0                    # self.log_debug(x, y, jump, 2)                else:                    if howmany == 0:                        #: Found pixel                        howmany = howmany + 1                        # self.log_debug(x, y, jump, 2)                    else:                        howmany = howmany + 1            if howmany == 1:                #: Clean pixel                pix[x - 1, y] = self.BACKGROUND        for x in imagewidth:            howmany = 0            for y in imageheight:                curpix = pix[x, y]                # if jump is True:                if curpix > self.BACKGROUND:                    if howmany <= cleandeep and howmany > 0:                        #: Clean pixel                        for ic in range(1, cleandeep + 1):                            #: input('2'+str(ic))                            if y - ic > 0:                                pix[x, y - ic] = self.BACKGROUND                    howmany = 0                    # self.log_debug(x, y, jump)                else:                    if howmany == 0:                        #: Found pixel                        howmany = howmany + 1                        # self.log_debug(x, y, jump)                    else:                        howmany = howmany + 1            if howmany == 1:                #: Clean pixel                pix[x - 1, y] = self.BACKGROUND",a23e8479-c61a-4c9e-913a-edc9c13e44be
anticaptchas,CircleCaptcha.py,find_first_pixel_x,105,134,"def find_first_pixel_x(self, im, pix, curx, cury, color=-1, ExitWithBlack=False):        imagewidth = list(range(curx + 1, int(im.size[0])))        jump = True        newx = (-1, -1)        blackfound = 0        for x in imagewidth:            curpix = pix[x, cury]            if curpix < self.BLACKCOLOR:                blackfound = blackfound + 1                if ExitWithBlack is True and blackfound >= 3:                    break  #: Exit if found black                else:                    continue            if curpix >= self.BACKGROUND:                #: Found first pixel white                jump = False                continue            if (curpix < self.BACKGROUND and color == -1) or (                curpix == color and color > -1            ):                if jump is False:                    #: Found pixel                    curcolor = curpix                    newx = x, curcolor                    break        return newx",,"def find_first_pixel_x(self, im, pix, curx, cury, color=-1, ExitWithBlack=False):        imagewidth = list(range(curx + 1, int(im.size[0])))        jump = True        newx = (-1, -1)        blackfound = 0        for x in imagewidth:            curpix = pix[x, cury]            if curpix < self.BLACKCOLOR:                blackfound = blackfound + 1                if ExitWithBlack is True and blackfound >= 3:                    break  #: Exit if found black                else:                    continue            if curpix >= self.BACKGROUND:                #: Found first pixel white                jump = False                continue            if (curpix < self.BACKGROUND and color == -1) or (                curpix == color and color > -1            ):                if jump is False:                    #: Found pixel                    curcolor = curpix                    newx = x, curcolor                    break        return newx",bf5a8bca-821f-4e18-8f88-514350279f4c
anticaptchas,CircleCaptcha.py,find_last_pixel_x,136,162,"def find_last_pixel_x(self, im, pix, curx, cury, color=-1, ExitWithBlack=False):        imagewidth = list(range(curx + 1, int(im.size[0])))        newx = (-1, -1)        blackfound = 0        for x in imagewidth:            curpix = pix[x, cury]            if curpix < self.BLACKCOLOR:                blackfound = blackfound + 1                if ExitWithBlack is True and blackfound >= 3:                    break  #: Exit if found black                else:                    continue            if curpix >= self.BACKGROUND:                if newx != (-1, -1):                    #: Found last pixel and the first white                    break            if (curpix < self.BACKGROUND and color == -1) or (                curpix == color and color > -1            ):                #: Found pixel                curcolor = curpix                newx = x, curcolor        return newx",,"def find_last_pixel_x(self, im, pix, curx, cury, color=-1, ExitWithBlack=False):        imagewidth = list(range(curx + 1, int(im.size[0])))        newx = (-1, -1)        blackfound = 0        for x in imagewidth:            curpix = pix[x, cury]            if curpix < self.BLACKCOLOR:                blackfound = blackfound + 1                if ExitWithBlack is True and blackfound >= 3:                    break  #: Exit if found black                else:                    continue            if curpix >= self.BACKGROUND:                if newx != (-1, -1):                    #: Found last pixel and the first white                    break            if (curpix < self.BACKGROUND and color == -1) or (                curpix == color and color > -1            ):                #: Found pixel                curcolor = curpix                newx = x, curcolor        return newx",c38c328d-9a8c-48e5-8d5b-87f0ed319439
anticaptchas,CircleCaptcha.py,find_last_pixel_y,164,194,"def find_last_pixel_y(        self, im, pix, curx, cury, DownToUp, color=-1, ExitWithBlack=False    ):        if DownToUp is False:            imageheight = list(range(int(cury) + 1, int(im.size[1]) - 1))        else:            imageheight = list(range(int(cury) - 1, 1, -1))        newy = (-1, -1)        blackfound = 0        for y in imageheight:            curpix = pix[curx, y]            if curpix < self.BLACKCOLOR:                blackfound = blackfound + 1                if ExitWithBlack is True and blackfound >= 3:                    break  #: Exit if found black                else:                    continue            if curpix >= self.BACKGROUND:                if newy != (-1, -1):                    #: Found last pixel and the first white                    break            if (curpix < self.BACKGROUND and color == -1) or (                curpix == color and color > -1            ):                #: Found pixel                newy = y, color        return newy",,"def find_last_pixel_y(        self, im, pix, curx, cury, DownToUp, color=-1, ExitWithBlack=False    ):        if DownToUp is False:            imageheight = list(range(int(cury) + 1, int(im.size[1]) - 1))        else:            imageheight = list(range(int(cury) - 1, 1, -1))        newy = (-1, -1)        blackfound = 0        for y in imageheight:            curpix = pix[curx, y]            if curpix < self.BLACKCOLOR:                blackfound = blackfound + 1                if ExitWithBlack is True and blackfound >= 3:                    break  #: Exit if found black                else:                    continue            if curpix >= self.BACKGROUND:                if newy != (-1, -1):                    #: Found last pixel and the first white                    break            if (curpix < self.BACKGROUND and color == -1) or (                curpix == color and color > -1            ):                #: Found pixel                newy = y, color        return newy",551270a0-edb8-470c-a34a-0e3ebe0b5017
anticaptchas,CircleCaptcha.py,find_circle,196,220,"def find_circle(self, pix, x1, y1, x2, y2, x3, y3):        #: Trasposizione coordinate        #: A(0, 0) B(x2-x1, y2-y1) C(x3-x1, y3-y1)        #: x**2+y**2+ax+bx+c=0        p2 = (x2 - x1, y2 - y1)        p3 = (x3 - x1, y3 - y1)        #: 1        c = 0        #: 2        #: p2[0]**2+a*p2[0]+c=0        #: a*p2[0]=-1*(p2[0]**2-c)        #: a=(-1*(p2[0]**2-c))/p2[0]        a = (-1 * (p2[0] ** 2 - c)) / p2[0]        #: 3        #: p3[0]**2+p3[1]**2+a*p3[0]+b*p3[1]+c=0        #: b*p3[1]=-(p3[0]**2+p3[1]**2+a*p3[0]+c)        #: b=(-1 * (p3[0]**2+p3[1]**2+a*p3[0]+c)) / p3[1]        b = (-1 * (p3[0] ** 2 + p3[1] ** 2 + a * p3[0] + c)) / p3[1]        r = math.floor(math.sqrt((-1 * (a / 2)) ** 2 + (-1 * (b / 2)) ** 2))        cx = math.floor((-1 * (a / 2)) + x1)        cy = math.floor((-1 * (b / 2)) + y1)        return cx, cy, r",,"def find_circle(self, pix, x1, y1, x2, y2, x3, y3):        #: Trasposizione coordinate        #: A(0, 0) B(x2-x1, y2-y1) C(x3-x1, y3-y1)        #: x**2+y**2+ax+bx+c=0        p2 = (x2 - x1, y2 - y1)        p3 = (x3 - x1, y3 - y1)        #: 1        c = 0        #: 2        #: p2[0]**2+a*p2[0]+c=0        #: a*p2[0]=-1*(p2[0]**2-c)        #: a=(-1*(p2[0]**2-c))/p2[0]        a = (-1 * (p2[0] ** 2 - c)) / p2[0]        #: 3        #: p3[0]**2+p3[1]**2+a*p3[0]+b*p3[1]+c=0        #: b*p3[1]=-(p3[0]**2+p3[1]**2+a*p3[0]+c)        #: b=(-1 * (p3[0]**2+p3[1]**2+a*p3[0]+c)) / p3[1]        b = (-1 * (p3[0] ** 2 + p3[1] ** 2 + a * p3[0] + c)) / p3[1]        r = math.floor(math.sqrt((-1 * (a / 2)) ** 2 + (-1 * (b / 2)) ** 2))        cx = math.floor((-1 * (a / 2)) + x1)        cy = math.floor((-1 * (b / 2)) + y1)        return cx, cy, r",f89ca398-262f-4ebe-9da2-c8012c656923
anticaptchas,CircleCaptcha.py,verify_circle_new,222,297,"def verify_circle_new(self, im, pix, c):                imagewidth = list(range(int(c[0] - c[2]), int(c[0] + c[2])))        min_ray = 15        max_ray = 30        exactfind = False        howmany = 0        missing = 0        missinglist = []        pointsofcircle = []        if (c[2] < min_ray) or (c[2] > max_ray):            return -1        #: Check cardinal points (at least 3) (if found i have to leave this position)        if pix[c[0] + c[2], c[1]] < self.BLACKCOLOR:            return -2        if pix[c[0] - c[2], c[1]] < self.BLACKCOLOR:            return -2        if pix[c[0], c[1] + c[2]] < self.BLACKCOLOR:            return -2        if pix[c[0], c[1] - c[2]] < self.BLACKCOLOR:            return -2        cardinalpoints = 0        if self.verify_point(im, pix, c[0] + c[2], c[1], True) == 1:            cardinalpoints = cardinalpoints + 1        if self.verify_point(im, pix, c[0] + c[2], c[1], False) == -1:            return -2        if self.verify_point(im, pix, c[0] - c[2], c[1], True) == 1:            cardinalpoints = cardinalpoints + 1        if self.verify_point(im, pix, c[0] - c[2], c[1], False) == -1:            return -2        if self.verify_point(im, pix, c[0], c[1] + c[2], True) == 1:            cardinalpoints = cardinalpoints + 1        if self.verify_point(im, pix, c[0], c[1] + c[2], False) == -1:            return -2        if self.verify_point(im, pix, c[0], c[1] - c[2], True) == 1:            cardinalpoints = cardinalpoints + 1        if self.verify_point(im, pix, c[0], c[1] - c[2], False) == -1:            return -2        if cardinalpoints < 3:            return -1        for x in imagewidth:            #: Pitagora            y = int(round(c[1] - math.sqrt(c[2] ** 2 - (c[0] - x) ** 2)))            y2 = int(round(c[1] + math.sqrt(c[2] ** 2 - (c[0] - x) ** 2)))            howmany = howmany + 2            if self.verify_point(im, pix, x, y, exactfind) == 0:                missing = missing + 1                missinglist.append((x, y))            else:                pointsofcircle.append((x, y))            if self.verify_point(im, pix, x, y, False) == -1:                return -2            if self.verify_point(im, pix, x, y2, exactfind) == 0:                missing = missing + 1                missinglist.append((x, y2))            else:                pointsofcircle.append((x, y2))            if self.verify_point(im, pix, x, y2, False) == -1:                return -2","This is the MAIN function to recognize the circle returns: 1 -> Found closed
circle 0 -> Found open circle.

-1 -> Not found circle
-2 -> Found black position then leave position","def verify_circle_new(self, im, pix, c):        """"""        This is the MAIN function to recognize the circle returns: 1 -> Found closed        circle 0 -> Found open circle.        -1 -> Not found circle        -2 -> Found black position then leave position        """"""        imagewidth = list(range(int(c[0] - c[2]), int(c[0] + c[2])))        min_ray = 15        max_ray = 30        exactfind = False        howmany = 0        missing = 0        missinglist = []        pointsofcircle = []        if (c[2] < min_ray) or (c[2] > max_ray):            return -1        #: Check cardinal points (at least 3) (if found i have to leave this position)        if pix[c[0] + c[2], c[1]] < self.BLACKCOLOR:            return -2        if pix[c[0] - c[2], c[1]] < self.BLACKCOLOR:            return -2        if pix[c[0], c[1] + c[2]] < self.BLACKCOLOR:            return -2        if pix[c[0], c[1] - c[2]] < self.BLACKCOLOR:            return -2        cardinalpoints = 0        if self.verify_point(im, pix, c[0] + c[2], c[1], True) == 1:            cardinalpoints = cardinalpoints + 1        if self.verify_point(im, pix, c[0] + c[2], c[1], False) == -1:            return -2        if self.verify_point(im, pix, c[0] - c[2], c[1], True) == 1:            cardinalpoints = cardinalpoints + 1        if self.verify_point(im, pix, c[0] - c[2], c[1], False) == -1:            return -2        if self.verify_point(im, pix, c[0], c[1] + c[2], True) == 1:            cardinalpoints = cardinalpoints + 1        if self.verify_point(im, pix, c[0], c[1] + c[2], False) == -1:            return -2        if self.verify_point(im, pix, c[0], c[1] - c[2], True) == 1:            cardinalpoints = cardinalpoints + 1        if self.verify_point(im, pix, c[0], c[1] - c[2], False) == -1:            return -2        if cardinalpoints < 3:            return -1        for x in imagewidth:            #: Pitagora            y = int(round(c[1] - math.sqrt(c[2] ** 2 - (c[0] - x) ** 2)))            y2 = int(round(c[1] + math.sqrt(c[2] ** 2 - (c[0] - x) ** 2)))            howmany = howmany + 2            if self.verify_point(im, pix, x, y, exactfind) == 0:                missing = missing + 1                missinglist.append((x, y))            else:                pointsofcircle.append((x, y))            if self.verify_point(im, pix, x, y, False) == -1:                return -2            if self.verify_point(im, pix, x, y2, exactfind) == 0:                missing = missing + 1                missinglist.append((x, y2))            else:                pointsofcircle.append((x, y2))            if self.verify_point(im, pix, x, y2, False) == -1:                return -2

This is the MAIN function to recognize the circle returns: 1 -> Found closed
circle 0 -> Found open circle.

-1 -> Not found circle
-2 -> Found black position then leave position",50cff84b-0fba-4d18-ae23-22477b76d71a
anticaptchas,CircleCaptcha.py,verify_circle,299,496,"def verify_circle(self, im, pix, c):                imageheight = list(range(int(c[1] - c[2]), int(c[1] + c[2])))        imagewidth = list(range(int(c[0] - c[2]), int(c[0] + c[2])))        min_ray = 15        max_ray = 30        exactfind = False        howmany = 0        missing = 0        missingconsecutive = 0        missinglist = []        minX = 0        maxX = 0        minY = 0        maxY = 0        pointsofcircle = []        if (c[2] < min_ray) or (c[2] > max_ray):            return -1        #: Check cardinal points (at least 3) (if found i have to leave this position)        if pix[c[0] + c[2], c[1]] < self.BLACKCOLOR:            return -2        if pix[c[0] - c[2], c[1]] < self.BLACKCOLOR:            return -2        if pix[c[0], c[1] + c[2]] < self.BLACKCOLOR:            return -2        if pix[c[0], c[1] - c[2]] < self.BLACKCOLOR:            return -2        cardinalpoints = 0        if self.verify_point(im, pix, c[0] + c[2], c[1], True) == 1:            cardinalpoints = cardinalpoints + 1        if self.verify_point(im, pix, c[0] + c[2], c[1], False) == -1:            return -2        if self.verify_point(im, pix, c[0] - c[2], c[1], True) == 1:            cardinalpoints = cardinalpoints + 1        if self.verify_point(im, pix, c[0] - c[2], c[1], False) == -1:            return -2        if self.verify_point(im, pix, c[0], c[1] + c[2], True) == 1:            cardinalpoints = cardinalpoints + 1        if self.verify_point(im, pix, c[0], c[1] + c[2], False) == -1:            return -2        if self.verify_point(im, pix, c[0], c[1] - c[2], True) == 1:            cardinalpoints = cardinalpoints + 1        if self.verify_point(im, pix, c[0], c[1] - c[2], False) == -1:            return -2        if cardinalpoints < 3:            return -1        for x in imagewidth:            #: Pitagora            y = int(round(c[1] - math.sqrt(c[2] ** 2 - (c[0] - x) ** 2)))            y2 = int(round(c[1] + math.sqrt(c[2] ** 2 - (c[0] - x) ** 2)))            howmany = howmany + 2            if self.verify_point(im, pix, x, y, exactfind) == 0:                missing = missing + 1                missinglist.append((x, y))            else:                pointsofcircle.append((x, y))            if self.verify_point(im, pix, x, y, False) == -1:                return -2            if self.verify_point(im, pix, x, y2, exactfind) == 0:                missing = missing + 1                missinglist.append((x, y2))            else:                pointsofcircle.append((x, y2))            if self.verify_point(im, pix, x, y2, False) == -1:                return -2        for y in imageheight:            #: Pitagora            x = int(round(c[0] - math.sqrt(c[2] ** 2 - (c[1] - y) ** 2)))            x2 = int(round(c[0] + math.sqrt(c[2] ** 2 - (c[1] - y) ** 2)))            howmany = howmany + 2            if self.verify_point(im, pix, x, y, exactfind) == 0:                missing = missing + 1                missinglist.append((x, y))            else:                pointsofcircle.append((x, y))            if self.verify_point(im, pix, x, y, False) == -1:                return -2            if self.verify_point(im, pix, x2, y, exactfind) == 0:                missing = missing + 1                missinglist.append((x2, y))            else:                pointsofcircle.append((x2, y))            if self.verify_point(im, pix, x2, y, exactfind) == -1:                return -2        for p in missinglist:            #: Left and bottom            if (                self.verify_point(im, pix, p[0] - 1, p[1], exactfind) == 1                and self.verify_point(im, pix, p[0], p[1] + 1, exactfind) == 1            ):                missing = missing - 1            elif (                self.verify_point(im, pix, p[0] - 1, p[1], exactfind) == 1                and self.verify_point(im, pix, p[0], p[1] - 1, exactfind) == 1            ):                missing = missing - 1                #: Right and bottom            elif (                self.verify_point(im, pix, p[0] + 1, p[1], exactfind) == 1                and self.verify_point(im, pix, p[0], p[1] + 1, exactfind) == 1            ):                missing = missing - 1                #: Right and up            elif (                self.verify_point(im, pix, p[0] + 1, p[1], exactfind) == 1                and self.verify_point(im, pix, p[0], p[1] - 1, exactfind) == 1            ):                missing = missing - 1            if (                (p[0], p[1] + 1) in missinglist                or (p[0], p[1] - 1) in missinglist                or (p[0] + 1, p[1]) in missinglist                or (p[0] - 1, p[1]) in missinglist                or (p[0] + 1, p[1] + 1) in missinglist                or (p[0] - 1, p[1] + 1) in missinglist                or (p[0] + 1, p[1] - 1) in missinglist                or (p[0] - 1, p[1] - 1) in missinglist                or self.verify_point(im, pix, p[0], p[1], False) == 1            ):                missingconsecutive = missingconsecutive + 1            # else:            #     pix[p[0], p[1]] = 0        if len(missinglist) > 0:            minX = min(missinglist, key=operator.itemgetter(0))[0]            maxX = max(missinglist, key=operator.itemgetter(0))[0]            minY = min(missinglist, key=operator.itemgetter(1))[1]            maxY = max(missinglist, key=operator.itemgetter(1))[1]        #: Assial Simmetric        if self.pyload.debug:            self.log_debug(                ""Center: {}"".format(c),                ""Missing: {}"".format(missing),                ""Howmany: {}"".format(howmany),                ""Ratio: {}"".format(missing / howmany),                ""Missing consecutives: {}"".format(missingconsecutive),                ""Missing X lenght: {}:{}"".format(minX, maxX),                ""Missing Y lenght: {}:{}"".format(minY, maxY),                ""Ratio without consecutives: {}"".format(                    (missing - missingconsecutive) / howmany                ),                ""List missing: {}"".format(missinglist),            )        #: Lenght of missing cannot be over 75% of diameter        if maxX - minX >= c[2] * 2 * 0.75:            return -1        if maxY - minY >= c[2] * 2 * 0.75:            #: input('tro')            return -1                if (            missing / howmany > 0.25            or missingconsecutive >= (howmany / 4) * 2            or howmany < 80        ):            return -1        # elif missing / howmany < 0.10:        elif missing == 0:            self.pointsofcirclefound.extend(pointsofcircle)            return 1        elif (missing - missingconsecutive) / howmany < 0.20:            return 0        else:            self.pointsofcirclefound.extend(pointsofcircle)            return 1","This is the MAIN function to recognize the circle returns: 1 -> Found closed
circle 0 -> Found open circle.

-1 -> Not found circle
-2 -> Found black position then leave position","def verify_circle(self, im, pix, c):        """"""        This is the MAIN function to recognize the circle returns: 1 -> Found closed        circle 0 -> Found open circle.        -1 -> Not found circle        -2 -> Found black position then leave position        """"""        imageheight = list(range(int(c[1] - c[2]), int(c[1] + c[2])))        imagewidth = list(range(int(c[0] - c[2]), int(c[0] + c[2])))        min_ray = 15        max_ray = 30        exactfind = False        howmany = 0        missing = 0        missingconsecutive = 0        missinglist = []        minX = 0        maxX = 0        minY = 0        maxY = 0        pointsofcircle = []        if (c[2] < min_ray) or (c[2] > max_ray):            return -1        #: Check cardinal points (at least 3) (if found i have to leave this position)        if pix[c[0] + c[2], c[1]] < self.BLACKCOLOR:            return -2        if pix[c[0] - c[2], c[1]] < self.BLACKCOLOR:            return -2        if pix[c[0], c[1] + c[2]] < self.BLACKCOLOR:            return -2        if pix[c[0], c[1] - c[2]] < self.BLACKCOLOR:            return -2        cardinalpoints = 0        if self.verify_point(im, pix, c[0] + c[2], c[1], True) == 1:            cardinalpoints = cardinalpoints + 1        if self.verify_point(im, pix, c[0] + c[2], c[1], False) == -1:            return -2        if self.verify_point(im, pix, c[0] - c[2], c[1], True) == 1:            cardinalpoints = cardinalpoints + 1        if self.verify_point(im, pix, c[0] - c[2], c[1], False) == -1:            return -2        if self.verify_point(im, pix, c[0], c[1] + c[2], True) == 1:            cardinalpoints = cardinalpoints + 1        if self.verify_point(im, pix, c[0], c[1] + c[2], False) == -1:            return -2        if self.verify_point(im, pix, c[0], c[1] - c[2], True) == 1:            cardinalpoints = cardinalpoints + 1        if self.verify_point(im, pix, c[0], c[1] - c[2], False) == -1:            return -2        if cardinalpoints < 3:            return -1        for x in imagewidth:            #: Pitagora            y = int(round(c[1] - math.sqrt(c[2] ** 2 - (c[0] - x) ** 2)))            y2 = int(round(c[1] + math.sqrt(c[2] ** 2 - (c[0] - x) ** 2)))            howmany = howmany + 2            if self.verify_point(im, pix, x, y, exactfind) == 0:                missing = missing + 1                missinglist.append((x, y))            else:                pointsofcircle.append((x, y))            if self.verify_point(im, pix, x, y, False) == -1:                return -2            if self.verify_point(im, pix, x, y2, exactfind) == 0:                missing = missing + 1                missinglist.append((x, y2))            else:                pointsofcircle.append((x, y2))            if self.verify_point(im, pix, x, y2, False) == -1:                return -2        for y in imageheight:            #: Pitagora            x = int(round(c[0] - math.sqrt(c[2] ** 2 - (c[1] - y) ** 2)))            x2 = int(round(c[0] + math.sqrt(c[2] ** 2 - (c[1] - y) ** 2)))            howmany = howmany + 2            if self.verify_point(im, pix, x, y, exactfind) == 0:                missing = missing + 1                missinglist.append((x, y))            else:                pointsofcircle.append((x, y))            if self.verify_point(im, pix, x, y, False) == -1:                return -2            if self.verify_point(im, pix, x2, y, exactfind) == 0:                missing = missing + 1                missinglist.append((x2, y))            else:                pointsofcircle.append((x2, y))            if self.verify_point(im, pix, x2, y, exactfind) == -1:                return -2        for p in missinglist:            #: Left and bottom            if (                self.verify_point(im, pix, p[0] - 1, p[1], exactfind) == 1                and self.verify_point(im, pix, p[0], p[1] + 1, exactfind) == 1            ):                missing = missing - 1            elif (                self.verify_point(im, pix, p[0] - 1, p[1], exactfind) == 1                and self.verify_point(im, pix, p[0], p[1] - 1, exactfind) == 1            ):                missing = missing - 1                #: Right and bottom            elif (                self.verify_point(im, pix, p[0] + 1, p[1], exactfind) == 1                and self.verify_point(im, pix, p[0], p[1] + 1, exactfind) == 1            ):                missing = missing - 1                #: Right and up            elif (                self.verify_point(im, pix, p[0] + 1, p[1], exactfind) == 1                and self.verify_point(im, pix, p[0], p[1] - 1, exactfind) == 1            ):                missing = missing - 1            if (                (p[0], p[1] + 1) in missinglist                or (p[0], p[1] - 1) in missinglist                or (p[0] + 1, p[1]) in missinglist                or (p[0] - 1, p[1]) in missinglist                or (p[0] + 1, p[1] + 1) in missinglist                or (p[0] - 1, p[1] + 1) in missinglist                or (p[0] + 1, p[1] - 1) in missinglist                or (p[0] - 1, p[1] - 1) in missinglist                or self.verify_point(im, pix, p[0], p[1], False) == 1            ):                missingconsecutive = missingconsecutive + 1            # else:            #     pix[p[0], p[1]] = 0        if len(missinglist) > 0:            minX = min(missinglist, key=operator.itemgetter(0))[0]            maxX = max(missinglist, key=operator.itemgetter(0))[0]            minY = min(missinglist, key=operator.itemgetter(1))[1]            maxY = max(missinglist, key=operator.itemgetter(1))[1]        #: Assial Simmetric        if self.pyload.debug:            self.log_debug(                ""Center: {}"".format(c),                ""Missing: {}"".format(missing),                ""Howmany: {}"".format(howmany),                ""Ratio: {}"".format(missing / howmany),                ""Missing consecutives: {}"".format(missingconsecutive),                ""Missing X lenght: {}:{}"".format(minX, maxX),                ""Missing Y lenght: {}:{}"".format(minY, maxY),                ""Ratio without consecutives: {}"".format(                    (missing - missingconsecutive) / howmany                ),                ""List missing: {}"".format(missinglist),            )        #: Lenght of missing cannot be over 75% of diameter        if maxX - minX >= c[2] * 2 * 0.75:            return -1        if maxY - minY >= c[2] * 2 * 0.75:            #: input('tro')            return -1        """"""        #: Lenght of missing cannot be less 10% of diameter        if maxX - minX < c[2] * 2 * 0.10 and maxY - minY < c[2] * 2 * 0.10:            return -1        """"""        if (            missing / howmany > 0.25            or missingconsecutive >= (howmany / 4) * 2            or howmany < 80        ):            return -1        # elif missing / howmany < 0.10:        elif missing == 0:            self.pointsofcirclefound.extend(pointsofcircle)            return 1        elif (missing - missingconsecutive) / howmany < 0.20:            return 0        else:            self.pointsofcirclefound.extend(pointsofcircle)            return 1

This is the MAIN function to recognize the circle returns: 1 -> Found closed
circle 0 -> Found open circle.

-1 -> Not found circle
-2 -> Found black position then leave position",b7320599-351e-42f2-b93d-737d0e03db51
anticaptchas,CircleCaptcha.py,verify_point,498,538,"def verify_point(self, im, pix, x, y, exact, color=-1):        #: Verify point        result = 0        if x < 0 or x >= im.size[0]:            return result        if y < 0 or y >= im.size[1]:            return result        curpix = pix[x, y]        if (curpix == color and color > -1) or (            curpix < self.BACKGROUND and color == -1        ):            if curpix > self.BLACKCOLOR:                result = 1            else:                result = -1        #: Verify around        if exact is False:            if x + 1 < im.size[0]:                curpix = pix[x + 1, y]                if (curpix == color and color > -1) or (                    curpix < self.BACKGROUND and color == -1                ):                    if curpix > self.BLACKCOLOR:                        result = 1                if curpix <= self.BLACKCOLOR:                    result = -1            if x > 0:                curpix = pix[x - 1, y]                if (curpix == color and color > -1) or (                    curpix < self.BACKGROUND and color == -1                ):                    if curpix > self.BLACKCOLOR:                        result = 1                if curpix <= self.BLACKCOLOR:                    result = -1        # self.log_debug(f""{(x, y)} = {result}"")        return result",,"def verify_point(self, im, pix, x, y, exact, color=-1):        #: Verify point        result = 0        if x < 0 or x >= im.size[0]:            return result        if y < 0 or y >= im.size[1]:            return result        curpix = pix[x, y]        if (curpix == color and color > -1) or (            curpix < self.BACKGROUND and color == -1        ):            if curpix > self.BLACKCOLOR:                result = 1            else:                result = -1        #: Verify around        if exact is False:            if x + 1 < im.size[0]:                curpix = pix[x + 1, y]                if (curpix == color and color > -1) or (                    curpix < self.BACKGROUND and color == -1                ):                    if curpix > self.BLACKCOLOR:                        result = 1                if curpix <= self.BLACKCOLOR:                    result = -1            if x > 0:                curpix = pix[x - 1, y]                if (curpix == color and color > -1) or (                    curpix < self.BACKGROUND and color == -1                ):                    if curpix > self.BLACKCOLOR:                        result = 1                if curpix <= self.BLACKCOLOR:                    result = -1        # self.log_debug(f""{(x, y)} = {result}"")        return result",e237745b-c695-49d6-b2d8-7e536df18cad
anticaptchas,CircleCaptcha.py,decrypt,540,797,"def decrypt(self, img):        i_debug_save_file = 0        mypalette = None        for im in ImageSequence(img):            im.save(""orig.png"", ""png"")            if mypalette is not None:                im.putpalette(mypalette)            mypalette = im.getpalette()            im = im.convert(""L"")            if self.pyload.debug:                i_debug_save_file = i_debug_save_file + 1                # if i_debug_save_file < 7:                # continue                im.save(""output{}.png"".format(i_debug_save_file), ""png"")                input(""frame: {}"".format(im))            pix = im.load()            stepheight = list(range(1, im.size[1], 2))            #: stepheight = range(45, 47)            lst_points = []  #: Declares an empty list for the points            lstX = []  #: CoordinateX            lstY = []  #: CoordinateY            lst_colors = []  #: Declares an empty list named lst            min_distance = 10            max_diameter = 70            if self.pyload.debug:                imdebug = im.copy()                draw = ImageDraw.Draw(imdebug)                pixcopy = imdebug.load()            #: Clean image for powerfull search            self.clean_image(im, pix)            im.save(""cleaned{}.png"".format(i_debug_save_file), ""png"")            found = set()            findnewcircle = True            #: Finding all the circles            for y1 in stepheight:                x1 = 1                for k in range(1, 100):                    findnewcircle = False                    retval = self.find_first_pixel_x(im, pix, x1, y1, -1, False)                    x1 = retval[0]                    if x1 == -2:                        break                    if x1 == -1:                        break                    if self.pyload.debug:                        self.log_debug(f""x1, y1 -> {(x1, y1)}: {pix[x1, y1]}"")                    if (x1, y1) in self.pointsofcirclefound:                        if self.pyload.debug:                            self.log_debug(f""Found {(x1, y1)}"")                        continue                    if self.pyload.debug:                        pixcopy[x1, y1] = 45  #: (255, 0, 0, 255)                    #: found 1 pixel, seeking x2, y2                    x2 = x1                    y2 = y1                    for i in range(1, 100):                        retval = self.find_last_pixel_x(im, pix, x2, y2, -1, True)                        x2 = retval[0]                        if x1 == -2:                            findnewcircle = True                            break                        if x2 == -1:                            break                        if self.pyload.debug:                            self.log_debug(                                ""x2, y2 -> {}: {}"".format((x2, y1), pix[x2, y1])                            )                        if abs(x2 - x1) < min_distance:                            continue                        if abs(x2 - x1) > (im.size[1] * 2 / 3):                            break                        if abs(x2 - x1) > max_diameter:                            break                        if self.pyload.debug:                            pixcopy[x2, y2] = 65  #: (0, 255, 0, 255)                        #: found 2 pixel, seeking x3, y3                        #: Verify cord                        for invert in range(2):                            x3 = math.floor(x2 - ((x2 - x1) / 2))                            y3 = y1                            for j in range(1, 50):                                retval = self.find_last_pixel_y(                                    im, pix, x3, y3, invert == 1, -1, True                                )                                # self.log_debug(x3, y3, retval[0], invert)                                y3 = retval[0]                                if y3 == -2:                                    findnewcircle = True                                    break                                if y3 == -1:                                    break                                if self.pyload.debug:                                    self.log_debug(                                        ""x3, y3 -> ""                                        + str((x3, y3))                                        + "": ""                                        + str(pix[x3, y3])                                    )                                #: Verify cord                                if abs(y3 - y2) < min_distance:                                    continue                                if abs(y3 - y2) > (im.size[1] * 2 / 3):                                    break                                if abs(y3 - y2) > max_diameter:                                    break                                if self.pyload.debug:                                    pixcopy[x3, y3] = 85                                #: found 3 pixel. try circle                                c = self.find_circle(pix, x1, y1, x2, y2, x3, y3)                                if (                                    c[0] + c[2] >= im.size[0]                                    or c[1] + c[2] >= im.size[1]                                    or c[0] - c[2] <= 0                                    or c[1] - c[2] <= 0                                ):                                    continue                                if self.pyload.debug:                                    pixcopy[c[0], c[1]] = 0                                #: (x-r, y-r, x+r, y+r)                                verified = self.verify_circle(im, pix, c)                                if verified == -1:                                    verified = -1                                elif verified == 0:                                    found.add(((c[0], c[1], c[2]), verified))                                    findnewcircle = True                                elif verified == 1:                                    found.add(((c[0], c[1], c[2]), verified))                                    findnewcircle = True                                if self.pyload.debug:                                    _pause = """"                                    # if verified == -1:                                    # draw.ellipse((c[0]-c[2], c[1]-c[2], c[0]+c[2], c[1]+c[2]), outline=0)                                    # _pause = ""NOTDOUND""                                    # imdebug.save(""debug.png"", ""png"")                                    if verified == 0:                                        draw.ellipse(                                            (                                                c[0] - c[2],                                                c[1] - c[2],                                                c[0] + c[2],                                                c[1] + c[2],                                            ),                                            outline=120,                                        )                                        _pause = ""OPENED""                                    if verified == 1:                                        draw.ellipse(                                            (                                                c[0] - c[2],                                                c[1] - c[2],                                                c[0] + c[2],                                                c[1] + c[2],                                            ),                                            outline=65,                                        )                                        _pause = ""CLOSED""                                    imdebug.save(""debug.png"", ""png"")                                    if _pause != """":                                        valore = input(                                            ""Found ""                                            + _pause                                            + "" CIRCLE circle press [Enter] = continue / [q] for Quit: ""                                            + str(verified)                                        )                                        if valore == ""q"":                                            sys.exit()                                if findnewcircle is True:                                    break                            if findnewcircle is True:                                break                        if findnewcircle is True:                            break            if self.pyload.debug:                self.log_debug(""Howmany opened circle?"", found)            #: Clean results            for c in found:                verify = c[1]                if verify == 0:                    p = c[0]                    if (                        ((p[0], p[1] + 1, p[2]), 1) in found                        or ((p[0], p[1] - 1, p[2]), 1) in found                        or ((p[0] + 1, p[1], p[2]), 1) in found                        or ((p[0] - 1, p[1], p[2]), 1) in found                        or ((p[0] + 1, p[1] + 1, p[2]), 1) in found                        or ((p[0] - 1, p[1] + 1, p[2]), 1) in found                        or ((p[0] + 1, p[1] - 1, p[2]), 1) in found                        or ((p[0] - 1, p[1] - 1, p[2]), 1) in found                    ):                        #: Delete nearly circle                        verify = -1                    if (                        ((p[0], p[1] + 1, p[2] + 1), 1) in found                        or ((p[0], p[1] - 1, p[2] + 1), 1) in found                        or ((p[0] + 1, p[1], p[2] + 1), 1) in found                        or ((p[0] - 1, p[1], p[2] + 1), 1) in found                        or ((p[0] + 1, p[1] + 1, p[2] + 1), 1) in found                        or ((p[0] - 1, p[1] + 1, p[2] + 1), 1) in found                        or ((p[0] + 1, p[1] - 1, p[2] + 1), 1) in found                        or ((p[0] - 1, p[1] - 1, p[2] + 1), 1) in found                    ):                        #: Delete nearly circle                        verify = -1                    if (                        ((p[0], p[1] + 1, p[2] - 1), 1) in found                        or ((p[0], p[1] - 1, p[2] - 1), 1) in found                        or ((p[0] + 1, p[1], p[2] - 1), 1) in found                        or ((p[0] - 1, p[1], p[2] - 1), 1) in found                        or ((p[0] + 1, p[1] + 1, p[2] - 1), 1) in found                        or ((p[0] - 1, p[1] + 1, p[2] - 1), 1) in found                        or ((p[0] + 1, p[1] - 1, p[2] - 1), 1) in found                        or ((p[0] - 1, p[1] - 1, p[2] - 1), 1) in found                    ):                        #: Delete nearly circle                        verify = -1                # if verify == 0:                # if self.pyload.debug:                # pix[c[0][0], c[0][1]] = 90 #(255, 255, 0)                # im.save(""output.png"", ""png"")                # return c[0][0], c[0][1]                # elif verify == 1:                # if self.pyload.debug:                # pix[c[0][0], c[0][1]] = 40 #(255, 0, 0)                # im.save(""output.png"", ""png"")                # else:                # if self.pyload.debug:                # pix[c[0][0], c[0][1]] = 180 #(0, 0, 255)                # im.save(""output.png"", ""png"")        if self.pyload.debug:            im.save(""output.png"", ""png"")",,"def decrypt(self, img):        i_debug_save_file = 0        mypalette = None        for im in ImageSequence(img):            im.save(""orig.png"", ""png"")            if mypalette is not None:                im.putpalette(mypalette)            mypalette = im.getpalette()            im = im.convert(""L"")            if self.pyload.debug:                i_debug_save_file = i_debug_save_file + 1                # if i_debug_save_file < 7:                # continue                im.save(""output{}.png"".format(i_debug_save_file), ""png"")                input(""frame: {}"".format(im))            pix = im.load()            stepheight = list(range(1, im.size[1], 2))            #: stepheight = range(45, 47)            lst_points = []  #: Declares an empty list for the points            lstX = []  #: CoordinateX            lstY = []  #: CoordinateY            lst_colors = []  #: Declares an empty list named lst            min_distance = 10            max_diameter = 70            if self.pyload.debug:                imdebug = im.copy()                draw = ImageDraw.Draw(imdebug)                pixcopy = imdebug.load()            #: Clean image for powerfull search            self.clean_image(im, pix)            im.save(""cleaned{}.png"".format(i_debug_save_file), ""png"")            found = set()            findnewcircle = True            #: Finding all the circles            for y1 in stepheight:                x1 = 1                for k in range(1, 100):                    findnewcircle = False                    retval = self.find_first_pixel_x(im, pix, x1, y1, -1, False)                    x1 = retval[0]                    if x1 == -2:                        break                    if x1 == -1:                        break                    if self.pyload.debug:                        self.log_debug(f""x1, y1 -> {(x1, y1)}: {pix[x1, y1]}"")                    if (x1, y1) in self.pointsofcirclefound:                        if self.pyload.debug:                            self.log_debug(f""Found {(x1, y1)}"")                        continue                    if self.pyload.debug:                        pixcopy[x1, y1] = 45  #: (255, 0, 0, 255)                    #: found 1 pixel, seeking x2, y2                    x2 = x1                    y2 = y1                    for i in range(1, 100):                        retval = self.find_last_pixel_x(im, pix, x2, y2, -1, True)                        x2 = retval[0]                        if x1 == -2:                            findnewcircle = True                            break                        if x2 == -1:                            break                        if self.pyload.debug:                            self.log_debug(                                ""x2, y2 -> {}: {}"".format((x2, y1), pix[x2, y1])                            )                        if abs(x2 - x1) < min_distance:                            continue                        if abs(x2 - x1) > (im.size[1] * 2 / 3):                            break                        if abs(x2 - x1) > max_diameter:                            break                        if self.pyload.debug:                            pixcopy[x2, y2] = 65  #: (0, 255, 0, 255)                        #: found 2 pixel, seeking x3, y3                        #: Verify cord                        for invert in range(2):                            x3 = math.floor(x2 - ((x2 - x1) / 2))                            y3 = y1                            for j in range(1, 50):                                retval = self.find_last_pixel_y(                                    im, pix, x3, y3, invert == 1, -1, True                                )                                # self.log_debug(x3, y3, retval[0], invert)                                y3 = retval[0]                                if y3 == -2:                                    findnewcircle = True                                    break                                if y3 == -1:                                    break                                if self.pyload.debug:                                    self.log_debug(                                        ""x3, y3 -> ""                                        + str((x3, y3))                                        + "": ""                                        + str(pix[x3, y3])                                    )                                #: Verify cord                                if abs(y3 - y2) < min_distance:                                    continue                                if abs(y3 - y2) > (im.size[1] * 2 / 3):                                    break                                if abs(y3 - y2) > max_diameter:                                    break                                if self.pyload.debug:                                    pixcopy[x3, y3] = 85                                #: found 3 pixel. try circle                                c = self.find_circle(pix, x1, y1, x2, y2, x3, y3)                                if (                                    c[0] + c[2] >= im.size[0]                                    or c[1] + c[2] >= im.size[1]                                    or c[0] - c[2] <= 0                                    or c[1] - c[2] <= 0                                ):                                    continue                                if self.pyload.debug:                                    pixcopy[c[0], c[1]] = 0                                #: (x-r, y-r, x+r, y+r)                                verified = self.verify_circle(im, pix, c)                                if verified == -1:                                    verified = -1                                elif verified == 0:                                    found.add(((c[0], c[1], c[2]), verified))                                    findnewcircle = True                                elif verified == 1:                                    found.add(((c[0], c[1], c[2]), verified))                                    findnewcircle = True                                if self.pyload.debug:                                    _pause = """"                                    # if verified == -1:                                    # draw.ellipse((c[0]-c[2], c[1]-c[2], c[0]+c[2], c[1]+c[2]), outline=0)                                    # _pause = ""NOTDOUND""                                    # imdebug.save(""debug.png"", ""png"")                                    if verified == 0:                                        draw.ellipse(                                            (                                                c[0] - c[2],                                                c[1] - c[2],                                                c[0] + c[2],                                                c[1] + c[2],                                            ),                                            outline=120,                                        )                                        _pause = ""OPENED""                                    if verified == 1:                                        draw.ellipse(                                            (                                                c[0] - c[2],                                                c[1] - c[2],                                                c[0] + c[2],                                                c[1] + c[2],                                            ),                                            outline=65,                                        )                                        _pause = ""CLOSED""                                    imdebug.save(""debug.png"", ""png"")                                    if _pause != """":                                        valore = input(                                            ""Found ""                                            + _pause                                            + "" CIRCLE circle press [Enter] = continue / [q] for Quit: ""                                            + str(verified)                                        )                                        if valore == ""q"":                                            sys.exit()                                if findnewcircle is True:                                    break                            if findnewcircle is True:                                break                        if findnewcircle is True:                            break            if self.pyload.debug:                self.log_debug(""Howmany opened circle?"", found)            #: Clean results            for c in found:                verify = c[1]                if verify == 0:                    p = c[0]                    if (                        ((p[0], p[1] + 1, p[2]), 1) in found                        or ((p[0], p[1] - 1, p[2]), 1) in found                        or ((p[0] + 1, p[1], p[2]), 1) in found                        or ((p[0] - 1, p[1], p[2]), 1) in found                        or ((p[0] + 1, p[1] + 1, p[2]), 1) in found                        or ((p[0] - 1, p[1] + 1, p[2]), 1) in found                        or ((p[0] + 1, p[1] - 1, p[2]), 1) in found                        or ((p[0] - 1, p[1] - 1, p[2]), 1) in found                    ):                        #: Delete nearly circle                        verify = -1                    if (                        ((p[0], p[1] + 1, p[2] + 1), 1) in found                        or ((p[0], p[1] - 1, p[2] + 1), 1) in found                        or ((p[0] + 1, p[1], p[2] + 1), 1) in found                        or ((p[0] - 1, p[1], p[2] + 1), 1) in found                        or ((p[0] + 1, p[1] + 1, p[2] + 1), 1) in found                        or ((p[0] - 1, p[1] + 1, p[2] + 1), 1) in found                        or ((p[0] + 1, p[1] - 1, p[2] + 1), 1) in found                        or ((p[0] - 1, p[1] - 1, p[2] + 1), 1) in found                    ):                        #: Delete nearly circle                        verify = -1                    if (                        ((p[0], p[1] + 1, p[2] - 1), 1) in found                        or ((p[0], p[1] - 1, p[2] - 1), 1) in found                        or ((p[0] + 1, p[1], p[2] - 1), 1) in found                        or ((p[0] - 1, p[1], p[2] - 1), 1) in found                        or ((p[0] + 1, p[1] + 1, p[2] - 1), 1) in found                        or ((p[0] - 1, p[1] + 1, p[2] - 1), 1) in found                        or ((p[0] + 1, p[1] - 1, p[2] - 1), 1) in found                        or ((p[0] - 1, p[1] - 1, p[2] - 1), 1) in found                    ):                        #: Delete nearly circle                        verify = -1                # if verify == 0:                # if self.pyload.debug:                # pix[c[0][0], c[0][1]] = 90 #(255, 255, 0)                # im.save(""output.png"", ""png"")                # return c[0][0], c[0][1]                # elif verify == 1:                # if self.pyload.debug:                # pix[c[0][0], c[0][1]] = 40 #(255, 0, 0)                # im.save(""output.png"", ""png"")                # else:                # if self.pyload.debug:                # pix[c[0][0], c[0][1]] = 180 #(0, 0, 255)                # im.save(""output.png"", ""png"")        if self.pyload.debug:            im.save(""output.png"", ""png"")",c46d0346-e286-48cf-aa69-a7657d2d907b
anticaptchas,CircleCaptcha.py,decrypt_from_web,800,804,"def decrypt_from_web(self, url):        file = io.StringIO(urllib.request.urlopen(url).read())        img = Image.open(file)        coords = self.decrypt(img)        self.log_info(self._(""Coords: {}"").format(coords))",,"def decrypt_from_web(self, url):        file = io.StringIO(urllib.request.urlopen(url).read())        img = Image.open(file)        coords = self.decrypt(img)        self.log_info(self._(""Coords: {}"").format(coords))",78e52bde-256c-4577-aa3d-6662b1ec5166
anticaptchas,CircleCaptcha.py,decrypt_from_file,807,810,"def decrypt_from_file(self, filename):        #: Can be many different formats.        coords = self.decrypt(Image.open(filename))        self.log_info(self._(""Coords: {}"").format(coords))",,"def decrypt_from_file(self, filename):        #: Can be many different formats.        coords = self.decrypt(Image.open(filename))        self.log_info(self._(""Coords: {}"").format(coords))",11e56937-d423-44d6-9f5f-656bfce77e2f
anticaptchas,CoinHive.py,detect_key,59,69,"def detect_key(self, data=None):        html = data or self.retrieve_data()        m = re.search(self.KEY_PATTERN, html)        if m is not None:            self.key = m.group(1).strip()            self.log_debug(f""Key: {self.key}"")            return self.key        else:            self.log_warning(self._(""Key pattern not found""))            return None",,"def detect_key(self, data=None):        html = data or self.retrieve_data()        m = re.search(self.KEY_PATTERN, html)        if m is not None:            self.key = m.group(1).strip()            self.log_debug(f""Key: {self.key}"")            return self.key        else:            self.log_warning(self._(""Key pattern not found""))            return None",44acec21-83c5-4a54-92e7-4067019fb556
anticaptchas,CoinHive.py,detect_hashes,71,80,"def detect_hashes(self, data=None):        html = data or self.retrieve_data()        m = re.search(self.HASHES_PATTERN, html)        if m is not None:            self.hashes = m.group(1).strip()            self.log_debug(f""Hashes: {self.hashes}"")            return self.hashes        else:            self.log_warning(self._(""Hashes pattern not found""))            return None",,"def detect_hashes(self, data=None):        html = data or self.retrieve_data()        m = re.search(self.HASHES_PATTERN, html)        if m is not None:            self.hashes = m.group(1).strip()            self.log_debug(f""Hashes: {self.hashes}"")            return self.hashes        else:            self.log_warning(self._(""Hashes pattern not found""))            return None",09756798-31ee-4338-8830-8ba5c6e0a999
anticaptchas,CoinHive.py,challenge,82,97,"def challenge(self, key=None, hashes=None, data=None):        key = key or self.retrieve_key(data)        hashes = hashes or self.detect_hashes(data)        params = {            ""url"": self.pyfile.url,            ""key"": key,            ""hashes"": hashes,            ""script"": {                ""signature"": self.COINHIVE_INTERACTIVE_SIG,                ""code"": self.COINHIVE_INTERACTIVE_JS,            },        }        result = self.decrypt_interactive(params, timeout=300)        return result",,"def challenge(self, key=None, hashes=None, data=None):        key = key or self.retrieve_key(data)        hashes = hashes or self.detect_hashes(data)        params = {            ""url"": self.pyfile.url,            ""key"": key,            ""hashes"": hashes,            ""script"": {                ""signature"": self.COINHIVE_INTERACTIVE_SIG,                ""code"": self.COINHIVE_INTERACTIVE_JS,            },        }        result = self.decrypt_interactive(params, timeout=300)        return result",d2827656-c8d5-4752-87d2-cbcd71273306
anticaptchas,HCaptcha.py,detect_key,83,102,"def detect_key(self, data=None):        html = data or self.retrieve_data()        m = re.search(self.KEY_PATTERN, html)        if m is not None:            key = urllib.parse.unquote(m.group(1).strip())            m = re.search(self.KEY_FORMAT_PATTERN, key)            if m is not None:                self.key = key                self.log_debug(""Key: {}"".format(self.key))                return self.key            else:                self.log_debug(                    key,                    ""Wrong key format, this probably because it is not a hCaptcha key"",                )        self.log_warning(self._(""Key pattern not found""))        return None",,"def detect_key(self, data=None):        html = data or self.retrieve_data()        m = re.search(self.KEY_PATTERN, html)        if m is not None:            key = urllib.parse.unquote(m.group(1).strip())            m = re.search(self.KEY_FORMAT_PATTERN, key)            if m is not None:                self.key = key                self.log_debug(""Key: {}"".format(self.key))                return self.key            else:                self.log_debug(                    key,                    ""Wrong key format, this probably because it is not a hCaptcha key"",                )        self.log_warning(self._(""Key pattern not found""))        return None",7448ae70-523b-4fc1-8d96-a2c45146e490
anticaptchas,HCaptcha.py,challenge,104,107,"def challenge(self, key=None, data=None):        key = key or self.retrieve_key(data)        return self._challenge_js(key)",,"def challenge(self, key=None, data=None):        key = key or self.retrieve_key(data)        return self._challenge_js(key)",83fd2804-7f26-4e51-8912-d1d6e736956e
anticaptchas,HCaptcha.py,_challenge_js,110,124,"def _challenge_js(self, key):        self.log_debug(""Challenge hCaptcha interactive"")        params = {            ""url"": self.pyfile.url,            ""sitekey"": key,            ""script"": {                ""signature"": self.HCAPTCHA_INTERACTIVE_SIG,                ""code"": self.HCAPTCHA_INTERACTIVE_JS,            },        }        result = self.decrypt_interactive(params, timeout=300)        return result",,"def _challenge_js(self, key):        self.log_debug(""Challenge hCaptcha interactive"")        params = {            ""url"": self.pyfile.url,            ""sitekey"": key,            ""script"": {                ""signature"": self.HCAPTCHA_INTERACTIVE_SIG,                ""code"": self.HCAPTCHA_INTERACTIVE_JS,            },        }        result = self.decrypt_interactive(params, timeout=300)        return result",9252ab5d-b65b-4c3e-bba3-caba07a65a66
anticaptchas,ReCaptcha.py,detect_key,140,156,"def detect_key(self, data=None):        html = data or self.retrieve_data()        m = re.search(self.KEY_V2_PATTERN, html)        if m is not None:            key = urllib.parse.unquote(m.group(1).strip())            m = re.search(self.KEY_FORMAT_V2_PATTERN, key)            if m is not None:                self.key = key                self.log_debug(f""Key: {self.key}"")                return self.key            else:                self.log_debug(key, ""Wrong key format, this probably because it is not a reCAPTCHA key"")        self.log_warning(self._(""Key pattern not found""))        return None",,"def detect_key(self, data=None):        html = data or self.retrieve_data()        m = re.search(self.KEY_V2_PATTERN, html)        if m is not None:            key = urllib.parse.unquote(m.group(1).strip())            m = re.search(self.KEY_FORMAT_V2_PATTERN, key)            if m is not None:                self.key = key                self.log_debug(f""Key: {self.key}"")                return self.key            else:                self.log_debug(key, ""Wrong key format, this probably because it is not a reCAPTCHA key"")        self.log_warning(self._(""Key pattern not found""))        return None",f21f363a-e01b-47fd-a1e1-298760ebb4c3
anticaptchas,ReCaptcha.py,detect_secure_token,158,168,"def detect_secure_token(self, data=None):        html = data or self.retrieve_data()        m = re.search(self.STOKEN_V2_PATTERN, html)        if m is not None:            self.secure_token = m.group(1).strip()            self.log_debug(f""Secure Token: {self.secure_token}"")            return self.secure_token        else:            self.log_warning(self._(""Secure Token pattern not found""))            return None",,"def detect_secure_token(self, data=None):        html = data or self.retrieve_data()        m = re.search(self.STOKEN_V2_PATTERN, html)        if m is not None:            self.secure_token = m.group(1).strip()            self.log_debug(f""Secure Token: {self.secure_token}"")            return self.secure_token        else:            self.log_warning(self._(""Secure Token pattern not found""))            return None",8b767540-7800-4cb6-8d67-e234045ca7fb
anticaptchas,ReCaptcha.py,detect_version,170,188,"def detect_version(self, data=None):        data = data or self.retrieve_data()        v2 = re.search(self.KEY_V2_PATTERN, data) is not None        invisible = re.search(self.INVISIBLE_V2_PATTERN, data) is not None        if v2 is True:            if invisible is True:                self.log_debug(""Detected reCAPTCHA v2 invisible"")                return ""2invisible""            else:                self.log_debug(""Detected reCAPTCHA v2"")                return 2        else:            self.log_warning(                self._(""Could not properly detect reCAPTCHA version, defaulting to v2"")            )            return 2",,"def detect_version(self, data=None):        data = data or self.retrieve_data()        v2 = re.search(self.KEY_V2_PATTERN, data) is not None        invisible = re.search(self.INVISIBLE_V2_PATTERN, data) is not None        if v2 is True:            if invisible is True:                self.log_debug(""Detected reCAPTCHA v2 invisible"")                return ""2invisible""            else:                self.log_debug(""Detected reCAPTCHA v2"")                return 2        else:            self.log_warning(                self._(""Could not properly detect reCAPTCHA version, defaulting to v2"")            )            return 2",359eb1b3-bf09-4d3c-ac5c-4169123dd7a6
anticaptchas,ReCaptcha.py,challenge,190,208,"def challenge(self, key=None, data=None, version=None, secure_token=None):        key = key or self.retrieve_key(data)        secure_token = (            secure_token or self.detect_secure_token(data)            if secure_token is not False            else None        )        if version in (2, ""2js"", ""2invisible""):            return getattr(self, ""_challenge_v{}"".format(version))(                key, secure_token=secure_token            )        else:            return self.challenge(                key,                data,                version=self.detect_version(data=data),                secure_token=secure_token,            )",,"def challenge(self, key=None, data=None, version=None, secure_token=None):        key = key or self.retrieve_key(data)        secure_token = (            secure_token or self.detect_secure_token(data)            if secure_token is not False            else None        )        if version in (2, ""2js"", ""2invisible""):            return getattr(self, ""_challenge_v{}"".format(version))(                key, secure_token=secure_token            )        else:            return self.challenge(                key,                data,                version=self.detect_version(data=data),                secure_token=secure_token,            )",92f982c7-69a2-41a4-97ec-606e79ca8602
anticaptchas,ReCaptcha.py,_prepare_image,210,335,"def _prepare_image(self, image, challenge_msg):        dummy_text = ""pk""        # This is just a string to calculate biggest height of a text, since usually        # the letters 'p' and 'k' reach to the lower most respective higher most        # points in a text font (see typography) and thus we can hereby calculate        # the biggest text height of a given font        with io.StringIO() as s:            s.write(image)            s.seek(0)            img = Image.open(s)            draw = ImageDraw.Draw(img)            font_name = ""arialbd""            if os.name == ""nt"":                font = ImageFont.truetype(font_name, 13)            else:                font = None            tile_size = {""width"": img.size[0] // 3, ""height"": img.size[1] // 3}            tile_index_size = {                ""width"": draw.textsize(""0"")[0],                ""height"": draw.textsize(""0"")[1],            }            margin = 2            for x in range(3):                for y in range(3):                    tile_index_pos = {                        ""x"": x * tile_size[""width""]                        + (tile_size[""width""] // 2)                        - (tile_index_size[""width""] // 2),                        ""y"": y * tile_size[""height""],                    }                    draw.rectangle(                        [                            tile_index_pos[""x""] - margin,                            tile_index_pos[""y""],                            tile_index_pos[""x""] + tile_index_size[""width""] + margin,                            tile_index_pos[""y""] + tile_index_size[""height""],                        ],                        fill=""white"",                    )                    index_number = str(y * 3 + x + 1)                    text_width, text_height = draw.textsize(index_number, font=font)                    draw.text(                        (                            tile_index_pos[""x""]                            + (tile_index_size[""width""] // 2)                            - (text_width // 2),                            tile_index_pos[""y""]                            + (tile_index_size[""height""] // 2)                            - (text_height // 2),                        ),                        index_number,                        ""#000"",                        font=font,                    )            if os.name == ""nt"":                font = ImageFont.truetype(font_name, 16)            _sol = 0            _eol = 1            while True:                # determine maximum width of line                while draw.textsize(challenge_msg[_sol:_eol], font=font)[0] < img.size[                    0                ] and _eol < len(challenge_msg):                    _eol += 1                # if we've wrapped the text, then adjust the wrap to the last word                if _eol < len(challenge_msg):                    _eol = challenge_msg.rfind("" "", 0, _eol)                    if _eol > 0:                        challenge_msg = (                            challenge_msg[:_eol] + ""\n"" + challenge_msg[_eol + 1:]                        )                        _sol = _eol + 1                else:                    break            message = challenge_msg + '\n(Type image numbers like ""258"")'            # the text's real height is twice as big as returned by font.getsize() since we use            # a newline character which indeed breaks the text but doesn't count as a second line            # in font.getsize().            if os.name == ""nt"":                text_area_height = draw.multiline_textsize(message, font=font)[1]            else:                lines = message.split(""\n"")                text_area_height = len(lines) * draw.textsize(dummy_text, font=font)[1]            margin = 5            text_area_height = (                text_area_height + margin * 2            )  #: add some margin on top and bottom of text            img2 = Image.new(                ""RGB"", (img.size[0], img.size[1] + text_area_height), ""white""            )            img2.paste(img, (0, text_area_height))            draw = ImageDraw.Draw(img2)            if os.name == ""nt"":                draw.text((3, margin), message, fill=""black"", font=font)            else:                for i in range(len(lines)):                    draw.text(                        (3, i * draw.textsize(dummy_text, font=font)[1] + margin),                        lines[i],                        fill=""black"",                        font=font,                    )            s.truncate(0)            img2.save(s, format=""JPEG"")            img = s.getvalue()        return img",,"def _prepare_image(self, image, challenge_msg):        dummy_text = ""pk""        # This is just a string to calculate biggest height of a text, since usually        # the letters 'p' and 'k' reach to the lower most respective higher most        # points in a text font (see typography) and thus we can hereby calculate        # the biggest text height of a given font        with io.StringIO() as s:            s.write(image)            s.seek(0)            img = Image.open(s)            draw = ImageDraw.Draw(img)            font_name = ""arialbd""            if os.name == ""nt"":                font = ImageFont.truetype(font_name, 13)            else:                font = None            tile_size = {""width"": img.size[0] // 3, ""height"": img.size[1] // 3}            tile_index_size = {                ""width"": draw.textsize(""0"")[0],                ""height"": draw.textsize(""0"")[1],            }            margin = 2            for x in range(3):                for y in range(3):                    tile_index_pos = {                        ""x"": x * tile_size[""width""]                        + (tile_size[""width""] // 2)                        - (tile_index_size[""width""] // 2),                        ""y"": y * tile_size[""height""],                    }                    draw.rectangle(                        [                            tile_index_pos[""x""] - margin,                            tile_index_pos[""y""],                            tile_index_pos[""x""] + tile_index_size[""width""] + margin,                            tile_index_pos[""y""] + tile_index_size[""height""],                        ],                        fill=""white"",                    )                    index_number = str(y * 3 + x + 1)                    text_width, text_height = draw.textsize(index_number, font=font)                    draw.text(                        (                            tile_index_pos[""x""]                            + (tile_index_size[""width""] // 2)                            - (text_width // 2),                            tile_index_pos[""y""]                            + (tile_index_size[""height""] // 2)                            - (text_height // 2),                        ),                        index_number,                        ""#000"",                        font=font,                    )            if os.name == ""nt"":                font = ImageFont.truetype(font_name, 16)            _sol = 0            _eol = 1            while True:                # determine maximum width of line                while draw.textsize(challenge_msg[_sol:_eol], font=font)[0] < img.size[                    0                ] and _eol < len(challenge_msg):                    _eol += 1                # if we've wrapped the text, then adjust the wrap to the last word                if _eol < len(challenge_msg):                    _eol = challenge_msg.rfind("" "", 0, _eol)                    if _eol > 0:                        challenge_msg = (                            challenge_msg[:_eol] + ""\n"" + challenge_msg[_eol + 1:]                        )                        _sol = _eol + 1                else:                    break            message = challenge_msg + '\n(Type image numbers like ""258"")'            # the text's real height is twice as big as returned by font.getsize() since we use            # a newline character which indeed breaks the text but doesn't count as a second line            # in font.getsize().            if os.name == ""nt"":                text_area_height = draw.multiline_textsize(message, font=font)[1]            else:                lines = message.split(""\n"")                text_area_height = len(lines) * draw.textsize(dummy_text, font=font)[1]            margin = 5            text_area_height = (                text_area_height + margin * 2            )  #: add some margin on top and bottom of text            img2 = Image.new(                ""RGB"", (img.size[0], img.size[1] + text_area_height), ""white""            )            img2.paste(img, (0, text_area_height))            draw = ImageDraw.Draw(img2)            if os.name == ""nt"":                draw.text((3, margin), message, fill=""black"", font=font)            else:                for i in range(len(lines)):                    draw.text(                        (3, i * draw.textsize(dummy_text, font=font)[1] + margin),                        lines[i],                        fill=""black"",                        font=font,                    )            s.truncate(0)            img2.save(s, format=""JPEG"")            img = s.getvalue()        return img",5c5b9cbf-029f-41dc-9b2b-e53a0a14106e
anticaptchas,ReCaptcha.py,_challenge_v2,337,418,"def _challenge_v2(self, key, secure_token=None):        fallback_url = (            ""http://www.google.com/recaptcha/api/fallback?k=""            + key            + (""&stoken="" + secure_token if secure_token else """")        )        html = self.pyfile.plugin.load(fallback_url, ref=self.pyfile.url)        if (            re.search(r'href=""https://support.google.com/recaptcha.*""', html)            is not None        ):            self.log_warning(                self._(""reCAPTCHA noscript is blocked, trying reCAPTCHA interactive"")            )            return self._challenge_v2js(key, secure_token=secure_token)        for i in range(10):            try:                challenge = re.search(r'name=""c""\s+value=\s*""([^""]+)', html).group(1)            except (AttributeError, IndexError):                self.fail(self._(""reCAPTCHA challenge pattern not found""))            try:                challenge_msg = re.search(                    r'<label .*?class=""fbc-imageselect-message-text"">(.*?)</label>',                    html,                ).group(1)            except (AttributeError, IndexError):                try:                    challenge_msg = re.search(                        r""<div .*?class=\""fbc-imageselect-message-error\"">(.*?)</div>"",                        html,                    ).group(1)                except (AttributeError, IndexError):                    self.fail(self._(""reCAPTCHA challenge message not found""))            challenge_msg = re.sub(r""<.*?>"", """", challenge_msg)            image_url = urllib.parse.urljoin(                ""http://www.google.com"",                re.search(r'""(/recaptcha/api2/payload[^""]+)', html).group(1),            )            img = self.pyfile.plugin.load(image_url, ref=fallback_url, decode=False)            img = self._prepare_image(img, challenge_msg)            response = self.decrypt_image(img)            post_str = (                ""c=""                + urllib.parse.quote_plus(challenge)                + """".join(                    ""&response={}"".format(str(int(k) - 1))                    for k in response                    if k.isdigit()                )            )            html = self.pyfile.plugin.load(                fallback_url, post=post_str, ref=fallback_url            )            try:                result = re.search(                    r'<div class=""fbc-verification-token""><textarea .*readonly>(.*?)</textarea>',                    html,                ).group(1)                self.correct()                break            except (AttributeError, IndexError):                self.invalid()        else:            self.fail(self._(""reCAPTCHA max retries exceeded""))        return result",,"def _challenge_v2(self, key, secure_token=None):        fallback_url = (            ""http://www.google.com/recaptcha/api/fallback?k=""            + key            + (""&stoken="" + secure_token if secure_token else """")        )        html = self.pyfile.plugin.load(fallback_url, ref=self.pyfile.url)        if (            re.search(r'href=""https://support.google.com/recaptcha.*""', html)            is not None        ):            self.log_warning(                self._(""reCAPTCHA noscript is blocked, trying reCAPTCHA interactive"")            )            return self._challenge_v2js(key, secure_token=secure_token)        for i in range(10):            try:                challenge = re.search(r'name=""c""\s+value=\s*""([^""]+)', html).group(1)            except (AttributeError, IndexError):                self.fail(self._(""reCAPTCHA challenge pattern not found""))            try:                challenge_msg = re.search(                    r'<label .*?class=""fbc-imageselect-message-text"">(.*?)</label>',                    html,                ).group(1)            except (AttributeError, IndexError):                try:                    challenge_msg = re.search(                        r""<div .*?class=\""fbc-imageselect-message-error\"">(.*?)</div>"",                        html,                    ).group(1)                except (AttributeError, IndexError):                    self.fail(self._(""reCAPTCHA challenge message not found""))            challenge_msg = re.sub(r""<.*?>"", """", challenge_msg)            image_url = urllib.parse.urljoin(                ""http://www.google.com"",                re.search(r'""(/recaptcha/api2/payload[^""]+)', html).group(1),            )            img = self.pyfile.plugin.load(image_url, ref=fallback_url, decode=False)            img = self._prepare_image(img, challenge_msg)            response = self.decrypt_image(img)            post_str = (                ""c=""                + urllib.parse.quote_plus(challenge)                + """".join(                    ""&response={}"".format(str(int(k) - 1))                    for k in response                    if k.isdigit()                )            )            html = self.pyfile.plugin.load(                fallback_url, post=post_str, ref=fallback_url            )            try:                result = re.search(                    r'<div class=""fbc-verification-token""><textarea .*readonly>(.*?)</textarea>',                    html,                ).group(1)                self.correct()                break            except (AttributeError, IndexError):                self.invalid()        else:            self.fail(self._(""reCAPTCHA max retries exceeded""))        return result",43f20fbe-fbc1-472b-b5b3-2302aa44c878
anticaptchas,ReCaptcha.py,_challenge_v2js,422,437,"def _challenge_v2js(self, key, secure_token=None):        self.log_debug(""Challenge reCAPTCHA v2 interactive"")        params = {            ""url"": self.pyfile.url,            ""sitekey"": key,            ""securetoken"": secure_token,            ""script"": {                ""signature"": self.RECAPTCHA_INTERACTIVE_SIG,                ""code"": self.RECAPTCHA_INTERACTIVE_JS,            },        }        result = self.decrypt_interactive(params, timeout=300)        return result",,"def _challenge_v2js(self, key, secure_token=None):        self.log_debug(""Challenge reCAPTCHA v2 interactive"")        params = {            ""url"": self.pyfile.url,            ""sitekey"": key,            ""securetoken"": secure_token,            ""script"": {                ""signature"": self.RECAPTCHA_INTERACTIVE_SIG,                ""code"": self.RECAPTCHA_INTERACTIVE_JS,            },        }        result = self.decrypt_interactive(params, timeout=300)        return result",1893d8bd-69b0-4c85-b914-67dc6839326a
anticaptchas,ReCaptcha.py,_challenge_v2invisible,440,455,"def _challenge_v2invisible(self, key, secure_token=None):        self.log_debug(""Challenge reCAPTCHA v2 invisible"")        params = {            ""url"": self.pyfile.url,            ""sitekey"": key,            ""securetoken"": secure_token,            ""script"": {                ""signature"": self.RECAPTCHA_INVISIBLE_SIG,                ""code"": self.RECAPTCHA_INVISIBLE_JS,            },        }        result = self.decrypt_invisible(params, timeout=300)        return result",,"def _challenge_v2invisible(self, key, secure_token=None):        self.log_debug(""Challenge reCAPTCHA v2 invisible"")        params = {            ""url"": self.pyfile.url,            ""sitekey"": key,            ""securetoken"": secure_token,            ""script"": {                ""signature"": self.RECAPTCHA_INVISIBLE_SIG,                ""code"": self.RECAPTCHA_INVISIBLE_JS,            },        }        result = self.decrypt_invisible(params, timeout=300)        return result",0c9ac175-99fb-45d9-b0a6-7ea7eeb44b4b
anticaptchas,SolveMedia.py,detect_key,24,34,"def detect_key(self, data=None):        html = data or self.retrieve_data()        m = re.search(self.KEY_PATTERN, html)        if m is not None:            self.key = m.group(1).strip()            self.log_debug(f""Key: {self.key}"")            return self.key        else:            self.log_debug(""Key pattern not found"")            return None",,"def detect_key(self, data=None):        html = data or self.retrieve_data()        m = re.search(self.KEY_PATTERN, html)        if m is not None:            self.key = m.group(1).strip()            self.log_debug(f""Key: {self.key}"")            return self.key        else:            self.log_debug(""Key pattern not found"")            return None",ab7e0ffe-2503-4f0a-99c0-df0c0bdbbc99
anticaptchas,SolveMedia.py,challenge,36,105,"def challenge(self, key=None, data=None):        key = key or self.retrieve_key(data)        html = self.pyfile.plugin.load(            ""http://api.solvemedia.com/papi/challenge.noscript"", get={""k"": key}        )        for i in range(1, 11):            try:                magic = re.search(r'name=""magic"" value=""(.+?)""', html).group(1)            except AttributeError:                self.log_warning(self._(""Magic pattern not found""))                magic = None            try:                challenge = re.search(                    r'<input type=hidden name=""adcopy_challenge"" id=""adcopy_challenge"" value=""(.+?)"">',                    html,                ).group(1)            except AttributeError:                self.fail(self._(""SolveMedia challenge pattern not found""))            else:                self.log_debug(f""Challenge: {challenge}"")            try:                result = self.result(""http://api.solvemedia.com/papi/media"", challenge)            except Fail as exc:                self.log_warning(                    exc,                    exc_info=self.pyload.debug > 1,                    stack_info=self.pyload.debug > 2,                )                self.pyfile.plugin.captcha.invalid()                result = None            html = self.pyfile.plugin.load(                ""http://api.solvemedia.com/papi/verify.noscript"",                post={                    ""adcopy_response"": result,                    ""k"": key,                    ""l"": ""en"",                    ""t"": ""img"",                    ""s"": ""standard"",                    ""magic"": magic,                    ""adcopy_challenge"": challenge,                    ""ref"": self.pyfile.url,                },            )            try:                redirect = re.search(r'URL=(.+?)"">', html).group(1)            except AttributeError:                self.fail(self._(""SolveMedia verify pattern not found""))            else:                if ""error"" in html:                    self.log_warning(self._(""Captcha code was invalid""))                    self.log_debug(f""Retry #{i}"")                    html = self.pyfile.plugin.load(redirect)                else:                    break        else:            self.fail(self._(""SolveMedia max retries exceeded""))        return result, challenge",,"def challenge(self, key=None, data=None):        key = key or self.retrieve_key(data)        html = self.pyfile.plugin.load(            ""http://api.solvemedia.com/papi/challenge.noscript"", get={""k"": key}        )        for i in range(1, 11):            try:                magic = re.search(r'name=""magic"" value=""(.+?)""', html).group(1)            except AttributeError:                self.log_warning(self._(""Magic pattern not found""))                magic = None            try:                challenge = re.search(                    r'<input type=hidden name=""adcopy_challenge"" id=""adcopy_challenge"" value=""(.+?)"">',                    html,                ).group(1)            except AttributeError:                self.fail(self._(""SolveMedia challenge pattern not found""))            else:                self.log_debug(f""Challenge: {challenge}"")            try:                result = self.result(""http://api.solvemedia.com/papi/media"", challenge)            except Fail as exc:                self.log_warning(                    exc,                    exc_info=self.pyload.debug > 1,                    stack_info=self.pyload.debug > 2,                )                self.pyfile.plugin.captcha.invalid()                result = None            html = self.pyfile.plugin.load(                ""http://api.solvemedia.com/papi/verify.noscript"",                post={                    ""adcopy_response"": result,                    ""k"": key,                    ""l"": ""en"",                    ""t"": ""img"",                    ""s"": ""standard"",                    ""magic"": magic,                    ""adcopy_challenge"": challenge,                    ""ref"": self.pyfile.url,                },            )            try:                redirect = re.search(r'URL=(.+?)"">', html).group(1)            except AttributeError:                self.fail(self._(""SolveMedia verify pattern not found""))            else:                if ""error"" in html:                    self.log_warning(self._(""Captcha code was invalid""))                    self.log_debug(f""Retry #{i}"")                    html = self.pyfile.plugin.load(redirect)                else:                    break        else:            self.fail(self._(""SolveMedia max retries exceeded""))        return result, challenge",2ee6cdaf-ac41-4961-89ac-4e6531b654ce
anticaptchas,SolveMedia.py,result,107,111,"def result(self, server, challenge):        result = self.decrypt(            server, get={""c"": challenge}, cookies=True, input_type=""gif""        )        return result",,"def result(self, server, challenge):        result = self.decrypt(            server, get={""c"": challenge}, cookies=True, input_type=""gif""        )        return result",89233d7a-6b17-42c6-9237-d165efd5add2
anticaptchas,UlozTo.py,recognize,22,37,"def recognize(self, audio):                # print(""!!!CAPTCHA :"", audio)        try:            cfg_file = os.path.join(os.path.split(clslib.__file__)[0], ""ulozto.cfg"")            ext_file = os.path.splitext(audio)[1]            text = clslib.classify_audio_file(audio, cfg_file, ext_file)            return text        except NameError:            self.log_error(                self._(""Unable to decode audio captcha""),                self._(                    ""Please install adecaptcha library from https://github.com/izderadicka/adecaptcha""                ),            )",Audio decoding - more info could be found at https://launchpad.net/adecaptcha ,"def recognize(self, audio):        """""" Audio decoding - more info could be found at https://launchpad.net/adecaptcha """"""        # print(""!!!CAPTCHA :"", audio)        try:            cfg_file = os.path.join(os.path.split(clslib.__file__)[0], ""ulozto.cfg"")            ext_file = os.path.splitext(audio)[1]            text = clslib.classify_audio_file(audio, cfg_file, ext_file)            return text        except NameError:            self.log_error(                self._(""Unable to decode audio captcha""),                self._(                    ""Please install adecaptcha library from https://github.com/izderadicka/adecaptcha""                ),            )

Audio decoding - more info could be found at https://launchpad.net/adecaptcha ",ee4a4f03-141e-4e1a-96c0-1c7912f801d7
base,account.py,__init__,31,46,"def __init__(self, manager, accounts):        self._init(manager.pyload)        self.m = self.manager = manager        self.lock = threading.RLock()        self.accounts = accounts  # TODO: Recheck in 0.6.x        self.user = None        self.timeout = self.LOGIN_TIMEOUT        #: Callback of periodical job task, used by AddonManager        self.periodical = Periodical(self, self.periodical_task)        self.cb = self.periodical.cb  # TODO: Recheck in 0.6.x        self.init()",,"def __init__(self, manager, accounts):        self._init(manager.pyload)        self.m = self.manager = manager        self.lock = threading.RLock()        self.accounts = accounts  # TODO: Recheck in 0.6.x        self.user = None        self.timeout = self.LOGIN_TIMEOUT        #: Callback of periodical job task, used by AddonManager        self.periodical = Periodical(self, self.periodical_task)        self.cb = self.periodical.cb  # TODO: Recheck in 0.6.x        self.init()",8776e897-f5b5-45a8-9fae-610cd4b963bf
base,account.py,__bool__,48,49,def __bool__(self):        return self.user is not None,,def __bool__(self):        return self.user is not None,40d9551c-6396-4814-a986-c2205dc56c9a
base,account.py,logged,52,69,"def logged(self):                if not self.user:            return False        self.sync()        if (            self.info[""login""][""timestamp""] == 0            or self.timeout != -1            and self.info[""login""][""timestamp""] + self.timeout < time.time()        ):            self.log_debug(f""Reached login timeout for user `{self.user}`"")            return False        else:            return True",Checks if user is still logged in.,"def logged(self):        """"""        Checks if user is still logged in.        """"""        if not self.user:            return False        self.sync()        if (            self.info[""login""][""timestamp""] == 0            or self.timeout != -1            and self.info[""login""][""timestamp""] + self.timeout < time.time()        ):            self.log_debug(f""Reached login timeout for user `{self.user}`"")            return False        else:            return True

Checks if user is still logged in.",c1b61994-05b4-40ce-8cf6-c6181e6ab964
base,account.py,premium,72,73,"def premium(self):        return bool(self.get_data(""premium""))",,"def premium(self):        return bool(self.get_data(""premium""))",3452c2ee-35f4-4b19-99cc-0e9ceb76ca3a
base,account.py,_log,75,103,"def _log(self, level, plugintype, pluginname, args, kwargs):        log = getattr(self.pyload.log, level)        #: Hide any user/password        try:            user = self.user            hidden_user = ""{:*<{}}"".format(self.user[:3], 7)            args = tuple(arg.replace(user, hidden_user) if isinstance(arg, str) else arg                         for arg in args if arg)        except (KeyError, TypeError):            pass        try:            pw = self.info[""login""][""password""]            hidden_pw = ""*"" * 10            args = tuple(arg.replace(pw, hidden_pw) if isinstance(arg, str) else arg                         for arg in args if arg)        except (KeyError, TypeError):            pass        log(            ""{plugintype} {pluginname}: {msg}"".format(                plugintype=plugintype.upper(),                pluginname=pluginname,                msg="" | "".join([""%s""] * len(args)),            ),            *args,            **kwargs,        )",,"def _log(self, level, plugintype, pluginname, args, kwargs):        log = getattr(self.pyload.log, level)        #: Hide any user/password        try:            user = self.user            hidden_user = ""{:*<{}}"".format(self.user[:3], 7)            args = tuple(arg.replace(user, hidden_user) if isinstance(arg, str) else arg                         for arg in args if arg)        except (KeyError, TypeError):            pass        try:            pw = self.info[""login""][""password""]            hidden_pw = ""*"" * 10            args = tuple(arg.replace(pw, hidden_pw) if isinstance(arg, str) else arg                         for arg in args if arg)        except (KeyError, TypeError):            pass        log(            ""{plugintype} {pluginname}: {msg}"".format(                plugintype=plugintype.upper(),                pluginname=pluginname,                msg="" | "".join([""%s""] * len(args)),            ),            *args,            **kwargs,        )",95268520-dae8-45b1-99ca-2a5956b1cc77
base,account.py,setup,105,110,def setup(self):                pass,"Setup for environment and other things, called before logging (possibly more than
one time)","def setup(self):        """"""        Setup for environment and other things, called before logging (possibly more than        one time)        """"""        pass

Setup for environment and other things, called before logging (possibly more than
one time)",0eb002de-0c6f-4104-9ba7-f29a578286ea
base,account.py,periodical_task,112,113,def periodical_task(self):        raise NotImplementedError,,def periodical_task(self):        raise NotImplementedError,819e745b-5a99-424e-9c8d-03d1321b06ab
base,account.py,signin,115,119,"def signin(self, user, password, data):                raise NotImplementedError","Login into account, the cookies will be saved so user can be recognized.","def signin(self, user, password, data):        """"""        Login into account, the cookies will be saved so user can be recognized.        """"""        raise NotImplementedError

Login into account, the cookies will be saved so user can be recognized.",7650c0cf-d890-44d1-a62d-8efbb0c21db0
base,account.py,login,121,167,"def login(self):        self.clean()        self.sync()        self.info[""login""][""stats""][0] += 1        if self.info[""login""][""stats""][0] == 1:            self.log_info(self._(""Login user `{}`..."").format(self.user))        else:            self.log_info(self._(""Relogin user `{}`..."").format(self.user))        self.req = self.pyload.request_factory.get_request(self.classname, self.user)        self.setup()        timestamp = time.time()        try:            self.signin(self.user, self.info[""login""][""password""], self.info[""data""])        except NotImplementedError:            self.log_error(                self._(""Could not login user `{}`"").format(self.user),                self._(""Plugin is missing a function"")            )        except Skip as exc:            self.log_warning(self._(""Skipped login user `{}`"").format(self.user), exc)            self.info[""login""][""valid""] = True            new_timeout = timestamp - self.info[""login""][""timestamp""]            if self.TUNE_TIMEOUT and new_timeout > self.timeout:                self.timeout = new_timeout        except Exception as exc:            self.log_error(self._(""Could not login user `{}`"").format(self.user), exc)            self.info[""login""][""valid""] = False        else:            self.info[""login""][""valid""] = True        finally:            #: Set timestamp for login            self.info[""login""][""timestamp""] = timestamp            self.syncback()            return bool(self.info[""login""][""valid""])",,"def login(self):        self.clean()        self.sync()        self.info[""login""][""stats""][0] += 1        if self.info[""login""][""stats""][0] == 1:            self.log_info(self._(""Login user `{}`..."").format(self.user))        else:            self.log_info(self._(""Relogin user `{}`..."").format(self.user))        self.req = self.pyload.request_factory.get_request(self.classname, self.user)        self.setup()        timestamp = time.time()        try:            self.signin(self.user, self.info[""login""][""password""], self.info[""data""])        except NotImplementedError:            self.log_error(                self._(""Could not login user `{}`"").format(self.user),                self._(""Plugin is missing a function"")            )        except Skip as exc:            self.log_warning(self._(""Skipped login user `{}`"").format(self.user), exc)            self.info[""login""][""valid""] = True            new_timeout = timestamp - self.info[""login""][""timestamp""]            if self.TUNE_TIMEOUT and new_timeout > self.timeout:                self.timeout = new_timeout        except Exception as exc:            self.log_error(self._(""Could not login user `{}`"").format(self.user), exc)            self.info[""login""][""valid""] = False        else:            self.info[""login""][""valid""] = True        finally:            #: Set timestamp for login            self.info[""login""][""timestamp""] = timestamp            self.syncback()            return bool(self.info[""login""][""valid""])",cf4d404a-6d46-4b8c-a1b6-45f2d194584d
base,account.py,logout,169,175,"def logout(self):                self.sync()        self.info[""login""][""timestamp""] = 0        self.syncback()",Invalidate the account timestamp so relogin will be forced next time.,"def logout(self):        """"""        Invalidate the account timestamp so relogin will be forced next time.        """"""        self.sync()        self.info[""login""][""timestamp""] = 0        self.syncback()

Invalidate the account timestamp so relogin will be forced next time.",fdc2615d-2d2f-43b3-a8b4-5741a7406f3d
base,account.py,syncback,178,182,def syncback(self):                return self.sync(reverse=True),Wrapper to directly sync self.info -> self.accounts[self.user],"def syncback(self):        """"""        Wrapper to directly sync self.info -> self.accounts[self.user]        """"""        return self.sync(reverse=True)

Wrapper to directly sync self.info -> self.accounts[self.user]",e577eade-b451-4f8f-8145-f047025fc252
base,account.py,sync,185,208,"def sync(self, reverse=False):                if not self.user:            return        u = self.accounts[self.user]        if reverse:            u.update(self.info[""data""])            u.update(self.info[""login""])        else:            d = {""login"": {}, ""data"": {}}            for k, v in u.items():                if k in (""password"", ""timestamp"", ""stats"", ""valid""):                    d[""login""][k] = v                else:                    d[""data""][k] = v            self.info.update(d)","Sync self.accounts[self.user] -> self.info or self.info ->
self.accounts[self.user] (if reverse is True)","def sync(self, reverse=False):        """"""        Sync self.accounts[self.user] -> self.info or self.info ->        self.accounts[self.user] (if reverse is True)        """"""        if not self.user:            return        u = self.accounts[self.user]        if reverse:            u.update(self.info[""data""])            u.update(self.info[""login""])        else:            d = {""login"": {}, ""data"": {}}            for k, v in u.items():                if k in (""password"", ""timestamp"", ""stats"", ""valid""):                    d[""login""][k] = v                else:                    d[""data""][k] = v            self.info.update(d)

Sync self.accounts[self.user] -> self.info or self.info ->
self.accounts[self.user] (if reverse is True)",920fa381-a4c7-4e67-bafb-a4caf3bd7381
base,account.py,relogin,210,211,def relogin(self):        return self.login(),,def relogin(self):        return self.login(),bd2ed01a-4e7f-40dc-a6cc-eb9092ff63be
base,account.py,reset,213,222,"def reset(self):        self.sync()        def clear(x):            return {} if isinstance(x, dict) else [] if is_sequence(x) else None        self.info[""data""] = {k: clear(v) for k, v in self.info[""data""].items()}        self.info[""data""][""options""] = {""limit_dl"": [""0""]}        self.syncback()",,"def reset(self):        self.sync()        def clear(x):            return {} if isinstance(x, dict) else [] if is_sequence(x) else None        self.info[""data""] = {k: clear(v) for k, v in self.info[""data""].items()}        self.info[""data""][""options""] = {""limit_dl"": [""0""]}        self.syncback()",7205aace-115c-4a4f-8a0a-7b53c69dbd7a
base,account.py,get_info,224,250,"def get_info(self, refresh=True):                if not self.logged:            if self.relogin():                refresh = True            else:                refresh = False                self.reset()        if refresh and self.info[""login""][""valid""]:            self.log_info(                self._(""Grabbing account info for user `{}`..."").format(self.user)            )            self.info = self._grab_info()            self.syncback()            self.log_debug(                ""Account info for user `{}`: {}"".format(self.user, self.info)            )        return self.info","Retrieve account infos for a user, do **not** overwrite this method! just use
it to retrieve infos in downloader plugins. see `grab_info`

:return: dictionary with information","def get_info(self, refresh=True):        """"""        Retrieve account infos for a user, do **not** overwrite this method! just use        it to retrieve infos in downloader plugins. see `grab_info`        :return: dictionary with information        """"""        if not self.logged:            if self.relogin():                refresh = True            else:                refresh = False                self.reset()        if refresh and self.info[""login""][""valid""]:            self.log_info(                self._(""Grabbing account info for user `{}`..."").format(self.user)            )            self.info = self._grab_info()            self.syncback()            self.log_debug(                ""Account info for user `{}`: {}"".format(self.user, self.info)            )        return self.info

Retrieve account infos for a user, do **not** overwrite this method! just use
it to retrieve infos in downloader plugins. see `grab_info`

:return: dictionary with information",b44d35f7-a020-4a9e-a99d-3c162a19807c
base,account.py,get_login,252,254,"def get_login(self, key=None, default=None):        d = self.get_info()[""login""]        return d.get(key, default) if key else d",,"def get_login(self, key=None, default=None):        d = self.get_info()[""login""]        return d.get(key, default) if key else d",6ecdd23f-4af2-4cc3-bccf-e62e86a95930
base,account.py,get_data,256,258,"def get_data(self, key=None, default=None):        d = self.get_info()[""data""]        return d.get(key, default) if key else d",,"def get_data(self, key=None, default=None):        d = self.get_info()[""data""]        return d.get(key, default) if key else d",43392175-2ef0-4cf5-b3f2-981ed1a11cfa
base,account.py,_grab_info,260,281,"def _grab_info(self):        try:            data = self.grab_info(                self.user, self.info[""login""][""password""], self.info[""data""]            )            if data and isinstance(data, dict):                self.info[""data""].update(data)        except NotImplementedError:            self.log_error(                self._(""Error loading info for user `{}`"").format(self.user),                self._(""Plugin is missing a function"")            )        except Exception as exc:            self.log_warning(                self._(""Error loading info for user `{}`"").format(self.user), exc            )        finally:            return self.info",,"def _grab_info(self):        try:            data = self.grab_info(                self.user, self.info[""login""][""password""], self.info[""data""]            )            if data and isinstance(data, dict):                self.info[""data""].update(data)        except NotImplementedError:            self.log_error(                self._(""Error loading info for user `{}`"").format(self.user),                self._(""Plugin is missing a function"")            )        except Exception as exc:            self.log_warning(                self._(""Error loading info for user `{}`"").format(self.user), exc            )        finally:            return self.info",d90bb031-a5c3-4c73-9398-98402fca825a
base,account.py,grab_info,283,293,"def grab_info(self, user, password, data):                raise NotImplementedError","This should be overwritten in account plugin and retrieving account information
for user.

:param user:
:param password:
:param data:
:return:","def grab_info(self, user, password, data):        """"""        This should be overwritten in account plugin and retrieving account information        for user.        :param user:        :param password:        :param data:        :return:        """"""        raise NotImplementedError

This should be overwritten in account plugin and retrieving account information
for user.

:param user:
:param password:
:param data:
:return:",e555c82e-714c-45c9-89a3-329ead84beaa
base,account.py,init_accounts,300,305,"def init_accounts(self):        accounts = dict(self.accounts)        self.accounts.clear()        for user, info in accounts.items():            self.add(user, info[""password""], info[""options""])",,"def init_accounts(self):        accounts = dict(self.accounts)        self.accounts.clear()        for user, info in accounts.items():            self.add(user, info[""password""], info[""options""])",976d0c23-2e37-40af-930a-6bd9b07432bf
base,account.py,get_account_data,308,312,"def get_account_data(self, user, force=False):        if force:            self.accounts[user][""plugin""].get_info()        return self.accounts[user]",,"def get_account_data(self, user, force=False):        if force:            self.accounts[user][""plugin""].get_info()        return self.accounts[user]",5cea58fb-edaa-4e65-8fee-18523e873b16
base,account.py,get_all_accounts,315,321,"def get_all_accounts(self, force=False):        if force:            self.init_accounts()  # TODO: Recheck in 0.6.x        # NOTE: `init_accounts()` already calls get_account_data(user, True), avoid calling `get_info()` twice        # NOTE: So force=False always here        return [self.get_account_data(user, False) for user in self.accounts]",,"def get_all_accounts(self, force=False):        if force:            self.init_accounts()  # TODO: Recheck in 0.6.x        # NOTE: `init_accounts()` already calls get_account_data(user, True), avoid calling `get_info()` twice        # NOTE: So force=False always here        return [self.get_account_data(user, False) for user in self.accounts]",b0fede37-619b-411b-be08-79f9ee419e3b
base,account.py,schedule_refresh,325,326,"def schedule_refresh(self, user, force=False):        pass",,"def schedule_refresh(self, user, force=False):        pass",c79fc8dd-ec3c-4eaf-bf5d-e8c96fc10e2b
base,account.py,add,329,357,"def add(self, user, password=None, options={}):        self.log_info(self._(""Adding user `{}`..."").format(user[:3] + ""*"" * 7))        if user in self.accounts:            self.log_error(                self._(""Error adding user `{}`"").format(user),                self._(""User already exists""),            )            return False        d = {            ""login"": user,            ""options"": options or {""limit_dl"": [""0""]},            ""password"": password or """",            ""plugin"": self.pyload.account_manager.get_account_plugin(self.classname),            ""premium"": None,            ""stats"": [0, 0],  #: login_count, chosen_time            ""timestamp"": 0,            ""trafficleft"": None,            ""type"": self.__name__,            ""valid"": None,            ""validuntil"": None,        }        u = self.accounts[user] = d        result = u[""plugin""].choose(user)        u[""plugin""].get_info()        return result",,"def add(self, user, password=None, options={}):        self.log_info(self._(""Adding user `{}`..."").format(user[:3] + ""*"" * 7))        if user in self.accounts:            self.log_error(                self._(""Error adding user `{}`"").format(user),                self._(""User already exists""),            )            return False        d = {            ""login"": user,            ""options"": options or {""limit_dl"": [""0""]},            ""password"": password or """",            ""plugin"": self.pyload.account_manager.get_account_plugin(self.classname),            ""premium"": None,            ""stats"": [0, 0],  #: login_count, chosen_time            ""timestamp"": 0,            ""trafficleft"": None,            ""type"": self.__name__,            ""valid"": None,            ""validuntil"": None,        }        u = self.accounts[user] = d        result = u[""plugin""].choose(user)        u[""plugin""].get_info()        return result",e1d48860-ab12-418a-a270-79bc6b1c8b9d
base,account.py,update_accounts,360,377,"def update_accounts(self, user, password=None, options={}):                if user in self.accounts:            self.log_info(self._(""Updating account info for user `{}`..."").format(user))            u = self.accounts[user]            if password:                u[""password""] = password            if options:                u[""options""].update(options)            u[""plugin""].relogin()        else:            self.add(user, password, options)",Updates account and return true if anything changed.,"def update_accounts(self, user, password=None, options={}):        """"""        Updates account and return true if anything changed.        """"""        if user in self.accounts:            self.log_info(self._(""Updating account info for user `{}`..."").format(user))            u = self.accounts[user]            if password:                u[""password""] = password            if options:                u[""options""].update(options)            u[""plugin""].relogin()        else:            self.add(user, password, options)

Updates account and return true if anything changed.",82f6ce89-cfb8-48bc-9e46-85e206921323
base,account.py,remove_account,380,385,"def remove_account(self, user):        self.log_info(self._(""Removing user `{}`..."").format(user))        self.accounts.pop(user, None)        self.pyload.request_factory.remove_cookie_jar(self.classname, user)        if user is self.user:            self.choose()",,"def remove_account(self, user):        self.log_info(self._(""Removing user `{}`..."").format(user))        self.accounts.pop(user, None)        self.pyload.request_factory.remove_cookie_jar(self.classname, user)        if user is self.user:            self.choose()",e451aa4d-9638-4073-9e39-cd414ab1d24d
base,account.py,select,388,455,"def select(self):        def hide(secret):            hidden = secret[:3] + ""*******""            return hidden        free_accounts = {}        premium_accounts = {}        for user in self.accounts:            if not self.accounts[user][""plugin""].choose(user):                continue            info = self.accounts[user][""plugin""].get_info()            data = info[""data""]            if not info[""login""][""valid""]:                continue            if data[""options""].get(""time""):                time_data = """"                try:                    time_data = data[""options""][""time""][0]                    start, end = time_data.split(""-"")                    if not seconds.compare(start.split("":""), end.split("":"")):                        continue                except Exception:                    self.log_warning(                        self._(                            ""Invalid time format `{}` for account `{}`, use 1:22-3:44""                        ).format(hide(user), time_data)                    )            if data[""trafficleft""] == 0:                self.log_warning(                    self._(                        ""Not using account `{}` because the account has no traffic left""                    ).format(hide(user))                )                continue            validuntil = -1 if not data[""validuntil""] else data[""validuntil""]            if time.time() > validuntil > 0:                self.log_warning(                    self._(                        ""Not using account `{}` because the account has expired""                    ).format(hide(user))                )                continue            if data[""premium""]:                premium_accounts[user] = copy.copy(info)            else:                free_accounts[user] = copy.copy(info)        account_list = list((premium_accounts or free_accounts).items())        if not account_list:            return None, None        #: Choose the oldest used account        chosen_account = sorted(account_list, key=lambda x: x[1][""login""][""stats""][1])[0]        self.accounts[chosen_account[0]][""stats""][1] = time.time()        self.log_debug(""Using account {}"".format(hide(chosen_account[0])))        return chosen_account",,"def select(self):        def hide(secret):            hidden = secret[:3] + ""*******""            return hidden        free_accounts = {}        premium_accounts = {}        for user in self.accounts:            if not self.accounts[user][""plugin""].choose(user):                continue            info = self.accounts[user][""plugin""].get_info()            data = info[""data""]            if not info[""login""][""valid""]:                continue            if data[""options""].get(""time""):                time_data = """"                try:                    time_data = data[""options""][""time""][0]                    start, end = time_data.split(""-"")                    if not seconds.compare(start.split("":""), end.split("":"")):                        continue                except Exception:                    self.log_warning(                        self._(                            ""Invalid time format `{}` for account `{}`, use 1:22-3:44""                        ).format(hide(user), time_data)                    )            if data[""trafficleft""] == 0:                self.log_warning(                    self._(                        ""Not using account `{}` because the account has no traffic left""                    ).format(hide(user))                )                continue            validuntil = -1 if not data[""validuntil""] else data[""validuntil""]            if time.time() > validuntil > 0:                self.log_warning(                    self._(                        ""Not using account `{}` because the account has expired""                    ).format(hide(user))                )                continue            if data[""premium""]:                premium_accounts[user] = copy.copy(info)            else:                free_accounts[user] = copy.copy(info)        account_list = list((premium_accounts or free_accounts).items())        if not account_list:            return None, None        #: Choose the oldest used account        chosen_account = sorted(account_list, key=lambda x: x[1][""login""][""stats""][1])[0]        self.accounts[chosen_account[0]][""stats""][1] = time.time()        self.log_debug(""Using account {}"".format(hide(chosen_account[0])))        return chosen_account",7abe8565-a01e-4c72-9ffc-dc48735d0c7e
base,account.py,choose,458,491,"def choose(self, user=None):                if not user:            user = self.select()[0]        elif user not in self.accounts:            self.log_error(                self._(""Error choosing user `{}`"").format(user),                self._(""User does not exists""),            )            return False        else:            if self.req and user == self.user:                return True        if user is None:            return False        else:            self.user = user            self.info.clear()            self.req.close()            self.req = self.pyload.request_factory.get_request(                self.classname, self.user            )            if not self.logged:                self.relogin()            return True",Choose a valid account.,"def choose(self, user=None):        """"""        Choose a valid account.        """"""        if not user:            user = self.select()[0]        elif user not in self.accounts:            self.log_error(                self._(""Error choosing user `{}`"").format(user),                self._(""User does not exists""),            )            return False        else:            if self.req and user == self.user:                return True        if user is None:            return False        else:            self.user = user            self.info.clear()            self.req.close()            self.req = self.pyload.request_factory.get_request(                self.classname, self.user            )            if not self.logged:                self.relogin()            return True

Choose a valid account.",ba8b9b36-2431-4788-9340-32662195b5a9
base,account.py,parse_traffic,493,495,"def parse_traffic(self, size, unit=None):  #: returns bytes        self.log_debug(f""Size: {size}"", f""Unit: {unit or 'N/D'}"")        return parse.bytesize(size, unit or ""byte"")",,"def parse_traffic(self, size, unit=None):  #: returns bytes        self.log_debug(f""Size: {size}"", f""Unit: {unit or 'N/D'}"")        return parse.bytesize(size, unit or ""byte"")",83762ba3-271f-4299-8494-99afbf2cd44c
base,account.py,fail_login,497,498,"def fail_login(self, msg=""Login handshake has failed""):        return self.fail(msg)",,"def fail_login(self, msg=""Login handshake has failed""):        return self.fail(msg)",4f19c9e9-7bd3-42b8-bd7c-94c2ad26b34a
base,account.py,skip_login,500,501,"def skip_login(self, msg=""Already signed in""):        return self.skip(msg)",,"def skip_login(self, msg=""Already signed in""):        return self.skip(msg)",264c15e0-6e08-4db7-90d1-1af37b49b2da
base,addon.py,threaded,12,17,"def threaded(func):    @wraps(func)    def wrapper(self, *args, **kwargs):        return self.pyload.adm.start_thread(func, self, *args, **kwargs)    return wrapper",,"def threaded(func):    @wraps(func)    def wrapper(self, *args, **kwargs):        return self.pyload.adm.start_thread(func, self, *args, **kwargs)    return wrapper",fd5cba22-3210-412f-b616-6c3b21725216
base,addon.py,expose,21,34,"def expose(func):        @wraps(func)    def wrapper(self, *args, **kwargs):        if not wrapper._exposed:            self.pyload.adm.add_rpc(func.__module__, func.__name__, func.__doc__)            wrapper._exposed = True        return func(self, *args, **kwargs)    wrapper._exposed = False    return wrapper",Used for decoration to declare rpc services.,"def expose(func):    """"""    Used for decoration to declare rpc services.    """"""    @wraps(func)    def wrapper(self, *args, **kwargs):        if not wrapper._exposed:            self.pyload.adm.add_rpc(func.__module__, func.__name__, func.__doc__)            wrapper._exposed = True        return func(self, *args, **kwargs)    wrapper._exposed = False    return wrapper

Used for decoration to declare rpc services.",bfadbad9-f70d-43de-a093-40770e1e5c2e
base,addon.py,__init__,47,63,"def __init__(self, core, manager):        self._init(core)        #: `AddonManager`        self.m = self.manager = manager        self.lock = threading.Lock()        #: Automatically register event listeners for functions, attribute will be deleted dont use it yourself        self.event_map = {}        #: Callback of periodical job task, used by AddonManager        self.periodical = Periodical(self, self.periodical_task)        self.cb = self.periodical.cb  # TODO: Recheck in 0.6.x        self.init()        self._init_events()  # TODO: Remove in 0.6.x        self.init_events()",,"def __init__(self, core, manager):        self._init(core)        #: `AddonManager`        self.m = self.manager = manager        self.lock = threading.Lock()        #: Automatically register event listeners for functions, attribute will be deleted dont use it yourself        self.event_map = {}        #: Callback of periodical job task, used by AddonManager        self.periodical = Periodical(self, self.periodical_task)        self.cb = self.periodical.cb  # TODO: Recheck in 0.6.x        self.init()        self._init_events()  # TODO: Remove in 0.6.x        self.init_events()",eb7f3652-c7fe-4000-b391-1896964c4806
base,addon.py,activated,66,70,"def activated(self):                return self.config.get(""enabled"")",Checks if addon is activated.,"def activated(self):        """"""        Checks if addon is activated.        """"""        return self.config.get(""enabled"")

Checks if addon is activated.",3f8003db-ee40-4480-8c08-c82b09c465a0
base,addon.py,_init_events,73,86,"def _init_events(self):        event_map = {            ""all_downloads_finished"": ""all_downloads_finished"",            ""all_downloads_processed"": ""all_downloads_processed"",            ""config_changed"": ""config_changed"",            ""download_processed"": ""download_processed"",            ""download_start"": ""download_start"",            ""links_added"": ""links_added"",            ""package_deleted"": ""package_deleted"",            ""package_failed"": ""package_failed"",            ""package_processed"": ""package_processed"",        }        for event, funcs in event_map.items():            self.m.add_event(event, getattr(self, funcs))",,"def _init_events(self):        event_map = {            ""all_downloads_finished"": ""all_downloads_finished"",            ""all_downloads_processed"": ""all_downloads_processed"",            ""config_changed"": ""config_changed"",            ""download_processed"": ""download_processed"",            ""download_start"": ""download_start"",            ""links_added"": ""links_added"",            ""package_deleted"": ""package_deleted"",            ""package_failed"": ""package_failed"",            ""package_processed"": ""package_processed"",        }        for event, funcs in event_map.items():            self.m.add_event(event, getattr(self, funcs))",50773070-ac01-45a8-a917-c9bc3a134573
base,addon.py,init_events,88,97,"def init_events(self):        if self.event_map:            for event, funcs in self.event_map.items():                if not is_sequence(funcs):                    funcs = [funcs]                for fn in funcs:                    self.m.add_event(event, getattr(self, fn))            #: Delete for various reasons            self.event_map = None",,"def init_events(self):        if self.event_map:            for event, funcs in self.event_map.items():                if not is_sequence(funcs):                    funcs = [funcs]                for fn in funcs:                    self.m.add_event(event, getattr(self, fn))            #: Delete for various reasons            self.event_map = None",95aee772-3758-4fff-9bfc-71307c8f547b
base,addon.py,periodical_task,99,100,def periodical_task(self):        raise NotImplementedError,,def periodical_task(self):        raise NotImplementedError,b1da35ef-68f9-41c8-ba05-728252cd7f63
base,addon.py,is_activated,103,104,def is_activated(self):        return self.activated,,def is_activated(self):        return self.activated,88d89f8a-6d0c-4534-888d-0560d4174549
base,addon.py,deactivate,106,110,def deactivate(self):                pass,Called when addon was deactivated.,"def deactivate(self):        """"""        Called when addon was deactivated.        """"""        pass

Called when addon was deactivated.",e66b0d67-9569-4e24-80fb-5eb409097002
base,addon.py,unload,113,115,"def unload(self):        self.db.store(""info"", self.info)        return self.deactivate()",,"def unload(self):        self.db.store(""info"", self.info)        return self.deactivate()",8b88fab6-ca46-46e8-843a-58c0a41428ba
base,addon.py,activate,117,121,def activate(self):                pass,Called when addon was activated.,"def activate(self):        """"""        Called when addon was activated.        """"""        pass

Called when addon was activated.",f9c1e0ed-df83-48f8-ace8-a6e1462b28cb
base,addon.py,core_ready,124,126,"def core_ready(self):        self.db.retrieve(""info"", self.info)        return self.activate()",,"def core_ready(self):        self.db.retrieve(""info"", self.info)        return self.activate()",18e082a1-dcac-4994-846a-fee0b92940c4
base,addon.py,exit,128,132,def exit(self):                pass,Called by core.shutdown just before pyLoad exit.,"def exit(self):        """"""        Called by core.shutdown just before pyLoad exit.        """"""        pass

Called by core.shutdown just before pyLoad exit.",097c2ce5-0c7f-4646-9c4d-6ef273959ef3
base,addon.py,core_exiting,135,137,def core_exiting(self):        self.unload()  # TODO: Fix in 0.6.x        return self.exit(),,def core_exiting(self):        self.unload()  # TODO: Fix in 0.6.x        return self.exit(),449bda8c-522b-446c-990d-e9dbe39fc8c1
base,addon.py,config_changed,139,140,"def config_changed(self, category, option, value, section):        pass",,"def config_changed(self, category, option, value, section):        pass",c3d3433a-24c2-4895-9b1b-e55e393b77ac
base,addon.py,all_downloads_finished,142,143,def all_downloads_finished(self):        pass,,def all_downloads_finished(self):        pass,abd8b486-8231-4b64-b446-2ede1dab1c5c
base,addon.py,all_downloads_processed,145,146,def all_downloads_processed(self):        pass,,def all_downloads_processed(self):        pass,411c5aa3-e82e-4664-9349-ca843addf71d
base,addon.py,links_added,148,149,"def links_added(self, urls, pypack):        pass",,"def links_added(self, urls, pypack):        pass",c766601a-b16f-4c55-8d86-5856629675d5
base,addon.py,download_preparing,151,152,"def download_preparing(self, pyfile):        pass",,"def download_preparing(self, pyfile):        pass",19c3f205-0e9e-4943-9e36-a65c102e249a
base,addon.py,download_start,159,160,"def download_start(self, pyfile, url, filename):        pass",,"def download_start(self, pyfile, url, filename):        pass",5023a124-6c0e-47a2-9e08-538998d1f11e
base,addon.py,download_processed,162,163,"def download_processed(self, pyfile):        pass",,"def download_processed(self, pyfile):        pass",3aa1563c-909c-470a-b4cd-f60ca8fc9353
base,addon.py,download_finished,165,166,"def download_finished(self, pyfile):        pass",,"def download_finished(self, pyfile):        pass",89609d26-c89b-44a8-95a6-136b8e3c0922
base,addon.py,download_failed,168,169,"def download_failed(self, pyfile):        pass",,"def download_failed(self, pyfile):        pass",43b20870-1753-49ff-ac06-1c85dd60e063
base,addon.py,package_processed,171,172,"def package_processed(self, pypack):        pass",,"def package_processed(self, pypack):        pass",d9dee310-83a0-4499-be45-ac36f423f079
base,addon.py,package_deleted,174,175,"def package_deleted(self, pid):        pass",,"def package_deleted(self, pid):        pass",2b5b4f5f-171a-4ad1-a896-0d732c60523f
base,addon.py,package_failed,177,178,"def package_failed(self, pypack):        pass",,"def package_failed(self, pypack):        pass",add78ec5-5285-4e53-8326-1b40c3f69d25
base,addon.py,package_finished,180,181,"def package_finished(self, pypack):        pass",,"def package_finished(self, pypack):        pass",1640c252-2a6e-4f57-97c8-482d570dc122
base,addon.py,before_reconnect,183,184,"def before_reconnect(self, ip):        pass",,"def before_reconnect(self, ip):        pass",d49ae287-54fe-47ec-96dd-887efdeea00f
base,addon.py,after_reconnect,186,187,"def after_reconnect(self, ip, old_ip):        pass",,"def after_reconnect(self, ip, old_ip):        pass",b43f78f3-c1ec-463d-afd9-0df0b9e92fff
base,addon.py,captcha_task,189,194,"def captcha_task(self, task):                pass","New captcha task for the plugin, it MUST set the handler and timeout or will be
ignored.","def captcha_task(self, task):        """"""        New captcha task for the plugin, it MUST set the handler and timeout or will be        ignored.        """"""        pass

New captcha task for the plugin, it MUST set the handler and timeout or will be
ignored.",753e3063-26c4-4396-be74-1adfcd7be226
base,addon.py,captcha_correct,196,197,"def captcha_correct(self, task):        pass",,"def captcha_correct(self, task):        pass",35ba726a-152f-4018-a470-db189a7650d4
base,addon.py,captcha_invalid,199,200,"def captcha_invalid(self, task):        pass",,"def captcha_invalid(self, task):        pass",a441d79f-a4dd-4710-9f14-83b949d7affe
base,captcha.py,__init__,21,27,"def __init__(self, pyfile):        self._init(pyfile.m.pyload)        self.pyfile = pyfile        self.task = None  #: captcha_manager task        self.init()",,"def __init__(self, pyfile):        self._init(pyfile.m.pyload)        self.pyfile = pyfile        self.task = None  #: captcha_manager task        self.init()",806f8fa4-89ad-45ee-b7a0-211716c31e36
base,captcha.py,_log,29,33,"def _log(self, level, plugintype, pluginname, args, kwargs):        args = (self.__name__,) + args        return self.pyfile.plugin._log(            level, plugintype, self.pyfile.plugin.__name__, args, kwargs        )",,"def _log(self, level, plugintype, pluginname, args, kwargs):        args = (self.__name__,) + args        return self.pyfile.plugin._log(            level, plugintype, self.pyfile.plugin.__name__, args, kwargs        )",78ff9126-24df-4ef6-9dbe-0c9f3a96cb70
base,captcha.py,recognize,35,39,"def recognize(self, image):                pass",Extend to build your custom anti-captcha ocr.,"def recognize(self, image):        """"""        Extend to build your custom anti-captcha ocr.        """"""        pass

Extend to build your custom anti-captcha ocr.",649b54eb-72ca-475b-9433-7664aac45736
base,captcha.py,decrypt,41,63,"def decrypt(        self,        url,        get={},        post={},        ref=False,        cookies=True,        req=None,        input_type=""jpg"",        output_type=""textual"",        ocr=True,        timeout=120,    ):        img = self.load(            url,            get=get,            post=post,            ref=ref,            cookies=cookies,            decode=False,            req=req or self.pyfile.plugin.req,        )        return self.decrypt_image(img, input_type, output_type, ocr, timeout)",,"def decrypt(        self,        url,        get={},        post={},        ref=False,        cookies=True,        req=None,        input_type=""jpg"",        output_type=""textual"",        ocr=True,        timeout=120,    ):        img = self.load(            url,            get=get,            post=post,            ref=ref,            cookies=cookies,            decode=False,            req=req or self.pyfile.plugin.req,        )        return self.decrypt_image(img, input_type, output_type, ocr, timeout)",77bba9ce-8b07-4098-832b-196f76a8afdc
base,captcha.py,decrypt_image,65,157,"def decrypt_image(        self, img, input_type=""jpg"", output_type=""textual"", ocr=False, timeout=120    ):                result = None        time_ref = ""{:.2f}"".format(time.time())[-6:].replace(""."", """")        img_path = os.path.join(            self.pyload.tempdir,            ""captcha_image_{}_{}.{}"".format(                self.pyfile.plugin.__name__, time_ref, input_type            ),        )        with open(img_path, ""wb"") as img_fp:            img_fp.write(img)        if ocr:            self.log_info(self._(""Using OCR to decrypt captcha...""))            if isinstance(ocr, str):                _OCR = self.pyload.plugin_manager.load_class(                    ""anticaptcha"", ocr                )  #: Rename `captcha` to `ocr` in 0.6.x                result = _OCR(self.pyfile).recognize(img_fp.name)            else:                result = self.recognize(img_fp.name)                if not result:                    self.log_warning(self._(""No OCR result""))        if not result:            captcha_manager = self.pyload.captcha_manager            timeout = max(timeout, 50)            try:                params = {                    ""src"": ""data:image/{};base64,{}"".format(                        input_type, to_str(base64.standard_b64encode(img))                    ),                    ""file"": img_fp.name,                    ""captcha_plugin"": self.__name__,                    ""plugin"": self.pyfile.plugin.__name__,                    ""url"": self.pyfile.url,                }                self.task = captcha_manager.new_task(input_type, params, output_type)                captcha_manager.handle_captcha(self.task, timeout)                while self.task.is_waiting():                    self.pyfile.plugin.check_status()                    time.sleep(1)            finally:                captcha_manager.remove_task(self.task)            result = self.task.result            if self.task.error:                if not self.task.handler and not self.pyload.is_client_connected():                    self.log_warning(                        self._(""No Client connected for captcha decrypting"")                    )                    self.fail(self._(""No Client connected for captcha decrypting""))                else:                    self.pyfile.plugin.retry_captcha(msg=self.task.error)            elif self.task.result:                self.log_info(self._(""Captcha result: `{}`"").format(result))            else:                self.pyfile.plugin.retry_captcha(                    msg=self._(                        ""No captcha result obtained in appropriate timing ({}s)""                    ).format(timeout)                )        self.remove(img_fp.name, try_trash=False)        return result","Loads a captcha and decrypts it with ocr, plugin, user input.

:param img: image raw data
:param get: get part for request
:param post: post part for request
:param cookies: True if cookies should be enabled
:param input_type: Type of the Image
:param output_type: 'textual' if text is written on the captcha        or 'positional' for captcha where the user have to click        on a specific region on the captcha
:param ocr: if True, builtin ocr is used. if string, the OCR plugin name is used

:return: result of decrypting","def decrypt_image(        self, img, input_type=""jpg"", output_type=""textual"", ocr=False, timeout=120    ):        """"""        Loads a captcha and decrypts it with ocr, plugin, user input.        :param img: image raw data        :param get: get part for request        :param post: post part for request        :param cookies: True if cookies should be enabled        :param input_type: Type of the Image        :param output_type: 'textual' if text is written on the captcha\        or 'positional' for captcha where the user have to click\        on a specific region on the captcha        :param ocr: if True, builtin ocr is used. if string, the OCR plugin name is used        :return: result of decrypting        """"""        result = None        time_ref = ""{:.2f}"".format(time.time())[-6:].replace(""."", """")        img_path = os.path.join(            self.pyload.tempdir,            ""captcha_image_{}_{}.{}"".format(                self.pyfile.plugin.__name__, time_ref, input_type            ),        )        with open(img_path, ""wb"") as img_fp:            img_fp.write(img)        if ocr:            self.log_info(self._(""Using OCR to decrypt captcha...""))            if isinstance(ocr, str):                _OCR = self.pyload.plugin_manager.load_class(                    ""anticaptcha"", ocr                )  #: Rename `captcha` to `ocr` in 0.6.x                result = _OCR(self.pyfile).recognize(img_fp.name)            else:                result = self.recognize(img_fp.name)                if not result:                    self.log_warning(self._(""No OCR result""))        if not result:            captcha_manager = self.pyload.captcha_manager            timeout = max(timeout, 50)            try:                params = {                    ""src"": ""data:image/{};base64,{}"".format(                        input_type, to_str(base64.standard_b64encode(img))                    ),                    ""file"": img_fp.name,                    ""captcha_plugin"": self.__name__,                    ""plugin"": self.pyfile.plugin.__name__,                    ""url"": self.pyfile.url,                }                self.task = captcha_manager.new_task(input_type, params, output_type)                captcha_manager.handle_captcha(self.task, timeout)                while self.task.is_waiting():                    self.pyfile.plugin.check_status()                    time.sleep(1)            finally:                captcha_manager.remove_task(self.task)            result = self.task.result            if self.task.error:                if not self.task.handler and not self.pyload.is_client_connected():                    self.log_warning(                        self._(""No Client connected for captcha decrypting"")                    )                    self.fail(self._(""No Client connected for captcha decrypting""))                else:                    self.pyfile.plugin.retry_captcha(msg=self.task.error)            elif self.task.result:                self.log_info(self._(""Captcha result: `{}`"").format(result))            else:                self.pyfile.plugin.retry_captcha(                    msg=self._(                        ""No captcha result obtained in appropriate timing ({}s)""                    ).format(timeout)                )        self.remove(img_fp.name, try_trash=False)        return result

Loads a captcha and decrypts it with ocr, plugin, user input.

:param img: image raw data
:param get: get part for request
:param post: post part for request
:param cookies: True if cookies should be enabled
:param input_type: Type of the Image
:param output_type: 'textual' if text is written on the captcha        or 'positional' for captcha where the user have to click        on a specific region on the captcha
:param ocr: if True, builtin ocr is used. if string, the OCR plugin name is used

:return: result of decrypting",e8517c5e-f6fb-4be7-89be-2c2f5775f9c7
base,captcha.py,decrypt_interactive,159,201,"def decrypt_interactive(self, params={}, timeout=120):        captcha_manager = self.pyload.captcha_manager        timeout = max(timeout, 50)        try:            params.update(                {                    ""captcha_plugin"": self.__name__,                    ""plugin"": self.pyfile.plugin.__name__,                    ""url"": self.pyfile.url,                }            )            self.task = captcha_manager.new_task(""interactive"", params, ""interactive"")            captcha_manager.handle_captcha(self.task, timeout)            while self.task.is_waiting():                self.pyfile.plugin.check_status()                time.sleep(1)        finally:            captcha_manager.remove_task(self.task)        result = self.task.result        if self.task.error:            if not self.task.handler and not self.pyload.is_client_connected():                self.log_warning(self._(""No Client connected for captcha decrypting""))                self.fail(self._(""No Client connected for captcha decrypting""))            else:                self.pyfile.plugin.retry_captcha(msg=self.task.error)        elif self.task.result:            self.log_info(self._(""Captcha result: `{}`"").format(result))        else:            self.pyfile.plugin.retry_captcha(                msg=self._(                    ""No captcha result obtained in appropriate timing ({}s)""                ).format(timeout)            )        return result",,"def decrypt_interactive(self, params={}, timeout=120):        captcha_manager = self.pyload.captcha_manager        timeout = max(timeout, 50)        try:            params.update(                {                    ""captcha_plugin"": self.__name__,                    ""plugin"": self.pyfile.plugin.__name__,                    ""url"": self.pyfile.url,                }            )            self.task = captcha_manager.new_task(""interactive"", params, ""interactive"")            captcha_manager.handle_captcha(self.task, timeout)            while self.task.is_waiting():                self.pyfile.plugin.check_status()                time.sleep(1)        finally:            captcha_manager.remove_task(self.task)        result = self.task.result        if self.task.error:            if not self.task.handler and not self.pyload.is_client_connected():                self.log_warning(self._(""No Client connected for captcha decrypting""))                self.fail(self._(""No Client connected for captcha decrypting""))            else:                self.pyfile.plugin.retry_captcha(msg=self.task.error)        elif self.task.result:            self.log_info(self._(""Captcha result: `{}`"").format(result))        else:            self.pyfile.plugin.retry_captcha(                msg=self._(                    ""No captcha result obtained in appropriate timing ({}s)""                ).format(timeout)            )        return result",73a23494-5893-4dc5-85ad-cebf9491af7e
base,captcha.py,decrypt_invisible,203,245,"def decrypt_invisible(self, params={}, timeout=120):        captcha_manager = self.pyload.captcha_manager        timeout = max(timeout, 50)        try:            params.update(                {                    ""captcha_plugin"": self.__name__,                    ""plugin"": self.pyfile.plugin.__name__,                    ""url"": self.pyfile.url,                }            )            self.task = captcha_manager.new_task(""invisible"", params, ""invisible"")            captcha_manager.handle_captcha(self.task, timeout)            while self.task.is_waiting():                self.pyfile.plugin.check_status()                time.sleep(1)        finally:            captcha_manager.remove_task(self.task)        result = self.task.result        if self.task.error:            if not self.task.handler and not self.pyload.is_client_connected():                self.log_warning(self._(""No Client connected for captcha decrypting""))                self.fail(self._(""No Client connected for captcha decrypting""))            else:                self.pyfile.plugin.retry_captcha(msg=self.task.error)        elif self.task.result:            self.log_info(self._(""Captcha result: `{}`"").format(result))        else:            self.pyfile.plugin.retry_captcha(                msg=self._(                    ""No captcha result obtained in appropriate timing ({}s)""                ).format(timeout)            )        return result",,"def decrypt_invisible(self, params={}, timeout=120):        captcha_manager = self.pyload.captcha_manager        timeout = max(timeout, 50)        try:            params.update(                {                    ""captcha_plugin"": self.__name__,                    ""plugin"": self.pyfile.plugin.__name__,                    ""url"": self.pyfile.url,                }            )            self.task = captcha_manager.new_task(""invisible"", params, ""invisible"")            captcha_manager.handle_captcha(self.task, timeout)            while self.task.is_waiting():                self.pyfile.plugin.check_status()                time.sleep(1)        finally:            captcha_manager.remove_task(self.task)        result = self.task.result        if self.task.error:            if not self.task.handler and not self.pyload.is_client_connected():                self.log_warning(self._(""No Client connected for captcha decrypting""))                self.fail(self._(""No Client connected for captcha decrypting""))            else:                self.pyfile.plugin.retry_captcha(msg=self.task.error)        elif self.task.result:            self.log_info(self._(""Captcha result: `{}`"").format(result))        else:            self.pyfile.plugin.retry_captcha(                msg=self._(                    ""No captcha result obtained in appropriate timing ({}s)""                ).format(timeout)            )        return result",44b42609-0a68-4bae-82d0-4a7c4d40ac0a
base,captcha.py,invalid,247,253,"def invalid(self, msg=""""):        if not self.task:            return        self.log_warning(self._(""Invalid captcha""), msg, self.task.result)        self.task.invalid()        self.task = None",,"def invalid(self, msg=""""):        if not self.task:            return        self.log_warning(self._(""Invalid captcha""), msg, self.task.result)        self.task.invalid()        self.task = None",fb25864a-6a6a-4f86-91d8-eb040cc3aee6
base,captcha.py,correct,255,261,"def correct(self):        if not self.task:            return        self.log_info(self._(""Correct captcha""), self.task.result)        self.task.correct()        self.task = None",,"def correct(self):        if not self.task:            return        self.log_info(self._(""Correct captcha""), self.task.result)        self.task.correct()        self.task = None",8772e8c9-b05c-44a3-b0dc-00200ad5436c
base,captcha_service.py,init,17,18,def init(self):        self.key = None,,def init(self):        self.key = None,e549b7f3-0d86-43ca-a187-bc1a8b7263ce
base,captcha_service.py,retrieve_key,21,25,"def retrieve_key(self, data):        if self.detect_key(data):            return self.key        else:            self.fail(self._(""{} key not found"").format(self.__name__))",,"def retrieve_key(self, data):        if self.detect_key(data):            return self.key        else:            self.fail(self._(""{} key not found"").format(self.__name__))",b2960950-f7cc-4d9f-aca5-359cb38c38d9
base,captcha_service.py,retrieve_data,27,28,"def retrieve_data(self):        return self.pyfile.plugin.data or self.pyfile.plugin.last_html or """"",,"def retrieve_data(self):        return self.pyfile.plugin.data or self.pyfile.plugin.last_html or """"",69a473db-3e2c-4b40-a717-18c190e88246
base,captcha_service.py,detect_key,30,31,"def detect_key(self, data=None):        raise NotImplementedError",,"def detect_key(self, data=None):        raise NotImplementedError",4844f268-0414-4104-9035-b7be6643504b
base,captcha_service.py,challenge,33,34,"def challenge(self, key=None, data=None):        raise NotImplementedError",,"def challenge(self, key=None, data=None):        raise NotImplementedError",519f4554-4fdd-4365-84b1-33b5d4a5dd01
base,captcha_service.py,result,36,37,"def result(self, server, challenge):        raise NotImplementedError",,"def result(self, server, challenge):        raise NotImplementedError",a396cde2-9850-4b22-bed6-e20539554b30
base,chat_bot.py,__init__,42,48,"def __init__(self, *args, **kwargs):        self.max_lines = 256        self.more = []        BaseAddon.__init__(self, *args, **kwargs)        Thread.__init__(self)        self.daemon = True",,"def __init__(self, *args, **kwargs):        self.max_lines = 256        self.more = []        BaseAddon.__init__(self, *args, **kwargs)        Thread.__init__(self)        self.daemon = True",7f85a931-fb03-4730-aaae-bc19dcea7682
base,chat_bot.py,init,50,54,"def init(self):        self.event_map = {            ""all_downloads_processed"": ""all_downloads_processed"",            ""pyload_updated"": ""pyload_updated"",        }",,"def init(self):        self.event_map = {            ""all_downloads_processed"": ""all_downloads_processed"",            ""pyload_updated"": ""pyload_updated"",        }",d218ee4b-aaf9-4d91-90f3-93b0ad2b4b64
base,chat_bot.py,all_downloads_processed,56,57,def all_downloads_processed(self):        pass,,def all_downloads_processed(self):        pass,4e25cc75-4eb2-4cb2-b6d5-69a4c388a023
base,chat_bot.py,pyload_updated,59,60,"def pyload_updated(self, etag):        pass",,"def pyload_updated(self, etag):        pass",4ea90d38-140a-4a37-9d9b-fd2e9de8a533
base,chat_bot.py,activate,62,63,def activate(self):        Thread.start(self),,def activate(self):        Thread.start(self),4bdce6c6-ad94-47b7-9a30-7d8d861398a7
base,chat_bot.py,run,65,66,def run(self):        raise NotImplementedError,,def run(self):        raise NotImplementedError,6fd3cb09-8e43-4915-85b1-10e8e2a37250
base,chat_bot.py,do_bot_command,68,71,"def do_bot_command(self, cmd, args):        cmd = self.SHORTCUT_COMMANDS.get(cmd.lower(), cmd.lower())        handler = getattr(self, ""_cmd_{}"".format(cmd), self._cmd_error)        return handler(args)",,"def do_bot_command(self, cmd, args):        cmd = self.SHORTCUT_COMMANDS.get(cmd.lower(), cmd.lower())        handler = getattr(self, ""_cmd_{}"".format(cmd), self._cmd_error)        return handler(args)",a9df6ebc-32b5-4366-8f1c-439db7f65127
base,chat_bot.py,_cmd_error,73,74,"def _cmd_error(self, args):        return [self._(""ERROR: invalid command, for a list of commands enter: help"")]",,"def _cmd_error(self, args):        return [self._(""ERROR: invalid command, for a list of commands enter: help"")]",a032b738-c033-4e01-a56c-b69275577de8
base,chat_bot.py,_cmd_status,76,98,"def _cmd_status(self, args):        downloads = self.pyload.api.status_downloads()        if not downloads:            return [self._(""INFO: There are no active downloads currently."")]        lines = [self._(""ID - Name - Status - Speed - ETA - Progress"")]        for data in downloads:            if data.status == 5:                temp_progress = data.format_wait            else:                temp_progress = ""{}% ({})"".format(data.percent, data.format_size)            lines.append(                ""#{} - {} - {} - {} - {} - {}"".format(                    data.fid,                    data.name,                    data.statusmsg,                    ""{}"".format(format.speed(data.speed)),                    ""{}"".format(data.format_eta),                    temp_progress,                )            )        return lines",,"def _cmd_status(self, args):        downloads = self.pyload.api.status_downloads()        if not downloads:            return [self._(""INFO: There are no active downloads currently."")]        lines = [self._(""ID - Name - Status - Speed - ETA - Progress"")]        for data in downloads:            if data.status == 5:                temp_progress = data.format_wait            else:                temp_progress = ""{}% ({})"".format(data.percent, data.format_size)            lines.append(                ""#{} - {} - {} - {} - {} - {}"".format(                    data.fid,                    data.name,                    data.statusmsg,                    ""{}"".format(format.speed(data.speed)),                    ""{}"".format(data.format_eta),                    temp_progress,                )            )        return lines",3f132c10-95dd-4979-a75a-761cfd275866
base,chat_bot.py,_cmd_queue,100,114,"def _cmd_queue(self, args):        packages = self.pyload.api.get_queue_data()        if not packages:            return [self._(""INFO: There are no packages in queue."")]        lines = []        for pack in packages:            lines.append(                'PACKAGE #{}: ""{}"" with {} links.'.format(                    pack.pid, pack.name, len(pack.links)                )            )        return lines",,"def _cmd_queue(self, args):        packages = self.pyload.api.get_queue_data()        if not packages:            return [self._(""INFO: There are no packages in queue."")]        lines = []        for pack in packages:            lines.append(                'PACKAGE #{}: ""{}"" with {} links.'.format(                    pack.pid, pack.name, len(pack.links)                )            )        return lines",441b95ed-f06b-4d28-b571-6607b6b372c2
base,chat_bot.py,_cmd_collector,116,129,"def _cmd_collector(self, args):        packages = self.pyload.api.get_collector_data()        if not packages:            return [self._(""INFO: No packages in collector!"")]        lines = []        for pack in packages:            lines.append(                'PACKAGE #{}: ""{}"" with {} links.'.format(                    pack.pid, pack.name, len(pack.links)                )            )        return lines",,"def _cmd_collector(self, args):        packages = self.pyload.api.get_collector_data()        if not packages:            return [self._(""INFO: No packages in collector!"")]        lines = []        for pack in packages:            lines.append(                'PACKAGE #{}: ""{}"" with {} links.'.format(                    pack.pid, pack.name, len(pack.links)                )            )        return lines",7e59c6ab-d2f6-4cc3-b87b-1c44193bf041
base,chat_bot.py,_cmd_info,131,154,"def _cmd_info(self, args):        try:            file_id = int(args[0])        except IndexError:            return [                self._(""ERROR: Missing argument""),                self._(""Use info command like this: info <link id>""),            ]        except ValueError:            return [self._(""ERROR: invalid link id {}"").format(args[0])]        try:            info = self.pyload.api.get_file_data(int(file_id))        except FileDoesNotExists:            return [self._(""ERROR: Link doesn't exists."")]        return [            self._(""LINK #{}: {} ({}) [{}][{}]"").format(                info.fid, info.name, info.format_size, info.statusmsg, info            )        ]",,"def _cmd_info(self, args):        try:            file_id = int(args[0])        except IndexError:            return [                self._(""ERROR: Missing argument""),                self._(""Use info command like this: info <link id>""),            ]        except ValueError:            return [self._(""ERROR: invalid link id {}"").format(args[0])]        try:            info = self.pyload.api.get_file_data(int(file_id))        except FileDoesNotExists:            return [self._(""ERROR: Link doesn't exists."")]        return [            self._(""LINK #{}: {} ({}) [{}][{}]"").format(                info.fid, info.name, info.format_size, info.statusmsg, info            )        ]",c4cdafca-0965-4b53-95fa-55288fa63a12
base,chat_bot.py,_cmd_packinfo,156,195,"def _cmd_packinfo(self, args):        try:            id_or_name = args[0]        except IndexError:            return [                self._(""ERROR: Missing argument""),                self._(""ERROR: Use packinfo like this: packinfo <name|id>""),            ]        lines = []        pack = self._get_package_by_name_or_id(id_or_name)        if not pack:            return [self._(""ERROR: Package doesn't exists."")]        self.more = []        lines.append(            'PACKAGE #{}: ""{}"" with {} links:'.format(pack.pid, pack.name, len(pack.links))        )        for pyfile in pack.links:            self.more.append(                ""LINK #{}: {} ({}) [{}]"".format(                    pyfile.fid,                    pyfile.name,                    pyfile.format_size,                    pyfile.statusmsg,                )            )        if len(self.more) < self.max_lines:            lines.extend(self.more)            self.more = []        else:            lines.extend(self.more[:self.max_lines])            self.more = self.more[self.max_lines:]            lines.append(""{} more links to display."".format(len(self.more)))        return lines",,"def _cmd_packinfo(self, args):        try:            id_or_name = args[0]        except IndexError:            return [                self._(""ERROR: Missing argument""),                self._(""ERROR: Use packinfo like this: packinfo <name|id>""),            ]        lines = []        pack = self._get_package_by_name_or_id(id_or_name)        if not pack:            return [self._(""ERROR: Package doesn't exists."")]        self.more = []        lines.append(            'PACKAGE #{}: ""{}"" with {} links:'.format(pack.pid, pack.name, len(pack.links))        )        for pyfile in pack.links:            self.more.append(                ""LINK #{}: {} ({}) [{}]"".format(                    pyfile.fid,                    pyfile.name,                    pyfile.format_size,                    pyfile.statusmsg,                )            )        if len(self.more) < self.max_lines:            lines.extend(self.more)            self.more = []        else:            lines.extend(self.more[:self.max_lines])            self.more = self.more[self.max_lines:]            lines.append(""{} more links to display."".format(len(self.more)))        return lines",1b633c3b-e228-44e4-afcc-e6f2f4b26a54
base,chat_bot.py,_cmd_more,197,205,"def _cmd_more(self, args):        if not self.more:            return [self._(""No more information to display."")]        lines = self.more[:self.max_lines]        self.more = self.more[self.max_lines:]        lines.append(""{} more links to display."".format(len(self.more)))        return lines",,"def _cmd_more(self, args):        if not self.more:            return [self._(""No more information to display."")]        lines = self.more[:self.max_lines]        self.more = self.more[self.max_lines:]        lines.append(""{} more links to display."".format(len(self.more)))        return lines",2c25b594-0d1a-4d2e-906c-4ea739aa5610
base,chat_bot.py,_cmd_unpause,207,209,"def _cmd_unpause(self, args):        self.pyload.api.unpause_server()        return [self._(""INFO: Starting downloads."")]",,"def _cmd_unpause(self, args):        self.pyload.api.unpause_server()        return [self._(""INFO: Starting downloads."")]",caab3938-ab9a-489c-b2ca-bf0d457ecf03
base,chat_bot.py,_cmd_pause,211,213,"def _cmd_pause(self, args):        self.pyload.api.pause_server()        return [self._(""INFO: No new downloads will be started."")]",,"def _cmd_pause(self, args):        self.pyload.api.pause_server()        return [self._(""INFO: No new downloads will be started."")]",92e3a46e-0587-4288-9bcd-204cee22dfe1
base,chat_bot.py,_cmd_togglepause,215,219,"def _cmd_togglepause(self, args):        if self.pyload.api.toggle_pause():            return [self._(""INFO: Starting downloads."")]        else:            return [self._(""INFO: No new downloads will be started."")]",,"def _cmd_togglepause(self, args):        if self.pyload.api.toggle_pause():            return [self._(""INFO: Starting downloads."")]        else:            return [self._(""INFO: No new downloads will be started."")]",41e51dd6-9010-495d-b3db-3c987758aeb5
base,chat_bot.py,_cmd_add,221,246,"def _cmd_add(self, args):        if len(args) < 2:            return [                self._('ERROR: Add links like this: ""add <name|id> link(s)"". '),                self._(""This will add the link <link> to to the package name <name> / the package with id <id>!""),            ]        id_or_name = args[0].strip()        links = [x.strip() for x in args[1:]]        pack = self._get_package_by_name_or_id(id_or_name)        if not pack:            #: Create new package            id = self.pyload.api.add_package(id_or_name, links, 1)            return [                self._(""INFO: Created new Package {} [#{}] with {} links."").format(                    id_or_name, id, len(links)                )            ]        self.pyload.api.add_files(pack.pid, links)        return [            self._(""INFO: Added {} links to Package {} [#{}]"").format(                len(links), pack.name, pack.pid            )        ]",,"def _cmd_add(self, args):        if len(args) < 2:            return [                self._('ERROR: Add links like this: ""add <name|id> link(s)"". '),                self._(""This will add the link <link> to to the package name <name> / the package with id <id>!""),            ]        id_or_name = args[0].strip()        links = [x.strip() for x in args[1:]]        pack = self._get_package_by_name_or_id(id_or_name)        if not pack:            #: Create new package            id = self.pyload.api.add_package(id_or_name, links, 1)            return [                self._(""INFO: Created new Package {} [#{}] with {} links."").format(                    id_or_name, id, len(links)                )            ]        self.pyload.api.add_files(pack.pid, links)        return [            self._(""INFO: Added {} links to Package {} [#{}]"").format(                len(links), pack.name, pack.pid            )        ]",898b02e5-1ee9-46dd-b9eb-35b912e21f1c
base,chat_bot.py,_cmd_del,248,269,"def _cmd_del(self, args):        if len(args) < 2:            return [                self._(""ERROR: Use del command like this: del -p|-l <id> [...]""),                self._(""(-p indicates that the ids are from packages,""),                self._(""-l indicates that the ids are from links""),            ]        if args[0] == ""-p"":            ret = self.pyload.api.delete_packages(int(arg) for arg in args[1:])            return [self._(""INFO: Deleted {} packages!"").format(len(args[1:]))]        elif args[0] == ""-l"":            ret = self.pyload.api.del_links(int(arg) for arg in args[1:])            return [self._(""INFO: Deleted {} links!"").format(len(args[1:]))]        else:            return [                self._(""ERROR: Use del command like this: del <-p|-l> <id> [...]""),                self._(""-p indicates that the ids are from packages,""),                self._(""-l indicates that the ids are from links""),            ]",,"def _cmd_del(self, args):        if len(args) < 2:            return [                self._(""ERROR: Use del command like this: del -p|-l <id> [...]""),                self._(""(-p indicates that the ids are from packages,""),                self._(""-l indicates that the ids are from links""),            ]        if args[0] == ""-p"":            ret = self.pyload.api.delete_packages(int(arg) for arg in args[1:])            return [self._(""INFO: Deleted {} packages!"").format(len(args[1:]))]        elif args[0] == ""-l"":            ret = self.pyload.api.del_links(int(arg) for arg in args[1:])            return [self._(""INFO: Deleted {} links!"").format(len(args[1:]))]        else:            return [                self._(""ERROR: Use del command like this: del <-p|-l> <id> [...]""),                self._(""-p indicates that the ids are from packages,""),                self._(""-l indicates that the ids are from links""),            ]",637bfeab-f02c-4d47-8702-c1f2b0b97471
base,chat_bot.py,_cmd_push,271,291,"def _cmd_push(self, args):        try:            package_id = int(args[0])        except IndexError:            return [                self._(""ERROR: Missing argument""),                self._(""Push package to queue like this: push <package id>"")            ]        except ValueError:            return [self._(""ERROR: invalid package id {}"").format(args[0])]        try:            self.pyload.api.get_package_info(package_id)        except PackageDoesNotExists:            return [self._(""ERROR: Package #{} does not exist."").format(package_id)]        self.pyload.api.push_to_queue(package_id)        return [self._(""INFO: Pushed package #{} to queue."").format(package_id)]",,"def _cmd_push(self, args):        try:            package_id = int(args[0])        except IndexError:            return [                self._(""ERROR: Missing argument""),                self._(""Push package to queue like this: push <package id>"")            ]        except ValueError:            return [self._(""ERROR: invalid package id {}"").format(args[0])]        try:            self.pyload.api.get_package_info(package_id)        except PackageDoesNotExists:            return [self._(""ERROR: Package #{} does not exist."").format(package_id)]        self.pyload.api.push_to_queue(package_id)        return [self._(""INFO: Pushed package #{} to queue."").format(package_id)]",ae3c197e-a26d-4605-9e9a-d73a76484ea7
base,chat_bot.py,_cmd_pull,293,310,"def _cmd_pull(self, args):        try:            package_id = int(args[0])        except IndexError:            return [                self._(""ERROR: Missing argument""),                self._(""Pull package from queue like this: pull <package id>""),            ]        except ValueError:            return [self._(""ERROR: invalid package id {}"").format(args[0])]        if not self.pyload.api.get_package_data(package_id):            return [self._(""ERROR: Package #{} does not exist."").format(package_id)]        self.pyload.api.pull_from_queue(package_id)        return [self._(""INFO: Pulled package #{} from queue to collector."").format(package_id)]",,"def _cmd_pull(self, args):        try:            package_id = int(args[0])        except IndexError:            return [                self._(""ERROR: Missing argument""),                self._(""Pull package from queue like this: pull <package id>""),            ]        except ValueError:            return [self._(""ERROR: invalid package id {}"").format(args[0])]        if not self.pyload.api.get_package_data(package_id):            return [self._(""ERROR: Package #{} does not exist."").format(package_id)]        self.pyload.api.pull_from_queue(package_id)        return [self._(""INFO: Pulled package #{} from queue to collector."").format(package_id)]",b52d7ad9-1f32-4abd-95e7-cdd7e8f51eca
base,chat_bot.py,_cmd_captcha,312,324,"def _cmd_captcha(self, args):                if not args:            return [self._(""ERROR: Captcha ID missing."")]        task = self.pyload.captcha_manager.get_task_by_id(args[0])        if not task:            return [self._(""ERROR: Captcha Task with ID {} does not exists."").format(args[0])]        task.set_result("" "".join(args[1:]))        return [self._(""INFO: Result {} saved."").format("" "".join(args[1:]))]",Captcha answer.,"def _cmd_captcha(self, args):        """"""        Captcha answer.        """"""        if not args:            return [self._(""ERROR: Captcha ID missing."")]        task = self.pyload.captcha_manager.get_task_by_id(args[0])        if not task:            return [self._(""ERROR: Captcha Task with ID {} does not exists."").format(args[0])]        task.set_result("" "".join(args[1:]))        return [self._(""INFO: Result {} saved."").format("" "".join(args[1:]))]

Captcha answer.",528b1a5d-639a-4eec-87d8-1b2c4c8f3e23
base,chat_bot.py,_cmd_freespace,326,328,"def _cmd_freespace(self, args):        b = format.size(int(self.pyload.api.free_space()))        return [self._(""INFO: Free space is {}."").format(b)]",,"def _cmd_freespace(self, args):        b = format.size(int(self.pyload.api.free_space()))        return [self._(""INFO: Free space is {}."").format(b)]",641edc56-f864-4a9b-b087-83c39f16984c
base,chat_bot.py,_cmd_restart,330,332,"def _cmd_restart(self, args):        self.pyload.api.restart()        return [self._(""INFO: Done."")]",,"def _cmd_restart(self, args):        self.pyload.api.restart()        return [self._(""INFO: Done."")]",b082ead2-c766-4ec0-9165-a815f9fe1539
base,chat_bot.py,_cmd_restartfailed,334,336,"def _cmd_restartfailed(self, args):        self.pyload.api.restart_failed()        return [self._(""INFO: Restarting all failed downloads."")]",,"def _cmd_restartfailed(self, args):        self.pyload.api.restart_failed()        return [self._(""INFO: Restarting all failed downloads."")]",b07dfb2c-65d9-4268-a477-fa8691ba001e
base,chat_bot.py,_cmd_restartfile,338,355,"def _cmd_restartfile(self, args):        try:            file_id = int(args[0])        except IndexError:            return [                self._(""ERROR: Missing argument""),                self._(""Use restartfile command like this: pull <package id>""),            ]        except ValueError:            return [self._(""ERROR: Invalid file id"")]        if not self.pyload.api.get_file_data(file_id):            return [self._(""ERROR: File #{} does not exist."").format(file_id)]        self.pyload.api.restart_file(file_id)        return [self._(""INFO: Restart file #{}."").format(file_id)]",,"def _cmd_restartfile(self, args):        try:            file_id = int(args[0])        except IndexError:            return [                self._(""ERROR: Missing argument""),                self._(""Use restartfile command like this: pull <package id>""),            ]        except ValueError:            return [self._(""ERROR: Invalid file id"")]        if not self.pyload.api.get_file_data(file_id):            return [self._(""ERROR: File #{} does not exist."").format(file_id)]        self.pyload.api.restart_file(file_id)        return [self._(""INFO: Restart file #{}."").format(file_id)]",2d634884-9782-41d3-a878-23bdc31d1302
base,chat_bot.py,_cmd_restartpackage,357,367,"def _cmd_restartpackage(self, args):        try:            id_or_name = args[0]        except IndexError:            return [self._(""ERROR: missing argument"")]        pack = self._get_package_by_name_or_id(id_or_name)        if not pack:            return [self._(""ERROR: Package {} does not exist."").format(id_or_name)]        self.pyload.api.restart_package(pack.pid)        return [self._(""INFO: Restart package {} (#{})."").format(pack.name, pack.pid)]",,"def _cmd_restartpackage(self, args):        try:            id_or_name = args[0]        except IndexError:            return [self._(""ERROR: missing argument"")]        pack = self._get_package_by_name_or_id(id_or_name)        if not pack:            return [self._(""ERROR: Package {} does not exist."").format(id_or_name)]        self.pyload.api.restart_package(pack.pid)        return [self._(""INFO: Restart package {} (#{})."").format(pack.name, pack.pid)]",5b790152-9774-457c-9b4c-2123fb4ccc03
base,chat_bot.py,_cmd_deletefinished,369,370,"def _cmd_deletefinished(self, args):        return [self._(""INFO: Deleted package ids: {}."").format(self.pyload.api.delete_finished())]",,"def _cmd_deletefinished(self, args):        return [self._(""INFO: Deleted package ids: {}."").format(self.pyload.api.delete_finished())]",304bc0ae-de10-4d67-be6c-ec110e65352d
base,chat_bot.py,_cmd_getlog,372,398,"def _cmd_getlog(self, args):                self.more = []        lines = []        log = self.pyload.api.get_log()        for line in log:            if line:                if line[-1] == '\n':                    line = line[:-1]                self.more.append(""LOG: {}"".format(line))        if args and args[0] == 'last':            if len(args) < 2:                self.more = self.more[-self.max_lines:]            else:                self.more = self.more[-(int(args[1])):]        if len(self.more) < self.max_lines:            lines.extend(self.more)            self.more = []        else:            lines.extend(self.more[:self.max_lines])            self.more = self.more[self.max_lines:]            lines.append(""{} more logs to display."".format(len(self.more)))        return lines",Returns most recent log entries.,"def _cmd_getlog(self, args):        """"""Returns most recent log entries.""""""        self.more = []        lines = []        log = self.pyload.api.get_log()        for line in log:            if line:                if line[-1] == '\n':                    line = line[:-1]                self.more.append(""LOG: {}"".format(line))        if args and args[0] == 'last':            if len(args) < 2:                self.more = self.more[-self.max_lines:]            else:                self.more = self.more[-(int(args[1])):]        if len(self.more) < self.max_lines:            lines.extend(self.more)            self.more = []        else:            lines.extend(self.more[:self.max_lines])            self.more = self.more[self.max_lines:]            lines.append(""{} more logs to display."".format(len(self.more)))        return lines

Returns most recent log entries.",a190cf14-8093-428a-bde6-490e79318a74
base,chat_bot.py,_cmd_help,400,432,"def _cmd_help(self, args):        lines = [            ""The following commands are available:"",            ""add <package|packid> <links> [...] Adds link to package. (creates new package if it does not exist)"",            ""captcha <id> <answer>              Solve a captcha task with id <id>"",            ""collector                          Shows all packages in collector"",            ""del -p|-l <id> [...]               Deletes all packages|links with the ids specified"",            ""deletefinished                     Deletes all finished files and completly finished packages"",            ""freespace                          Available free space at download directory in bytes"",            ""getlog [last [nb]]                 Returns most recent log entries"",            ""help                               Shows this help message"",            ""info <id>                          Shows info of the link with id <id>"",            ""more                               Shows more info when the result was truncated"",            ""packinfo <package|packid>          Shows info of the package with id <id>"",            ""pause                              Stops the download (but not abort active downloads)"",            ""pull <id>                          Pull package from queue"",            ""push <id>                          Push package to queue"",            ""queue                              Shows all packages in the queue"",            ""restart                            Restart pyload core"",            ""restartfailed                      Restarts all failed files"",            ""restartfile <id>                   Resets file status, so it will be downloaded again"",            ""restartpackage <package|packid>    Restarts a package, resets every containing files"",            ""status                             Show general download status"",            ""togglepause                        Toggle pause state"",            ""unpause                            Starts all downloads""        ]        lines.append(""Shortcuts:"")        lines.append("", "".join(            cmd_short + "": "" + cmd_long            for cmd_short, cmd_long in self.SHORTCUT_COMMANDS.items())        )        return lines",,"def _cmd_help(self, args):        lines = [            ""The following commands are available:"",            ""add <package|packid> <links> [...] Adds link to package. (creates new package if it does not exist)"",            ""captcha <id> <answer>              Solve a captcha task with id <id>"",            ""collector                          Shows all packages in collector"",            ""del -p|-l <id> [...]               Deletes all packages|links with the ids specified"",            ""deletefinished                     Deletes all finished files and completly finished packages"",            ""freespace                          Available free space at download directory in bytes"",            ""getlog [last [nb]]                 Returns most recent log entries"",            ""help                               Shows this help message"",            ""info <id>                          Shows info of the link with id <id>"",            ""more                               Shows more info when the result was truncated"",            ""packinfo <package|packid>          Shows info of the package with id <id>"",            ""pause                              Stops the download (but not abort active downloads)"",            ""pull <id>                          Pull package from queue"",            ""push <id>                          Push package to queue"",            ""queue                              Shows all packages in the queue"",            ""restart                            Restart pyload core"",            ""restartfailed                      Restarts all failed files"",            ""restartfile <id>                   Resets file status, so it will be downloaded again"",            ""restartpackage <package|packid>    Restarts a package, resets every containing files"",            ""status                             Show general download status"",            ""togglepause                        Toggle pause state"",            ""unpause                            Starts all downloads""        ]        lines.append(""Shortcuts:"")        lines.append("", "".join(            cmd_short + "": "" + cmd_long            for cmd_short, cmd_long in self.SHORTCUT_COMMANDS.items())        )        return lines",8316b0e2-e18f-4d72-9441-1c4b2d10de3e
base,chat_bot.py,_get_package_by_name_or_id,434,444,"def _get_package_by_name_or_id(self, id_or_name):                if id_or_name.isdigit():            try:                package_id = int(id_or_name)                pack = self.pyload.api.get_package_data(package_id)            except PackageDoesNotExists:                pack = self._get_package_by_name(id_or_name)        else:            pack = self._get_package_by_name(id_or_name)        return pack",Return the first PackageData found or None.,"def _get_package_by_name_or_id(self, id_or_name):        """"""Return the first PackageData found or None.""""""        if id_or_name.isdigit():            try:                package_id = int(id_or_name)                pack = self.pyload.api.get_package_data(package_id)            except PackageDoesNotExists:                pack = self._get_package_by_name(id_or_name)        else:            pack = self._get_package_by_name(id_or_name)        return pack

Return the first PackageData found or None.",0669cf38-22aa-41f9-8723-507e9aaf733f
base,chat_bot.py,_get_package_by_name,446,457,"def _get_package_by_name(self, name):                pq = self.pyload.api.get_queue_data()        for pack in pq:            if pack.name == name:                return pack        pc = self.pyload.api.get_collector()        for pack in pc:            if pack.name == name:                return pack        return None",Return the first PackageData found or None.,"def _get_package_by_name(self, name):        """"""Return the first PackageData found or None.""""""        pq = self.pyload.api.get_queue_data()        for pack in pq:            if pack.name == name:                return pack        pc = self.pyload.api.get_collector()        for pack in pc:            if pack.name == name:                return pack        return None

Return the first PackageData found or None.",b3df9ac4-5908-4ede-aec9-85a387cfbd4e
base,container.py,process,31,47,"def process(self, pyfile):                self._make_tmpfile()        self.decrypt(pyfile)        if self.links:            self._generate_packages()        elif not self.packages:            self.error(self._(""No link grabbed""), ""decrypt"")        self._delete_tmpfile()        self._create_packages()",Main method.,"def process(self, pyfile):        """"""        Main method.        """"""        self._make_tmpfile()        self.decrypt(pyfile)        if self.links:            self._generate_packages()        elif not self.packages:            self.error(self._(""No link grabbed""), ""decrypt"")        self._delete_tmpfile()        self._create_packages()

Main method.",2841aaf3-15a7-4bd5-a9f7-7499023a09ee
base,container.py,_delete_tmpfile,49,51,"def _delete_tmpfile(self):        if os.path.basename(self.pyfile.name).startswith(""tmp_""):            self.remove(self.pyfile.url, try_trash=False)",,"def _delete_tmpfile(self):        if os.path.basename(self.pyfile.name).startswith(""tmp_""):            self.remove(self.pyfile.url, try_trash=False)",9b772335-48be-4cc3-8ccc-2c9cb2080860
base,container.py,_make_tmpfile,53,76,"def _make_tmpfile(self):                remote = bool(urllib.parse.urlparse(self.pyfile.url).netloc)        if remote:            content = self.load(self.pyfile.url)            self.pyfile.name = ""tmp_"" + self.pyfile.name            self.pyfile.url = os.path.join(                self.pyload.config.get(""general"", ""storage_folder""), self.pyfile.name            )            try:                with open(self.pyfile.url, mode=""wb"") as fp:                    fp.write(content.encode())            except IOError as exc:                self.fail(exc)        elif not exists(self.pyfile.url):            self.fail(self._(""File not found""))","Loads container to disk if its stored remotely and overwrite url, or check
existent on several places at disk.","def _make_tmpfile(self):        """"""        Loads container to disk if its stored remotely and overwrite url, or check        existent on several places at disk.        """"""        remote = bool(urllib.parse.urlparse(self.pyfile.url).netloc)        if remote:            content = self.load(self.pyfile.url)            self.pyfile.name = ""tmp_"" + self.pyfile.name            self.pyfile.url = os.path.join(                self.pyload.config.get(""general"", ""storage_folder""), self.pyfile.name            )            try:                with open(self.pyfile.url, mode=""wb"") as fp:                    fp.write(content.encode())            except IOError as exc:                self.fail(exc)        elif not exists(self.pyfile.url):            self.fail(self._(""File not found""))

Loads container to disk if its stored remotely and overwrite url, or check
existent on several places at disk.",6b4e52c4-845d-46d4-b46e-b2486c77cd0c
base,dead_decrypter.py,get_info,20,23,"def get_info(self, *args, **kwargs):        info = super(DeadDecrypter, self).get_info(*args, **kwargs)        info[""status""] = 1        return info",,"def get_info(self, *args, **kwargs):        info = super(DeadDecrypter, self).get_info(*args, **kwargs)        info[""status""] = 1        return info",0069a6ba-73b0-4dae-b6fa-e32bbbb3305c
base,dead_decrypter.py,setup,25,26,"def setup(self):        self.offline(self._(""Decrypter is no longer available""))",,"def setup(self):        self.offline(self._(""Decrypter is no longer available""))",6351ccc9-ba17-4c71-8a49-ff3ea3e9072d
base,dead_downloader.py,get_info,20,23,"def get_info(self, *args, **kwargs):        info = super(DeadDownloader, self).get_info(*args, **kwargs)        info[""status""] = 1        return info",,"def get_info(self, *args, **kwargs):        info = super(DeadDownloader, self).get_info(*args, **kwargs)        info[""status""] = 1        return info",c0e1cba3-fc08-40e7-bdb5-b0bd680fdc9b
base,dead_downloader.py,setup,25,26,"def setup(self):        self.offline(self._(""Downloader is no longer available""))",,"def setup(self):        self.offline(self._(""Downloader is no longer available""))",b0d2d367-192b-4feb-8dd3-9652a59221f1
base,decrypter.py,init_base,31,34,"def init_base(self):        #: Put all packages here. It's a list of tuples like: ( name, [list of links], folder )        self.packages = []        self.links = []",,"def init_base(self):        #: Put all packages here. It's a list of tuples like: ( name, [list of links], folder )        self.packages = []        self.links = []",6744e361-91db-46ee-ab3e-e3afe8aa7ee1
base,decrypter.py,setup_base,36,38,def setup_base(self):        self.packages = []        self.links = [],,def setup_base(self):        self.packages = []        self.links = [],bb471fff-9577-472a-9f58-a9e8c4953db9
base,decrypter.py,process,40,49,"def process(self, pyfile):        self.decrypt(pyfile)        if self.links:            self._generate_packages()        elif not self.packages:            self.error(self._(""No link grabbed""), ""decrypt"")        self._create_packages()",,"def process(self, pyfile):        self.decrypt(pyfile)        if self.links:            self._generate_packages()        elif not self.packages:            self.error(self._(""No link grabbed""), ""decrypt"")        self._create_packages()",b00bdc50-c81d-4db1-a14a-0cd05020d008
base,decrypter.py,decrypt,51,55,"def decrypt(self, pyfile):                raise NotImplementedError","The ""main"" method of every decrypter plugin, you **have to** overwrite it.","def decrypt(self, pyfile):        """"""        The ""main"" method of every decrypter plugin, you **have to** overwrite it.        """"""        raise NotImplementedError

The ""main"" method of every decrypter plugin, you **have to** overwrite it.",0afc8bf4-8aa4-46fb-81ab-5c33aa37e4e2
base,decrypter.py,_generate_packages,57,72,"def _generate_packages(self):                name = self.info[""pattern""].get(""N"")        if name is None:            links = [self.fixurl(url) for url in self.links]            pdict = self.pyload.api.generate_packages(links)            packages = [                (name, links, parse.name(name)) for name, links in pdict.items()            ]        else:            packages = [(name, self.links, parse.name(name))]        self.packages.extend(packages)",Generate new packages from self.links.,"def _generate_packages(self):        """"""        Generate new packages from self.links.        """"""        name = self.info[""pattern""].get(""N"")        if name is None:            links = [self.fixurl(url) for url in self.links]            pdict = self.pyload.api.generate_packages(links)            packages = [                (name, links, parse.name(name)) for name, links in pdict.items()            ]        else:            packages = [(name, self.links, parse.name(name))]        self.packages.extend(packages)

Generate new packages from self.links.",7bb31c0f-1022-4a18-a12c-f94e2d88cb16
base,decrypter.py,_create_packages,74,121,"def _create_packages(self):                pack_folder = self.pyfile.package().folder        pack_password = self.pyfile.package().password        pack_queue = self.pyfile.package().queue        folder_per_package = self.config.get(""folder_per_package"", ""Default"")        if folder_per_package == ""Default"":            folder_per_package = self.pyload.config.get(""general"", ""folder_per_package"")        else:            folder_per_package = folder_per_package == ""Yes""        for name, links, folder in self.packages:            self.log_info(                self._(""Create package: {}"").format(name),                self._(""{} links"").format(len(links)),            )            links = [self.fixurl(url) for url in links]            self.log_debug(""LINKS for package "" + name, links)            pid = self.pyload.api.add_package(name, links, pack_queue)            if pack_password:                self.pyload.api.set_package_data(pid, {""password"": pack_password})            #: Workaround to do not break API add_package method            def set_folder(x):                return self.pyload.api.set_package_data(                    pid, {""_folder"": safename(x or """")}                )            if not folder_per_package:                folder = pack_folder            elif not folder or folder == name:                folder = parse.name(name)            self.log_info(                self._(""Save package `{name}` to folder: {folder}"").format(                    name=name, folder=folder                )            )            set_folder(folder)",Create new packages from self.packages.,"def _create_packages(self):        """"""        Create new packages from self.packages.        """"""        pack_folder = self.pyfile.package().folder        pack_password = self.pyfile.package().password        pack_queue = self.pyfile.package().queue        folder_per_package = self.config.get(""folder_per_package"", ""Default"")        if folder_per_package == ""Default"":            folder_per_package = self.pyload.config.get(""general"", ""folder_per_package"")        else:            folder_per_package = folder_per_package == ""Yes""        for name, links, folder in self.packages:            self.log_info(                self._(""Create package: {}"").format(name),                self._(""{} links"").format(len(links)),            )            links = [self.fixurl(url) for url in links]            self.log_debug(""LINKS for package "" + name, links)            pid = self.pyload.api.add_package(name, links, pack_queue)            if pack_password:                self.pyload.api.set_package_data(pid, {""password"": pack_password})            #: Workaround to do not break API add_package method            def set_folder(x):                return self.pyload.api.set_package_data(                    pid, {""_folder"": safename(x or """")}                )            if not folder_per_package:                folder = pack_folder            elif not folder or folder == name:                folder = parse.name(name)            self.log_info(                self._(""Save package `{name}` to folder: {folder}"").format(                    name=name, folder=folder                )            )            set_folder(folder)

Create new packages from self.packages.",cf2884c1-5f51-4df7-95d4-380967949480
base,downloader.py,last_download,34,35,"def last_download(self):        return self._last_download if exists(self._last_download) else """"",,"def last_download(self):        return self._last_download if exists(self._last_download) else """"",438d1e7f-8299-4414-b5e8-ed0626a6f539
base,downloader.py,last_download,38,43,"def last_download(self, value):        if isinstance(value, str) and exists(value):            self._last_download = value        else:            self._last_download = """"",,"def last_download(self, value):        if isinstance(value, str) and exists(value):            self._last_download = value        else:            self._last_download = """"",269859e2-2eae-4c0a-94f1-186f62b2c305
base,downloader.py,init_base,45,65,"def init_base(self):        #: Enable simultaneous processing of multiple downloads        self.limit_dl = 0        #: Download chunks limit        self.chunk_limit = None        #: Enable download resuming if the hoster supports resuming        self.resume_download = False        #: Location where the last call to download was saved        self._last_download = """"        #: Re match of the last call to `check_download`        self.last_check = None        #: Restart flag        self.restart_free = False  # TODO: Recheck in 0.6.x        #: Download is possible with premium account only, don't fallback to free download        self.no_fallback = False",,"def init_base(self):        #: Enable simultaneous processing of multiple downloads        self.limit_dl = 0        #: Download chunks limit        self.chunk_limit = None        #: Enable download resuming if the hoster supports resuming        self.resume_download = False        #: Location where the last call to download was saved        self._last_download = """"        #: Re match of the last call to `check_download`        self.last_check = None        #: Restart flag        self.restart_free = False  # TODO: Recheck in 0.6.x        #: Download is possible with premium account only, don't fallback to free download        self.no_fallback = False",571e4871-2154-425a-9ced-e8d29d004400
base,downloader.py,setup_base,67,78,"def setup_base(self):        self._last_download = """"        self.last_check = None        self.restart_free = False        self.no_fallback = False        if self.account:            self.chunk_limit = -1  #: -1 for unlimited            self.resume_download = True        else:            self.chunk_limit = 1            self.resume_download = False",,"def setup_base(self):        self._last_download = """"        self.last_check = None        self.restart_free = False        self.no_fallback = False        if self.account:            self.chunk_limit = -1  #: -1 for unlimited            self.resume_download = True        else:            self.chunk_limit = 1            self.resume_download = False",29950048-27e3-466a-9b62-cea4889c248c
base,downloader.py,load_account,80,84,def load_account(self):        if self.restart_free:            self.account = False        else:            super().load_account(),,def load_account(self):        if self.restart_free:            self.account = False        else:            super().load_account(),5714bacc-7651-4a24-9159-40614113ae5f
base,downloader.py,_process,87,126,"def _process(self, thread):        self.thread = thread        try:            self._initialize()            self._setup()            # TODO: Enable in 0.6.x            # self.pyload.addon_manager.download_preparing(self.pyfile)            # self.check_status()            self.check_duplicates()            self.pyfile.set_status(""starting"")            try:                self.log_info(self._(""Processing url: "") + self.pyfile.url)                self.process(self.pyfile)                self.check_status()                self._check_download()            except Fail as exc:  # TODO: Move to DownloadThread in 0.6.x                self.log_warning(                    self._(""Premium download failed"")                    if self.premium                    else self._(""Free download failed""),                    str(exc),                )                if (                    not self.no_fallback                    and self.config.get(""fallback"", True)                    and self.premium                ):                    self.restart(premium=False)                else:                    raise        finally:            self._finalize()",,"def _process(self, thread):        self.thread = thread        try:            self._initialize()            self._setup()            # TODO: Enable in 0.6.x            # self.pyload.addon_manager.download_preparing(self.pyfile)            # self.check_status()            self.check_duplicates()            self.pyfile.set_status(""starting"")            try:                self.log_info(self._(""Processing url: "") + self.pyfile.url)                self.process(self.pyfile)                self.check_status()                self._check_download()            except Fail as exc:  # TODO: Move to DownloadThread in 0.6.x                self.log_warning(                    self._(""Premium download failed"")                    if self.premium                    else self._(""Free download failed""),                    str(exc),                )                if (                    not self.no_fallback                    and self.config.get(""fallback"", True)                    and self.premium                ):                    self.restart(premium=False)                else:                    raise        finally:            self._finalize()",fbf1bba5-aaea-4a64-9a3c-d8c8a3c611a1
base,downloader.py,_finalize,129,156,"def _finalize(self):        pypack = self.pyfile.package()        self.pyload.addon_manager.dispatch_event(""download_processed"", self.pyfile)        try:            unfinished = any(                fdata.get(""status"") in (3, 7)                for fid, fdata in pypack.get_children().items()                if fid != self.pyfile.id            )            if unfinished:                return            self.pyload.addon_manager.dispatch_event(""package_processed"", pypack)            failed = any(                fdata.get(""status"") in (1, 6, 8, 9, 14)                for fid, fdata in pypack.get_children().items()            )            if not failed:                return            self.pyload.addon_manager.dispatch_event(""package_failed"", pypack)        finally:            self.check_status()",,"def _finalize(self):        pypack = self.pyfile.package()        self.pyload.addon_manager.dispatch_event(""download_processed"", self.pyfile)        try:            unfinished = any(                fdata.get(""status"") in (3, 7)                for fid, fdata in pypack.get_children().items()                if fid != self.pyfile.id            )            if unfinished:                return            self.pyload.addon_manager.dispatch_event(""package_processed"", pypack)            failed = any(                fdata.get(""status"") in (1, 6, 8, 9, 14)                for fid, fdata in pypack.get_children().items()            )            if not failed:                return            self.pyload.addon_manager.dispatch_event(""package_failed"", pypack)        finally:            self.check_status()",de784197-a898-4b19-9caa-cf1ce49b679a
base,downloader.py,isresource,158,215,"def isresource(self, url, redirect=True, resumable=None):        resource = False        if resumable is None:            resumable = self.resume_download        if type(redirect) == int:            maxredirs = max(redirect, 1)        elif redirect:            maxredirs = (                self.config.get(""maxredirs"", default=5, plugin=""UserAgentSwitcher"")            )        else:            maxredirs = 1        header = self.load(url, just_header=True, redirect=False)        for i in range(1, maxredirs):            if not redirect or header.get(""connection"") == ""close"":                resumable = False            if ""content-disposition"" in header:                resource = url            elif header.get(""location""):                location = self.fixurl(header.get(""location""), url)                code = header.get(""code"")                if code in (301, 302) or resumable:                    self.log_debug(f""Redirect #{i} to: {location}"")                    header = self.load(location, just_header=True, redirect=False)                    url = location                    continue            else:                contenttype = header.get(""content-type"")                extension = os.path.splitext(parse.name(url))[-1]                if contenttype:                    mimetype = contenttype.split("";"")[0].strip()                elif extension:                    mimetype = (                        mimetypes.guess_type(extension, False)[0]                        or ""application/octet-stream""                    )                else:                    mimetype = None                if mimetype and (resource or ""html"" not in mimetype):                    resource = url                else:                    resource = False            return resource",,"def isresource(self, url, redirect=True, resumable=None):        resource = False        if resumable is None:            resumable = self.resume_download        if type(redirect) == int:            maxredirs = max(redirect, 1)        elif redirect:            maxredirs = (                self.config.get(""maxredirs"", default=5, plugin=""UserAgentSwitcher"")            )        else:            maxredirs = 1        header = self.load(url, just_header=True, redirect=False)        for i in range(1, maxredirs):            if not redirect or header.get(""connection"") == ""close"":                resumable = False            if ""content-disposition"" in header:                resource = url            elif header.get(""location""):                location = self.fixurl(header.get(""location""), url)                code = header.get(""code"")                if code in (301, 302) or resumable:                    self.log_debug(f""Redirect #{i} to: {location}"")                    header = self.load(location, just_header=True, redirect=False)                    url = location                    continue            else:                contenttype = header.get(""content-type"")                extension = os.path.splitext(parse.name(url))[-1]                if contenttype:                    mimetype = contenttype.split("";"")[0].strip()                elif extension:                    mimetype = (                        mimetypes.guess_type(extension, False)[0]                        or ""application/octet-stream""                    )                else:                    mimetype = None                if mimetype and (resource or ""html"" not in mimetype):                    resource = url                else:                    resource = False            return resource",0caec85b-d189-44b8-8407-7b9a4babdfaf
base,downloader.py,_on_notification,217,222,"def _on_notification(self, notification):        if ""progress"" in notification:            self.pyfile.set_progress(notification[""progress""])        if ""disposition"" in notification:            self.pyfile.set_name(notification[""disposition""])",,"def _on_notification(self, notification):        if ""progress"" in notification:            self.pyfile.set_progress(notification[""progress""])        if ""disposition"" in notification:            self.pyfile.set_name(notification[""disposition""])",e1077c93-3b32-4e37-b319-8b1d4d362a17
base,downloader.py,_download,224,277,"def _download(        self, url, filename, get, post, ref, cookies, disposition, resume, chunks    ):        # TODO: Safe-filename check in HTTPDownload in 0.6.x        filename = os.fsdecode(filename)        resume = self.resume_download if resume is None else bool(resume)        dl_chunks = self.pyload.config.get(""download"", ""chunks"")        chunk_limit = chunks or self.chunk_limit or -1        if -1 in (dl_chunks, chunk_limit):            chunks = max(dl_chunks, chunk_limit)        else:            chunks = min(dl_chunks, chunk_limit)        try:            newname = self.req.http_download(                url,                filename,                size=self.pyfile.size,                get=get,                post=post,                ref=ref,                cookies=cookies,                chunks=chunks,                resume=resume,                status_notify=self._on_notification,                disposition=disposition,            )        except IOError as exc:            self.log_error(str(exc))            self.fail(self._(""IOError {}"").format(exc.errno))        except BadHeader as exc:            self.req.http.code = exc.code            raise        else:            if self.req.code in (404, 410):                if newname:                    bad_file = os.path.join(os.path.dirname(filename), newname)                else:                    bad_file = filename                self.remove(bad_file)                return """"            else:                self.log_info(self._(""File saved""))            return newname        finally:            self.pyfile.size = self.req.size            self.captcha.correct()",,"def _download(        self, url, filename, get, post, ref, cookies, disposition, resume, chunks    ):        # TODO: Safe-filename check in HTTPDownload in 0.6.x        filename = os.fsdecode(filename)        resume = self.resume_download if resume is None else bool(resume)        dl_chunks = self.pyload.config.get(""download"", ""chunks"")        chunk_limit = chunks or self.chunk_limit or -1        if -1 in (dl_chunks, chunk_limit):            chunks = max(dl_chunks, chunk_limit)        else:            chunks = min(dl_chunks, chunk_limit)        try:            newname = self.req.http_download(                url,                filename,                size=self.pyfile.size,                get=get,                post=post,                ref=ref,                cookies=cookies,                chunks=chunks,                resume=resume,                status_notify=self._on_notification,                disposition=disposition,            )        except IOError as exc:            self.log_error(str(exc))            self.fail(self._(""IOError {}"").format(exc.errno))        except BadHeader as exc:            self.req.http.code = exc.code            raise        else:            if self.req.code in (404, 410):                if newname:                    bad_file = os.path.join(os.path.dirname(filename), newname)                else:                    bad_file = filename                self.remove(bad_file)                return """"            else:                self.log_info(self._(""File saved""))            return newname        finally:            self.pyfile.size = self.req.size            self.captcha.correct()",70430d12-7f8b-41ea-b3db-4f0034c140b5
base,downloader.py,download,279,347,"def download(        self,        url,        get={},        post={},        ref=True,        cookies=True,        disposition=True,        resume=None,        chunks=None,    ):                self.check_status()        if self.pyload.debug:            self.log_debug(                ""DOWNLOAD URL "" + url,                *[                    ""{}={}"".format(key, value)                    for key, value in locals().items()                    if key not in (""self"", ""url"", ""_[1]"")                ],            )        dl_basename = parse.name(self.pyfile.name)        self.pyfile.name = dl_basename        self.check_duplicates()        self.pyfile.set_status(""downloading"")        dl_url = self.fixurl(url)        dl_folder = self.pyload.config.get(""general"", ""storage_folder"")        dl_dirname = safejoin(dl_folder, self.pyfile.package().folder)        dl_filename = safejoin(dl_dirname, self.pyfile.name)        os.makedirs(dl_dirname, exist_ok=True)        self.set_permissions(dl_dirname)        self.pyload.addon_manager.dispatch_event(            ""download_start"", self.pyfile, dl_url, dl_filename        )        self.check_status()        newname = self._download(            dl_url, dl_filename, get, post, ref, cookies, disposition, resume, chunks        )        if disposition and newname:            self.pyfile.name = newname            dl_filename = safejoin(dl_dirname, newname)        self.set_permissions(dl_filename)        self.last_download = dl_filename        return dl_filename","Downloads the content at url to download folder.

:param url:
:param get:
:param post:
:param ref:
:param cookies:
:param disposition: if True and server provides content-disposition header        the filename will be changed if needed
:return: The location where the file was saved","def download(        self,        url,        get={},        post={},        ref=True,        cookies=True,        disposition=True,        resume=None,        chunks=None,    ):        """"""        Downloads the content at url to download folder.        :param url:        :param get:        :param post:        :param ref:        :param cookies:        :param disposition: if True and server provides content-disposition header\        the filename will be changed if needed        :return: The location where the file was saved        """"""        self.check_status()        if self.pyload.debug:            self.log_debug(                ""DOWNLOAD URL "" + url,                *[                    ""{}={}"".format(key, value)                    for key, value in locals().items()                    if key not in (""self"", ""url"", ""_[1]"")                ],            )        dl_basename = parse.name(self.pyfile.name)        self.pyfile.name = dl_basename        self.check_duplicates()        self.pyfile.set_status(""downloading"")        dl_url = self.fixurl(url)        dl_folder = self.pyload.config.get(""general"", ""storage_folder"")        dl_dirname = safejoin(dl_folder, self.pyfile.package().folder)        dl_filename = safejoin(dl_dirname, self.pyfile.name)        os.makedirs(dl_dirname, exist_ok=True)        self.set_permissions(dl_dirname)        self.pyload.addon_manager.dispatch_event(            ""download_start"", self.pyfile, dl_url, dl_filename        )        self.check_status()        newname = self._download(            dl_url, dl_filename, get, post, ref, cookies, disposition, resume, chunks        )        if disposition and newname:            self.pyfile.name = newname            dl_filename = safejoin(dl_dirname, newname)        self.set_permissions(dl_filename)        self.last_download = dl_filename        return dl_filename

Downloads the content at url to download folder.

:param url:
:param get:
:param post:
:param ref:
:param cookies:
:param disposition: if True and server provides content-disposition header        the filename will be changed if needed
:return: The location where the file was saved",411f9829-b392-4faa-8959-bb479e4b1a72
base,downloader.py,scan_download,349,381,"def scan_download(self, rules, read_size=1_048_576):                if not self.last_download:            self.log_warning(self._(""No file to scan""))            return        dl_file = os.fsdecode(self.last_download)  # TODO: Recheck in 0.6.x        with open(dl_file, mode=""rb"") as fp:            content = fp.read(read_size)        for name, rule in rules.items():            if isinstance(rule, bytes):                if rule in content:                    return name            elif isinstance(rule, str):                raise TypeError(f""Cannot check binary data with string rule '{name}'"")            elif hasattr(rule, ""search""):                m = rule.search(content)                if m is not None:                    self.last_check = m                    return name            elif callable(rule):                return rule(content)","Checks the content of the last downloaded file, re match is saved to
`last_check`

:param rules: dict with names and rules to match (compiled regexp or strings)
:param read_size: size to read and scan
:return: dictionary key of the first rule that matched","def scan_download(self, rules, read_size=1_048_576):        """"""        Checks the content of the last downloaded file, re match is saved to        `last_check`        :param rules: dict with names and rules to match (compiled regexp or strings)        :param read_size: size to read and scan        :return: dictionary key of the first rule that matched        """"""        if not self.last_download:            self.log_warning(self._(""No file to scan""))            return        dl_file = os.fsdecode(self.last_download)  # TODO: Recheck in 0.6.x        with open(dl_file, mode=""rb"") as fp:            content = fp.read(read_size)        for name, rule in rules.items():            if isinstance(rule, bytes):                if rule in content:                    return name            elif isinstance(rule, str):                raise TypeError(f""Cannot check binary data with string rule '{name}'"")            elif hasattr(rule, ""search""):                m = rule.search(content)                if m is not None:                    self.last_check = m                    return name            elif callable(rule):                return rule(content)

Checks the content of the last downloaded file, re match is saved to
`last_check`

:param rules: dict with names and rules to match (compiled regexp or strings)
:param read_size: size to read and scan
:return: dictionary key of the first rule that matched",5f32ddb9-2899-4d12-aaf2-71d9cc6cc994
base,downloader.py,_check_download,383,407,"def _check_download(self):        def _is_empty_file(content):            firstbyte = content[0:1]            whitespaces_count = len(re.findall(rb""[%s\s]"" % firstbyte, content))            return whitespaces_count == len(content)        self.log_info(self._(""Checking download...""))        self.pyfile.set_custom_status(self._(""checking""))        if not self.last_download:            if self.captcha.task:                self.retry_captcha()            else:                self.error(self._(""No file downloaded""))        elif self.scan_download({""Empty file"": _is_empty_file}):            if self.remove(self.last_download):                self.last_download = """"            self.error(self._(""Empty file""))        else:            self.pyload.addon_manager.dispatch_event(""download_check"", self.pyfile)            self.check_status()        self.log_info(self._(""File is OK""))",,"def _check_download(self):        def _is_empty_file(content):            firstbyte = content[0:1]            whitespaces_count = len(re.findall(rb""[%s\s]"" % firstbyte, content))            return whitespaces_count == len(content)        self.log_info(self._(""Checking download...""))        self.pyfile.set_custom_status(self._(""checking""))        if not self.last_download:            if self.captcha.task:                self.retry_captcha()            else:                self.error(self._(""No file downloaded""))        elif self.scan_download({""Empty file"": _is_empty_file}):            if self.remove(self.last_download):                self.last_download = """"            self.error(self._(""Empty file""))        else:            self.pyload.addon_manager.dispatch_event(""download_check"", self.pyfile)            self.check_status()        self.log_info(self._(""File is OK""))",ac777746-4978-47ef-a49b-5fb3d6416f27
base,downloader.py,out_of_traffic,409,429,"def out_of_traffic(self):        if not self.account:            return False        traffic = self.account.get_data(""trafficleft"")        if traffic is None:            return True        elif traffic == -1:            return False        else:            size = self.pyfile.size            self.log_info(                self._(""Filesize: {}"").format(format.size(size)),                self._(""Traffic left for user `{}`: {}"").format(                    self.account.user, format.size(traffic)                ),            )            return size > traffic",,"def out_of_traffic(self):        if not self.account:            return False        traffic = self.account.get_data(""trafficleft"")        if traffic is None:            return True        elif traffic == -1:            return False        else:            size = self.pyfile.size            self.log_info(                self._(""Filesize: {}"").format(format.size(size)),                self._(""Traffic left for user `{}`: {}"").format(                    self.account.user, format.size(traffic)                ),            )            return size > traffic",1b8a47ed-bae4-407a-9f08-b848bbf4f5f5
base,downloader.py,check_duplicates,471,526,"def check_duplicates(self):                pack_folder = self.pyfile.package().folder        for pyfile in list(self.pyload.files.cache.values()):            if (                pyfile != self.pyfile                and pyfile.name == self.pyfile.name                and pyfile.package().folder == pack_folder            ):                if pyfile.status in (                    0,                    12,                    5,                    7,                ):  #: finished / downloading / waiting / starting                    self.skip(pyfile.pluginname)        dl_folder = self.pyload.config.get(""general"", ""storage_folder"")        dl_file = os.path.join(dl_folder, pack_folder, self.pyfile.name)        if not exists(dl_file):            return        if os.stat(dl_file).st_size == 0:            if self.remove(self.last_download):                self.last_download = """"            return        if self.pyload.config.get(""download"", ""skip_existing""):            plugin = self.pyload.db.find_duplicates(                self.pyfile.id, pack_folder, self.pyfile.name            )            msg = plugin[0] if plugin else self._(""File exists"")            self.skip(msg)        else:            # Same file exists but, it does not belong to our pack, add a trailing            # counter            name, ext = os.path.splitext(self.pyfile.name)            m = re.match(r""(.+?)(?:\((\d+)\))?$"", name)            dl_n = int(m.group(2) or ""0"")            while True:                name = ""{} ({}){}"".format(m.group(1), dl_n + 1, ext)                dl_file = os.path.join(dl_folder, pack_folder, name)                if not exists(dl_file):                    break                dl_n += 1            self.pyfile.name = name","Checks if same file was downloaded within same package.

:raises Skip:","def check_duplicates(self):        """"""        Checks if same file was downloaded within same package.        :raises Skip:        """"""        pack_folder = self.pyfile.package().folder        for pyfile in list(self.pyload.files.cache.values()):            if (                pyfile != self.pyfile                and pyfile.name == self.pyfile.name                and pyfile.package().folder == pack_folder            ):                if pyfile.status in (                    0,                    12,                    5,                    7,                ):  #: finished / downloading / waiting / starting                    self.skip(pyfile.pluginname)        dl_folder = self.pyload.config.get(""general"", ""storage_folder"")        dl_file = os.path.join(dl_folder, pack_folder, self.pyfile.name)        if not exists(dl_file):            return        if os.stat(dl_file).st_size == 0:            if self.remove(self.last_download):                self.last_download = """"            return        if self.pyload.config.get(""download"", ""skip_existing""):            plugin = self.pyload.db.find_duplicates(                self.pyfile.id, pack_folder, self.pyfile.name            )            msg = plugin[0] if plugin else self._(""File exists"")            self.skip(msg)        else:            # Same file exists but, it does not belong to our pack, add a trailing            # counter            name, ext = os.path.splitext(self.pyfile.name)            m = re.match(r""(.+?)(?:\((\d+)\))?$"", name)            dl_n = int(m.group(2) or ""0"")            while True:                name = ""{} ({}){}"".format(m.group(1), dl_n + 1, ext)                dl_file = os.path.join(dl_folder, pack_folder, name)                if not exists(dl_file):                    break                dl_n += 1            self.pyfile.name = name

Checks if same file was downloaded within same package.

:raises Skip:",c626e7db-51d0-4ca2-b120-aaee512b66cd
base,downloader.py,check_for_same_files,529,530,"def check_for_same_files(self, *args, **kwargs):        pass",,"def check_for_same_files(self, *args, **kwargs):        pass",854f3e1d-b76d-4a71-9334-d035bd2b5bd4
base,extractor.py,archivetype,48,64,"def archivetype(cls, filename):                name = os.path.basename(filename).lower()        for ext in cls.EXTENSIONS:            if isinstance(ext, str):                if name.endswith(""."" + ext):                    return ext            elif isinstance(ext, tuple):                if re.search(r""\."" + ext[1] + ""$"", name):                    return ext[0]        return None","Get archive default extension from filename

:param filename: file name to test
:return: Extension or None","def archivetype(cls, filename):        """"""        Get archive default extension from filename        :param filename: file name to test        :return: Extension or None        """"""        name = os.path.basename(filename).lower()        for ext in cls.EXTENSIONS:            if isinstance(ext, str):                if name.endswith(""."" + ext):                    return ext            elif isinstance(ext, tuple):                if re.search(r""\."" + ext[1] + ""$"", name):                    return ext[0]        return None

Get archive default extension from filename

:param filename: file name to test
:return: Extension or None",d0f9fd62-76bb-4dd2-90b5-f43a4efd2bf7
base,extractor.py,isarchive,67,78,"def isarchive(cls, filename):        name = os.path.basename(filename).lower()        for ext in cls.EXTENSIONS:            if isinstance(ext, str):                if name.endswith(""."" + ext):                    return True            elif isinstance(ext, tuple):                if re.search(r""\."" + ext[1] + ""$"", name):                    return True        return False",,"def isarchive(cls, filename):        name = os.path.basename(filename).lower()        for ext in cls.EXTENSIONS:            if isinstance(ext, str):                if name.endswith(""."" + ext):                    return True            elif isinstance(ext, tuple):                if re.search(r""\."" + ext[1] + ""$"", name):                    return True        return False",07264040-9874-4032-a312-10728063c304
base,extractor.py,ismultipart,81,82,"def ismultipart(cls, filename):        return False",,"def ismultipart(cls, filename):        return False",6f91891d-1087-4dee-ac9c-979891c40b19
base,extractor.py,find,85,89,def find(cls):                pass,Check if system statisfy dependencies,"def find(cls):        """"""        Check if system statisfy dependencies        """"""        pass

Check if system statisfy dependencies",2a66fca5-09dc-4094-a90a-bce98e7a5016
base,extractor.py,get_targets,92,117,"def get_targets(cls, files_ids):                targets = []        processed = []        for id, fname, fout in files_ids:            if not cls.isarchive(fname):                continue            if cls.ismultipart(fname):                pname = cls._RE_PART.sub("""", fname)            else:                pname = os.path.splitext(fname)[0]            if pname in processed:                continue            processed.append(pname)            targets.append((id, fname, fout))        return targets","Filter suited targets from list of filename id tuple list

:param files_ids: List of filepathes
:return: List of targets, id tuple list","def get_targets(cls, files_ids):        """"""        Filter suited targets from list of filename id tuple list        :param files_ids: List of filepathes        :return: List of targets, id tuple list        """"""        targets = []        processed = []        for id, fname, fout in files_ids:            if not cls.isarchive(fname):                continue            if cls.ismultipart(fname):                pname = cls._RE_PART.sub("""", fname)            else:                pname = os.path.splitext(fname)[0]            if pname in processed:                continue            processed.append(pname)            targets.append((id, fname, fout))        return targets

Filter suited targets from list of filename id tuple list

:param files_ids: List of filepathes
:return: List of targets, id tuple list",45c3a65a-f215-4cb0-9382-51897940ac9d
base,extractor.py,__init__,119,146,"def __init__(        self,        pyfile,        filename,        out,        fullpath=True,        overwrite=False,        excludefiles=[],        priority=0,        keepbroken=False,    ):                self._init(pyfile.m.pyload)        self.pyfile = pyfile        self.filename = filename        self.name = os.path.basename(filename)        self.out = out        self.fullpath = fullpath        self.overwrite = overwrite        self.excludefiles = excludefiles        self.priority = priority        self.keepbroken = keepbroken        self.files = None        self.init()",Initialize extractor for specific file,"def __init__(        self,        pyfile,        filename,        out,        fullpath=True,        overwrite=False,        excludefiles=[],        priority=0,        keepbroken=False,    ):        """"""        Initialize extractor for specific file        """"""        self._init(pyfile.m.pyload)        self.pyfile = pyfile        self.filename = filename        self.name = os.path.basename(filename)        self.out = out        self.fullpath = fullpath        self.overwrite = overwrite        self.excludefiles = excludefiles        self.priority = priority        self.keepbroken = keepbroken        self.files = None        self.init()

Initialize extractor for specific file",4840f588-f886-4302-b80c-1c1cdb865451
base,extractor.py,target,149,150,def target(self):        return os.fsdecode(self.filename),,def target(self):        return os.fsdecode(self.filename),7b717547-9da5-4d16-b562-8cc14ff4e3d5
base,extractor.py,dest,153,154,def dest(self):        return os.fsdecode(self.out),,def dest(self):        return os.fsdecode(self.out),f0d7621d-a038-4932-8d2a-efcba2fa1687
base,extractor.py,verify,156,161,"def verify(self, password=None):                pass","Testing with Extractors built-in method Raise error if password is needed,
integrity is questionable or else","def verify(self, password=None):        """"""        Testing with Extractors built-in method Raise error if password is needed,        integrity is questionable or else        """"""        pass

Testing with Extractors built-in method Raise error if password is needed,
integrity is questionable or else",73333301-b3cc-43ec-bc12-7ae05373e7bc
base,extractor.py,repair,163,164,def repair(self):        pass,,def repair(self):        pass,b4b0248b-a116-4774-9e2a-60a53d623084
base,extractor.py,extract,166,170,"def extract(self, password=None):                raise NotImplementedError",Extract the archive Raise specific errors in case of failure,"def extract(self, password=None):        """"""        Extract the archive Raise specific errors in case of failure        """"""        raise NotImplementedError

Extract the archive Raise specific errors in case of failure",d070c7fb-f301-49eb-afad-0966e4ae7ba2
base,extractor.py,chunks,172,176,def chunks(self):                return [self.filename],Return list of archive parts,"def chunks(self):        """"""        Return list of archive parts        """"""        return [self.filename]

Return list of archive parts",0a45cb4b-18bd-4556-bdcb-c32100f1f1e0
base,extractor.py,list,178,182,"def list(self, password=None):                raise NotImplementedError",Return list of archive files,"def list(self, password=None):        """"""        Return list of archive files        """"""        raise NotImplementedError

Return list of archive files",a15227bd-7697-4502-b1ce-3eec27ec5a01
base,extractor.py,progress,184,188,"def progress(self, x):                return self.pyfile.set_progress(int(x))",Set extraction progress,"def progress(self, x):        """"""        Set extraction progress        """"""        return self.pyfile.set_progress(int(x))

Set extraction progress",931be62c-3648-4180-a1ac-f45ac46a7a32
base,hoster.py,get_info,17,19,"def get_info(urls):    #: result = [ .. (name, size, status, url) .. ]    pass",,"def get_info(urls):    #: result = [ .. (name, size, status, url) .. ]    pass",97cd1475-ad9b-46fa-8ea0-4e85dc99944c
base,hoster.py,parse_file_info,23,25,"def parse_file_info(klass, url="""", html=""""):    info = klass.get_info(url, html)    return info[""name""], info[""size""], info[""status""], info[""url""]",,"def parse_file_info(klass, url="""", html=""""):    info = klass.get_info(url, html)    return info[""name""], info[""size""], info[""status""], info[""url""]",da0f9cc5-f57d-4105-b861-576068300861
base,hoster.py,get_info,46,63,"def get_info(self, url="""", html=""""):        url = fixurl(url, unquote=True)        info = {            ""name"": parse.name(url),            ""hash"": {},            ""pattern"": {},            ""size"": 0,            ""status"": 7 if url else 8,            ""url"": replace_patterns(url, self.URL_REPLACEMENTS),        }        try:            info[""pattern""] = re.match(self.__pattern__, url).groupdict()        except Exception:            pass        return info",,"def get_info(self, url="""", html=""""):        url = fixurl(url, unquote=True)        info = {            ""name"": parse.name(url),            ""hash"": {},            ""pattern"": {},            ""size"": 0,            ""status"": 7 if url else 8,            ""url"": replace_patterns(url, self.URL_REPLACEMENTS),        }        try:            info[""pattern""] = re.match(self.__pattern__, url).groupdict()        except Exception:            pass        return info",acd89291-4b49-4173-9c27-415f54937350
base,hoster.py,__init__,65,100,"def __init__(self, pyfile):        self._init(pyfile.m.pyload)        #: Engage want reconnection        self.want_reconnect = False        #: Enable simultaneous processing of multiple downloads        self.multi_dl = True        #: time.time() + wait in seconds        self.waiting = False        #: Account handler instance, see :py:class:`Account`        self.account = None        self.premium = None        #: Associated pyfile instance, see `PyFile`        self.pyfile = pyfile        #: Holds thread in future        self.thread = None        #: Captcha stuff        # TODO: Replace in 0.6.x:        # _Captcha = self.pyload.plugin_manager.load_class(""anticaptcha"", self.classname) or BaseCaptcha        # self.captcha = _Captcha(pyfile)        self.captcha = BaseCaptcha(pyfile)        #: Some plugins store html code here        self.data = """"        #: Dict of the amount of retries already made        self.retries = {}        self.init_base()        self.init()",,"def __init__(self, pyfile):        self._init(pyfile.m.pyload)        #: Engage want reconnection        self.want_reconnect = False        #: Enable simultaneous processing of multiple downloads        self.multi_dl = True        #: time.time() + wait in seconds        self.waiting = False        #: Account handler instance, see :py:class:`Account`        self.account = None        self.premium = None        #: Associated pyfile instance, see `PyFile`        self.pyfile = pyfile        #: Holds thread in future        self.thread = None        #: Captcha stuff        # TODO: Replace in 0.6.x:        # _Captcha = self.pyload.plugin_manager.load_class(""anticaptcha"", self.classname) or BaseCaptcha        # self.captcha = _Captcha(pyfile)        self.captcha = BaseCaptcha(pyfile)        #: Some plugins store html code here        self.data = """"        #: Dict of the amount of retries already made        self.retries = {}        self.init_base()        self.init()",489ddf8f-d685-43e1-ae1f-0b73d3f82d5b
base,hoster.py,_log,102,129,"def _log(self, level, plugintype, pluginname, args, kwargs):        log = getattr(self.pyload.log, level)        #: Hide any user/password        try:            user = self.account.user            hidden_user = ""{:*<{}}"".format(self.account.user[:3], 7)            args = tuple(arg.replace(user, hidden_user) for arg in args if arg)        except (AttributeError, KeyError, TypeError):            pass        try:            pw = self.account.info[""login""][""password""]            hidden_pw = ""*"" * 10            args = tuple(arg.replace(pw, hidden_pw) for arg in args if arg)        except (AttributeError, KeyError, TypeError):            pass        log(            ""{plugintype} {pluginname}[{id}]: {msg}"".format(                plugintype=plugintype.upper(),                pluginname=pluginname,                id=self.pyfile.id,                msg="" | "".join([""%s""] * len(args)),            ),            *args,            **kwargs,        )",,"def _log(self, level, plugintype, pluginname, args, kwargs):        log = getattr(self.pyload.log, level)        #: Hide any user/password        try:            user = self.account.user            hidden_user = ""{:*<{}}"".format(self.account.user[:3], 7)            args = tuple(arg.replace(user, hidden_user) for arg in args if arg)        except (AttributeError, KeyError, TypeError):            pass        try:            pw = self.account.info[""login""][""password""]            hidden_pw = ""*"" * 10            args = tuple(arg.replace(pw, hidden_pw) for arg in args if arg)        except (AttributeError, KeyError, TypeError):            pass        log(            ""{plugintype} {pluginname}[{id}]: {msg}"".format(                plugintype=plugintype.upper(),                pluginname=pluginname,                id=self.pyfile.id,                msg="" | "".join([""%s""] * len(args)),            ),            *args,            **kwargs,        )",efeebba7-9ff6-480c-80b2-f7f9a96e35d7
base,hoster.py,init_base,131,132,def init_base(self):        pass,,def init_base(self):        pass,afd21bfe-4038-47ee-a183-cf565897ee16
base,hoster.py,setup_base,134,135,def setup_base(self):        pass,,def setup_base(self):        pass,87078fe0-b7a5-4b87-a0e6-d6d2ed7c9ecb
base,hoster.py,setup,137,142,def setup(self):                pass,"Setup for enviroment and other things, called before downloading (possibly more
than one time)","def setup(self):        """"""        Setup for enviroment and other things, called before downloading (possibly more        than one time)        """"""        pass

Setup for enviroment and other things, called before downloading (possibly more
than one time)",4165f743-5469-4579-8781-2998f16fc7ce
base,hoster.py,_setup,144,174,"def _setup(self):        # TODO: Remove in 0.6.x        self.pyfile.error = """"        self.data = """"        self.last_html = """"        self.last_header = {}        if self.config.get(""use_premium"", True):            self.load_account()  # TODO: Move to PluginThread in 0.6.x        else:            self.account = False        try:            self.req.close()        except Exception:            pass        if self.account:            self.req = self.pyload.request_factory.get_request(                self.classname, self.account.user            )            # NOTE: Avoid one unnecessary get_info call by `self.account.premium` here            self.premium = self.account.info[""data""][""premium""]        else:            self.req = self.pyload.request_factory.get_request(self.classname)            self.premium = False        self.setup_base()        self.grab_info()        self.setup()        self.check_status()",,"def _setup(self):        # TODO: Remove in 0.6.x        self.pyfile.error = """"        self.data = """"        self.last_html = """"        self.last_header = {}        if self.config.get(""use_premium"", True):            self.load_account()  # TODO: Move to PluginThread in 0.6.x        else:            self.account = False        try:            self.req.close()        except Exception:            pass        if self.account:            self.req = self.pyload.request_factory.get_request(                self.classname, self.account.user            )            # NOTE: Avoid one unnecessary get_info call by `self.account.premium` here            self.premium = self.account.info[""data""][""premium""]        else:            self.req = self.pyload.request_factory.get_request(self.classname)            self.premium = False        self.setup_base()        self.grab_info()        self.setup()        self.check_status()",0ebae568-c011-421e-a7e2-05bcb7cc6092
base,hoster.py,load_account,176,183,def load_account(self):        if self.account is None:            self.account = self.pyload.account_manager.get_account_plugin(                self.classname            )        if self.account:            self.account.choose(),,def load_account(self):        if self.account is None:            self.account = self.pyload.account_manager.get_account_plugin(                self.classname            )        if self.account:            self.account.choose(),8c03d00a-0c67-479d-9b9d-dd5d34e23515
base,hoster.py,_update_name,185,193,"def _update_name(self):        name = self.info.get(""name"")        if name and name != self.info.get(""url""):            self.pyfile.name = name        else:            name = self.pyfile.name        self.log_info(self._(""Link name: {}"").format(name))",,"def _update_name(self):        name = self.info.get(""name"")        if name and name != self.info.get(""url""):            self.pyfile.name = name        else:            name = self.pyfile.name        self.log_info(self._(""Link name: {}"").format(name))",e2e9ac74-b6f9-4b44-ae18-0c4b62c607f1
base,hoster.py,_update_size,195,209,"def _update_size(self):        size = self.info.get(""size"")        if size > 0:            # TODO: Fix int conversion in 0.6.x            self.pyfile.size = int(self.info.get(""size""))        else:            size = self.pyfile.size        if size:            self.log_info(                self._(""Link size: {} ({} bytes)"").format(format.size(size), size)            )        else:            self.log_info(self._(""Link size: N/D""))",,"def _update_size(self):        size = self.info.get(""size"")        if size > 0:            # TODO: Fix int conversion in 0.6.x            self.pyfile.size = int(self.info.get(""size""))        else:            size = self.pyfile.size        if size:            self.log_info(                self._(""Link size: {} ({} bytes)"").format(format.size(size), size)            )        else:            self.log_info(self._(""Link size: N/D""))",0f147e3e-7615-47cb-8bef-3ed764e99bd7
base,hoster.py,_update_status,211,215,"def _update_status(self):        self.pyfile.status = self.info.get(""status"", 14)        self.pyfile.sync()        self.log_info(self._(""Link status: "") + self.pyfile.get_status_name())",,"def _update_status(self):        self.pyfile.status = self.info.get(""status"", 14)        self.pyfile.sync()        self.log_info(self._(""Link status: "") + self.pyfile.get_status_name())",0f339a86-bb06-4903-86a3-b83fa915119b
base,hoster.py,sync_info,217,220,def sync_info(self):        self._update_name()        self._update_size()        self._update_status(),,def sync_info(self):        self._update_name()        self._update_size()        self._update_status(),ee7507f1-828b-46e2-94f6-db0ee03f0ec3
base,hoster.py,grab_info,222,234,"def grab_info(self):        if self.pyfile.status != 2:            self.log_info(self._(""Grabbing link info...""))            old_info = dict(self.info)            new_info = self.get_info(replace_patterns(self.pyfile.url, self.URL_REPLACEMENTS), self.data)            self.info.update(new_info)            self.log_debug(f""Link info: {self.info}"")            self.log_debug(f""Previous link info: {old_info}"")            self.sync_info()",,"def grab_info(self):        if self.pyfile.status != 2:            self.log_info(self._(""Grabbing link info...""))            old_info = dict(self.info)            new_info = self.get_info(replace_patterns(self.pyfile.url, self.URL_REPLACEMENTS), self.data)            self.info.update(new_info)            self.log_debug(f""Link info: {self.info}"")            self.log_debug(f""Previous link info: {old_info}"")            self.sync_info()",0ee57f59-d5be-4555-8f71-84a44951f6fc
base,hoster.py,check_status,236,252,def check_status(self):        status = self.pyfile.status        if status == 1:            self.offline()        elif status == 4:            self.skip(self.pyfile.statusname)        elif status == 6:            self.temp_offline()        elif status == 8:            self.fail()        elif status == 9 or self.pyfile.abort:            self.abort(),,def check_status(self):        status = self.pyfile.status        if status == 1:            self.offline()        elif status == 4:            self.skip(self.pyfile.statusname)        elif status == 6:            self.temp_offline()        elif status == 8:            self.fail()        elif status == 9 or self.pyfile.abort:            self.abort(),66fba934-6b45-4054-a409-2075830fb4d4
base,hoster.py,_initialize,254,262,"def _initialize(self):        self.log_debug(""Plugin version: "" + self.__version__)        self.log_debug(""Plugin status: "" + self.__status__)        if self.__status__ == ""broken"":            self.abort(self._(""Plugin is temporarily unavailable""))        elif self.__status__ == ""testing"":            self.log_warning(self._(""Plugin may be unstable""))",,"def _initialize(self):        self.log_debug(""Plugin version: "" + self.__version__)        self.log_debug(""Plugin status: "" + self.__status__)        if self.__status__ == ""broken"":            self.abort(self._(""Plugin is temporarily unavailable""))        elif self.__status__ == ""testing"":            self.log_warning(self._(""Plugin may be unstable""))",d4ef5b60-8f5b-43ed-a2fd-3c0f85edf1c4
base,hoster.py,_process,264,286,"def _process(self, thread):                self.thread = thread        self._initialize()        self._setup()        # TODO: Enable in 0.6.x        # self.pyload.addon_manager.download_preparing(self.pyfile)        # self.check_status()        # TODO: Remove in 0.6.x        if self.__type__ == ""decrypter"":            self.pyload.addon_manager.download_preparing(self.pyfile)            self.check_status()        self.pyfile.set_status(""starting"")        self.log_info(self._(""Processing url: "") + self.pyfile.url)        self.process(self.pyfile)        self.check_status()",Handles important things to do before starting.,"def _process(self, thread):        """"""        Handles important things to do before starting.        """"""        self.thread = thread        self._initialize()        self._setup()        # TODO: Enable in 0.6.x        # self.pyload.addon_manager.download_preparing(self.pyfile)        # self.check_status()        # TODO: Remove in 0.6.x        if self.__type__ == ""decrypter"":            self.pyload.addon_manager.download_preparing(self.pyfile)            self.check_status()        self.pyfile.set_status(""starting"")        self.log_info(self._(""Processing url: "") + self.pyfile.url)        self.process(self.pyfile)        self.check_status()

Handles important things to do before starting.",467cbb91-a9b8-4977-b9cd-210c9f9a9e89
base,hoster.py,preprocessing,289,291,"def preprocessing(self, *args, **kwargs):        # NOTE: Recheck info thread synchronization in 0.6.x        return self._process(*args, **kwargs)",,"def preprocessing(self, *args, **kwargs):        # NOTE: Recheck info thread synchronization in 0.6.x        return self._process(*args, **kwargs)",8f7f937c-84a9-4917-8e77-47acac76a715
base,hoster.py,process,293,297,"def process(self, pyfile):                raise NotImplementedError","The ""main"" method of every downloader plugin, you **have to** overwrite it.","def process(self, pyfile):        """"""        The ""main"" method of every downloader plugin, you **have to** overwrite it.        """"""        raise NotImplementedError

The ""main"" method of every downloader plugin, you **have to** overwrite it.",974eac17-d4ce-4577-a7ab-866f4b3242d9
base,hoster.py,set_reconnect,299,306,"def set_reconnect(self, reconnect):        if self.pyload.config.get(""reconnect"", ""enabled""):            reconnect = reconnect and self.pyload.api.is_time_reconnect()            self.log_debug(                ""RECONNECT{} required"".format("""" if reconnect else "" not""),                ""Previous want_reconnect: {}"".format(self.want_reconnect),            )            self.want_reconnect = bool(reconnect)",,"def set_reconnect(self, reconnect):        if self.pyload.config.get(""reconnect"", ""enabled""):            reconnect = reconnect and self.pyload.api.is_time_reconnect()            self.log_debug(                ""RECONNECT{} required"".format("""" if reconnect else "" not""),                ""Previous want_reconnect: {}"".format(self.want_reconnect),            )            self.want_reconnect = bool(reconnect)",7defeaa7-e08b-423f-8ecb-c0cd076bebcd
base,hoster.py,set_wait,308,329,"def set_wait(self, seconds, strict=False):                wait_time = float(seconds)        if wait_time < 0:            return False        old_wait_until = self.pyfile.wait_until        new_wait_until = time.time() + wait_time + float(not strict)        self.log_debug(            ""WAIT set to timestamp {}"".format(new_wait_until),            ""Previous wait_until: {}"".format(old_wait_until),        )        self.pyfile.wait_until = new_wait_until        return True","Set a specific wait time later used with wait()

:param seconds: wait time in seconds
:param strict: strict mode","def set_wait(self, seconds, strict=False):        """"""        Set a specific wait time later used with wait()        :param seconds: wait time in seconds        :param strict: strict mode        """"""        wait_time = float(seconds)        if wait_time < 0:            return False        old_wait_until = self.pyfile.wait_until        new_wait_until = time.time() + wait_time + float(not strict)        self.log_debug(            ""WAIT set to timestamp {}"".format(new_wait_until),            ""Previous wait_until: {}"".format(old_wait_until),        )        self.pyfile.wait_until = new_wait_until        return True

Set a specific wait time later used with wait()

:param seconds: wait time in seconds
:param strict: strict mode",4f8559cd-602c-466c-8ec5-ce7f4fd4e32b
base,hoster.py,wait,331,384,"def wait(self, seconds=None, reconnect=None):                if seconds is not None:            self.set_wait(seconds)        wait_time = self.pyfile.wait_until - time.time()        if wait_time < 1:            self.log_warning(self._(""Invalid wait time interval""))            return        if reconnect is None:            reconnect = wait_time > self.config.get(""max_wait"", 10) * 60        self.set_reconnect(reconnect)        self.waiting = True        status = self.pyfile.status  # NOTE: Recheck in 0.6.x        self.pyfile.set_status(""waiting"")        self.log_info(self._(""Waiting {}..."").format(format.time(wait_time)))        if self.want_reconnect:            self.log_info(self._(""Requiring reconnection...""))            if self.account:                self.log_warning(self._(""Reconnection ignored due logged account""))        if not self.want_reconnect or self.account:            while self.pyfile.wait_until > time.time():                self.check_status()                time.sleep(2)        else:            while self.pyfile.wait_until > time.time():                self.check_status()                self.thread.m.reconnecting.wait(1)                if self.thread.m.reconnecting.is_set():                    self.waiting = False                    self.want_reconnect = False                    self.req.clear_cookies()                    raise Reconnect                time.sleep(2)        self.waiting = False        self.pyfile.status = status","Waits the time previously set.

:param seconds: How many seconds to wait or if equals to None then use the value from set_wait()
:param reconnect: True if reconnect would avoid wait time","def wait(self, seconds=None, reconnect=None):        """"""        Waits the time previously set.        :param seconds: How many seconds to wait or if equals to None then use the value from set_wait()        :param reconnect: True if reconnect would avoid wait time        """"""        if seconds is not None:            self.set_wait(seconds)        wait_time = self.pyfile.wait_until - time.time()        if wait_time < 1:            self.log_warning(self._(""Invalid wait time interval""))            return        if reconnect is None:            reconnect = wait_time > self.config.get(""max_wait"", 10) * 60        self.set_reconnect(reconnect)        self.waiting = True        status = self.pyfile.status  # NOTE: Recheck in 0.6.x        self.pyfile.set_status(""waiting"")        self.log_info(self._(""Waiting {}..."").format(format.time(wait_time)))        if self.want_reconnect:            self.log_info(self._(""Requiring reconnection...""))            if self.account:                self.log_warning(self._(""Reconnection ignored due logged account""))        if not self.want_reconnect or self.account:            while self.pyfile.wait_until > time.time():                self.check_status()                time.sleep(2)        else:            while self.pyfile.wait_until > time.time():                self.check_status()                self.thread.m.reconnecting.wait(1)                if self.thread.m.reconnecting.is_set():                    self.waiting = False                    self.want_reconnect = False                    self.req.clear_cookies()                    raise Reconnect                time.sleep(2)        self.waiting = False        self.pyfile.status = status

Waits the time previously set.

:param seconds: How many seconds to wait or if equals to None then use the value from set_wait()
:param reconnect: True if reconnect would avoid wait time",4ebb8054-3a80-4e72-9a57-d82a4167526f
base,hoster.py,skip,386,390,"def skip(self, msg=""""):                raise Skip(msg or self.pyfile.error or self.pyfile.pluginname)",Skip and give msg.,"def skip(self, msg=""""):        """"""        Skip and give msg.        """"""        raise Skip(msg or self.pyfile.error or self.pyfile.pluginname)

Skip and give msg.",710c7d0b-4b49-4340-8644-03a2dae35438
base,hoster.py,fail,393,408,"def fail(self, msg=""""):                msg = msg.strip()        if msg:            self.pyfile.error = msg        else:            msg = (                self.pyfile.error                or self.info.get(""error"")                or self.pyfile.get_status_name()            )        raise Fail(msg)",Fail and give msg.,"def fail(self, msg=""""):        """"""        Fail and give msg.        """"""        msg = msg.strip()        if msg:            self.pyfile.error = msg        else:            msg = (                self.pyfile.error                or self.info.get(""error"")                or self.pyfile.get_status_name()            )        raise Fail(msg)

Fail and give msg.",06248c2c-704c-49d4-b17d-0c536ba0ef50
base,hoster.py,error,410,418,"def error(self, msg="""", type=""Parse""):        type = self._(""{} error"").format(            type.strip().capitalize() if type else self._(""Unknown"")        )        msg = self._(""{type}: {msg} | Plugin may be out of date"").format(            type=type, msg=msg or self.pyfile.error        )        self.fail(msg)",,"def error(self, msg="""", type=""Parse""):        type = self._(""{} error"").format(            type.strip().capitalize() if type else self._(""Unknown"")        )        msg = self._(""{type}: {msg} | Plugin may be out of date"").format(            type=type, msg=msg or self.pyfile.error        )        self.fail(msg)",02e40fd0-655b-43df-b2c6-84a6cbbb40ea
base,hoster.py,abort,420,427,"def abort(self, msg=""""):                if msg:  # TODO: Remove in 0.6.x            self.pyfile.error = msg        raise Abort",Abort and give msg.,"def abort(self, msg=""""):        """"""        Abort and give msg.        """"""        if msg:  # TODO: Remove in 0.6.x            self.pyfile.error = msg        raise Abort

Abort and give msg.",4988fc58-82c9-4ea7-83ef-757b1860a4f3
base,hoster.py,offline,430,434,"def offline(self, msg=""""):                self.fail(""offline"")",Fail and indicate file is offline.,"def offline(self, msg=""""):        """"""        Fail and indicate file is offline.        """"""        self.fail(""offline"")

Fail and indicate file is offline.",ccfbe5c0-7690-47e5-86cb-a4255995ff91
base,hoster.py,temp_offline,437,441,"def temp_offline(self, msg=""""):                self.fail(""temp. offline"")","Fail and indicates file ist temporary offline, the core may take consequences.","def temp_offline(self, msg=""""):        """"""        Fail and indicates file ist temporary offline, the core may take consequences.        """"""        self.fail(""temp. offline"")

Fail and indicates file ist temporary offline, the core may take consequences.",385b75cc-cf37-47f4-bccf-306bd364fcc2
base,hoster.py,restart,443,459,"def restart(self, msg="""", premium=True):        if not msg:            msg = (                self._(""Restart plugin"")                if premium                else self._(""Fallback to free processing"")            )        if not premium:            if self.premium:                self.restart_free = True            else:                self.fail(                    ""{} | {}"".format(msg, self._(""Url was already processed as free""))                )        raise Retry(msg)",,"def restart(self, msg="""", premium=True):        if not msg:            msg = (                self._(""Restart plugin"")                if premium                else self._(""Fallback to free processing"")            )        if not premium:            if self.premium:                self.restart_free = True            else:                self.fail(                    ""{} | {}"".format(msg, self._(""Url was already processed as free""))                )        raise Retry(msg)",ec7a6357-57a7-44cf-8fe1-f1eb4ea51beb
base,hoster.py,retry,461,487,"def retry(self, attempts=5, wait=1, msg="""", msgfail=""Max retries reached""):                frame = inspect.currentframe()        try:            id = frame.f_back.f_lineno        finally:            del frame  #: Delete the frame or it won't be cleaned        if id not in self.retries:            self.retries[id] = 0        if 0 < attempts <= self.retries[id]:            self.fail(msgfail)        self.retries[id] += 1        self.wait(wait)        raise Retry(msg)","Retries and begin again from the beginning.

:param attempts: number of maximum retries
:param wait: time to wait in seconds before retry
:param msg: message to pass to retry if attempts value was not yet reached
:param msgfail: message passed to fail if attempts value was reached","def retry(self, attempts=5, wait=1, msg="""", msgfail=""Max retries reached""):        """"""        Retries and begin again from the beginning.        :param attempts: number of maximum retries        :param wait: time to wait in seconds before retry        :param msg: message to pass to retry if attempts value was not yet reached        :param msgfail: message passed to fail if attempts value was reached        """"""        frame = inspect.currentframe()        try:            id = frame.f_back.f_lineno        finally:            del frame  #: Delete the frame or it won't be cleaned        if id not in self.retries:            self.retries[id] = 0        if 0 < attempts <= self.retries[id]:            self.fail(msgfail)        self.retries[id] += 1        self.wait(wait)        raise Retry(msg)

Retries and begin again from the beginning.

:param attempts: number of maximum retries
:param wait: time to wait in seconds before retry
:param msg: message to pass to retry if attempts value was not yet reached
:param msgfail: message passed to fail if attempts value was reached",a42e8ec8-e879-4a4c-958f-307b88e91a88
base,hoster.py,retry_captcha,489,493,"def retry_captcha(        self, attempts=10, wait=1, msg="""", msgfail=""Max captcha retries reached""    ):        self.captcha.invalid(msg)        self.retry(attempts, wait, msg=self._(""Retry Captcha""), msgfail=msgfail)",,"def retry_captcha(        self, attempts=10, wait=1, msg="""", msgfail=""Max captcha retries reached""    ):        self.captcha.invalid(msg)        self.retry(attempts, wait, msg=self._(""Retry Captcha""), msgfail=msgfail)",522baace-0d1f-4a72-8f7b-b2e183518c9f
base,hoster.py,fixurl,495,502,"def fixurl(self, url, baseurl=None):        baseurl = baseurl or self.pyfile.url        if not urllib.parse.urlparse(url).scheme:            url_p = urllib.parse.urlparse(baseurl)            baseurl = ""{}://{}"".format(url_p.scheme, url_p.netloc)            url = urllib.parse.urljoin(baseurl, url)        return url",,"def fixurl(self, url, baseurl=None):        baseurl = baseurl or self.pyfile.url        if not urllib.parse.urlparse(url).scheme:            url_p = urllib.parse.urlparse(baseurl)            baseurl = ""{}://{}"".format(url_p.scheme, url_p.netloc)            url = urllib.parse.urljoin(baseurl, url)        return url",c1d3c42b-48db-4811-8158-0007e007d11e
base,hoster.py,load,504,506,"def load(self, *args, **kwargs):        self.check_status()        return super().load(*args, **kwargs)",,"def load(self, *args, **kwargs):        self.check_status()        return super().load(*args, **kwargs)",0d7799f1-262e-4bb5-9d27-f8b8b3842bc1
base,hoster.py,parse_html_form,508,509,"def parse_html_form(self, attr_str="""", input_names={}):        return parse_html_form(attr_str, self.data, input_names)",,"def parse_html_form(self, attr_str="""", input_names={}):        return parse_html_form(attr_str, self.data, input_names)",58227a70-c21e-4fe1-9c2f-a20ac568cbd4
base,hoster.py,get_password,511,515,"def get_password(self):                return self.pyfile.package().password or """"",Get the password the user provided in the package.,"def get_password(self):        """"""        Get the password the user provided in the package.        """"""        return self.pyfile.package().password or """"

Get the password the user provided in the package.",a2e0ed62-654b-44f9-a15c-ddbf66cf99b2
base,hoster.py,clean,517,524,"def clean(self):                super().clean()        for attr in (""account"", ""html"", ""pyfile"", ""thread""):            if hasattr(self, attr):                setattr(self, attr, None)",Clean everything and remove references.,"def clean(self):        """"""        Clean everything and remove references.        """"""        super().clean()        for attr in (""account"", ""html"", ""pyfile"", ""thread""):            if hasattr(self, attr):                setattr(self, attr, None)

Clean everything and remove references.",74da3004-da98-4465-8ebe-a230c078b82b
base,multi_account.py,init,63,75,def init(self):        self.need_reactivate = False        self.plugins = []        self.supported = []        self.pluginclass = None        self.pluginmodule = None        self.plugintype = None        self.fail_count = 0        self.init_plugin(),,def init(self):        self.need_reactivate = False        self.plugins = []        self.supported = []        self.pluginclass = None        self.pluginmodule = None        self.plugintype = None        self.fail_count = 0        self.init_plugin(),a9ec794f-8b2d-48c3-946f-a34f0b563120
base,multi_account.py,init_plugin,77,97,"def init_plugin(self):        plugin, self.plugintype = self.pyload.plugin_manager.find_plugin(self.classname)        if plugin:            self.pluginmodule = self.pyload.plugin_manager.load_module(                self.plugintype, self.classname            )            self.pluginclass = self.pyload.plugin_manager.load_class(                self.plugintype, self.classname            )            self.pyload.addon_manager.add_event(""plugin_updated"", self.plugins_updated)            self.periodical.start(3, threaded=True)        else:            self.log_warning(                self._(                    ""Multi-downloader feature will be deactivated due missing plugin reference""                )            )",,"def init_plugin(self):        plugin, self.plugintype = self.pyload.plugin_manager.find_plugin(self.classname)        if plugin:            self.pluginmodule = self.pyload.plugin_manager.load_module(                self.plugintype, self.classname            )            self.pluginclass = self.pyload.plugin_manager.load_class(                self.plugintype, self.classname            )            self.pyload.addon_manager.add_event(""plugin_updated"", self.plugins_updated)            self.periodical.start(3, threaded=True)        else:            self.log_warning(                self._(                    ""Multi-downloader feature will be deactivated due missing plugin reference""                )            )",8a87143b-8c69-4893-abcb-1b6829e2eb95
base,multi_account.py,plugins_updated,99,103,"def plugins_updated(self, type_plugins):        if not any(            t in (""base"", ""addon"") for t, n in type_plugins        ):  #: do nothing if restart required            self.reactivate()",,"def plugins_updated(self, type_plugins):        if not any(            t in (""base"", ""addon"") for t, n in type_plugins        ):  #: do nothing if restart required            self.reactivate()",00380091-d841-4aac-99cc-c5e7af8184a7
base,multi_account.py,periodical_task,105,106,def periodical_task(self):        self.reactivate(refresh=True),,def periodical_task(self):        self.reactivate(refresh=True),c0adb999-a0f2-4eaa-ad66-7115d5743f54
base,multi_account.py,replace_domains,108,117,"def replace_domains(self, list):        for r in self.DOMAIN_REPLACEMENTS:            pattern, repl = r            _re = re.compile(pattern, re.I | re.U)            list = [                _re.sub(repl, domain) if _re.match(domain) else domain                for domain in list            ]        return list",,"def replace_domains(self, list):        for r in self.DOMAIN_REPLACEMENTS:            pattern, repl = r            _re = re.compile(pattern, re.I | re.U)            list = [                _re.sub(repl, domain) if _re.match(domain) else domain                for domain in list            ]        return list",432efb06-d492-445b-b6ce-343e6ecdd1db
base,multi_account.py,parse_domains,119,131,"def parse_domains(self, list):        _re = re.compile(            r""^(?:https?://)?(?:www\.)?(?:\w+\.)*((?:(?:\d{1,3}\.){3}\d{1,3}|[\w\-^_]{3,63}(?:\.[a-zA-Z]{2,}){1,2})(?:\:\d+)?)"",            re.I | re.U,        )        domains = [            domain.strip().lower()            for url in list            for domain in _re.findall(url)        ]        return self.replace_domains(uniquify(domains))",,"def parse_domains(self, list):        _re = re.compile(            r""^(?:https?://)?(?:www\.)?(?:\w+\.)*((?:(?:\d{1,3}\.){3}\d{1,3}|[\w\-^_]{3,63}(?:\.[a-zA-Z]{2,}){1,2})(?:\:\d+)?)"",            re.I | re.U,        )        domains = [            domain.strip().lower()            for url in list            for domain in _re.findall(url)        ]        return self.replace_domains(uniquify(domains))",b3c27965-63c5-41f0-ab52-92f24141472e
base,multi_account.py,_grab_hosters,133,159,"def _grab_hosters(self):        self.info[""data""][""hosters""] = []        try:            hosterlist = self.grab_hosters(                self.user, self.info[""login""][""password""], self.info[""data""]            )            if hosterlist and isinstance(hosterlist, list):                domains = self.parse_domains(hosterlist)                self.info[""data""][""hosters""] = sorted(domains)                self.sync(reverse=True)        except Exception as exc:            self.log_warning(                self._(""Error loading downloader list for user `{}`"").format(self.user),                exc,                exc_info=self.pyload.debug > 1,                stack_info=self.pyload.debug > 2,            )        finally:            self.log_debug(                ""Downloader list for user `{}`: {}"".format(                    self.user, self.info[""data""][""hosters""]                )            )            return self.info[""data""][""hosters""]",,"def _grab_hosters(self):        self.info[""data""][""hosters""] = []        try:            hosterlist = self.grab_hosters(                self.user, self.info[""login""][""password""], self.info[""data""]            )            if hosterlist and isinstance(hosterlist, list):                domains = self.parse_domains(hosterlist)                self.info[""data""][""hosters""] = sorted(domains)                self.sync(reverse=True)        except Exception as exc:            self.log_warning(                self._(""Error loading downloader list for user `{}`"").format(self.user),                exc,                exc_info=self.pyload.debug > 1,                stack_info=self.pyload.debug > 2,            )        finally:            self.log_debug(                ""Downloader list for user `{}`: {}"".format(                    self.user, self.info[""data""][""hosters""]                )            )            return self.info[""data""][""hosters""]",9c61a993-108f-4faf-a7f0-067946fd68e9
base,multi_account.py,grab_hosters,161,167,"def grab_hosters(self, user, password, data):                raise NotImplementedError","Load list of supported downloaders.

:return: List of domain names","def grab_hosters(self, user, password, data):        """"""        Load list of supported downloaders.        :return: List of domain names        """"""        raise NotImplementedError

Load list of supported downloaders.

:return: List of domain names",e62806f9-f7df-46f9-b806-3e6189a9c238
base,multi_account.py,_override,169,256,"def _override(self):        prev_supported = self.supported        new_supported = []        excluded = []        self.supported = []        if self.plugintype == ""downloader"":            plugin_map = {                name.lower(): name                for name in self.pyload.plugin_manager.downloader_plugins.keys()            }            account_list = [                account.type.lower()                for account in self.pyload.api.get_accounts(False)                if account.valid and account.premium            ]        else:            plugin_map = {}            account_list = [                name[::-1].replace(""Folder""[::-1], """", 1).lower()[::-1]                for name in self.pyload.plugin_manager.decrypter_plugins.keys()            ]        for plugin in self.get_plugins():            name = remove_chars(plugin, ""-."")            if name in account_list:                excluded.append(plugin)            else:                if name in plugin_map:                    self.supported.append(plugin_map[name])                else:                    new_supported.append(plugin)        removed = [plugin for plugin in prev_supported if plugin not in self.supported]        if removed:            self.log_debug(f""Unload: {', '.join(removed)}"")            for plugin in removed:                self.unload_plugin(plugin)        if not self.supported and not new_supported:            self.log_error(self._(""No {} loaded"").format(self.plugintype))            return        #: Inject plugin plugin        self.log_debug(            ""Overwritten {}s: {}"".format(                self.plugintype, "", "".join(sorted(self.supported))            )        )        for plugin in self.supported:            hdict = self.pyload.plugin_manager.plugins[self.plugintype][plugin]            hdict[""new_module""] = self.pluginmodule            hdict[""new_name""] = self.classname        if excluded:            self.log_info(                self._(""{}s not overwritten: {}"").format(                    self.plugintype.capitalize(), "", "".join(sorted(excluded))                )            )        if new_supported:            plugins = sorted(new_supported)            self.log_debug(f""New {self.plugintype}s: {', '.join(plugins)}"")            #: Create new regexp            domains = ""|"".join(x.replace(""."", r""\."") for x in plugins)            pattern = rf"".*(?P<DOMAIN>{domains}).*""            if (                hasattr(self.pluginclass, ""__pattern__"")                and isinstance(self.pluginclass.__pattern__, str)                and ""://"" in self.pluginclass.__pattern__            ):                pattern = rf""{self.pluginclass.__pattern__}|{pattern}""            self.log_debug(f""Pattern: {pattern}"")            hdict = self.pyload.plugin_manager.plugins[self.plugintype][self.classname]            hdict[""pattern""] = pattern            hdict[""re""] = re.compile(pattern)",,"def _override(self):        prev_supported = self.supported        new_supported = []        excluded = []        self.supported = []        if self.plugintype == ""downloader"":            plugin_map = {                name.lower(): name                for name in self.pyload.plugin_manager.downloader_plugins.keys()            }            account_list = [                account.type.lower()                for account in self.pyload.api.get_accounts(False)                if account.valid and account.premium            ]        else:            plugin_map = {}            account_list = [                name[::-1].replace(""Folder""[::-1], """", 1).lower()[::-1]                for name in self.pyload.plugin_manager.decrypter_plugins.keys()            ]        for plugin in self.get_plugins():            name = remove_chars(plugin, ""-."")            if name in account_list:                excluded.append(plugin)            else:                if name in plugin_map:                    self.supported.append(plugin_map[name])                else:                    new_supported.append(plugin)        removed = [plugin for plugin in prev_supported if plugin not in self.supported]        if removed:            self.log_debug(f""Unload: {', '.join(removed)}"")            for plugin in removed:                self.unload_plugin(plugin)        if not self.supported and not new_supported:            self.log_error(self._(""No {} loaded"").format(self.plugintype))            return        #: Inject plugin plugin        self.log_debug(            ""Overwritten {}s: {}"".format(                self.plugintype, "", "".join(sorted(self.supported))            )        )        for plugin in self.supported:            hdict = self.pyload.plugin_manager.plugins[self.plugintype][plugin]            hdict[""new_module""] = self.pluginmodule            hdict[""new_name""] = self.classname        if excluded:            self.log_info(                self._(""{}s not overwritten: {}"").format(                    self.plugintype.capitalize(), "", "".join(sorted(excluded))                )            )        if new_supported:            plugins = sorted(new_supported)            self.log_debug(f""New {self.plugintype}s: {', '.join(plugins)}"")            #: Create new regexp            domains = ""|"".join(x.replace(""."", r""\."") for x in plugins)            pattern = rf"".*(?P<DOMAIN>{domains}).*""            if (                hasattr(self.pluginclass, ""__pattern__"")                and isinstance(self.pluginclass.__pattern__, str)                and ""://"" in self.pluginclass.__pattern__            ):                pattern = rf""{self.pluginclass.__pattern__}|{pattern}""            self.log_debug(f""Pattern: {pattern}"")            hdict = self.pyload.plugin_manager.plugins[self.plugintype][self.classname]            hdict[""pattern""] = pattern            hdict[""re""] = re.compile(pattern)",ac04b046-f478-4537-a32f-5d9e6f03c1a5
base,multi_account.py,get_plugins,258,302,"def get_plugins(self, cached=True):        if cached and self.plugins:            return self.plugins        for _ in range(5):            try:                plugin_set = set(self._grab_hosters())                break            except Exception as exc:                self.log_warning(                    exc,                    self._(""Waiting 1 minute and retry""),                    exc_info=self.pyload.debug > 1,                    stack_info=self.pyload.debug > 2,                )                time.sleep(60)        else:            self.log_warning(self._(""No hoster list retrieved""))            return []        try:            mh_mode = self.config.get(""mh_mode"", ""all"")            if mh_mode in (""listed"", ""unlisted""):                mh_list = (                    self.config.get(""mh_list"", """")                    .replace(""|"", "","")                    .replace("";"", "","")                    .split("","")                )                config_set = set(mh_list)                if mh_mode == ""listed"":                    plugin_set &= config_set                else:                    plugin_set -= config_set        except Exception as exc:            self.log_error(exc)        self.plugins = list(plugin_set)        return self.plugins",,"def get_plugins(self, cached=True):        if cached and self.plugins:            return self.plugins        for _ in range(5):            try:                plugin_set = set(self._grab_hosters())                break            except Exception as exc:                self.log_warning(                    exc,                    self._(""Waiting 1 minute and retry""),                    exc_info=self.pyload.debug > 1,                    stack_info=self.pyload.debug > 2,                )                time.sleep(60)        else:            self.log_warning(self._(""No hoster list retrieved""))            return []        try:            mh_mode = self.config.get(""mh_mode"", ""all"")            if mh_mode in (""listed"", ""unlisted""):                mh_list = (                    self.config.get(""mh_list"", """")                    .replace(""|"", "","")                    .replace("";"", "","")                    .split("","")                )                config_set = set(mh_list)                if mh_mode == ""listed"":                    plugin_set &= config_set                else:                    plugin_set -= config_set        except Exception as exc:            self.log_error(exc)        self.plugins = list(plugin_set)        return self.plugins",8cdad501-aca2-42b0-9c63-7c10275dbbef
base,multi_account.py,unload_plugin,304,312,"def unload_plugin(self, plugin):        #: Reset module        hdict = self.pyload.plugin_manager.plugins[self.plugintype][plugin]        if ""pyload"" in hdict:            hdict.pop(""pyload"", None)        if ""new_module"" in hdict:            hdict.pop(""new_module"", None)            hdict.pop(""new_name"", None)",,"def unload_plugin(self, plugin):        #: Reset module        hdict = self.pyload.plugin_manager.plugins[self.plugintype][plugin]        if ""pyload"" in hdict:            hdict.pop(""pyload"", None)        if ""new_module"" in hdict:            hdict.pop(""new_module"", None)            hdict.pop(""new_name"", None)",971af130-06f7-4c79-bf98-e2d986077ee2
base,multi_account.py,reactivate,314,430,"def reactivate(self, refresh=False):        reloading = self.info[""data""].get(""hosters"") is not None        if self.info['login']['valid'] is None:            return        else:            interval = self.config.get('mh_interval', 12) * 60 * 60            self.periodical.set_interval(interval)        if self.info['login']['valid'] is False:            self.fail_count += 1            if self.fail_count < 3:                if reloading:                    self.log_error(                        self._(                            ""Could not reload hoster list - invalid account, retry in 5 minutes""                        )                    )                else:                    self.log_error(                        self._(                            ""Could not load hoster list - invalid account, retry in 5 minutes""                        )                    )                self.periodical.set_interval(timedelta(minutes=5).total_seconds())            else:                if reloading:                    self.log_error(                        self._(                            ""Could not reload hoster list - invalid account, deactivating""                        )                    )                else:                    self.log_error(                        self._(                            ""Could not load hoster list - invalid account, deactivating""                        )                    )                self.deactivate()            return        if not self.logged:            if not self.relogin():                self.fail_count += 1                if self.fail_count < 3:                    if reloading:                        self.log_error(                            self._(                                ""Could not reload hoster list - login failed, retry in 5 minutes""                            )                        )                    else:                        self.log_error(                            self._(                                ""Could not load hoster list - login failed, retry in 5 minutes""                            )                        )                    self.periodical.set_interval(timedelta(minutes=5).total_seconds())                else:                    if reloading:                        self.log_error(                            self._(                                ""Could not reload hoster list - login failed, deactivating""                            )                        )                    else:                        self.log_error(                            self._(                                ""Could not load hoster list - login failed, deactivating""                            )                        )                    self.deactivate()                return        self.pyload.addon_manager.add_event(""plugin_updated"", self.plugins_updated)        if refresh or not reloading:            if not self.get_plugins(cached=False):                self.fail_count += 1                if self.fail_count < 3:                    self.log_error(                        self._(                            ""Failed to load hoster list for user `{}`, retry in 5 minutes""                        ).format(self.user)                    )                    self.periodical.set_interval(timedelta(minutes=5).total_seconds())                else:                    self.log_error(                        self._(                            ""Failed to load hoster list for user `{}`, deactivating""                        ).format(self.user)                    )                    self.deactivate()                return        if self.fail_count:            self.fail_count = 0            interval = timedelta(hours=self.config.get(""mh_interval"", 12)).total_seconds()            self.periodical.set_interval(interval)        self._override()",,"def reactivate(self, refresh=False):        reloading = self.info[""data""].get(""hosters"") is not None        if self.info['login']['valid'] is None:            return        else:            interval = self.config.get('mh_interval', 12) * 60 * 60            self.periodical.set_interval(interval)        if self.info['login']['valid'] is False:            self.fail_count += 1            if self.fail_count < 3:                if reloading:                    self.log_error(                        self._(                            ""Could not reload hoster list - invalid account, retry in 5 minutes""                        )                    )                else:                    self.log_error(                        self._(                            ""Could not load hoster list - invalid account, retry in 5 minutes""                        )                    )                self.periodical.set_interval(timedelta(minutes=5).total_seconds())            else:                if reloading:                    self.log_error(                        self._(                            ""Could not reload hoster list - invalid account, deactivating""                        )                    )                else:                    self.log_error(                        self._(                            ""Could not load hoster list - invalid account, deactivating""                        )                    )                self.deactivate()            return        if not self.logged:            if not self.relogin():                self.fail_count += 1                if self.fail_count < 3:                    if reloading:                        self.log_error(                            self._(                                ""Could not reload hoster list - login failed, retry in 5 minutes""                            )                        )                    else:                        self.log_error(                            self._(                                ""Could not load hoster list - login failed, retry in 5 minutes""                            )                        )                    self.periodical.set_interval(timedelta(minutes=5).total_seconds())                else:                    if reloading:                        self.log_error(                            self._(                                ""Could not reload hoster list - login failed, deactivating""                            )                        )                    else:                        self.log_error(                            self._(                                ""Could not load hoster list - login failed, deactivating""                            )                        )                    self.deactivate()                return        self.pyload.addon_manager.add_event(""plugin_updated"", self.plugins_updated)        if refresh or not reloading:            if not self.get_plugins(cached=False):                self.fail_count += 1                if self.fail_count < 3:                    self.log_error(                        self._(                            ""Failed to load hoster list for user `{}`, retry in 5 minutes""                        ).format(self.user)                    )                    self.periodical.set_interval(timedelta(minutes=5).total_seconds())                else:                    self.log_error(                        self._(                            ""Failed to load hoster list for user `{}`, deactivating""                        ).format(self.user)                    )                    self.deactivate()                return        if self.fail_count:            self.fail_count = 0            interval = timedelta(hours=self.config.get(""mh_interval"", 12)).total_seconds()            self.periodical.set_interval(interval)        self._override()",b0e82102-5523-44c0-946d-3ee40e7738c1
base,multi_account.py,deactivate,432,455,"def deactivate(self):                self.log_info(self._(""Reverting back to default hosters""))        self.pyload.addon_manager.remove_event(            ""plugin_updated"", self.plugins_updated        )        self.periodical.stop()        self.fail_count = 0        if self.supported:            self.log_debug(f""Unload: {', '.join(self.supported)}"")            for plugin in self.supported:                self.unload_plugin(plugin)        #: Reset pattern        hdict = self.pyload.plugin_manager.plugins[self.plugintype][self.classname]        hdict[""pattern""] = getattr(self.pluginclass, ""__pattern__"", r""^unmatchable$"")        hdict[""re""] = re.compile(hdict[""pattern""])",Remove override for all plugins.,"def deactivate(self):        """"""        Remove override for all plugins.        """"""        self.log_info(self._(""Reverting back to default hosters""))        self.pyload.addon_manager.remove_event(            ""plugin_updated"", self.plugins_updated        )        self.periodical.stop()        self.fail_count = 0        if self.supported:            self.log_debug(f""Unload: {', '.join(self.supported)}"")            for plugin in self.supported:                self.unload_plugin(plugin)        #: Reset pattern        hdict = self.pyload.plugin_manager.plugins[self.plugintype][self.classname]        hdict[""pattern""] = getattr(self.pluginclass, ""__pattern__"", r""^unmatchable$"")        hdict[""re""] = re.compile(hdict[""pattern""])

Remove override for all plugins.",71a99c98-728b-48ad-831a-743ba963458c
base,multi_account.py,update_accounts,457,463,"def update_accounts(self, user, password=None, options={}):        super().update_accounts(user, password, options)        if self.need_reactivate:            interval = timedelta(hours=self.config.get(""mh_interval"", 12)).total_seconds()            self.periodical.restart(interval, threaded=True, delay=2)        self.need_reactivate = True",,"def update_accounts(self, user, password=None, options={}):        super().update_accounts(user, password, options)        if self.need_reactivate:            interval = timedelta(hours=self.config.get(""mh_interval"", 12)).total_seconds()            self.periodical.restart(interval, threaded=True, delay=2)        self.need_reactivate = True",c12f9e9c-2b71-4da0-aef6-d8cc6be92c4c
base,multi_account.py,remove_account,465,467,"def remove_account(self, user):        self.deactivate()        super().remove_account(user)",,"def remove_account(self, user):        self.deactivate()        super().remove_account(user)",a3b60713-162e-482d-bf7c-49f8e480a399
base,multi_decrypter.py,init,28,31,"def init(self):        self.PLUGIN_NAME = self.pyload.plugin_manager.decrypter_plugins.get(            self.classname        )[""name""]",,"def init(self):        self.PLUGIN_NAME = self.pyload.plugin_manager.decrypter_plugins.get(            self.classname        )[""name""]",fd50989e-c34e-443a-a0f1-caf4636c80fe
base,multi_decrypter.py,_log,33,35,"def _log(self, level, plugintype, pluginname, args, kwargs):        args = (self.PLUGIN_NAME,) + args        return super()._log(level, plugintype, pluginname, args, kwargs)",,"def _log(self, level, plugintype, pluginname, args, kwargs):        args = (self.PLUGIN_NAME,) + args        return super()._log(level, plugintype, pluginname, args, kwargs)",23bea781-6ad0-474e-8c70-e07bacc2362c
base,multi_downloader.py,get_info,38,39,"def get_info(self, url="""", html=""""):        return super(SimpleDownloader, self).get_info(url, html)",,"def get_info(self, url="""", html=""""):        return super(SimpleDownloader, self).get_info(url, html)",36e4caa6-d617-431c-bc79-a1769fe01a5a
base,multi_downloader.py,init,41,44,"def init(self):        self.PLUGIN_NAME = self.pyload.plugin_manager.downloader_plugins.get(            self.classname        )[""name""]",,"def init(self):        self.PLUGIN_NAME = self.pyload.plugin_manager.downloader_plugins.get(            self.classname        )[""name""]",a4c7f665-3173-43cd-94f5-c4ce2690c6b4
base,multi_downloader.py,_log,46,48,"def _log(self, level, plugintype, pluginname, args, kwargs):        args = (self.PLUGIN_NAME,) + args        return super()._log(level, plugintype, pluginname, args, kwargs)",,"def _log(self, level, plugintype, pluginname, args, kwargs):        args = (self.PLUGIN_NAME,) + args        return super()._log(level, plugintype, pluginname, args, kwargs)",d34c8ce4-0bb8-41e9-ab18-13b8bc188667
base,multi_downloader.py,setup,50,54,def setup(self):        self.no_fallback = True        self.chunk_limit = 1        self.multi_dl = bool(self.account)        self.resume_download = self.premium,,def setup(self):        self.no_fallback = True        self.chunk_limit = 1        self.multi_dl = bool(self.account)        self.resume_download = self.premium,99e4927f-658e-4c32-9413-74292e7b305e
base,multi_downloader.py,_preload,56,57,def _preload(self):        pass,,def _preload(self):        pass,fcacd36c-7938-49e2-8892-4422c4e1bdaa
base,multi_downloader.py,_prepare,59,73,"def _prepare(self):        super()._prepare()        if self.pyfile.pluginname != self.__name__:            overwritten_plugin = self.pyload.plugin_manager.load_class(""downloader"", self.pyfile.pluginname)            if overwritten_plugin is not None:                self.pyfile.url = replace_patterns(self.pyfile.url, overwritten_plugin.URL_REPLACEMENTS)        if self.DIRECT_LINK is None:            self.direct_dl = self.__pattern__ != r'^unmatchable$' and re.match(                self.__pattern__, self.pyfile.url            ) is not None        else:            self.direct_dl = self.DIRECT_LINK",,"def _prepare(self):        super()._prepare()        if self.pyfile.pluginname != self.__name__:            overwritten_plugin = self.pyload.plugin_manager.load_class(""downloader"", self.pyfile.pluginname)            if overwritten_plugin is not None:                self.pyfile.url = replace_patterns(self.pyfile.url, overwritten_plugin.URL_REPLACEMENTS)        if self.DIRECT_LINK is None:            self.direct_dl = self.__pattern__ != r'^unmatchable$' and re.match(                self.__pattern__, self.pyfile.url            ) is not None        else:            self.direct_dl = self.DIRECT_LINK",fce18d53-f422-4214-8379-9876b57cafd9
base,multi_downloader.py,_process,75,96,"def _process(self, thread):        try:            super()._process(thread)        except Fail as exc:            hdict = self.pyload.plugin_manager.downloader_plugins.get(                self.pyfile.pluginname, {}            )            if self.config.get(""revert_failed"", True) and hdict.get(""new_module""):                tmp_module = hdict.pop(""new_module"", None)                tmp_name = hdict.pop(""new_name"", None)                self.pyfile.plugin = None                self.pyfile.init_plugin()                hdict[""new_module""] = tmp_module                hdict[""new_name""] = tmp_name                self.restart(self._(""Revert to original downloader plugin""))            else:                raise",,"def _process(self, thread):        try:            super()._process(thread)        except Fail as exc:            hdict = self.pyload.plugin_manager.downloader_plugins.get(                self.pyfile.pluginname, {}            )            if self.config.get(""revert_failed"", True) and hdict.get(""new_module""):                tmp_module = hdict.pop(""new_module"", None)                tmp_name = hdict.pop(""new_name"", None)                self.pyfile.plugin = None                self.pyfile.init_plugin()                hdict[""new_module""] = tmp_module                hdict[""new_name""] = tmp_name                self.restart(self._(""Revert to original downloader plugin""))            else:                raise",2af6bd5c-4bc5-4360-87a2-a94c944b32ef
base,multi_downloader.py,handle_premium,98,99,"def handle_premium(self, pyfile):        return self.handle_free(pyfile)",,"def handle_premium(self, pyfile):        return self.handle_free(pyfile)",7efa5c15-0271-480b-a0c9-8ae4914fcfc6
base,multi_downloader.py,handle_free,101,106,"def handle_free(self, pyfile):        if self.premium:            raise NotImplementedError        else:            self.fail(self._(""MultiDownloader download failed""))",,"def handle_free(self, pyfile):        if self.premium:            raise NotImplementedError        else:            self.fail(self._(""MultiDownloader download failed""))",a67a39ad-030f-411b-b436-84cb2b799ebc
base,notifier.py,init,36,43,"def init(self):        self.event_map = {            ""all_downloads_processed"": ""all_downloads_processed"",            ""pyload_updated"": ""pyload_updated"",        }        self.last_notify = 0        self.notifications = 0",,"def init(self):        self.event_map = {            ""all_downloads_processed"": ""all_downloads_processed"",            ""pyload_updated"": ""pyload_updated"",        }        self.last_notify = 0        self.notifications = 0",f3d9a6f9-a58b-4358-9f34-e5c015dfc8d3
base,notifier.py,get_key,45,46,def get_key(self):        raise NotImplementedError,,def get_key(self):        raise NotImplementedError,b745fdd2-0ade-4f35-9e4e-520659555960
base,notifier.py,send,48,49,"def send(self, event, msg, key):        raise NotImplementedError",,"def send(self, event, msg, key):        raise NotImplementedError",17cf071f-89d7-4d72-9bf8-7fe38f9de447
base,notifier.py,pyload_updated,51,55,"def pyload_updated(self, etag):        if not self.config.get(""update"", True):            return        self.notify(self._(""pyLoad updated""), etag)",,"def pyload_updated(self, etag):        if not self.config.get(""update"", True):            return        self.notify(self._(""pyLoad updated""), etag)",49927c28-1199-4bf3-9fa9-8adb6a9c0720
base,notifier.py,exit,57,64,"def exit(self):        if not self.config.get(""exit"", True):            return        if self.pyload._do_restart:            self.notify(self._(""Restarting pyLoad""))        else:            self.notify(self._(""Exiting pyLoad""))",,"def exit(self):        if not self.config.get(""exit"", True):            return        if self.pyload._do_restart:            self.notify(self._(""Restarting pyLoad""))        else:            self.notify(self._(""Exiting pyLoad""))",27f25f6b-dddc-4790-ba9e-cde47f52027b
base,notifier.py,captcha_task,66,70,"def captcha_task(self, task):        if not self.config.get(""captcha"", True):            return        self.notify(self._(""Captcha""), self._(""New request waiting user input""))",,"def captcha_task(self, task):        if not self.config.get(""captcha"", True):            return        self.notify(self._(""Captcha""), self._(""New request waiting user input""))",bfceb2a0-58ee-4933-bf62-0d0f12679ab0
base,notifier.py,before_reconnect,72,76,"def before_reconnect(self, ip):        if not self.config.get(""reconnection"", False):            return        self.notify(self._(""Waiting reconnection""), self._(""Current IP: {}"").format(ip))",,"def before_reconnect(self, ip):        if not self.config.get(""reconnection"", False):            return        self.notify(self._(""Waiting reconnection""), self._(""Current IP: {}"").format(ip))",a563207e-109b-43da-b923-5dfab8a23324
base,notifier.py,after_reconnect,78,82,"def after_reconnect(self, ip, oldip):        if not self.config.get(""reconnection"", False):            return        self.notify(self._(""Reconnection failed""), self._(""Current IP: {}"").format(ip))",,"def after_reconnect(self, ip, oldip):        if not self.config.get(""reconnection"", False):            return        self.notify(self._(""Reconnection failed""), self._(""Current IP: {}"").format(ip))",af645c87-9a33-472f-a080-92ab153a4e60
base,notifier.py,package_finished,84,88,"def package_finished(self, pypack):        if not self.config.get(""packagefinished"", True):            return        self.notify(self._(""Package finished""), pypack.name)",,"def package_finished(self, pypack):        if not self.config.get(""packagefinished"", True):            return        self.notify(self._(""Package finished""), pypack.name)",759c4ce5-78ed-4437-b081-1aa8465609db
base,notifier.py,package_failed,90,94,"def package_failed(self, pypack):        if not self.config.get(""packagefailed"", True):            return        self.notify(self._(""Package failed""), pypack.name)",,"def package_failed(self, pypack):        if not self.config.get(""packagefailed"", True):            return        self.notify(self._(""Package failed""), pypack.name)",db66cb39-26d2-4836-8de5-7e67b0ed64c5
base,notifier.py,download_finished,96,100,"def download_finished(self, pyfile):        if not self.config.get(""downloadfinished"", False):            return        self.notify(self._(""Download finished""), pyfile.name)",,"def download_finished(self, pyfile):        if not self.config.get(""downloadfinished"", False):            return        self.notify(self._(""Download finished""), pyfile.name)",cc5ac2a6-158b-4688-9571-c1d168f012b2
base,notifier.py,download_failed,102,106,"def download_failed(self, pyfile):        if self.config.get(""downloadfailed"", True):            return        self.notify(self._(""Download failed""), pyfile.name)",,"def download_failed(self, pyfile):        if self.config.get(""downloadfailed"", True):            return        self.notify(self._(""Download failed""), pyfile.name)",a05e5a8d-a524-45b6-b9f1-bd0cdcbbaec0
base,notifier.py,all_downloads_processed,108,110,"def all_downloads_processed(self):        if self.config.get(""alldownloadsprocessed"", True):            self.notify(self._(""All downloads processed""))",,"def all_downloads_processed(self):        if self.config.get(""alldownloadsprocessed"", True):            self.notify(self._(""All downloads processed""))",4af57ba7-8274-4874-875f-3b5f9aac15d7
base,notifier.py,all_downloads_finished,112,114,"def all_downloads_finished(self):        if self.config.get(""alldownloadsfinished"", True):            self.notify(self._(""All downloads finished""))",,"def all_downloads_finished(self):        if self.config.get(""alldownloadsfinished"", True):            self.notify(self._(""All downloads finished""))",45ee348b-ed61-4a6e-9c39-6c7079fcf181
base,notifier.py,notify,117,156,"def notify(self, event, msg=None, key=None):        key = key or self.get_key()        if not key or is_sequence(key) and not all(key):            return        if is_sequence(msg):            msg = "" | "".join(a.strip() for a in msg if a.strip())        if self.pyload.is_client_connected() and not self.config.get(            ""ignoreclient"", False        ):            return        elapsed_time = time.time() - self.last_notify        if elapsed_time < self.config.get(""sendinterval"", 1):            return        elif elapsed_time > 60:            self.notifications = 0        elif self.notifications >= self.config.get(""sendpermin"", 60):            return        self.log_debug(""Sending notification..."")        try:            self.send(event, msg, key)        except Exception as exc:            self.log_error(self._(""Error sending notification""), exc)            return False        else:            self.log_debug(""Notification sent"")            return True        finally:            self.last_notify = time.time()            self.notifications += 1",,"def notify(self, event, msg=None, key=None):        key = key or self.get_key()        if not key or is_sequence(key) and not all(key):            return        if is_sequence(msg):            msg = "" | "".join(a.strip() for a in msg if a.strip())        if self.pyload.is_client_connected() and not self.config.get(            ""ignoreclient"", False        ):            return        elapsed_time = time.time() - self.last_notify        if elapsed_time < self.config.get(""sendinterval"", 1):            return        elif elapsed_time > 60:            self.notifications = 0        elif self.notifications >= self.config.get(""sendpermin"", 60):            return        self.log_debug(""Sending notification..."")        try:            self.send(event, msg, key)        except Exception as exc:            self.log_error(self._(""Error sending notification""), exc)            return False        else:            self.log_debug(""Notification sent"")            return True        finally:            self.last_notify = time.time()            self.notifications += 1",aba0a59e-83dc-4099-a87d-56bf994c9b10
base,ocr.py,__init__,25,28,"def __init__(self, pyfile):        self._init(pyfile.m.pyload)        self.pyfile = pyfile        self.init()",,"def __init__(self, pyfile):        self._init(pyfile.m.pyload)        self.pyfile = pyfile        self.init()",1ca7c2f7-b16f-4153-b806-8f11d385f889
base,ocr.py,_log,30,34,"def _log(self, level, plugintype, pluginname, args, kwargs):        args = (self.__name__,) + args        return self.pyfile.plugin._log(            level, plugintype, self.pyfile.plugin.__name__, args, kwargs        )",,"def _log(self, level, plugintype, pluginname, args, kwargs):        args = (self.__name__,) + args        return self.pyfile.plugin._log(            level, plugintype, self.pyfile.plugin.__name__, args, kwargs        )",7711b8b0-7ad2-49a8-982c-86f4a6f8b6a1
base,ocr.py,load_image,36,39,"def load_image(self, image):        self.img = Image.open(image)        self.pixels = self.img.load()        self.result_captcha = """"",,"def load_image(self, image):        self.img = Image.open(image)        self.pixels = self.img.load()        self.result_captcha = """"",a112420d-9a1b-4bd1-b903-9d2a8be02c15
base,ocr.py,deactivate,41,45,def deactivate(self):                pass,Delete all tmp images.,"def deactivate(self):        """"""        Delete all tmp images.        """"""        pass

Delete all tmp images.",e320b0ae-ed1f-4951-a4d2-8f83315255a3
base,ocr.py,threshold,47,48,"def threshold(self, value):        self.img = self.img.point(lambda a: a * value + 10)",,"def threshold(self, value):        self.img = self.img.point(lambda a: a * value + 10)",c4990078-0034-4577-8905-f29570b00c9c
base,ocr.py,call_cmd,50,65,"def call_cmd(self, command, *args, **kwargs):                call = [command] + args        self.log_debug(""EXECUTE "" + "" "".join(call))        popen = subprocess.Popen(call)        popen.wait()        output = popen.stdout.read() + "" | "" + popen.stderr.read()        popen.stdout.close()        popen.stderr.close()        self.log_debug(f""Tesseract ReturnCode {popen.returncode}"", f""Output: {output}"")",Run a command.,"def call_cmd(self, command, *args, **kwargs):        """"""        Run a command.        """"""        call = [command] + args        self.log_debug(""EXECUTE "" + "" "".join(call))        popen = subprocess.Popen(call)        popen.wait()        output = popen.stdout.read() + "" | "" + popen.stderr.read()        popen.stdout.close()        popen.stderr.close()        self.log_debug(f""Tesseract ReturnCode {popen.returncode}"", f""Output: {output}"")

Run a command.",d7e985d4-68b5-49e7-9efd-54ec230ca0e4
base,ocr.py,run_tesser,67,148,"def run_tesser(        self,        subset=False,        digits=True,        lowercase=True,        uppercase=True,        pagesegmode=None,    ):        # tmp_tif = tempfile.NamedTemporaryFile(suffix="".tif"")        try:            tmp_tif = open(                os.path.join(self.pyload.tempdir, f""tmp_tif_{self.classname}.tif""),                mode=""wb"",            )            tmp_tif.close()            # tmp_txt = tempfile.NamedTemporaryFile(suffix="".txt"")            tmp_txt = open(                os.path.join(self.pyload.tempdir, f""tmp_txt_{self.classname}.txt""),                mode=""wb"",            )            tmp_txt.close()        except IOError as exc:            self.log_error(exc)            return        self.log_debug(""Saving tiff..."")        self.img.save(tmp_tif.name, ""TIFF"")        if os.name == ""nt"":            command = os.path.join(PKGDIR, ""lib"", ""tesseract"", ""tesseract.exe"")        else:            command = ""tesseract""        args = [            os.path.realpath(tmp_tif.name),            os.path.realpath(tmp_txt.name).replace("".txt"", """"),        ]        if pagesegmode:            args.extend([""-psm"", str(pagesegmode)])        if subset and (digits or lowercase or uppercase):            # tmp_sub = tempfile.NamedTemporaryFile(suffix="".subset"")            with open(                os.path.join(                    self.pyload.tempdir, ""tmp_sub_{}.subset"".format(self.classname)                ),                ""wb"",            ) as tmp_sub:                tmp_sub.write(""tessedit_char_whitelist "")                if digits:                    tmp_sub.write(""0123456789"")                if lowercase:                    tmp_sub.write(""abcdefghijklmnopqrstuvwxyz"")                if uppercase:                    tmp_sub.write(""ABCDEFGHIJKLMNOPQRSTUVWXYZ"")                tmp_sub.write(""\n"")                args.append(""nobatch"")                args.append(os.path.realpath(tmp_sub.name))        self.log_debug(""Running tesseract..."")        self.call_cmd(command, *args)        self.log_debug(""Reading txt..."")        try:            with open(tmp_txt.name) as fp:                self.result_captcha = fp.read().replace(""\n"", """")        except Exception:            self.result_captcha = """"        self.log_info(self._(""OCR result: "") + self.result_captcha)        self.remove(tmp_tif.name, try_trash=False)        self.remove(tmp_txt.name, try_trash=False)        if subset and (digits or lowercase or uppercase):            self.remove(tmp_sub.name, try_trash=False)",,"def run_tesser(        self,        subset=False,        digits=True,        lowercase=True,        uppercase=True,        pagesegmode=None,    ):        # tmp_tif = tempfile.NamedTemporaryFile(suffix="".tif"")        try:            tmp_tif = open(                os.path.join(self.pyload.tempdir, f""tmp_tif_{self.classname}.tif""),                mode=""wb"",            )            tmp_tif.close()            # tmp_txt = tempfile.NamedTemporaryFile(suffix="".txt"")            tmp_txt = open(                os.path.join(self.pyload.tempdir, f""tmp_txt_{self.classname}.txt""),                mode=""wb"",            )            tmp_txt.close()        except IOError as exc:            self.log_error(exc)            return        self.log_debug(""Saving tiff..."")        self.img.save(tmp_tif.name, ""TIFF"")        if os.name == ""nt"":            command = os.path.join(PKGDIR, ""lib"", ""tesseract"", ""tesseract.exe"")        else:            command = ""tesseract""        args = [            os.path.realpath(tmp_tif.name),            os.path.realpath(tmp_txt.name).replace("".txt"", """"),        ]        if pagesegmode:            args.extend([""-psm"", str(pagesegmode)])        if subset and (digits or lowercase or uppercase):            # tmp_sub = tempfile.NamedTemporaryFile(suffix="".subset"")            with open(                os.path.join(                    self.pyload.tempdir, ""tmp_sub_{}.subset"".format(self.classname)                ),                ""wb"",            ) as tmp_sub:                tmp_sub.write(""tessedit_char_whitelist "")                if digits:                    tmp_sub.write(""0123456789"")                if lowercase:                    tmp_sub.write(""abcdefghijklmnopqrstuvwxyz"")                if uppercase:                    tmp_sub.write(""ABCDEFGHIJKLMNOPQRSTUVWXYZ"")                tmp_sub.write(""\n"")                args.append(""nobatch"")                args.append(os.path.realpath(tmp_sub.name))        self.log_debug(""Running tesseract..."")        self.call_cmd(command, *args)        self.log_debug(""Reading txt..."")        try:            with open(tmp_txt.name) as fp:                self.result_captcha = fp.read().replace(""\n"", """")        except Exception:            self.result_captcha = """"        self.log_info(self._(""OCR result: "") + self.result_captcha)        self.remove(tmp_tif.name, try_trash=False)        self.remove(tmp_txt.name, try_trash=False)        if subset and (digits or lowercase or uppercase):            self.remove(tmp_sub.name, try_trash=False)",f26df6cd-0617-44a6-9370-fef538c2d448
base,ocr.py,recognize,150,151,"def recognize(self, image):        raise NotImplementedError",,"def recognize(self, image):        raise NotImplementedError",51d75158-888e-4296-9d82-a7ee5c85ed24
base,ocr.py,to_greyscale,153,157,"def to_greyscale(self):        if self.img.mode != ""L"":            self.img = self.img.convert(""L"")        self.pixels = self.img.load()",,"def to_greyscale(self):        if self.img.mode != ""L"":            self.img = self.img.convert(""L"")        self.pixels = self.img.load()",94c56a9c-81f9-4b39-b849-e7cab84978cf
base,ocr.py,eval_black_white,159,167,"def eval_black_white(self, limit):        self.pixels = self.img.load()        w, h = self.img.size        for x in range(w):            for y in range(h):                if self.pixels[x, y] > limit:                    self.pixels[x, y] = 255                else:                    self.pixels[x, y] = 0",,"def eval_black_white(self, limit):        self.pixels = self.img.load()        w, h = self.img.size        for x in range(w):            for y in range(h):                if self.pixels[x, y] > limit:                    self.pixels[x, y] = 255                else:                    self.pixels[x, y] = 0",13b11aca-4ad7-4f30-89d0-61d22978760c
base,ocr.py,clean,169,220,"def clean(self, allowed):        pixels = self.pixels        w, h = self.img.size        for x in range(w):            for y in range(h):                if pixels[x, y] == 255:                    continue                #: No point in processing white pixels since we only want to remove black pixel                count = 0                try:                    if pixels[x - 1, y - 1] != 255:                        count += 1                    if pixels[x - 1, y] != 255:                        count += 1                    if pixels[x - 1, y + 1] != 255:                        count += 1                    if pixels[x, y + 1] != 255:                        count += 1                    if pixels[x + 1, y + 1] != 255:                        count += 1                    if pixels[x + 1, y] != 255:                        count += 1                    if pixels[x + 1, y - 1] != 255:                        count += 1                    if pixels[x, y - 1] != 255:                        count += 1                except Exception:                    pass                #: Not enough neighbors are dark pixels so mark this pixel                #: To be changed to white                if count < allowed:                    pixels[x, y] = 1        #: Second pass: this time set all 1's to 255 (white)        for x in range(w):            for y in range(h):                if pixels[x, y] == 1:                    pixels[x, y] = 255        self.pixels = pixels",,"def clean(self, allowed):        pixels = self.pixels        w, h = self.img.size        for x in range(w):            for y in range(h):                if pixels[x, y] == 255:                    continue                #: No point in processing white pixels since we only want to remove black pixel                count = 0                try:                    if pixels[x - 1, y - 1] != 255:                        count += 1                    if pixels[x - 1, y] != 255:                        count += 1                    if pixels[x - 1, y + 1] != 255:                        count += 1                    if pixels[x, y + 1] != 255:                        count += 1                    if pixels[x + 1, y + 1] != 255:                        count += 1                    if pixels[x + 1, y] != 255:                        count += 1                    if pixels[x + 1, y - 1] != 255:                        count += 1                    if pixels[x, y - 1] != 255:                        count += 1                except Exception:                    pass                #: Not enough neighbors are dark pixels so mark this pixel                #: To be changed to white                if count < allowed:                    pixels[x, y] = 1        #: Second pass: this time set all 1's to 255 (white)        for x in range(w):            for y in range(h):                if pixels[x, y] == 1:                    pixels[x, y] = 255        self.pixels = pixels",834bea19-1c1a-42d8-b229-2da38b0714c0
base,ocr.py,derotate_by_average,222,294,"def derotate_by_average(self):                w, h = self.img.size        pixels = self.pixels        for x in range(w):            for y in range(h):                if pixels[x, y] == 0:                    pixels[x, y] = 155        highest = {}        counts = {}        for angle in range(-45, 45):            tmpimage = self.img.rotate(angle)            pixels = tmpimage.load()            w, h = self.img.size            for x in range(w):                for y in range(h):                    if pixels[x, y] == 0:                        pixels[x, y] = 255            count = {}            for x in range(w):                count[x] = 0                for y in range(h):                    if pixels[x, y] == 155:                        count[x] += 1            sum = 0            cnt = 0            for x in count.values():                if x != 0:                    sum += x                    cnt += 1            avg = sum // cnt            counts[angle] = cnt            highest[angle] = 0            for x in count.values():                if x > highest[angle]:                    highest[angle] = x            highest[angle] = highest[angle] - avg        hkey = 0        hvalue = 0        for key, value in highest.items():            if value > hvalue:                hkey = key                hvalue = value        self.img = self.img.rotate(hkey)        pixels = self.img.load()        for x in range(w):            for y in range(h):                if pixels[x, y] == 0:                    pixels[x, y] = 255                if pixels[x, y] == 155:                    pixels[x, y] = 0        self.pixels = pixels",Rotate by checking each angle and guess most suitable.,"def derotate_by_average(self):        """"""        Rotate by checking each angle and guess most suitable.        """"""        w, h = self.img.size        pixels = self.pixels        for x in range(w):            for y in range(h):                if pixels[x, y] == 0:                    pixels[x, y] = 155        highest = {}        counts = {}        for angle in range(-45, 45):            tmpimage = self.img.rotate(angle)            pixels = tmpimage.load()            w, h = self.img.size            for x in range(w):                for y in range(h):                    if pixels[x, y] == 0:                        pixels[x, y] = 255            count = {}            for x in range(w):                count[x] = 0                for y in range(h):                    if pixels[x, y] == 155:                        count[x] += 1            sum = 0            cnt = 0            for x in count.values():                if x != 0:                    sum += x                    cnt += 1            avg = sum // cnt            counts[angle] = cnt            highest[angle] = 0            for x in count.values():                if x > highest[angle]:                    highest[angle] = x            highest[angle] = highest[angle] - avg        hkey = 0        hvalue = 0        for key, value in highest.items():            if value > hvalue:                hkey = key                hvalue = value        self.img = self.img.rotate(hkey)        pixels = self.img.load()        for x in range(w):            for y in range(h):                if pixels[x, y] == 0:                    pixels[x, y] = 255                if pixels[x, y] == 155:                    pixels[x, y] = 0        self.pixels = pixels

Rotate by checking each angle and guess most suitable.",c4c3100b-8cf5-41ca-bbcc-d85d99ae287c
base,ocr.py,split_captcha_letters,296,333,"def split_captcha_letters(self):        captcha = self.img        started = False        letters = []        width, height = captcha.size        bottomY, topY = 0, height        pixels = captcha.load()        for x in range(width):            black_pixel_in_col = False            for y in range(height):                if pixels[x, y] != 255:                    if not started:                        started = True                        firstX = x                        lastX = x                    if y > bottomY:                        bottomY = y                    if y < topY:                        topY = y                    if x > lastX:                        lastX = x                    black_pixel_in_col = True            if black_pixel_in_col is False and started is True:                rect = (firstX, topY, lastX, bottomY)                new_captcha = captcha.crop(rect)                w, h = new_captcha.size                if w > 5 and h > 5:                    letters.append(new_captcha)                started = False                bottomY, topY = 0, height        return letters",,"def split_captcha_letters(self):        captcha = self.img        started = False        letters = []        width, height = captcha.size        bottomY, topY = 0, height        pixels = captcha.load()        for x in range(width):            black_pixel_in_col = False            for y in range(height):                if pixels[x, y] != 255:                    if not started:                        started = True                        firstX = x                        lastX = x                    if y > bottomY:                        bottomY = y                    if y < topY:                        topY = y                    if x > lastX:                        lastX = x                    black_pixel_in_col = True            if black_pixel_in_col is False and started is True:                rect = (firstX, topY, lastX, bottomY)                new_captcha = captcha.crop(rect)                w, h = new_captcha.size                if w > 5 and h > 5:                    letters.append(new_captcha)                started = False                bottomY, topY = 0, height        return letters",c7f6f478-97e7-402f-a937-b6c060b25328
base,ocr.py,correct,335,352,"def correct(self, values, var=None):        if var:            result = var        else:            result = self.result_captcha        for key, item in values.items():            if key.__class__ is str:                result = result.replace(key, item)            else:                for expr in key:                    result = result.replace(expr, item)        if var:            return result        else:            self.result_captcha = result",,"def correct(self, values, var=None):        if var:            result = var        else:            result = self.result_captcha        for key, item in values.items():            if key.__class__ is str:                result = result.replace(key, item)            else:                for expr in key:                    result = result.replace(expr, item)        if var:            return result        else:            self.result_captcha = result",695d8dd5-45a2-4535-aa66-18b17df2d85d
base,plugin.py,__init__,33,35,"def __init__(self, core):        self._init(core)        self.init()",,"def __init__(self, core):        self._init(core)        self.init()",f82a140b-72d2-47eb-9f50-923da85b4a55
base,plugin.py,__repr__,37,40,"def __repr__(self):        return ""<{type} {name}>"".format(            type=self.__type__.capitalize(), name=self.classname        )",,"def __repr__(self):        return ""<{type} {name}>"".format(            type=self.__type__.capitalize(), name=self.classname        )",5424dca8-2921-4adf-abac-985be1a00290
base,plugin.py,classname,43,44,def classname(self):        return self.__class__.__name__,,def classname(self):        return self.__class__.__name__,f9413a79-cf3c-41a1-bd3f-f94fb7c3d255
base,plugin.py,_init,46,61,"def _init(self, core):        #: Internal modules        self.pyload = core        self._ = core._        self.db = DB(self)        self.config = Config(self)        #: Provide information in dict here        self.info = {}        #: Browser instance, see `network.Browser`        self.req = self.pyload.request_factory.get_request(self.classname)        #: Last loaded html        self.last_html = """"        self.last_header = {}",,"def _init(self, core):        #: Internal modules        self.pyload = core        self._ = core._        self.db = DB(self)        self.config = Config(self)        #: Provide information in dict here        self.info = {}        #: Browser instance, see `network.Browser`        self.req = self.pyload.request_factory.get_request(self.classname)        #: Last loaded html        self.last_html = """"        self.last_header = {}",bd265e1d-fdf3-4f31-a9b7-353790e397eb
base,plugin.py,init,63,67,def init(self):                pass,Initialize the plugin (in addition to `__init__`),"def init(self):        """"""        Initialize the plugin (in addition to `__init__`)        """"""        pass

Initialize the plugin (in addition to `__init__`)",7296ac74-bdfe-48f4-9e1e-c98eeaca3114
base,plugin.py,_log,70,80,"def _log(self, level, plugintype, pluginname, args, kwargs):        log = getattr(self.pyload.log, level)        log(            ""{plugintype} {pluginname}: {msg}"".format(                plugintype=plugintype.upper(),                pluginname=pluginname,                msg="" | "".join([""%s""] * len(args)),            ),            *args,            **kwargs,        )",,"def _log(self, level, plugintype, pluginname, args, kwargs):        log = getattr(self.pyload.log, level)        log(            ""{plugintype} {pluginname}: {msg}"".format(                plugintype=plugintype.upper(),                pluginname=pluginname,                msg="" | "".join([""%s""] * len(args)),            ),            *args,            **kwargs,        )",14c33a40-9689-40df-822f-9a13496a9a02
base,plugin.py,log_debug,82,83,"def log_debug(self, *args, **kwargs):        self._log(""debug"", self.__type__, self.__name__, args, kwargs)",,"def log_debug(self, *args, **kwargs):        self._log(""debug"", self.__type__, self.__name__, args, kwargs)",5bed8a3a-da59-4468-9ab1-820c4b2c6346
base,plugin.py,log_info,85,86,"def log_info(self, *args, **kwargs):        self._log(""info"", self.__type__, self.__name__, args, kwargs)",,"def log_info(self, *args, **kwargs):        self._log(""info"", self.__type__, self.__name__, args, kwargs)",0cc37ee7-59e5-487a-beca-287f78100216
base,plugin.py,log_warning,88,89,"def log_warning(self, *args, **kwargs):        self._log(""warning"", self.__type__, self.__name__, args, kwargs)",,"def log_warning(self, *args, **kwargs):        self._log(""warning"", self.__type__, self.__name__, args, kwargs)",633d82b4-b106-43e1-b7f8-ffbab2aa2120
base,plugin.py,log_error,91,96,"def log_error(self, *args, **kwargs):        kwargs[""exc_info""] = kwargs.get(            ""exc_info"", self.pyload.debug > 1 and sys.exc_info() != (None, None, None)        )        kwargs[""stack_info""] = kwargs.get(""stack_info"", self.pyload.debug > 2)        self._log(""error"", self.__type__, self.__name__, args, kwargs)",,"def log_error(self, *args, **kwargs):        kwargs[""exc_info""] = kwargs.get(            ""exc_info"", self.pyload.debug > 1 and sys.exc_info() != (None, None, None)        )        kwargs[""stack_info""] = kwargs.get(""stack_info"", self.pyload.debug > 2)        self._log(""error"", self.__type__, self.__name__, args, kwargs)",e05d4a3e-d402-4861-8f66-e464ac35a927
base,plugin.py,log_critical,98,103,"def log_critical(self, *args, **kwargs):        kwargs[""exc_info""] = kwargs.get(            ""exc_info"", sys.exc_info() != (None, None, None)        )        kwargs[""stack_info""] = kwargs.get(""stack_info"", True)        self._log(""critical"", self.__type__, self.__name__, args, kwargs)",,"def log_critical(self, *args, **kwargs):        kwargs[""exc_info""] = kwargs.get(            ""exc_info"", sys.exc_info() != (None, None, None)        )        kwargs[""stack_info""] = kwargs.get(""stack_info"", True)        self._log(""critical"", self.__type__, self.__name__, args, kwargs)",9ad9c293-a009-4477-a518-48f861cf7b94
base,plugin.py,remove,112,124,"def remove(self, path, try_trash=True):  # TODO: Change to `trash=True` in 0.6.x        try:            fs.remove(path, try_trash=try_trash)        except (NameError, OSError) as exc:            self.log_warning(                self._(""Error removing `{}`"").format(os.path.realpath(path)), exc            )            return False        else:            self.log_info(self._(""Path deleted: "") + os.path.realpath(path))            return True",,"def remove(self, path, try_trash=True):  # TODO: Change to `trash=True` in 0.6.x        try:            fs.remove(path, try_trash=try_trash)        except (NameError, OSError) as exc:            self.log_warning(                self._(""Error removing `{}`"").format(os.path.realpath(path)), exc            )            return False        else:            self.log_info(self._(""Path deleted: "") + os.path.realpath(path))            return True",bd660d77-e074-4e2f-8e21-20b9535d01f5
base,plugin.py,set_permissions,126,142,"def set_permissions(self, path):        path = os.fsdecode(path)        if not exists(path):            return        if self.pyload.config.get(""permission"", ""change_file""):            permission = self.pyload.config.get(                ""permission"", ""folder"" if os.path.isdir(path) else ""file""            )            mode = int(permission, 8)            os.chmod(path, mode)        if os.name != ""nt"" and self.pyload.config.get(""permission"", ""change_dl""):            uid = pwd.getpwnam(self.pyload.config.get(""permission"", ""user""))[2]            gid = grp.getgrnam(self.pyload.config.get(""permission"", ""group""))[2]            os.chown(path, uid, gid)",,"def set_permissions(self, path):        path = os.fsdecode(path)        if not exists(path):            return        if self.pyload.config.get(""permission"", ""change_file""):            permission = self.pyload.config.get(                ""permission"", ""folder"" if os.path.isdir(path) else ""file""            )            mode = int(permission, 8)            os.chmod(path, mode)        if os.name != ""nt"" and self.pyload.config.get(""permission"", ""change_dl""):            uid = pwd.getpwnam(self.pyload.config.get(""permission"", ""user""))[2]            gid = grp.getgrnam(self.pyload.config.get(""permission"", ""group""))[2]            os.chown(path, uid, gid)",7076755b-6f95-4ac7-83bf-e63d3a05bea3
base,plugin.py,skip,144,148,"def skip(self, msg):                raise Skip(msg)",Skip and give msg.,"def skip(self, msg):        """"""        Skip and give msg.        """"""        raise Skip(msg)

Skip and give msg.",f72d01be-fc51-47d4-8314-420fbafa29bb
base,plugin.py,fail,150,154,"def fail(self, msg):                raise Fail(msg)",Fail and give msg.,"def fail(self, msg):        """"""        Fail and give msg.        """"""        raise Fail(msg)

Fail and give msg.",20172a43-8793-4f32-ab69-9693cf94eaee
base,plugin.py,load,156,261,"def load(        self,        url,        get={},        post={},        ref=True,        cookies=True,        just_header=False,        decode=True,        multipart=False,        redirect=True,        req=None,    ):                if self.pyload.debug:            self.log_debug(                ""LOAD URL "" + url,                *[                    ""{}={}"".format(key, value)                    for key, value in locals().items()                    if key not in (""self"", ""url"", ""_[1]"")                ],            )        url = fixurl(url, unquote=True)  #: Recheck in 0.6.x        if req is False:            req = get_request()        elif not req:            req = self.req        # TODO: Move to network in 0.6.x        if isinstance(cookies, list):            set_cookies(req.cj, cookies)        # NOTE: req can be a HTTPRequest or a Browser object        http_req = self.req.http if hasattr(self.req, ""http"") else self.req        # TODO: Move to network in 0.6.x        if not redirect:            http_req.c.setopt(pycurl.FOLLOWLOCATION, 0)        elif type(redirect) is int:            http_req.c.setopt(pycurl.MAXREDIRS, redirect)        # TODO: Move to network in 0.6.x        if isinstance(ref, str):            req.last_url = ref        html = req.load(            url,            get,            post,            bool(ref),            bool(cookies),            just_header,            multipart,            decode is True,        )        # TODO: Move to network in 0.6.x        if not redirect:            # NOTE: req can be a HTTPRequest or a Browser object            http_req.c.setopt(pycurl.FOLLOWLOCATION, 1)        elif type(redirect) is int:            maxredirs = (                self.pyload.api.get_config_value(                    ""UserAgentSwitcher"", ""maxredirs"", ""plugin""                )                or 5            )            # NOTE: req can be a HTTPRequest or a Browser object            http_req.c.setopt(pycurl.MAXREDIRS, maxredirs)        # TODO: Move to network in 0.6.x        if decode:            html = purge.unescape(html)        self.last_html = html        if self.pyload.debug:            self.dump_html()        # TODO: Move to network in 0.6.x        header = {""code"": req.code, ""url"": req.last_effective_url}        header.update(parse_html_header(http_req.response_header))        self.last_header = header        if just_header:            return header        else:            return html","Load content at url and returns it.

:param url:
:param get:
:param post:
:param ref:
:param cookies:
:param just_header: If True only the header will be retrieved and returned as dict
:param decode: Wether to decode the output according to http header, should be True in most cases
:return: Loaded content","def load(        self,        url,        get={},        post={},        ref=True,        cookies=True,        just_header=False,        decode=True,        multipart=False,        redirect=True,        req=None,    ):        """"""        Load content at url and returns it.        :param url:        :param get:        :param post:        :param ref:        :param cookies:        :param just_header: If True only the header will be retrieved and returned as dict        :param decode: Wether to decode the output according to http header, should be True in most cases        :return: Loaded content        """"""        if self.pyload.debug:            self.log_debug(                ""LOAD URL "" + url,                *[                    ""{}={}"".format(key, value)                    for key, value in locals().items()                    if key not in (""self"", ""url"", ""_[1]"")                ],            )        url = fixurl(url, unquote=True)  #: Recheck in 0.6.x        if req is False:            req = get_request()        elif not req:            req = self.req        # TODO: Move to network in 0.6.x        if isinstance(cookies, list):            set_cookies(req.cj, cookies)        # NOTE: req can be a HTTPRequest or a Browser object        http_req = self.req.http if hasattr(self.req, ""http"") else self.req        # TODO: Move to network in 0.6.x        if not redirect:            http_req.c.setopt(pycurl.FOLLOWLOCATION, 0)        elif type(redirect) is int:            http_req.c.setopt(pycurl.MAXREDIRS, redirect)        # TODO: Move to network in 0.6.x        if isinstance(ref, str):            req.last_url = ref        html = req.load(            url,            get,            post,            bool(ref),            bool(cookies),            just_header,            multipart,            decode is True,        )        # TODO: Move to network in 0.6.x        if not redirect:            # NOTE: req can be a HTTPRequest or a Browser object            http_req.c.setopt(pycurl.FOLLOWLOCATION, 1)        elif type(redirect) is int:            maxredirs = (                self.pyload.api.get_config_value(                    ""UserAgentSwitcher"", ""maxredirs"", ""plugin""                )                or 5            )            # NOTE: req can be a HTTPRequest or a Browser object            http_req.c.setopt(pycurl.MAXREDIRS, maxredirs)        # TODO: Move to network in 0.6.x        if decode:            html = purge.unescape(html)        self.last_html = html        if self.pyload.debug:            self.dump_html()        # TODO: Move to network in 0.6.x        header = {""code"": req.code, ""url"": req.last_effective_url}        header.update(parse_html_header(http_req.response_header))        self.last_header = header        if just_header:            return header        else:            return html

Load content at url and returns it.

:param url:
:param get:
:param post:
:param ref:
:param cookies:
:param just_header: If True only the header will be retrieved and returned as dict
:param decode: Wether to decode the output according to http header, should be True in most cases
:return: Loaded content",eede178b-43d9-43d8-a42a-a24f3fdb6511
base,plugin.py,upload,263,389,"def upload(        self,        path,        url,        get={},        ref=True,        cookies=True,        just_header=False,        decode=True,        redirect=True,        req=None,    ):        # TODO: This should really go to HTTPRequest.py                if self.pyload.debug:            self.log_debug(                ""UPLOAD URL "" + url,                *[                    ""{}={}"".format(key, value)                    for key, value in locals().items()                    if key not in (""self"", ""url"", ""_[1]"")                ],            )        with open(os.fsencode(path), mode=""rb"") as fp:            url = fixurl(url, unquote=True)  #: Recheck in 0.6.x            if req is False:                req = get_request()            elif not req:                req = self.req            if isinstance(cookies, list):                set_cookies(req.cj, cookies)            # NOTE: req can be a HTTPRequest or a Browser object            http_req = req.http if hasattr(req, ""http"") else req            if not redirect:                http_req.c.setopt(pycurl.FOLLOWLOCATION, 0)            elif isinstance(redirect, int):                http_req.c.setopt(pycurl.MAXREDIRS, redirect)            if isinstance(ref, str):                http_req.last_url = ref            http_req.set_request_context(url, get, {}, bool(ref), bool(cookies), False)            http_req.c.setopt(pycurl.HTTPHEADER, http_req.request_headers)            http_req.response_header = b""""            http_req.c.setopt(pycurl.UPLOAD, 1)            http_req.c.setopt(pycurl.READFUNCTION, fp.read)            http_req.c.setopt(pycurl.INFILESIZE, os.path.getsize(path))            if just_header:                http_req.c.setopt(pycurl.FOLLOWLOCATION, 0)                http_req.c.setopt(pycurl.NOBODY, 1)                http_req.c.perform()                http_req.c.setopt(pycurl.FOLLOWLOCATION, 1)                http_req.c.setopt(pycurl.NOBODY, 0)            else:                http_req.c.perform()            http_req.c.setopt(pycurl.UPLOAD, 0)            http_req.c.setopt(pycurl.INFILESIZE, 0)            http_req.c.setopt(pycurl.POSTFIELDS, """")            http_req.last_effective_url = http_req.c.getinfo(pycurl.EFFECTIVE_URL)            http_req.add_cookies()            http_req.code = http_req.verify_header()            html = http_req.response_header if just_header else http_req.get_response()            http_req.rep.close()            http_req.rep = None            if decode is True:                html = http_req.decode_response(html)            if not redirect:                http_req.c.setopt(pycurl.FOLLOWLOCATION, 1)            elif isinstance(redirect, int):                maxredirs = (                    self.pyload.api.get_config_value(                        ""UserAgentSwitcher"", ""maxredirs"", ""plugin""                    )                    or 5                )                # NOTE: req can be a HTTPRequest or a Browser object                http_req.c.setopt(pycurl.MAXREDIRS, maxredirs)            if decode:                html = purge.unescape(html)            self.last_html = html            if self.pyload.debug:                self.dump_html()            # TODO: Move to network in 0.6.x            header = {""code"": req.code, ""url"": req.last_effective_url}            # NOTE: req can be a HTTPRequest or a Browser object            header.update(parse_html_header(http_req.response_header))            self.last_header = header            if just_header:                return header            else:                return html","Uploads a file at url and returns response content.

:param url:
:param get:
:param ref:
:param cookies:
:param just_header: If True only the header will be retrieved and returned as dict
:param decode: Wether to decode the output according to http header, should be True in most cases
:return: Response content","def upload(        self,        path,        url,        get={},        ref=True,        cookies=True,        just_header=False,        decode=True,        redirect=True,        req=None,    ):        # TODO: This should really go to HTTPRequest.py        """"""        Uploads a file at url and returns response content.        :param url:        :param get:        :param ref:        :param cookies:        :param just_header: If True only the header will be retrieved and returned as dict        :param decode: Wether to decode the output according to http header, should be True in most cases        :return: Response content        """"""        if self.pyload.debug:            self.log_debug(                ""UPLOAD URL "" + url,                *[                    ""{}={}"".format(key, value)                    for key, value in locals().items()                    if key not in (""self"", ""url"", ""_[1]"")                ],            )        with open(os.fsencode(path), mode=""rb"") as fp:            url = fixurl(url, unquote=True)  #: Recheck in 0.6.x            if req is False:                req = get_request()            elif not req:                req = self.req            if isinstance(cookies, list):                set_cookies(req.cj, cookies)            # NOTE: req can be a HTTPRequest or a Browser object            http_req = req.http if hasattr(req, ""http"") else req            if not redirect:                http_req.c.setopt(pycurl.FOLLOWLOCATION, 0)            elif isinstance(redirect, int):                http_req.c.setopt(pycurl.MAXREDIRS, redirect)            if isinstance(ref, str):                http_req.last_url = ref            http_req.set_request_context(url, get, {}, bool(ref), bool(cookies), False)            http_req.c.setopt(pycurl.HTTPHEADER, http_req.request_headers)            http_req.response_header = b""""            http_req.c.setopt(pycurl.UPLOAD, 1)            http_req.c.setopt(pycurl.READFUNCTION, fp.read)            http_req.c.setopt(pycurl.INFILESIZE, os.path.getsize(path))            if just_header:                http_req.c.setopt(pycurl.FOLLOWLOCATION, 0)                http_req.c.setopt(pycurl.NOBODY, 1)                http_req.c.perform()                http_req.c.setopt(pycurl.FOLLOWLOCATION, 1)                http_req.c.setopt(pycurl.NOBODY, 0)            else:                http_req.c.perform()            http_req.c.setopt(pycurl.UPLOAD, 0)            http_req.c.setopt(pycurl.INFILESIZE, 0)            http_req.c.setopt(pycurl.POSTFIELDS, """")            http_req.last_effective_url = http_req.c.getinfo(pycurl.EFFECTIVE_URL)            http_req.add_cookies()            http_req.code = http_req.verify_header()            html = http_req.response_header if just_header else http_req.get_response()            http_req.rep.close()            http_req.rep = None            if decode is True:                html = http_req.decode_response(html)            if not redirect:                http_req.c.setopt(pycurl.FOLLOWLOCATION, 1)            elif isinstance(redirect, int):                maxredirs = (                    self.pyload.api.get_config_value(                        ""UserAgentSwitcher"", ""maxredirs"", ""plugin""                    )                    or 5                )                # NOTE: req can be a HTTPRequest or a Browser object                http_req.c.setopt(pycurl.MAXREDIRS, maxredirs)            if decode:                html = purge.unescape(html)            self.last_html = html            if self.pyload.debug:                self.dump_html()            # TODO: Move to network in 0.6.x            header = {""code"": req.code, ""url"": req.last_effective_url}            # NOTE: req can be a HTTPRequest or a Browser object            header.update(parse_html_header(http_req.response_header))            self.last_header = header            if just_header:                return header            else:                return html

Uploads a file at url and returns response content.

:param url:
:param get:
:param ref:
:param cookies:
:param just_header: If True only the header will be retrieved and returned as dict
:param decode: Wether to decode the output according to http header, should be True in most cases
:return: Response content",cdace72f-7a8a-4e15-ba05-0f1b55cfca2d
base,plugin.py,dump_html,391,413,"def dump_html(self):        frame = inspect.currentframe()        try:            framefile = os.path.join(                self.pyload.tempdir,                self.classname,                ""{}_line{}.dump.html"".format(                    frame.f_back.f_code.co_name, frame.f_back.f_lineno                ),            )            os.makedirs(os.path.dirname(framefile), exist_ok=True)            is_bytes = isinstance(self.last_html, (bytes, bytearray))            with open(framefile, mode=""wb"" if is_bytes else ""w"") as fp:                fp.write(self.last_html)        except IOError as exc:            self.log_error(exc)        finally:            del frame",,"def dump_html(self):        frame = inspect.currentframe()        try:            framefile = os.path.join(                self.pyload.tempdir,                self.classname,                ""{}_line{}.dump.html"".format(                    frame.f_back.f_code.co_name, frame.f_back.f_lineno                ),            )            os.makedirs(os.path.dirname(framefile), exist_ok=True)            is_bytes = isinstance(self.last_html, (bytes, bytearray))            with open(framefile, mode=""wb"" if is_bytes else ""w"") as fp:                fp.write(self.last_html)        except IOError as exc:            self.log_error(exc)        finally:            del frame",3433eedd-4e2b-4a96-b270-0ad45f16e862
base,plugin.py,clean,415,427,def clean(self):                try:            # self.req.clear_cookies()            self.req.close()        except AttributeError:            pass        else:            self.req = None,Remove references.,"def clean(self):        """"""        Remove references.        """"""        try:            # self.req.clear_cookies()            self.req.close()        except AttributeError:            pass        else:            self.req = None

Remove references.",9409d179-7de3-4b8d-94fc-527715f86096
base,simple_decrypter.py,api_info,94,95,"def api_info(self, url):        return {}",,"def api_info(self, url):        return {}",ec982a7b-13e3-4b5d-8305-426a1e40004e
base,simple_decrypter.py,get_info,97,134,"def get_info(self, url="""", html=""""):        info = super(SimpleDecrypter, self).get_info(url)        info.update(self.api_info(url))        if not html and info[""status""] != 2:            if not url:                info[""error""] = ""missing url""                info[""status""] = 1            elif info[""status""] in (3, 7):                try:                    html = self.load(url, cookies=self.COOKIES, decode=self.TEXT_ENCODING)                except BadHeader as exc:                    info[""error""] = ""{}: {}"".format(exc.code, exc.content)                except Exception:                    pass        if html:            if search_pattern(self.OFFLINE_PATTERN, html) is not None:                info[""status""] = 1            elif search_pattern(self.TEMP_OFFLINE_PATTERN, html) is not None:                info[""status""] = 6            elif self.NAME_PATTERN:                m = search_pattern(self.NAME_PATTERN, html)                if m is not None:                    info[""status""] = 2                    info[""pattern""].update(m.groupdict())        if ""N"" in info[""pattern""]:            name = replace_patterns(info[""pattern""][""N""], self.NAME_REPLACEMENTS)            info[""name""] = parse.name(name)        return info",,"def get_info(self, url="""", html=""""):        info = super(SimpleDecrypter, self).get_info(url)        info.update(self.api_info(url))        if not html and info[""status""] != 2:            if not url:                info[""error""] = ""missing url""                info[""status""] = 1            elif info[""status""] in (3, 7):                try:                    html = self.load(url, cookies=self.COOKIES, decode=self.TEXT_ENCODING)                except BadHeader as exc:                    info[""error""] = ""{}: {}"".format(exc.code, exc.content)                except Exception:                    pass        if html:            if search_pattern(self.OFFLINE_PATTERN, html) is not None:                info[""status""] = 1            elif search_pattern(self.TEMP_OFFLINE_PATTERN, html) is not None:                info[""status""] = 6            elif self.NAME_PATTERN:                m = search_pattern(self.NAME_PATTERN, html)                if m is not None:                    info[""status""] = 2                    info[""pattern""].update(m.groupdict())        if ""N"" in info[""pattern""]:            name = replace_patterns(info[""pattern""][""N""], self.NAME_REPLACEMENTS)            info[""name""] = parse.name(name)        return info",190564ac-8bba-46c6-b593-d5526682c685
base,simple_decrypter.py,setup_base,137,150,"def setup_base(self):        account_name = self.classname.rsplit(""Folder"", 1)[0]        if self.account:            self.req = self.pyload.request_factory.get_request(                account_name, self.account.user            )            # NOTE: Don't call get_info here to reduce overhead            self.premium = self.account.info[""data""][""premium""]        else:            self.req = self.pyload.request_factory.get_request(account_name)            self.premium = False        super().setup_base()",,"def setup_base(self):        account_name = self.classname.rsplit(""Folder"", 1)[0]        if self.account:            self.req = self.pyload.request_factory.get_request(                account_name, self.account.user            )            # NOTE: Don't call get_info here to reduce overhead            self.premium = self.account.info[""data""][""premium""]        else:            self.req = self.pyload.request_factory.get_request(account_name)            self.premium = False        super().setup_base()",caa8a0d9-db04-4c93-a824-921e6fd465f5
base,simple_decrypter.py,load_account,153,157,"def load_account(self):        class_name = self.classname        self.__class__.__name__ = class_name.rsplit(""Folder"", 1)[0]        super().load_account()        self.__class__.__name__ = class_name",,"def load_account(self):        class_name = self.classname        self.__class__.__name__ = class_name.rsplit(""Folder"", 1)[0]        super().load_account()        self.__class__.__name__ = class_name",e14f4e8f-91ab-42fa-9225-7339722b07fb
base,simple_decrypter.py,handle_direct,159,164,"def handle_direct(self, pyfile):        self._preload()        link = self.last_header.get(""url"")        if re.match(self.__pattern__, link) is None:            self.links.append(link)",,"def handle_direct(self, pyfile):        self._preload()        link = self.last_header.get(""url"")        if re.match(self.__pattern__, link) is None:            self.links.append(link)",e76596c3-e4e3-49eb-bd75-e8fc15ea1487
base,simple_decrypter.py,_preload,166,172,"def _preload(self):        if self.data:            return        self.data = self.load(            self.pyfile.url, cookies=self.COOKIES, ref=False, decode=self.TEXT_ENCODING        )",,"def _preload(self):        if self.data:            return        self.data = self.load(            self.pyfile.url, cookies=self.COOKIES, ref=False, decode=self.TEXT_ENCODING        )",8f7e6789-6ad2-461e-a216-225640c12fa9
base,simple_decrypter.py,_prepare,174,199,"def _prepare(self):        self.direct_dl = False        if self.LOGIN_PREMIUM:            self.no_fallback = True            if not self.premium:                self.fail(self._(""Required premium account not found""))        if self.LOGIN_ACCOUNT and not self.account:            self.fail(self._(""Required account not found""))        self.req.set_option(""timeout"", 120)        if self.LINK_PATTERN:            if self.LINK_FREE_PATTERN is None:                self.LINK_FREE_PATTERN = self.LINK_PATTERN            if self.LINK_PREMIUM_PATTERN is None:                self.LINK_PREMIUM_PATTERN = self.LINK_PATTERN        if self.DIRECT_LINK is None:            self.direct_dl = bool(self.premium)        else:            self.direct_dl = self.DIRECT_LINK        self.pyfile.url = replace_patterns(self.pyfile.url, self.URL_REPLACEMENTS)",,"def _prepare(self):        self.direct_dl = False        if self.LOGIN_PREMIUM:            self.no_fallback = True            if not self.premium:                self.fail(self._(""Required premium account not found""))        if self.LOGIN_ACCOUNT and not self.account:            self.fail(self._(""Required account not found""))        self.req.set_option(""timeout"", 120)        if self.LINK_PATTERN:            if self.LINK_FREE_PATTERN is None:                self.LINK_FREE_PATTERN = self.LINK_PATTERN            if self.LINK_PREMIUM_PATTERN is None:                self.LINK_PREMIUM_PATTERN = self.LINK_PATTERN        if self.DIRECT_LINK is None:            self.direct_dl = bool(self.premium)        else:            self.direct_dl = self.DIRECT_LINK        self.pyfile.url = replace_patterns(self.pyfile.url, self.URL_REPLACEMENTS)",ade3b40d-9d2c-4cfb-89d1-8ad5c4e26e0e
base,simple_decrypter.py,decrypt,201,221,"def decrypt(self, pyfile):        self._prepare()        if self.direct_dl:            self.log_info(self._(""Looking for direct link...""))            self.handle_direct(pyfile)            if self.links or self.packages:                self.log_info(self._(""Direct link detected""))            else:                self.log_info(self._(""Direct link not found""))        if not self.links and not self.packages:            self._preload()            self.check_errors()            links = self.get_links()            self.links.extend(links)            if self.PAGES_PATTERN:                self.handle_pages(pyfile)",,"def decrypt(self, pyfile):        self._prepare()        if self.direct_dl:            self.log_info(self._(""Looking for direct link...""))            self.handle_direct(pyfile)            if self.links or self.packages:                self.log_info(self._(""Direct link detected""))            else:                self.log_info(self._(""Direct link not found""))        if not self.links and not self.packages:            self._preload()            self.check_errors()            links = self.get_links()            self.links.extend(links)            if self.PAGES_PATTERN:                self.handle_pages(pyfile)",bec3538b-a7a8-475d-99e5-d86b57aee5b8
base,simple_decrypter.py,handle_free,223,231,"def handle_free(self, pyfile):        if not self.LINK_FREE_PATTERN:            self.log_warning(self._(""Free decrypting not implemented""))        links = re.findall(self.LINK_FREE_PATTERN, self.data)        if not links:            self.error(self._(""Free decrypted link not found""))        else:            self.links.extend(links)",,"def handle_free(self, pyfile):        if not self.LINK_FREE_PATTERN:            self.log_warning(self._(""Free decrypting not implemented""))        links = re.findall(self.LINK_FREE_PATTERN, self.data)        if not links:            self.error(self._(""Free decrypted link not found""))        else:            self.links.extend(links)",74f01456-cdf1-463b-9eb1-25266dd61c2c
base,simple_decrypter.py,handle_premium,233,242,"def handle_premium(self, pyfile):        if not self.LINK_PREMIUM_PATTERN:            self.log_warning(self._(""Premium decrypting not implemented""))            self.restart(premium=False)        links = re.findall(self.LINK_PREMIUM_PATTERN, self.data)        if not links:            self.error(self._(""Premium decrypted link found""))        else:            self.links.extend(links)",,"def handle_premium(self, pyfile):        if not self.LINK_PREMIUM_PATTERN:            self.log_warning(self._(""Premium decrypting not implemented""))            self.restart(premium=False)        links = re.findall(self.LINK_PREMIUM_PATTERN, self.data)        if not links:            self.error(self._(""Premium decrypted link found""))        else:            self.links.extend(links)",b915e822-5242-495f-a6b8-65226e8e29b3
base,simple_decrypter.py,get_links,244,260,"def get_links(self):                if self.premium:            self.log_info(self._(""Decrypting as premium link...""))            self.handle_premium(self.pyfile)        elif not self.LOGIN_ACCOUNT:            self.log_info(self._(""Decrypting as free link...""))            self.handle_free(self.pyfile)        links = self.links        self.links = []        return links","Returns the links extracted from self.data You should override this only if it's
impossible to extract links using only the LINK_PATTERN.","def get_links(self):        """"""        Returns the links extracted from self.data You should override this only if it's        impossible to extract links using only the LINK_PATTERN.        """"""        if self.premium:            self.log_info(self._(""Decrypting as premium link...""))            self.handle_premium(self.pyfile)        elif not self.LOGIN_ACCOUNT:            self.log_info(self._(""Decrypting as free link...""))            self.handle_free(self.pyfile)        links = self.links        self.links = []        return links

Returns the links extracted from self.data You should override this only if it's
impossible to extract links using only the LINK_PATTERN.",5952d15a-ce9e-47ce-b798-09155e3fa645
base,simple_decrypter.py,load_page,262,263,"def load_page(self, number):        raise NotImplementedError",,"def load_page(self, number):        raise NotImplementedError",38ceff6c-d13c-46bb-8fa2-488f7d21c6c4
base,simple_decrypter.py,handle_pages,265,277,"def handle_pages(self, pyfile):        try:            pages = int(search_pattern(self.PAGES_PATTERN, self.data).group(1))        except (AttributeError, IndexError, ValueError):            pages = 1        links = self.links        for p in range(2, pages + 1):            self.data = self.load_page(p)            links.extend(self.get_links())        self.links = links",,"def handle_pages(self, pyfile):        try:            pages = int(search_pattern(self.PAGES_PATTERN, self.data).group(1))        except (AttributeError, IndexError, ValueError):            pages = 1        links = self.links        for p in range(2, pages + 1):            self.data = self.load_page(p)            links.extend(self.get_links())        self.links = links",880fb96b-b09c-4f05-b216-c4985d63c353
base,simple_decrypter.py,check_errors,279,380,"def check_errors(self, data=None):        self.log_info(self._(""Checking for link errors...""))        data = data or self.data        if not data:            self.log_warning(self._(""No data to check""))            return        elif isinstance(data, bytes):            self.log_debug(self._(""No check on binary data""))            return        if search_pattern(self.IP_BLOCKED_PATTERN, data):            self.fail(self._(""Connection from your current IP address is not allowed""))        elif not self.premium:            if search_pattern(self.PREMIUM_ONLY_PATTERN, data):                self.fail(self._(""Link can be decrypted by premium users only""))            elif search_pattern(self.SIZE_LIMIT_PATTERN, data):                self.fail(self._(""Link list too large for free decrypt""))        if self.ERROR_PATTERN:            m = search_pattern(self.ERROR_PATTERN, data)            if m is not None:                try:                    errmsg = m.group(1)                except (AttributeError, IndexError):                    errmsg = m.group(0)                finally:                    errmsg = re.sub(r""<.*?>"", "" "", errmsg.strip())                self.info[""error""] = errmsg                self.log_warning(errmsg)                if search_pattern(self.TEMP_OFFLINE_PATTERN, errmsg):                    self.temp_offline()                elif search_pattern(self.OFFLINE_PATTERN, errmsg):                    self.offline()                elif re.search(r""limit|wait|slot"", errmsg, re.I):                    wait_time = parse.seconds(errmsg)                    self.wait(                        wait_time,                        reconnect=wait_time > self.config.get(""max_wait"", 10) * 60,                    )                    self.restart(self._(""Download limit exceeded""))                elif re.search(r""country|ip|region|nation"", errmsg, re.I):                    self.fail(                        self._(""Connection from your current IP address is not allowed"")                    )                elif re.search(r""captcha|code"", errmsg, re.I):                    self.retry_captcha()                elif re.search(r""countdown|expired"", errmsg, re.I):                    self.retry(10, 60, self._(""Link expired""))                elif re.search(r""503|maint(e|ai)nance|temp|mirror"", errmsg, re.I):                    self.temp_offline()                elif re.search(r""up to|size"", errmsg, re.I):                    self.fail(self._(""Link list too large for free decrypt""))                elif re.search(                    r""404|sorry|offline|delet|remov|(no(t|thing)?|sn\'t) (found|(longer )?(available|exist))"",                    errmsg,                    re.I,                ):                    self.offline()                elif re.search(r""filename"", errmsg, re.I):                    self.fail(self._(""Invalid url""))                elif re.search(r""premium"", errmsg, re.I):                    self.fail(self._(""Link can be decrypted by premium users only""))                else:                    self.wait(60, reconnect=True)                    self.restart(errmsg)        elif self.WAIT_PATTERN:            m = search_pattern(self.WAIT_PATTERN, data)            if m is not None:                try:                    waitmsg = m.group(1).strip()                except (AttributeError, IndexError):                    waitmsg = m.group(0).strip()                wait_time = parse.seconds(waitmsg)                self.wait(                    wait_time,                    reconnect=wait_time > self.config.get(""max_wait"", 10) * 60,                )        self.log_info(self._(""No errors found""))        self.info.pop(""error"", None)",,"def check_errors(self, data=None):        self.log_info(self._(""Checking for link errors...""))        data = data or self.data        if not data:            self.log_warning(self._(""No data to check""))            return        elif isinstance(data, bytes):            self.log_debug(self._(""No check on binary data""))            return        if search_pattern(self.IP_BLOCKED_PATTERN, data):            self.fail(self._(""Connection from your current IP address is not allowed""))        elif not self.premium:            if search_pattern(self.PREMIUM_ONLY_PATTERN, data):                self.fail(self._(""Link can be decrypted by premium users only""))            elif search_pattern(self.SIZE_LIMIT_PATTERN, data):                self.fail(self._(""Link list too large for free decrypt""))        if self.ERROR_PATTERN:            m = search_pattern(self.ERROR_PATTERN, data)            if m is not None:                try:                    errmsg = m.group(1)                except (AttributeError, IndexError):                    errmsg = m.group(0)                finally:                    errmsg = re.sub(r""<.*?>"", "" "", errmsg.strip())                self.info[""error""] = errmsg                self.log_warning(errmsg)                if search_pattern(self.TEMP_OFFLINE_PATTERN, errmsg):                    self.temp_offline()                elif search_pattern(self.OFFLINE_PATTERN, errmsg):                    self.offline()                elif re.search(r""limit|wait|slot"", errmsg, re.I):                    wait_time = parse.seconds(errmsg)                    self.wait(                        wait_time,                        reconnect=wait_time > self.config.get(""max_wait"", 10) * 60,                    )                    self.restart(self._(""Download limit exceeded""))                elif re.search(r""country|ip|region|nation"", errmsg, re.I):                    self.fail(                        self._(""Connection from your current IP address is not allowed"")                    )                elif re.search(r""captcha|code"", errmsg, re.I):                    self.retry_captcha()                elif re.search(r""countdown|expired"", errmsg, re.I):                    self.retry(10, 60, self._(""Link expired""))                elif re.search(r""503|maint(e|ai)nance|temp|mirror"", errmsg, re.I):                    self.temp_offline()                elif re.search(r""up to|size"", errmsg, re.I):                    self.fail(self._(""Link list too large for free decrypt""))                elif re.search(                    r""404|sorry|offline|delet|remov|(no(t|thing)?|sn\'t) (found|(longer )?(available|exist))"",                    errmsg,                    re.I,                ):                    self.offline()                elif re.search(r""filename"", errmsg, re.I):                    self.fail(self._(""Invalid url""))                elif re.search(r""premium"", errmsg, re.I):                    self.fail(self._(""Link can be decrypted by premium users only""))                else:                    self.wait(60, reconnect=True)                    self.restart(errmsg)        elif self.WAIT_PATTERN:            m = search_pattern(self.WAIT_PATTERN, data)            if m is not None:                try:                    waitmsg = m.group(1).strip()                except (AttributeError, IndexError):                    waitmsg = m.group(0).strip()                wait_time = parse.seconds(waitmsg)                self.wait(                    wait_time,                    reconnect=wait_time > self.config.get(""max_wait"", 10) * 60,                )        self.log_info(self._(""No errors found""))        self.info.pop(""error"", None)",c542d317-646b-4bbe-92a2-d9502e87458d
base,simple_downloader.py,api_info,140,141,"def api_info(self, url):        return {}",,"def api_info(self, url):        return {}",61c9864d-f0dc-4d35-8ee5-2cc3bf3c216c
base,simple_downloader.py,get_info,143,210,"def get_info(self, url="""", html=""""):        info = super(SimpleDownloader, self).get_info(url)        info.update(self.api_info(url))        if not html and info[""status""] != 2:            if not url:                info[""error""] = ""missing url""                info[""status""] = 1            elif info[""status""] in (3, 7):                try:                    html = self.load(url, cookies=self.COOKIES, decode=self.TEXT_ENCODING)                except BadHeader as exc:                    info[""error""] = ""{}: {}"".format(exc.code, exc.content)                except Exception:                    pass        if html and info[""status""] in (3, 7):            if search_pattern(self.OFFLINE_PATTERN, html) is not None:                info[""status""] = 1            elif search_pattern(self.TEMP_OFFLINE_PATTERN, html) is not None:                info[""status""] = 6            else:                for pattern in (                    ""INFO_PATTERN"",                    ""NAME_PATTERN"",                    ""SIZE_PATTERN"",                    ""HASHSUM_PATTERN"",                ):                    try:                        attr = getattr(self, pattern)                        pdict = search_pattern(attr, html).groupdict()                        if all(True for k in pdict if k not in info[""pattern""]):                            info[""pattern""].update(pdict)                    except Exception:                        continue                    else:                        info[""status""] = 2        if ""N"" in info[""pattern""]:            name = replace_patterns(info[""pattern""][""N""], self.NAME_REPLACEMENTS)            info[""name""] = parse.name(name)        if ""S"" in info[""pattern""]:            size = replace_patterns(                info[""pattern""][""S""] + info[""pattern""][""U""]                if ""U"" in info[""pattern""]                else info[""pattern""][""S""],                self.SIZE_REPLACEMENTS,            )            info[""size""] = parse.bytesize(size)        elif isinstance(info[""size""], str):            unit = info[""units""] if ""units"" in info else None            info[""size""] = parse.bytesize(info[""size""], unit)        if ""H"" in info[""pattern""]:            hash_type = info[""pattern""][""H""].strip(""-"").upper()            info[""hash""][hash_type] = info[""pattern""][""D""]        return info",,"def get_info(self, url="""", html=""""):        info = super(SimpleDownloader, self).get_info(url)        info.update(self.api_info(url))        if not html and info[""status""] != 2:            if not url:                info[""error""] = ""missing url""                info[""status""] = 1            elif info[""status""] in (3, 7):                try:                    html = self.load(url, cookies=self.COOKIES, decode=self.TEXT_ENCODING)                except BadHeader as exc:                    info[""error""] = ""{}: {}"".format(exc.code, exc.content)                except Exception:                    pass        if html and info[""status""] in (3, 7):            if search_pattern(self.OFFLINE_PATTERN, html) is not None:                info[""status""] = 1            elif search_pattern(self.TEMP_OFFLINE_PATTERN, html) is not None:                info[""status""] = 6            else:                for pattern in (                    ""INFO_PATTERN"",                    ""NAME_PATTERN"",                    ""SIZE_PATTERN"",                    ""HASHSUM_PATTERN"",                ):                    try:                        attr = getattr(self, pattern)                        pdict = search_pattern(attr, html).groupdict()                        if all(True for k in pdict if k not in info[""pattern""]):                            info[""pattern""].update(pdict)                    except Exception:                        continue                    else:                        info[""status""] = 2        if ""N"" in info[""pattern""]:            name = replace_patterns(info[""pattern""][""N""], self.NAME_REPLACEMENTS)            info[""name""] = parse.name(name)        if ""S"" in info[""pattern""]:            size = replace_patterns(                info[""pattern""][""S""] + info[""pattern""][""U""]                if ""U"" in info[""pattern""]                else info[""pattern""][""S""],                self.SIZE_REPLACEMENTS,            )            info[""size""] = parse.bytesize(size)        elif isinstance(info[""size""], str):            unit = info[""units""] if ""units"" in info else None            info[""size""] = parse.bytesize(info[""size""], unit)        if ""H"" in info[""pattern""]:            hash_type = info[""pattern""][""H""].strip(""-"").upper()            info[""hash""][hash_type] = info[""pattern""][""D""]        return info",295f5487-3dca-4473-8a4e-01bb0f59fecc
base,simple_downloader.py,setup,212,214,def setup(self):        self.multi_dl = self.premium        self.resume_download = self.premium,,def setup(self):        self.multi_dl = self.premium        self.resume_download = self.premium,78f9cf6a-fa7e-4ea9-aa91-87834ab9906f
base,simple_downloader.py,_prepare,216,243,"def _prepare(self):        self.link = """"        self.direct_dl = False        if self.LOGIN_PREMIUM:            self.no_fallback = True            if not self.premium:                self.fail(self._(""Required premium account not found""))        if self.LOGIN_ACCOUNT and not self.account:            self.fail(self._(""Required account not found""))        self.req.set_option(""timeout"", 120)        if self.LINK_PATTERN:            if self.LINK_FREE_PATTERN is None:                self.LINK_FREE_PATTERN = self.LINK_PATTERN            if self.LINK_PREMIUM_PATTERN is None:                self.LINK_PREMIUM_PATTERN = self.LINK_PATTERN        if self.DIRECT_LINK is None:            self.direct_dl = bool(self.premium)        else:            self.direct_dl = self.DIRECT_LINK        self.pyfile.url = replace_patterns(self.pyfile.url, self.URL_REPLACEMENTS)",,"def _prepare(self):        self.link = """"        self.direct_dl = False        if self.LOGIN_PREMIUM:            self.no_fallback = True            if not self.premium:                self.fail(self._(""Required premium account not found""))        if self.LOGIN_ACCOUNT and not self.account:            self.fail(self._(""Required account not found""))        self.req.set_option(""timeout"", 120)        if self.LINK_PATTERN:            if self.LINK_FREE_PATTERN is None:                self.LINK_FREE_PATTERN = self.LINK_PATTERN            if self.LINK_PREMIUM_PATTERN is None:                self.LINK_PREMIUM_PATTERN = self.LINK_PATTERN        if self.DIRECT_LINK is None:            self.direct_dl = bool(self.premium)        else:            self.direct_dl = self.DIRECT_LINK        self.pyfile.url = replace_patterns(self.pyfile.url, self.URL_REPLACEMENTS)",2285c23c-3cea-4992-a56f-b357694d8237
base,simple_downloader.py,_preload,245,251,"def _preload(self):        if self.data:            return        self.data = self.load(            self.pyfile.url, cookies=self.COOKIES, ref=False, decode=self.TEXT_ENCODING        )",,"def _preload(self):        if self.data:            return        self.data = self.load(            self.pyfile.url, cookies=self.COOKIES, ref=False, decode=self.TEXT_ENCODING        )",d2b92402-b20a-4a83-b16c-4af613c542bb
base,simple_downloader.py,process,253,286,"def process(self, pyfile):        self._prepare()        if not self.link and self.direct_dl:            self.log_info(self._(""Looking for direct download link...""))            self.handle_direct(pyfile)            if self.link:                self.log_info(self._(""Direct download link detected""))            else:                self.log_info(self._(""Direct download link not found""))        if not self.link:            self._preload()            self.check_errors()            if self.info.get(""status"", 7) != 2:                super(SimpleDownloader, self).grab_info()                self.check_status()                self.pyfile.set_status(""starting"")                self.check_duplicates()            out_of_traffic = self.CHECK_TRAFFIC and self.out_of_traffic()            if self.premium and not out_of_traffic:                self.log_info(self._(""Processing as premium download...""))                self.handle_premium(pyfile)            elif not self.LOGIN_ACCOUNT or not out_of_traffic:                self.log_info(self._(""Processing as free download...""))                self.handle_free(pyfile)        if self.link and not self.last_download:            self.log_info(self._(""Downloading file...""))            self.download(self.link, disposition=self.DISPOSITION)",,"def process(self, pyfile):        self._prepare()        if not self.link and self.direct_dl:            self.log_info(self._(""Looking for direct download link...""))            self.handle_direct(pyfile)            if self.link:                self.log_info(self._(""Direct download link detected""))            else:                self.log_info(self._(""Direct download link not found""))        if not self.link:            self._preload()            self.check_errors()            if self.info.get(""status"", 7) != 2:                super(SimpleDownloader, self).grab_info()                self.check_status()                self.pyfile.set_status(""starting"")                self.check_duplicates()            out_of_traffic = self.CHECK_TRAFFIC and self.out_of_traffic()            if self.premium and not out_of_traffic:                self.log_info(self._(""Processing as premium download...""))                self.handle_premium(pyfile)            elif not self.LOGIN_ACCOUNT or not out_of_traffic:                self.log_info(self._(""Processing as free download...""))                self.handle_free(pyfile)        if self.link and not self.last_download:            self.log_info(self._(""Downloading file...""))            self.download(self.link, disposition=self.DISPOSITION)",2cc4f1b0-3b4d-4c9e-aa1e-d9736aeb12e3
base,simple_downloader.py,_check_download,288,290,def _check_download(self):        super()._check_download()        self.check_download(),,def _check_download(self):        super()._check_download()        self.check_download(),41e743b3-7e22-4784-afdc-752e273e728e
base,simple_downloader.py,check_download,292,326,"def check_download(self):        self.log_info(self._(""Checking file (with built-in rules)...""))        for r, p in self.FILE_ERRORS:            errmsg = self.scan_download({r: re.compile(p)})            if errmsg is not None:                errmsg = errmsg.strip().capitalize()                try:                    errmsg += "" | "" + self.last_check.group(1).strip()                except Exception:                    pass                self.log_warning(                    self._(""Check result: "") + errmsg,                    self._(""Waiting 1 minute and retry""),                )                self.wait(60, reconnect=True)                self.restart(errmsg)        else:            if self.CHECK_FILE:                self.log_info(self._(""Checking file (with custom rules)...""))                try:                    with open(os.fsdecode(self.last_download), mode=""r"", encoding='utf-8') as fp:                        self.data = fp.read(1_048_576)  # TODO: Recheck in 0.6.x                except UnicodeDecodeError:                    with open(os.fsdecode(self.last_download), mode=""r"", encoding='iso-8859-1') as fp:                        self.data = fp.read(1_048_576)  # TODO: Recheck in 0.6.x                self.check_errors()            else:                self.log_info(self._(""No errors found""))",,"def check_download(self):        self.log_info(self._(""Checking file (with built-in rules)...""))        for r, p in self.FILE_ERRORS:            errmsg = self.scan_download({r: re.compile(p)})            if errmsg is not None:                errmsg = errmsg.strip().capitalize()                try:                    errmsg += "" | "" + self.last_check.group(1).strip()                except Exception:                    pass                self.log_warning(                    self._(""Check result: "") + errmsg,                    self._(""Waiting 1 minute and retry""),                )                self.wait(60, reconnect=True)                self.restart(errmsg)        else:            if self.CHECK_FILE:                self.log_info(self._(""Checking file (with custom rules)...""))                try:                    with open(os.fsdecode(self.last_download), mode=""r"", encoding='utf-8') as fp:                        self.data = fp.read(1_048_576)  # TODO: Recheck in 0.6.x                except UnicodeDecodeError:                    with open(os.fsdecode(self.last_download), mode=""r"", encoding='iso-8859-1') as fp:                        self.data = fp.read(1_048_576)  # TODO: Recheck in 0.6.x                self.check_errors()            else:                self.log_info(self._(""No errors found""))",57f67571-c77c-4cbd-8106-da6da365902f
base,simple_downloader.py,check_errors,328,454,"def check_errors(self, data=None):        self.log_info(self._(""Checking for link errors...""))        data = data or self.data        if not data:            self.log_warning(self._(""No data to check""))            return        elif isinstance(data, bytes):            self.log_debug(self._(""No check on binary data""))            return        if search_pattern(self.IP_BLOCKED_PATTERN, data):            self.fail(self._(""Connection from your current IP address is not allowed""))        elif not self.premium:            if search_pattern(self.PREMIUM_ONLY_PATTERN, data):                self.fail(self._(""File can be downloaded by premium users only""))            elif search_pattern(self.SIZE_LIMIT_PATTERN, data):                self.fail(self._(""File too large for free download""))            elif self.DL_LIMIT_PATTERN:                m = search_pattern(self.DL_LIMIT_PATTERN, data)                if m is not None:                    try:                        errmsg = m.group(1)                    except (AttributeError, IndexError):                        errmsg = m.group(0)                    finally:                        errmsg = re.sub(r""<.*?>"", "" "", errmsg.strip())                    self.info[""error""] = errmsg                    self.log_warning(errmsg)                    wait_time = parse.seconds(errmsg)                    self.wait(                        wait_time,                        reconnect=wait_time > self.config.get(""max_wait"", 10) * 60,                    )                    self.restart(self._(""Download limit exceeded""))        if search_pattern(self.HAPPY_HOUR_PATTERN, data):            self.multi_dl = True        if self.ERROR_PATTERN:            m = search_pattern(self.ERROR_PATTERN, data)            if m is not None:                try:                    errmsg = m.group(1).strip()                except (AttributeError, IndexError):                    errmsg = m.group(0).strip()                finally:                    errmsg = re.sub(r""<.*?>"", "" "", errmsg)                self.info[""error""] = errmsg                self.log_warning(errmsg)                if search_pattern(self.TEMP_OFFLINE_PATTERN, errmsg):                    self.temp_offline()                elif search_pattern(self.OFFLINE_PATTERN, errmsg):                    self.offline()                elif re.search(r""limit|wait|slot"", errmsg, re.I):                    wait_time = parse.seconds(errmsg)                    self.wait(                        wait_time,                        reconnect=wait_time > self.config.get(""max_wait"", 10) * 60,                    )                    self.restart(self._(""Download limit exceeded""))                elif re.search(r""country|ip|region|nation"", errmsg, re.I):                    self.fail(                        self._(""Connection from your current IP address is not allowed"")                    )                elif re.search(r""captcha|code"", errmsg, re.I):                    self.retry_captcha()                elif re.search(r""countdown|expired"", errmsg, re.I):                    self.retry(10, 60, self._(""Link expired""))                elif re.search(r""503|maint(e|ai)nance|temp|mirror"", errmsg, re.I):                    self.temp_offline()                elif re.search(r""up to|size"", errmsg, re.I):                    self.fail(self._(""File too large for free download""))                elif re.search(                    r""404|sorry|offline|delet|remov|(no(t|thing)?|sn\'t) (found|(longer )?(available|exist))"",                    errmsg,                    re.I,                ):                    self.offline()                elif re.search(r""filename"", errmsg, re.I):                    self.fail(self._(""Invalid url""))                elif re.search(r""premium"", errmsg, re.I):                    self.fail(self._(""File can be downloaded by premium users only""))                else:                    self.wait(60, reconnect=True)                    self.restart(errmsg)        elif self.WAIT_PATTERN:            m = search_pattern(self.WAIT_PATTERN, data)            if m is not None:                try:                    waitmsg = m.group(1).strip()                except (AttributeError, IndexError):                    waitmsg = m.group(0).strip()                wait_time = parse.seconds(waitmsg)                self.wait(                    wait_time,                    reconnect=wait_time > self.config.get(""max_wait"", 10) * 60,                )        self.log_info(self._(""No errors found""))        self.info.pop(""error"", None)",,"def check_errors(self, data=None):        self.log_info(self._(""Checking for link errors...""))        data = data or self.data        if not data:            self.log_warning(self._(""No data to check""))            return        elif isinstance(data, bytes):            self.log_debug(self._(""No check on binary data""))            return        if search_pattern(self.IP_BLOCKED_PATTERN, data):            self.fail(self._(""Connection from your current IP address is not allowed""))        elif not self.premium:            if search_pattern(self.PREMIUM_ONLY_PATTERN, data):                self.fail(self._(""File can be downloaded by premium users only""))            elif search_pattern(self.SIZE_LIMIT_PATTERN, data):                self.fail(self._(""File too large for free download""))            elif self.DL_LIMIT_PATTERN:                m = search_pattern(self.DL_LIMIT_PATTERN, data)                if m is not None:                    try:                        errmsg = m.group(1)                    except (AttributeError, IndexError):                        errmsg = m.group(0)                    finally:                        errmsg = re.sub(r""<.*?>"", "" "", errmsg.strip())                    self.info[""error""] = errmsg                    self.log_warning(errmsg)                    wait_time = parse.seconds(errmsg)                    self.wait(                        wait_time,                        reconnect=wait_time > self.config.get(""max_wait"", 10) * 60,                    )                    self.restart(self._(""Download limit exceeded""))        if search_pattern(self.HAPPY_HOUR_PATTERN, data):            self.multi_dl = True        if self.ERROR_PATTERN:            m = search_pattern(self.ERROR_PATTERN, data)            if m is not None:                try:                    errmsg = m.group(1).strip()                except (AttributeError, IndexError):                    errmsg = m.group(0).strip()                finally:                    errmsg = re.sub(r""<.*?>"", "" "", errmsg)                self.info[""error""] = errmsg                self.log_warning(errmsg)                if search_pattern(self.TEMP_OFFLINE_PATTERN, errmsg):                    self.temp_offline()                elif search_pattern(self.OFFLINE_PATTERN, errmsg):                    self.offline()                elif re.search(r""limit|wait|slot"", errmsg, re.I):                    wait_time = parse.seconds(errmsg)                    self.wait(                        wait_time,                        reconnect=wait_time > self.config.get(""max_wait"", 10) * 60,                    )                    self.restart(self._(""Download limit exceeded""))                elif re.search(r""country|ip|region|nation"", errmsg, re.I):                    self.fail(                        self._(""Connection from your current IP address is not allowed"")                    )                elif re.search(r""captcha|code"", errmsg, re.I):                    self.retry_captcha()                elif re.search(r""countdown|expired"", errmsg, re.I):                    self.retry(10, 60, self._(""Link expired""))                elif re.search(r""503|maint(e|ai)nance|temp|mirror"", errmsg, re.I):                    self.temp_offline()                elif re.search(r""up to|size"", errmsg, re.I):                    self.fail(self._(""File too large for free download""))                elif re.search(                    r""404|sorry|offline|delet|remov|(no(t|thing)?|sn\'t) (found|(longer )?(available|exist))"",                    errmsg,                    re.I,                ):                    self.offline()                elif re.search(r""filename"", errmsg, re.I):                    self.fail(self._(""Invalid url""))                elif re.search(r""premium"", errmsg, re.I):                    self.fail(self._(""File can be downloaded by premium users only""))                else:                    self.wait(60, reconnect=True)                    self.restart(errmsg)        elif self.WAIT_PATTERN:            m = search_pattern(self.WAIT_PATTERN, data)            if m is not None:                try:                    waitmsg = m.group(1).strip()                except (AttributeError, IndexError):                    waitmsg = m.group(0).strip()                wait_time = parse.seconds(waitmsg)                self.wait(                    wait_time,                    reconnect=wait_time > self.config.get(""max_wait"", 10) * 60,                )        self.log_info(self._(""No errors found""))        self.info.pop(""error"", None)",65fc7691-0bc5-4dc8-901b-56d577efaf38
base,simple_downloader.py,get_file_info,457,460,def get_file_info(self):        self.info.clear()        self.grab_info()        return self.info,,def get_file_info(self):        self.info.clear()        self.grab_info()        return self.info,4718ba4d-ebd9-41c5-b501-162d8b080eab
base,simple_downloader.py,grab_info,462,464,"def grab_info(self):        if self.info.get(""status"", 7) != 2:            self.pyfile.name = parse.name(self.pyfile.url)",,"def grab_info(self):        if self.info.get(""status"", 7) != 2:            self.pyfile.name = parse.name(self.pyfile.url)",577f508c-2305-4b96-a570-53b919bdee41
base,simple_downloader.py,handle_direct,466,473,"def handle_direct(self, pyfile):        link = self.isresource(pyfile.url)        if link:            pyfile.name = parse.name(link)            self.link = pyfile.url        else:            self.link = None",,"def handle_direct(self, pyfile):        link = self.isresource(pyfile.url)        if link:            pyfile.name = parse.name(link)            self.link = pyfile.url        else:            self.link = None",3e664ed4-4eec-49fb-942c-67cc032e88c5
base,simple_downloader.py,handle_free,475,483,"def handle_free(self, pyfile):        if not self.LINK_FREE_PATTERN:            self.fail(self._(""Free download not implemented""))        m = search_pattern(self.LINK_FREE_PATTERN, self.data)        if m is None:            self.error(self._(""Free download link not found""))        else:            self.link = m.group(1)",,"def handle_free(self, pyfile):        if not self.LINK_FREE_PATTERN:            self.fail(self._(""Free download not implemented""))        m = search_pattern(self.LINK_FREE_PATTERN, self.data)        if m is None:            self.error(self._(""Free download link not found""))        else:            self.link = m.group(1)",dbc2b5fe-3134-462e-ab5b-d57055fa4f43
base,simple_downloader.py,handle_premium,485,494,"def handle_premium(self, pyfile):        if not self.LINK_PREMIUM_PATTERN:            self.log_warning(self._(""Premium download not implemented""))            self.restart(premium=False)        m = search_pattern(self.LINK_PREMIUM_PATTERN, self.data)        if m is None:            self.error(self._(""Premium download link not found""))        else:            self.link = m.group(1)",,"def handle_premium(self, pyfile):        if not self.LINK_PREMIUM_PATTERN:            self.log_warning(self._(""Premium download not implemented""))            self.restart(premium=False)        m = search_pattern(self.LINK_PREMIUM_PATTERN, self.data)        if m is None:            self.error(self._(""Premium download link not found""))        else:            self.link = m.group(1)",d8b3f25b-87b7-4697-9fa0-dfa1c63a6cdb
base,xfs_account.py,_set_xfs_cookie,55,60,"def _set_xfs_cookie(self):        cookie = (self.PLUGIN_DOMAIN, ""lang"", ""english"")        if isinstance(self.COOKIES, list) and cookie not in self.COOKIES:            self.COOKIES.insert(cookie)        else:            set_cookie(self.req.cj, *cookie)",,"def _set_xfs_cookie(self):        cookie = (self.PLUGIN_DOMAIN, ""lang"", ""english"")        if isinstance(self.COOKIES, list) and cookie not in self.COOKIES:            self.COOKIES.insert(cookie)        else:            set_cookie(self.req.cj, *cookie)",2608f65c-cfab-4a11-baf4-35fe3303fc11
base,xfs_account.py,setup,62,73,"def setup(self):        if not self.PLUGIN_DOMAIN:            self.fail_login(self._(""Missing PLUGIN DOMAIN""))        if not self.PLUGIN_URL:            self.PLUGIN_URL = ""http://www.{}/"".format(self.PLUGIN_DOMAIN)        if not self.LOGIN_URL:            self.LOGIN_URL = urllib.parse.urljoin(self.PLUGIN_URL, ""login.html"")        if self.COOKIES:            self._set_xfs_cookie()",,"def setup(self):        if not self.PLUGIN_DOMAIN:            self.fail_login(self._(""Missing PLUGIN DOMAIN""))        if not self.PLUGIN_URL:            self.PLUGIN_URL = ""http://www.{}/"".format(self.PLUGIN_DOMAIN)        if not self.LOGIN_URL:            self.LOGIN_URL = urllib.parse.urljoin(self.PLUGIN_URL, ""login.html"")        if self.COOKIES:            self._set_xfs_cookie()",082a5bb7-a42b-48a9-8a09-03b061aa395d
base,xfs_account.py,grab_info,79,185,"def grab_info(self, user, password, data):        validuntil = None        trafficleft = None        leechtraffic = None        premium = None        if not self.PLUGIN_URL:  # TODO: Remove in 0.6.x            return        self.data = self.load(            self.PLUGIN_URL, get={""op"": ""my_account""}, cookies=self.COOKIES        )        premium = True if search_pattern(self.PREMIUM_PATTERN, self.data) is not None else False        m = search_pattern(self.VALID_UNTIL_PATTERN, self.data)        if m is not None:            expiredate = m.group(1).strip()            self.log_debug(""Expire date: "" + expiredate)            previous_locale = locale.getlocale(locale.LC_TIME)            try:                locale.setlocale(locale.LC_TIME, ""en_US.UTF-8"")                validuntil = time.mktime(time.strptime(expiredate, ""%d %B %Y""))            except Exception as exc:                self.log_error(exc)            else:                self.log_debug(f""Valid until: {validuntil}"")                if validuntil > time.mktime(time.gmtime()):                    premium = True                    trafficleft = -1                else:                    premium = False                    validuntil = None  #: Registered account type (not premium)            finally:                locale.setlocale(locale.LC_TIME, previous_locale)        else:            self.log_debug(""VALID UNTIL PATTERN not found"")        m = search_pattern(self.TRAFFIC_LEFT_PATTERN, self.data)        if m is not None:            try:                traffic = m.groupdict()                size = traffic[""S""]                if ""nlimited"" in size:                    trafficleft = -1                    if validuntil is None:                        validuntil = -1                else:                    if ""U"" in traffic:                        unit = traffic[""U""]                    elif isinstance(self.TRAFFIC_LEFT_UNIT, str):                        unit = self.TRAFFIC_LEFT_UNIT                    else:                        unit = """"                    trafficleft = max(0, self.parse_traffic(size, unit))            except Exception as exc:                self.log_error(exc)        else:            self.log_debug(""TRAFFIC LEFT PATTERN not found"")        leech = [            m.groupdict() for m in re.finditer(self.LEECH_TRAFFIC_PATTERN, self.data)        ]        if leech:            leechtraffic = 0            try:                for traffic in leech:                    size = traffic[""S""]                    if ""nlimited"" in size:                        leechtraffic = -1                        if validuntil is None:                            validuntil = -1                        break                    else:                        if ""U"" in traffic:                            unit = traffic[""U""]                        elif isinstance(self.LEECH_TRAFFIC_UNIT, str):                            unit = self.LEECH_TRAFFIC_UNIT                        else:                            unit = """"                        leechtraffic += self.parse_traffic(size + unit)            except Exception as exc:                self.log_error(exc)        else:            self.log_debug(""LEECH TRAFFIC PATTERN not found"")        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""leechtraffic"": leechtraffic,            ""premium"": premium,        }",,"def grab_info(self, user, password, data):        validuntil = None        trafficleft = None        leechtraffic = None        premium = None        if not self.PLUGIN_URL:  # TODO: Remove in 0.6.x            return        self.data = self.load(            self.PLUGIN_URL, get={""op"": ""my_account""}, cookies=self.COOKIES        )        premium = True if search_pattern(self.PREMIUM_PATTERN, self.data) is not None else False        m = search_pattern(self.VALID_UNTIL_PATTERN, self.data)        if m is not None:            expiredate = m.group(1).strip()            self.log_debug(""Expire date: "" + expiredate)            previous_locale = locale.getlocale(locale.LC_TIME)            try:                locale.setlocale(locale.LC_TIME, ""en_US.UTF-8"")                validuntil = time.mktime(time.strptime(expiredate, ""%d %B %Y""))            except Exception as exc:                self.log_error(exc)            else:                self.log_debug(f""Valid until: {validuntil}"")                if validuntil > time.mktime(time.gmtime()):                    premium = True                    trafficleft = -1                else:                    premium = False                    validuntil = None  #: Registered account type (not premium)            finally:                locale.setlocale(locale.LC_TIME, previous_locale)        else:            self.log_debug(""VALID UNTIL PATTERN not found"")        m = search_pattern(self.TRAFFIC_LEFT_PATTERN, self.data)        if m is not None:            try:                traffic = m.groupdict()                size = traffic[""S""]                if ""nlimited"" in size:                    trafficleft = -1                    if validuntil is None:                        validuntil = -1                else:                    if ""U"" in traffic:                        unit = traffic[""U""]                    elif isinstance(self.TRAFFIC_LEFT_UNIT, str):                        unit = self.TRAFFIC_LEFT_UNIT                    else:                        unit = """"                    trafficleft = max(0, self.parse_traffic(size, unit))            except Exception as exc:                self.log_error(exc)        else:            self.log_debug(""TRAFFIC LEFT PATTERN not found"")        leech = [            m.groupdict() for m in re.finditer(self.LEECH_TRAFFIC_PATTERN, self.data)        ]        if leech:            leechtraffic = 0            try:                for traffic in leech:                    size = traffic[""S""]                    if ""nlimited"" in size:                        leechtraffic = -1                        if validuntil is None:                            validuntil = -1                        break                    else:                        if ""U"" in traffic:                            unit = traffic[""U""]                        elif isinstance(self.LEECH_TRAFFIC_UNIT, str):                            unit = self.LEECH_TRAFFIC_UNIT                        else:                            unit = """"                        leechtraffic += self.parse_traffic(size + unit)            except Exception as exc:                self.log_error(exc)        else:            self.log_debug(""LEECH TRAFFIC PATTERN not found"")        return {            ""validuntil"": validuntil,            ""trafficleft"": trafficleft,            ""leechtraffic"": leechtraffic,            ""premium"": premium,        }",65fad603-1d6d-4466-a6f1-d8ad9d7e8198
base,xfs_account.py,signin,187,206,"def signin(self, user, password, data):        self.data = self.load(self.LOGIN_URL, cookies=self.COOKIES)        if search_pattern(self.LOGIN_SKIP_PATTERN, self.data):            self.skip_login()        action, inputs = parse_html_form('name=""FL""', self.data)        if not inputs:            inputs = {""op"": ""login"", ""redirect"": self.PLUGIN_URL}        inputs.update({""login"": user, ""password"": password})        if action:            url = urllib.parse.urljoin(self.LOGIN_URL, action)        else:            url = self.LOGIN_URL        self.data = self.load(url, post=inputs, cookies=self.COOKIES)        self.check_errors()",,"def signin(self, user, password, data):        self.data = self.load(self.LOGIN_URL, cookies=self.COOKIES)        if search_pattern(self.LOGIN_SKIP_PATTERN, self.data):            self.skip_login()        action, inputs = parse_html_form('name=""FL""', self.data)        if not inputs:            inputs = {""op"": ""login"", ""redirect"": self.PLUGIN_URL}        inputs.update({""login"": user, ""password"": password})        if action:            url = urllib.parse.urljoin(self.LOGIN_URL, action)        else:            url = self.LOGIN_URL        self.data = self.load(url, post=inputs, cookies=self.COOKIES)        self.check_errors()",533037fd-9f02-4d3c-91db-a26609309553
base,xfs_account.py,check_errors,208,248,"def check_errors(self, data=None):        self.log_info(self._(""Checking for link errors...""))        data = data or self.data        if not data:            self.log_warning(self._(""No data to check""))            return        m = search_pattern(self.LOGIN_BAN_PATTERN, data)        if m is not None:            try:                errmsg = m.group(1)            except (AttributeError, IndexError):                errmsg = m.group(0)            finally:                errmsg = re.sub(r""<.*?>"", "" "", errmsg.strip())            new_timeout = parse.seconds(errmsg)            if new_timeout > self.timeout:                self.timeout = new_timeout            self.fail_login(errmsg)        m = search_pattern(self.LOGIN_FAIL_PATTERN, data)        if m is not None:            try:                errmsg = m.group(1)            except (AttributeError, IndexError):                errmsg = m.group(0)            finally:                errmsg = re.sub(r""<.*?>"", "" "", errmsg.strip())            self.timeout = self.LOGIN_TIMEOUT            self.fail_login(errmsg)        self.log_info(self._(""No errors found""))",,"def check_errors(self, data=None):        self.log_info(self._(""Checking for link errors...""))        data = data or self.data        if not data:            self.log_warning(self._(""No data to check""))            return        m = search_pattern(self.LOGIN_BAN_PATTERN, data)        if m is not None:            try:                errmsg = m.group(1)            except (AttributeError, IndexError):                errmsg = m.group(0)            finally:                errmsg = re.sub(r""<.*?>"", "" "", errmsg.strip())            new_timeout = parse.seconds(errmsg)            if new_timeout > self.timeout:                self.timeout = new_timeout            self.fail_login(errmsg)        m = search_pattern(self.LOGIN_FAIL_PATTERN, data)        if m is not None:            try:                errmsg = m.group(1)            except (AttributeError, IndexError):                errmsg = m.group(0)            finally:                errmsg = re.sub(r""<.*?>"", "" "", errmsg.strip())            self.timeout = self.LOGIN_TIMEOUT            self.fail_login(errmsg)        self.log_info(self._(""No errors found""))",89d3b27d-ddc9-4a94-a801-20875ef9d7bb
base,xfs_decrypter.py,_set_xfs_cookie,46,51,"def _set_xfs_cookie(self):        cookie = (self.PLUGIN_DOMAIN, ""lang"", ""english"")        if isinstance(self.COOKIES, list) and cookie not in self.COOKIES:            self.COOKIES.insert(cookie)        else:            set_cookie(self.req.cj, *cookie)",,"def _set_xfs_cookie(self):        cookie = (self.PLUGIN_DOMAIN, ""lang"", ""english"")        if isinstance(self.COOKIES, list) and cookie not in self.COOKIES:            self.COOKIES.insert(cookie)        else:            set_cookie(self.req.cj, *cookie)",72b523f1-2cbf-4efa-a315-0f8d4b662d91
base,xfs_decrypter.py,_prepare,53,60,"def _prepare(self):        if not self.PLUGIN_DOMAIN:            self.fail(self._(""Missing PLUGIN DOMAIN""))        if self.COOKIES:            self._set_xfs_cookie()        SimpleDecrypter._prepare(self)",,"def _prepare(self):        if not self.PLUGIN_DOMAIN:            self.fail(self._(""Missing PLUGIN DOMAIN""))        if self.COOKIES:            self._set_xfs_cookie()        SimpleDecrypter._prepare(self)",75d17051-c462-4823-89b9-156154f1e354
base,xfs_downloader.py,setup,72,75,def setup(self):        self.chunk_limit = -1 if self.premium else 1        self.multi_dl = self.premium        self.resume_download = self.premium,,def setup(self):        self.chunk_limit = -1 if self.premium else 1        self.multi_dl = self.premium        self.resume_download = self.premium,85376488-672c-4fdf-8b8f-e789cc2682bf
base,xfs_downloader.py,_set_xfs_cookie,77,82,"def _set_xfs_cookie(self):        cookie = (self.PLUGIN_DOMAIN, ""lang"", ""english"")        if isinstance(self.COOKIES, list) and cookie not in self.COOKIES:            self.COOKIES.insert(cookie)        else:            set_cookie(self.req.cj, *cookie)",,"def _set_xfs_cookie(self):        cookie = (self.PLUGIN_DOMAIN, ""lang"", ""english"")        if isinstance(self.COOKIES, list) and cookie not in self.COOKIES:            self.COOKIES.insert(cookie)        else:            set_cookie(self.req.cj, *cookie)",11dc1f4f-f5cb-4e61-87bf-e3156c4a277f
base,xfs_downloader.py,_prepare,84,98,"def _prepare(self):        if not self.PLUGIN_DOMAIN:            self.fail(self._(""Missing PLUGIN DOMAIN""))        if self.COOKIES:            self._set_xfs_cookie()        if not self.LINK_PATTERN:            domain = self.PLUGIN_DOMAIN.replace(""."", r""\."")            self.LINK_PATTERN = rf'(?:file: ""(.+?)""|(https?://(?:www\.)?([^/]*?{domain}|\d+\.\d+\.\d+\.\d+)(\:\d+)?(/d/|(/files)?/\d+/\w+/).+?)[""\'<])'        super(XFSDownloader, self)._prepare()        if self.DIRECT_LINK is None:            self.direct_dl = self.premium",,"def _prepare(self):        if not self.PLUGIN_DOMAIN:            self.fail(self._(""Missing PLUGIN DOMAIN""))        if self.COOKIES:            self._set_xfs_cookie()        if not self.LINK_PATTERN:            domain = self.PLUGIN_DOMAIN.replace(""."", r""\."")            self.LINK_PATTERN = rf'(?:file: ""(.+?)""|(https?://(?:www\.)?([^/]*?{domain}|\d+\.\d+\.\d+\.\d+)(\:\d+)?(/d/|(/files)?/\d+/\w+/).+?)[""\'<])'        super(XFSDownloader, self)._prepare()        if self.DIRECT_LINK is None:            self.direct_dl = self.premium",4539c708-4143-4cb6-98fa-c6417eabc66e
base,xfs_downloader.py,handle_free,100,127,"def handle_free(self, pyfile):        for i in range(1, 6):            self.log_debug(f""Getting download link #{i}..."")            self.check_errors()            m = search_pattern(self.LINK_PATTERN, self.data, flags=re.S)            if m is not None:                self.link = m.group(1)                break            self.data = self.load(                self.PLUGIN_URL or pyfile.url,                post=self._post_parameters(),                ref=self.PLUGIN_URL or pyfile.url,                redirect=False            )            if ""op="" not in self.last_header.get(""location"", ""op=""):                self.link = self.last_header.get(""location"")                break            m = search_pattern(self.LINK_PATTERN, self.data, flags=re.S)            if m is not None:                self.link = m.group(1)                break        else:            self.error(self._(""Too many OPs""))",,"def handle_free(self, pyfile):        for i in range(1, 6):            self.log_debug(f""Getting download link #{i}..."")            self.check_errors()            m = search_pattern(self.LINK_PATTERN, self.data, flags=re.S)            if m is not None:                self.link = m.group(1)                break            self.data = self.load(                self.PLUGIN_URL or pyfile.url,                post=self._post_parameters(),                ref=self.PLUGIN_URL or pyfile.url,                redirect=False            )            if ""op="" not in self.last_header.get(""location"", ""op=""):                self.link = self.last_header.get(""location"")                break            m = search_pattern(self.LINK_PATTERN, self.data, flags=re.S)            if m is not None:                self.link = m.group(1)                break        else:            self.error(self._(""Too many OPs""))",3348b4df-4e09-41e1-9d07-84b6725a4e1d
base,xfs_downloader.py,handle_premium,129,130,"def handle_premium(self, pyfile):        return self.handle_free(pyfile)",,"def handle_premium(self, pyfile):        return self.handle_free(pyfile)",7493676b-99ac-4b43-9424-cdb90fc0508c
base,xfs_downloader.py,_post_parameters,132,196,"def _post_parameters(self):        if self.FORM_PATTERN or self.FORM_INPUTS_MAP:            action, inputs = self.parse_html_form(                self.FORM_PATTERN or """", self.FORM_INPUTS_MAP or {}            )        else:            action, inputs = self.parse_html_form(                input_names={""op"": re.compile(r""^download"")}            )        if not inputs:            action, inputs = self.parse_html_form(""F1"")            if not inputs:                self.retry(                    msg=self.info.get(""error"") or self._(""TEXTAREA F1 not found"")                )        self.log_debug(inputs)        if ""op"" in inputs:            if ""password"" in inputs:                password = self.get_password()                if password:                    inputs[""password""] = password                else:                    self.fail(self._(""Missing password""))            if not self.premium:                m = search_pattern(self.WAIT_PATTERN, self.data)                if m is not None:                    try:                        waitmsg = m.group(1).strip()                    except (AttributeError, IndexError):                        waitmsg = m.group(0).strip()                    wait_time = parse.seconds(waitmsg)                    self.set_wait(wait_time)                    if (                        wait_time                        < timedelta(minutes=self.config.get(""max_wait"", 10)).total_seconds()                        or not self.pyload.config.get(""reconnect"", ""enabled"")                        or not self.pyload.api.is_time_reconnect()                    ):                        self.handle_captcha(inputs)                    self.wait()                else:                    self.handle_captcha(inputs)                if ""referer"" in inputs and len(inputs[""referer""]) == 0:                    inputs[""referer""] = self.PLUGIN_URL or self.pyfile.url        else:            inputs[""referer""] = self.PLUGIN_URL or self.pyfile.url        if self.premium:            inputs[""method_premium""] = ""Premium Download""            inputs.pop(""method_free"", None)        else:            inputs[""method_free""] = ""Free Download""            inputs.pop(""method_premium"", None)        return inputs",,"def _post_parameters(self):        if self.FORM_PATTERN or self.FORM_INPUTS_MAP:            action, inputs = self.parse_html_form(                self.FORM_PATTERN or """", self.FORM_INPUTS_MAP or {}            )        else:            action, inputs = self.parse_html_form(                input_names={""op"": re.compile(r""^download"")}            )        if not inputs:            action, inputs = self.parse_html_form(""F1"")            if not inputs:                self.retry(                    msg=self.info.get(""error"") or self._(""TEXTAREA F1 not found"")                )        self.log_debug(inputs)        if ""op"" in inputs:            if ""password"" in inputs:                password = self.get_password()                if password:                    inputs[""password""] = password                else:                    self.fail(self._(""Missing password""))            if not self.premium:                m = search_pattern(self.WAIT_PATTERN, self.data)                if m is not None:                    try:                        waitmsg = m.group(1).strip()                    except (AttributeError, IndexError):                        waitmsg = m.group(0).strip()                    wait_time = parse.seconds(waitmsg)                    self.set_wait(wait_time)                    if (                        wait_time                        < timedelta(minutes=self.config.get(""max_wait"", 10)).total_seconds()                        or not self.pyload.config.get(""reconnect"", ""enabled"")                        or not self.pyload.api.is_time_reconnect()                    ):                        self.handle_captcha(inputs)                    self.wait()                else:                    self.handle_captcha(inputs)                if ""referer"" in inputs and len(inputs[""referer""]) == 0:                    inputs[""referer""] = self.PLUGIN_URL or self.pyfile.url        else:            inputs[""referer""] = self.PLUGIN_URL or self.pyfile.url        if self.premium:            inputs[""method_premium""] = ""Premium Download""            inputs.pop(""method_free"", None)        else:            inputs[""method_free""] = ""Free Download""            inputs.pop(""method_premium"", None)        return inputs",1c0b8cac-7c6c-45ef-85db-51761c43ee40
base,xfs_downloader.py,handle_captcha,198,267,"def handle_captcha(self, inputs):        m = search_pattern(self.CAPTCHA_PATTERN, self.data)        if m is not None:            captcha_url = urljoin(self.pyfile.url, m.group(1))            inputs[""code""] = self.captcha.decrypt(captcha_url)            return        m = search_pattern(self.CAPTCHA_BLOCK_PATTERN, self.data, flags=re.S)        if m is not None:            captcha_div = m.group(1)            numerals = re.findall(                r""<span.*?padding-left\s*:\s*(\d+).*?>(\d)</span>"",                html_unescape(captcha_div),            )            self.log_debug(captcha_div)            code = inputs[""code""] = """".join(                a[1] for a in sorted(numerals, key=lambda i: int(i[0]))            )            self.log_debug(f""Captcha code: {code}"", numerals)            return        recaptcha = ReCaptcha(self.pyfile)        try:            captcha_key = search_pattern(self.RECAPTCHA_PATTERN, self.data).group(1)        except (AttributeError, IndexError):            captcha_key = recaptcha.detect_key()        else:            self.log_debug(f""ReCaptcha key: {captcha_key}"")        if captcha_key:            self.captcha = recaptcha            inputs[""g-recaptcha-response""] = recaptcha.challenge(captcha_key)            return        hcaptcha = HCaptcha(self.pyfile)        try:            captcha_key = search_pattern(self.HCAPTCHA_PATTERN, self.data).group(1)        except (AttributeError, IndexError):            captcha_key = hcaptcha.detect_key()        else:            self.log_debug(f""HCaptcha key: {captcha_key}"")        if captcha_key:            self.captcha = hcaptcha            inputs[""g-recaptcha-response""] = inputs[""h-captcha-response""] = hcaptcha.challenge(captcha_key)            return        solvemedia = SolveMedia(self.pyfile)        try:            captcha_key = search_pattern(self.SOLVEMEDIA_PATTERN, self.data).group(1)        except (AttributeError, IndexError):            captcha_key = solvemedia.detect_key()        else:            self.log_debug(f""SolveMedia key: {captcha_key}"")        if captcha_key:            self.captcha = solvemedia            (                inputs[""adcopy_response""],                inputs[""adcopy_challenge""],            ) = solvemedia.challenge(captcha_key)",,"def handle_captcha(self, inputs):        m = search_pattern(self.CAPTCHA_PATTERN, self.data)        if m is not None:            captcha_url = urljoin(self.pyfile.url, m.group(1))            inputs[""code""] = self.captcha.decrypt(captcha_url)            return        m = search_pattern(self.CAPTCHA_BLOCK_PATTERN, self.data, flags=re.S)        if m is not None:            captcha_div = m.group(1)            numerals = re.findall(                r""<span.*?padding-left\s*:\s*(\d+).*?>(\d)</span>"",                html_unescape(captcha_div),            )            self.log_debug(captcha_div)            code = inputs[""code""] = """".join(                a[1] for a in sorted(numerals, key=lambda i: int(i[0]))            )            self.log_debug(f""Captcha code: {code}"", numerals)            return        recaptcha = ReCaptcha(self.pyfile)        try:            captcha_key = search_pattern(self.RECAPTCHA_PATTERN, self.data).group(1)        except (AttributeError, IndexError):            captcha_key = recaptcha.detect_key()        else:            self.log_debug(f""ReCaptcha key: {captcha_key}"")        if captcha_key:            self.captcha = recaptcha            inputs[""g-recaptcha-response""] = recaptcha.challenge(captcha_key)            return        hcaptcha = HCaptcha(self.pyfile)        try:            captcha_key = search_pattern(self.HCAPTCHA_PATTERN, self.data).group(1)        except (AttributeError, IndexError):            captcha_key = hcaptcha.detect_key()        else:            self.log_debug(f""HCaptcha key: {captcha_key}"")        if captcha_key:            self.captcha = hcaptcha            inputs[""g-recaptcha-response""] = inputs[""h-captcha-response""] = hcaptcha.challenge(captcha_key)            return        solvemedia = SolveMedia(self.pyfile)        try:            captcha_key = search_pattern(self.SOLVEMEDIA_PATTERN, self.data).group(1)        except (AttributeError, IndexError):            captcha_key = solvemedia.detect_key()        else:            self.log_debug(f""SolveMedia key: {captcha_key}"")        if captcha_key:            self.captcha = solvemedia            (                inputs[""adcopy_response""],                inputs[""adcopy_challenge""],            ) = solvemedia.challenge(captcha_key)",22231e9e-27ee-4269-accc-93d1d612caef
containers,CCF.py,decrypt,38,65,"def decrypt(self, pyfile):        fs_filename = os.fsdecode(pyfile.url)        dlc_content = self.load(            ""http://service.jdownloader.net/dlcrypt/getDLC.php"",            post={                ""src"": ""ccf"",                ""filename"": ""test.ccf"",                ""upload"": FormFile(fs_filename),            },            multipart=True,        )        dl_folder = self.pyload.config.get(""general"", ""storage_folder"")        dlc_file = os.path.join(dl_folder, ""tmp_{}.dlc"".format(pyfile.name))        try:            dlc = base64.b64decode(                re.search(r""<dlc>(.+)</dlc>"", dlc_content, re.S).group(1)            )        except AttributeError:            self.fail(self._(""Container is corrupted""))        with open(dlc_file, mode=""wb"") as fp:            fp.write(dlc)        self.links = [dlc_file]",,"def decrypt(self, pyfile):        fs_filename = os.fsdecode(pyfile.url)        dlc_content = self.load(            ""http://service.jdownloader.net/dlcrypt/getDLC.php"",            post={                ""src"": ""ccf"",                ""filename"": ""test.ccf"",                ""upload"": FormFile(fs_filename),            },            multipart=True,        )        dl_folder = self.pyload.config.get(""general"", ""storage_folder"")        dlc_file = os.path.join(dl_folder, ""tmp_{}.dlc"".format(pyfile.name))        try:            dlc = base64.b64decode(                re.search(r""<dlc>(.+)</dlc>"", dlc_content, re.S).group(1)            )        except AttributeError:            self.fail(self._(""Container is corrupted""))        with open(dlc_file, mode=""wb"") as fp:            fp.write(dlc)        self.links = [dlc_file]",bb8d84d7-02c1-4c0f-87a1-d0c01949a524
containers,DLC.py,__init__,25,26,"def __init__(self, plugin):        self.plugin = plugin",,"def __init__(self, plugin):        self.plugin = plugin",027c2237-487f-48b1-b8ff-6848ceed9c0d
containers,DLC.py,decrypt,28,67,"def decrypt(self, data):        if not isinstance(data, bytes):            raise TypeError(""data must be bytes."")        data = data.strip()        data += b""="" * (-len(data) % 4)        dlc_key = data[-88:]        dlc_data = base64.b64decode(data[:-88])        dlc_content = self.plugin.load(self.API_URL.format(to_str(dlc_key)))        try:            rc = base64.b64decode(                re.search(r""<rc>(.+)</rc>"", dlc_content, re.S).group(1)            )[:16]        except AttributeError:            raise BadDLC        cipher = Cipher(            algorithms.AES(self.KEY), modes.CBC(self.IV), backend=default_backend()        )        decryptor = cipher.decryptor()        key = iv = decryptor.update(rc) + decryptor.finalize()        cipher = Cipher(            algorithms.AES(key), modes.CBC(iv), backend=default_backend()        )        decryptor = cipher.decryptor()        xml_data = to_str(base64.b64decode(            decryptor.update(dlc_data) + decryptor.finalize()        ))        root = xml.dom.minidom.parseString(xml_data).documentElement        content_node = root.getElementsByTagName(""content"")[0]        packages = DLCDecrypter._parse_packages(content_node)        return packages",,"def decrypt(self, data):        if not isinstance(data, bytes):            raise TypeError(""data must be bytes."")        data = data.strip()        data += b""="" * (-len(data) % 4)        dlc_key = data[-88:]        dlc_data = base64.b64decode(data[:-88])        dlc_content = self.plugin.load(self.API_URL.format(to_str(dlc_key)))        try:            rc = base64.b64decode(                re.search(r""<rc>(.+)</rc>"", dlc_content, re.S).group(1)            )[:16]        except AttributeError:            raise BadDLC        cipher = Cipher(            algorithms.AES(self.KEY), modes.CBC(self.IV), backend=default_backend()        )        decryptor = cipher.decryptor()        key = iv = decryptor.update(rc) + decryptor.finalize()        cipher = Cipher(            algorithms.AES(key), modes.CBC(iv), backend=default_backend()        )        decryptor = cipher.decryptor()        xml_data = to_str(base64.b64decode(            decryptor.update(dlc_data) + decryptor.finalize()        ))        root = xml.dom.minidom.parseString(xml_data).documentElement        content_node = root.getElementsByTagName(""content"")[0]        packages = DLCDecrypter._parse_packages(content_node)        return packages",9b666c47-5232-41d7-9e19-72275df4dc79
containers,DLC.py,_parse_packages,70,77,"def _parse_packages(start_node):        return [            (                to_str(base64.b64decode(node.getAttribute(""name""))),                DLCDecrypter._parse_links(node)            )            for node in start_node.getElementsByTagName(""package"")        ]",,"def _parse_packages(start_node):        return [            (                to_str(base64.b64decode(node.getAttribute(""name""))),                DLCDecrypter._parse_links(node)            )            for node in start_node.getElementsByTagName(""package"")        ]",163d1646-77e3-4697-8463-bcd23c9fb1f2
containers,DLC.py,_parse_links,80,84,"def _parse_links(start_node):        return [            to_str(base64.b64decode(node.getElementsByTagName(""url"")[0].firstChild.data))            for node in start_node.getElementsByTagName(""file"")        ]",,"def _parse_links(start_node):        return [            to_str(base64.b64decode(node.getElementsByTagName(""url"")[0].firstChild.data))            for node in start_node.getElementsByTagName(""file"")        ]",9d8e50f5-6c18-43f4-9d3a-9044f19b6ac5
containers,DLC.py,decrypt,116,130,"def decrypt(self, pyfile):        fs_filename = os.fsdecode(pyfile.url)        with open(fs_filename, ""rb"") as dlc:            data = dlc.read().strip()        decrypter = DLCDecrypter(self)        try:            packages = decrypter.decrypt(data)        except BadDLC:            self.fail(_(""Container is corrupted""))        self.packages = [(name or pyfile.name, links, name or pyfile.name)                         for name, links in packages]",,"def decrypt(self, pyfile):        fs_filename = os.fsdecode(pyfile.url)        with open(fs_filename, ""rb"") as dlc:            data = dlc.read().strip()        decrypter = DLCDecrypter(self)        try:            packages = decrypter.decrypt(data)        except BadDLC:            self.fail(_(""Container is corrupted""))        self.packages = [(name or pyfile.name, links, name or pyfile.name)                         for name, links in packages]",91dd903c-b965-4662-bdad-9d3b70d02353
containers,RSDF.py,decrypt,43,81,"def decrypt(self, pyfile):        KEY = bytes.fromhex(self.KEY)        IV = bytes.fromhex(self.IV)        backend = default_backend()        ecb = Cipher(algorithms.AES(KEY), modes.ECB(), backend=backend).encryptor()        iv = ecb.update(IV) + ecb.finalize()        cipher = Cipher(algorithms.AES(KEY), modes.CFB(iv), backend=backend)        encryptor = cipher.encryptor()        iv = encryptor.update(IV) + encryptor.finalize()        try:            fs_filename = os.fsdecode(pyfile.url)            with open(fs_filename, mode=""r"") as fp:                data = fp.read()        except IOError as exc:            self.fail(exc)        if re.search(r""<title>404 - Not Found</title>"", data):            pyfile.set_status(""offline"")        else:            try:                raw_links = bytes.fromhex("""".join(data.split())).splitlines()            except TypeError:                self.fail(self._(""Container is corrupted""))            for link in raw_links:                if not link:                    continue                cipher = Cipher(algorithms.AES(KEY), modes.CFB(iv), backend=backend)                decryptor = cipher.decryptor()                value = to_str(decryptor.update(base64.b64decode(link) + decryptor.finalize()))                link = value.replace(""CCF: "", """")                self.links.append(link)",,"def decrypt(self, pyfile):        KEY = bytes.fromhex(self.KEY)        IV = bytes.fromhex(self.IV)        backend = default_backend()        ecb = Cipher(algorithms.AES(KEY), modes.ECB(), backend=backend).encryptor()        iv = ecb.update(IV) + ecb.finalize()        cipher = Cipher(algorithms.AES(KEY), modes.CFB(iv), backend=backend)        encryptor = cipher.encryptor()        iv = encryptor.update(IV) + encryptor.finalize()        try:            fs_filename = os.fsdecode(pyfile.url)            with open(fs_filename, mode=""r"") as fp:                data = fp.read()        except IOError as exc:            self.fail(exc)        if re.search(r""<title>404 - Not Found</title>"", data):            pyfile.set_status(""offline"")        else:            try:                raw_links = bytes.fromhex("""".join(data.split())).splitlines()            except TypeError:                self.fail(self._(""Container is corrupted""))            for link in raw_links:                if not link:                    continue                cipher = Cipher(algorithms.AES(KEY), modes.CFB(iv), backend=backend)                decryptor = cipher.decryptor()                value = to_str(decryptor.update(base64.b64decode(link) + decryptor.finalize()))                link = value.replace(""CCF: "", """")                self.links.append(link)",02bab463-54a8-4987-a56a-f53ce6bc4288
containers,TORRENT.py,process,39,47,"def process(self, pyfile):        if re.match(self.DECRYPTER_PATTERN, pyfile.url) is not None:            self.log_error(self._(""No plugin is associated with torrents / magnets""),                           self._(""Please go to plugin settings -> TORRENT and select your preferred plugin""))            self.fail(self._(""No plugin is associated with torrents / magnets""))        elif re.match(self.CONTAINER_PATTERN, pyfile.url) is not None:            return super().process(pyfile)",,"def process(self, pyfile):        if re.match(self.DECRYPTER_PATTERN, pyfile.url) is not None:            self.log_error(self._(""No plugin is associated with torrents / magnets""),                           self._(""Please go to plugin settings -> TORRENT and select your preferred plugin""))            self.fail(self._(""No plugin is associated with torrents / magnets""))        elif re.match(self.CONTAINER_PATTERN, pyfile.url) is not None:            return super().process(pyfile)",b1d959ee-3e95-409a-be11-e760aa20f6d1
containers,TORRENT.py,decrypt,49,83,"def decrypt(self, pyfile):        fs_filename = os.fsencode(pyfile.url)        with open(fs_filename, mode=""rb"") as fp:            torrent_content = fp.read()        time_ref = ""{:.2f}"".format(time.time())[-6:].replace(""."", """")        pack_name = ""torrent {}"".format(time_ref)        if pyfile.url.endswith("".magnet""):            if torrent_content.startswith(b""magnet:?""):                self.packages.append((pyfile.package().name, [to_str(torrent_content)], pyfile.package().folder))        elif pyfile.url.endswith("".torrent""):            m = re.search(rb""name(\d+):"", torrent_content)            if m:                m = re.search(                    b"""".join((b""name"", m.group(1), b"":(.{"", m.group(1), b""})"")),                    torrent_content                )                if m:                    pack_name = safename(to_str(m.group(1)))            torrent_filename = os.path.join(                self.pyload.tempdir, ""tmp_{}.torrent"".format(pack_name)            )            with open(torrent_filename, mode=""wb"") as fp:                fp.write(torrent_content)            self.packages.append(                (                    pack_name,                    [""file://{}"".format(urllib.request.pathname2url(torrent_filename))],                    pack_name,                )            )",,"def decrypt(self, pyfile):        fs_filename = os.fsencode(pyfile.url)        with open(fs_filename, mode=""rb"") as fp:            torrent_content = fp.read()        time_ref = ""{:.2f}"".format(time.time())[-6:].replace(""."", """")        pack_name = ""torrent {}"".format(time_ref)        if pyfile.url.endswith("".magnet""):            if torrent_content.startswith(b""magnet:?""):                self.packages.append((pyfile.package().name, [to_str(torrent_content)], pyfile.package().folder))        elif pyfile.url.endswith("".torrent""):            m = re.search(rb""name(\d+):"", torrent_content)            if m:                m = re.search(                    b"""".join((b""name"", m.group(1), b"":(.{"", m.group(1), b""})"")),                    torrent_content                )                if m:                    pack_name = safename(to_str(m.group(1)))            torrent_filename = os.path.join(                self.pyload.tempdir, ""tmp_{}.torrent"".format(pack_name)            )            with open(torrent_filename, mode=""wb"") as fp:                fp.write(torrent_content)            self.packages.append(                (                    pack_name,                    [""file://{}"".format(urllib.request.pathname2url(torrent_filename))],                    pack_name,                )            )",7a2c3b55-e1a9-4c09-ae6b-b97c9246fef8
containers,TXT.py,decrypt,36,79,"def decrypt(self, pyfile):        try:            encoding = codecs.lookup(self.config.get(""encoding"")).name        except Exception:            encoding = ""utf-8-sig""        fs_filename = os.fsdecode(pyfile.url)        with open(fs_filename, encoding=encoding) as txt:            cur_pack = ""Parsed links from {}"".format(pyfile.name.split(""tmp_"")[-1])            packages = {cur_pack: []}            for link in txt.readlines():                link = link.strip()                if not link:                    continue                if link.startswith("";""):                    continue                if link.startswith(""["") and link.endswith(""]""):                    #: New package                    cur_pack = link[1:-1]                    packages[cur_pack] = []                    continue                packages[cur_pack].append(link)        #: Empty packages fix        for key, value in packages.items():            if not value:                packages.pop(key, None)        if self.config.get(""flush""):            try:                txt = open(fs_filename, mode=""w"")                txt.close()            except IOError:                self.log_warning(self._(""Failed to flush list""))        for name, links in packages.items():            self.packages.append((name, links, name))",,"def decrypt(self, pyfile):        try:            encoding = codecs.lookup(self.config.get(""encoding"")).name        except Exception:            encoding = ""utf-8-sig""        fs_filename = os.fsdecode(pyfile.url)        with open(fs_filename, encoding=encoding) as txt:            cur_pack = ""Parsed links from {}"".format(pyfile.name.split(""tmp_"")[-1])            packages = {cur_pack: []}            for link in txt.readlines():                link = link.strip()                if not link:                    continue                if link.startswith("";""):                    continue                if link.startswith(""["") and link.endswith(""]""):                    #: New package                    cur_pack = link[1:-1]                    packages[cur_pack] = []                    continue                packages[cur_pack].append(link)        #: Empty packages fix        for key, value in packages.items():            if not value:                packages.pop(key, None)        if self.config.get(""flush""):            try:                txt = open(fs_filename, mode=""w"")                txt.close()            except IOError:                self.log_warning(self._(""Failed to flush list""))        for name, links in packages.items():            self.packages.append((name, links, name))",5b2f3cee-ef66-4362-b070-cf6beb93df2d
decrypters,AlldebridComTorrent.py,api_request,34,41,"def api_request(self, method, get={}, post={}, multipart=False):        get.update({""agent"": ""pyLoad"",                    ""version"": self.pyload.version})        json_data = json.loads(self.load(self.API_URL + method, get=get, post=post, multipart=multipart))        if json_data[""status""] == ""success"":            return json_data[""data""]        else:            return json_data",,"def api_request(self, method, get={}, post={}, multipart=False):        get.update({""agent"": ""pyLoad"",                    ""version"": self.pyload.version})        json_data = json.loads(self.load(self.API_URL + method, get=get, post=post, multipart=multipart))        if json_data[""status""] == ""success"":            return json_data[""data""]        else:            return json_data",d30fc258-16f6-43c0-aa58-3cb3edf75ceb
decrypters,AlldebridComTorrent.py,sleep,43,47,"def sleep(self, sec):        for _i in range(sec):            if self.pyfile.abort:                break            time.sleep(1)",,"def sleep(self, sec):        for _i in range(sec):            if self.pyfile.abort:                break            time.sleep(1)",7de0653d-4ca6-4637-a714-6d82c8c73011
decrypters,AlldebridComTorrent.py,exit_error,49,53,"def exit_error(self, msg):        if self.tmp_file:            os.remove(self.tmp_file)        self.fail(msg)",,"def exit_error(self, msg):        if self.tmp_file:            os.remove(self.tmp_file)        self.fail(msg)",026a01c1-5583-4af5-8b26-f451d4615570
decrypters,AlldebridComTorrent.py,send_request_to_server,55,111,"def send_request_to_server(self):                if self.pyfile.url.endswith("".torrent""):            #: torrent URL            if self.pyfile.url.startswith(""http""):                #: remote URL, download the torrent to tmp directory                torrent_content = self.load(self.pyfile.url, decode=False)                torrent_filename = safejoin(self.pyload.tempdir, ""tmp_{}.torrent"".format(self.pyfile.package().name))                with open(torrent_filename, ""wb"") as f:                    f.write(torrent_content)            else:                #: URL is local torrent file (uploaded container)                torrent_filename = urllib.request.url2pathname(self.pyfile.url[7:])  #: trim the starting `file://`                if not exists(torrent_filename):                    self.fail(self._(""Torrent file does not exist""))            self.tmp_file = torrent_filename            #: Check if the torrent file path is inside pyLoad's config directory            if os.path.abspath(torrent_filename).startswith(self.pyload.tempdir + os.sep):                #: send the torrent content to the server                api_data = self.api_request(""magnet/upload/file"",                                            get={'apikey': self.api_token},                                            post={'files[]': FormFile(torrent_filename, mimetype=""application/x-bittorrent"")},                                            multipart=True)                if api_data.get(""error"", False):                    self.exit_error(""{} (code: {})"".format(api_data['error']['message'], api_data['error']['code']))                if api_data['files'][0].get('error', False):                    self.exit_error(""{} (code: {})"".format(api_data['files'][0]['error']['message'], api_data['files'][0]['error']['code']))                torrent_id = api_data['files'][0]['id']            else:                self.fail(self._(""Illegal URL"")) #: We don't allow files outside pyLoad's config directory        else:            #: magnet URL, send to the server            api_data = self.api_request(""magnet/upload"",                                        get={""apikey"": self.api_token,                                              ""magnets[]"": self.pyfile.url})            if api_data.get(""error"", False):                self.fail(""{} (code: {})"".format(api_data[""error""][""message""], api_data[""error""][""code""]))            if api_data[""magnets""][0].get(""error"", False):                self.fail(""{} (code: {})"".format(api_data['magnets'][0]['error']['message'], api_data['magnets'][0]['error']['code']))            torrent_id = api_data[""magnets""][0][""id""]        if self.tmp_file:            os.remove(self.tmp_file)        return torrent_id",Send torrent/magnet to the server ,"def send_request_to_server(self):        """""" Send torrent/magnet to the server """"""        if self.pyfile.url.endswith("".torrent""):            #: torrent URL            if self.pyfile.url.startswith(""http""):                #: remote URL, download the torrent to tmp directory                torrent_content = self.load(self.pyfile.url, decode=False)                torrent_filename = safejoin(self.pyload.tempdir, ""tmp_{}.torrent"".format(self.pyfile.package().name))                with open(torrent_filename, ""wb"") as f:                    f.write(torrent_content)            else:                #: URL is local torrent file (uploaded container)                torrent_filename = urllib.request.url2pathname(self.pyfile.url[7:])  #: trim the starting `file://`                if not exists(torrent_filename):                    self.fail(self._(""Torrent file does not exist""))            self.tmp_file = torrent_filename            #: Check if the torrent file path is inside pyLoad's config directory            if os.path.abspath(torrent_filename).startswith(self.pyload.tempdir + os.sep):                #: send the torrent content to the server                api_data = self.api_request(""magnet/upload/file"",                                            get={'apikey': self.api_token},                                            post={'files[]': FormFile(torrent_filename, mimetype=""application/x-bittorrent"")},                                            multipart=True)                if api_data.get(""error"", False):                    self.exit_error(""{} (code: {})"".format(api_data['error']['message'], api_data['error']['code']))                if api_data['files'][0].get('error', False):                    self.exit_error(""{} (code: {})"".format(api_data['files'][0]['error']['message'], api_data['files'][0]['error']['code']))                torrent_id = api_data['files'][0]['id']            else:                self.fail(self._(""Illegal URL"")) #: We don't allow files outside pyLoad's config directory        else:            #: magnet URL, send to the server            api_data = self.api_request(""magnet/upload"",                                        get={""apikey"": self.api_token,                                              ""magnets[]"": self.pyfile.url})            if api_data.get(""error"", False):                self.fail(""{} (code: {})"".format(api_data[""error""][""message""], api_data[""error""][""code""]))            if api_data[""magnets""][0].get(""error"", False):                self.fail(""{} (code: {})"".format(api_data['magnets'][0]['error']['message'], api_data['magnets'][0]['error']['code']))            torrent_id = api_data[""magnets""][0][""id""]        if self.tmp_file:            os.remove(self.tmp_file)        return torrent_id

Send torrent/magnet to the server ",426ae98c-31ef-4351-b6bc-eeebc65b80d5
decrypters,AlldebridComTorrent.py,wait_for_server_dl,113,155,"def wait_for_server_dl(self, torrent_id):                self.pyfile.set_custom_status(""torrent"")        self.pyfile.set_progress(0)        prev_status = -1        while True:            torrent_info = self.api_request(""magnet/status"",                                            get={""apikey"": self.api_token,                                                  ""id"": torrent_id})            if torrent_info.get(""error"", False):                self.fail(""{} (code: {})"".format(torrent_info[""error""][""message""], torrent_info[""error""][""code""]))            status_code = torrent_info[""magnets""][""statusCode""]            torrent_size = torrent_info[""magnets""][""size""]            if status_code > 4:                self.fail(""{} (code: {})"".format(torrent_info[""magnets""][""status""], status_code))            if status_code != prev_status:                if status_code in (0, 1):                    self.pyfile.name = torrent_info[""magnets""][""filename""]                    self.pyfile.size = torrent_size                elif status_code in (2, 3):                    self.pyfile.set_progress(100)                    self.pyfile.set_custom_status(""postprocessing"")            if status_code == 1:                if torrent_size > 0:                    self.pyfile.size = torrent_size                    progress = int(100 * torrent_info[""magnets""][""downloaded""] / torrent_size)                    self.pyfile.set_progress(progress)            elif status_code == 4:                self.pyfile.set_progress(100)                break            self.sleep(5)            prev_status = status_code        return [l[""link""] for l in torrent_info[""magnets""][""links""]]",Show progress while the server does the download ,"def wait_for_server_dl(self, torrent_id):        """""" Show progress while the server does the download """"""        self.pyfile.set_custom_status(""torrent"")        self.pyfile.set_progress(0)        prev_status = -1        while True:            torrent_info = self.api_request(""magnet/status"",                                            get={""apikey"": self.api_token,                                                  ""id"": torrent_id})            if torrent_info.get(""error"", False):                self.fail(""{} (code: {})"".format(torrent_info[""error""][""message""], torrent_info[""error""][""code""]))            status_code = torrent_info[""magnets""][""statusCode""]            torrent_size = torrent_info[""magnets""][""size""]            if status_code > 4:                self.fail(""{} (code: {})"".format(torrent_info[""magnets""][""status""], status_code))            if status_code != prev_status:                if status_code in (0, 1):                    self.pyfile.name = torrent_info[""magnets""][""filename""]                    self.pyfile.size = torrent_size                elif status_code in (2, 3):                    self.pyfile.set_progress(100)                    self.pyfile.set_custom_status(""postprocessing"")            if status_code == 1:                if torrent_size > 0:                    self.pyfile.size = torrent_size                    progress = int(100 * torrent_info[""magnets""][""downloaded""] / torrent_size)                    self.pyfile.set_progress(progress)            elif status_code == 4:                self.pyfile.set_progress(100)                break            self.sleep(5)            prev_status = status_code        return [l[""link""] for l in torrent_info[""magnets""][""links""]]

Show progress while the server does the download ",d468783c-fdb3-4e1a-a260-53945017ceea
decrypters,AlldebridComTorrent.py,delete_torrent_from_server,157,165,"def delete_torrent_from_server(self, torrent_id):                api_data = self.api_request(""magnet/delete"",                                    get={""apikey"": self.api_token,                                          ""id"": torrent_id})        if api_data.get(""error"", False):            self.log_warning(""{} (code: {})"".format(api_data[""error""][""message""], api_data[""error""][""code""]))",Remove the torrent from the server ,"def delete_torrent_from_server(self, torrent_id):        """""" Remove the torrent from the server """"""        api_data = self.api_request(""magnet/delete"",                                    get={""apikey"": self.api_token,                                          ""id"": torrent_id})        if api_data.get(""error"", False):            self.log_warning(""{} (code: {})"".format(api_data[""error""][""message""], api_data[""error""][""code""]))

Remove the torrent from the server ",5ed64743-b9b8-45d7-aba0-d9c7e93773c5
decrypters,AlldebridComTorrent.py,decrypt,167,184,"def decrypt(self, pyfile):        self.tmp_file = None        if ""AlldebridCom"" not in self.pyload.account_manager.plugins:            self.fail(self._(""This plugin requires an active Alldebrid.com account""))        account_plugin = self.pyload.account_manager.get_account_plugin(""AlldebridCom"")        if len(account_plugin.accounts) == 0:            self.fail(self._(""This plugin requires an active Alldebrid.com account""))        self.api_token = account_plugin.accounts[list(account_plugin.accounts.keys())[0]][""password""]        torrent_id = self.send_request_to_server()        torrent_urls = self.wait_for_server_dl(torrent_id)        self.packages = [(pyfile.package().name, torrent_urls, pyfile.package().name)]        if self.config.get(""del_finished""):            self.delete_torrent_from_server(torrent_id)",,"def decrypt(self, pyfile):        self.tmp_file = None        if ""AlldebridCom"" not in self.pyload.account_manager.plugins:            self.fail(self._(""This plugin requires an active Alldebrid.com account""))        account_plugin = self.pyload.account_manager.get_account_plugin(""AlldebridCom"")        if len(account_plugin.accounts) == 0:            self.fail(self._(""This plugin requires an active Alldebrid.com account""))        self.api_token = account_plugin.accounts[list(account_plugin.accounts.keys())[0]][""password""]        torrent_id = self.send_request_to_server()        torrent_urls = self.wait_for_server_dl(torrent_id)        self.packages = [(pyfile.package().name, torrent_urls, pyfile.package().name)]        if self.config.get(""del_finished""):            self.delete_torrent_from_server(torrent_id)",bb869d57-234c-498c-992f-2e7f377d2294
decrypters,ArchiveOrgFolder.py,decrypt,37,47,"def decrypt(self, pyfile):        self.data = self.load(pyfile.url)        m = re.search(self.NAME_PATTERN, self.data)        if m is not None:            name = m.group(1)        else:            name = pyfile.package().name        links = re.findall(self.LINK_PATTERN, self.data)        self.packages = [(name, links, name)]",,"def decrypt(self, pyfile):        self.data = self.load(pyfile.url)        m = re.search(self.NAME_PATTERN, self.data)        if m is not None:            name = m.group(1)        else:            name = pyfile.package().name        links = re.findall(self.LINK_PATTERN, self.data)        self.packages = [(name, links, name)]",b7ffeb05-6b32-465a-91d3-d508abac22c6
decrypters,ChipDe.py,decrypt,29,39,"def decrypt(self, pyfile):        self.data = self.load(pyfile.url)        try:            f = re.search(r'""(https?://media-video\.chip\.de/.+/MEDIA/.+)""', self.data)        except Exception:            self.fail(self._(""Failed to find the URL""))        else:            self.links = [f.group(1)]            self.log_debug(f""The file URL is {self.links[0]}"")",,"def decrypt(self, pyfile):        self.data = self.load(pyfile.url)        try:            f = re.search(r'""(https?://media-video\.chip\.de/.+/MEDIA/.+)""', self.data)        except Exception:            self.fail(self._(""Failed to find the URL""))        else:            self.links = [f.group(1)]            self.log_debug(f""The file URL is {self.links[0]}"")",fe2aaca6-73d4-49d1-875c-9b55dccd7cec
decrypters,CloudMailRuFolder.py,api_request,34,36,"def api_request(self, method, **kwargs):        json_data = self.load(self.API_URL + method, get=kwargs)        return json.loads(json_data)",,"def api_request(self, method, **kwargs):        json_data = self.load(self.API_URL + method, get=kwargs)        return json.loads(json_data)",84e2e924-a55d-47fb-b409-e184e25b69f1
decrypters,CloudMailRuFolder.py,decrypt,38,76,"def decrypt(self, pyfile):        api_data = self.api_request(""dispatcher"", api=2)        if api_data[""status""] != 200:            self.fail(self._(""API failure, status code {}"").format(api_data[""status""]))        base_url = api_data[""body""][""weblink_get""][0][""url""]        api_data = self.api_request(            ""folder"", weblink=self.info[""pattern""][""ID""], offset=0, limit=500, api=2        )        if api_data[""status""] != 200:            self.fail(self._(""API failure, status code {}"").format(api_data[""status""]))        pack_name = api_data[""body""][""name""]        pack_links = [            ""https://cloud.mail.ru/dl?q={}"".format(                base64.b64encode(                    json.dumps(                        {                            ""u"": ""{}/{}"".format(base_url, _link[""weblink""]),                            ""n"": _link[""name""],                            ""s"": _link[""size""],                        }                    ).encode(""utf-8"")                ).decode(""utf-8"")            )            for _link in api_data[""body""][""list""]            if _link[""type""] == ""file""        ]        if pack_links:            self.packages.append(                (                    pack_name or pyfile.package().name,                    pack_links,                    pack_name or pyfile.package().folder,                )            )",,"def decrypt(self, pyfile):        api_data = self.api_request(""dispatcher"", api=2)        if api_data[""status""] != 200:            self.fail(self._(""API failure, status code {}"").format(api_data[""status""]))        base_url = api_data[""body""][""weblink_get""][0][""url""]        api_data = self.api_request(            ""folder"", weblink=self.info[""pattern""][""ID""], offset=0, limit=500, api=2        )        if api_data[""status""] != 200:            self.fail(self._(""API failure, status code {}"").format(api_data[""status""]))        pack_name = api_data[""body""][""name""]        pack_links = [            ""https://cloud.mail.ru/dl?q={}"".format(                base64.b64encode(                    json.dumps(                        {                            ""u"": ""{}/{}"".format(base_url, _link[""weblink""]),                            ""n"": _link[""name""],                            ""s"": _link[""size""],                        }                    ).encode(""utf-8"")                ).decode(""utf-8"")            )            for _link in api_data[""body""][""list""]            if _link[""type""] == ""file""        ]        if pack_links:            self.packages.append(                (                    pack_name or pyfile.package().name,                    pack_links,                    pack_name or pyfile.package().folder,                )            )",9580f7e2-1aa6-4c6a-9629-562c2e7f1663
decrypters,CloudzillaToFolder.py,check_errors,38,44,"def check_errors(self):        m = re.search(self.PASSWORD_PATTERN, self.data)        if m is not None:            self.data = self.load(self.pyfile.url, get={""key"": self.get_password()})        if re.search(self.PASSWORD_PATTERN, self.data):            self.retry(msg=""Wrong password"")",,"def check_errors(self):        m = re.search(self.PASSWORD_PATTERN, self.data)        if m is not None:            self.data = self.load(self.pyfile.url, get={""key"": self.get_password()})        if re.search(self.PASSWORD_PATTERN, self.data):            self.retry(msg=""Wrong password"")",333a0f63-a927-44ab-9d07-fe9454afb9e9
decrypters,CriptTo.py,api_info,41,55,"def api_info(self, url):        info = {}        folder_id = re.match(self.__pattern__, url).group('ID')        folder_info = json.loads(self.load(""https://cript.to/api/v1/folder/info"",                                         get={'id': folder_id}))        if folder_info[""status""] == ""error"":            info[""status""] = 8            info[""error""] = folder_info[""message""]        else:            info[""status""] = 2            info[""name""] = folder_info[""data""][""name""]        return info",,"def api_info(self, url):        info = {}        folder_id = re.match(self.__pattern__, url).group('ID')        folder_info = json.loads(self.load(""https://cript.to/api/v1/folder/info"",                                         get={'id': folder_id}))        if folder_info[""status""] == ""error"":            info[""status""] = 8            info[""error""] = folder_info[""message""]        else:            info[""status""] = 2            info[""name""] = folder_info[""data""][""name""]        return info",0f0fe28d-40b1-49f8-b1d4-95bdaaf5d909
decrypters,CriptTo.py,decrypt,57,75,"def decrypt(self, pyfile):        self.data = self.load(pyfile.url)        self.handle_captcha()        self.handle_password()        for handle in (self.handle_CNL,                       self.handle_weblinks,                       self.handle_DLC):            urls = handle()            if urls:                self.packages = [(self.pyfile.name or pyfile.package().name,                                  urls,                                  self.pyfile.name or pyfile.package().name)]                return            elif self.packages:                return",,"def decrypt(self, pyfile):        self.data = self.load(pyfile.url)        self.handle_captcha()        self.handle_password()        for handle in (self.handle_CNL,                       self.handle_weblinks,                       self.handle_DLC):            urls = handle()            if urls:                self.packages = [(self.pyfile.name or pyfile.package().name,                                  urls,                                  self.pyfile.name or pyfile.package().name)]                return            elif self.packages:                return",ce50c76b-92aa-4b15-8ae3-eef9ea3f4978
decrypters,CriptTo.py,handle_captcha,77,143,"def handle_captcha(self):        url, inputs = self.parse_html_form('action=""{}""'.format(self.pyfile.url))        if inputs is None:            return        elif inputs[""do""] == ""captcha"":            captcha_type = inputs[""captcha_driver""]            if captcha_type == ""simplecaptcha"":                self.log_debug(""Internal captcha found"")                captcha_url = ""https://cript.to/captcha/simplecaptcha""                captcha_code = self.captcha.decrypt(captcha_url, input_type=""png"")                inputs[""simplecaptcha""] = captcha_code            elif captcha_type == ""circlecaptcha"":                self.log_debug(""Circle captcha found"")                captcha_url = ""https://cript.to/captcha/circlecaptcha""                captcha_code = self.captcha.decrypt(captcha_url, input_type=""png"", output_type=""positional"")                inputs[""button.x""] = captcha_code[0]                inputs[""button.y""] = captcha_code[1]            elif captcha_type == ""solvemedia"":                solvemedia = SolveMedia(self.pyfile)                captcha_key = solvemedia.detect_key()                if captcha_key:                    self.log_debug(""Solvemedia captcha found"")                    self.captcha = solvemedia                    response, challenge = solvemedia.challenge(captcha_key)                    inputs[""adcopy_challenge""] = challenge                    inputs[""adcopy_response""] = response                else:                    self.log_warning(self._(""Could not detect Solvemedia captcha key""))                    self.retry_captcha()            elif captcha_type == ""recaptcha"":                recaptcha = ReCaptcha(self.pyfile)                captcha_key = recaptcha.detect_key()                if captcha_key:                    self.log_debug(""ReCaptcha captcha found"")                    self.captcha = recaptcha                    response = recaptcha.challenge(captcha_key)                    inputs[""g-recaptcha-response""] = response                else:                    self.log_warning(self._(""Could not detect ReCaptcha captcha key""))                    self.retry_captcha()            else:                self.log_warning(self._(""Captcha Not found""))            inputs[""submit""] = ""confirm""            self.data = self.load(url, post=inputs)            url, inputs = self.parse_html_form('action=""{}""'.format(self.pyfile.url))            if inputs is not None:                if inputs[""do""] == ""captcha"":                    self.captcha.invalid()                    self.retry_captcha()",,"def handle_captcha(self):        url, inputs = self.parse_html_form('action=""{}""'.format(self.pyfile.url))        if inputs is None:            return        elif inputs[""do""] == ""captcha"":            captcha_type = inputs[""captcha_driver""]            if captcha_type == ""simplecaptcha"":                self.log_debug(""Internal captcha found"")                captcha_url = ""https://cript.to/captcha/simplecaptcha""                captcha_code = self.captcha.decrypt(captcha_url, input_type=""png"")                inputs[""simplecaptcha""] = captcha_code            elif captcha_type == ""circlecaptcha"":                self.log_debug(""Circle captcha found"")                captcha_url = ""https://cript.to/captcha/circlecaptcha""                captcha_code = self.captcha.decrypt(captcha_url, input_type=""png"", output_type=""positional"")                inputs[""button.x""] = captcha_code[0]                inputs[""button.y""] = captcha_code[1]            elif captcha_type == ""solvemedia"":                solvemedia = SolveMedia(self.pyfile)                captcha_key = solvemedia.detect_key()                if captcha_key:                    self.log_debug(""Solvemedia captcha found"")                    self.captcha = solvemedia                    response, challenge = solvemedia.challenge(captcha_key)                    inputs[""adcopy_challenge""] = challenge                    inputs[""adcopy_response""] = response                else:                    self.log_warning(self._(""Could not detect Solvemedia captcha key""))                    self.retry_captcha()            elif captcha_type == ""recaptcha"":                recaptcha = ReCaptcha(self.pyfile)                captcha_key = recaptcha.detect_key()                if captcha_key:                    self.log_debug(""ReCaptcha captcha found"")                    self.captcha = recaptcha                    response = recaptcha.challenge(captcha_key)                    inputs[""g-recaptcha-response""] = response                else:                    self.log_warning(self._(""Could not detect ReCaptcha captcha key""))                    self.retry_captcha()            else:                self.log_warning(self._(""Captcha Not found""))            inputs[""submit""] = ""confirm""            self.data = self.load(url, post=inputs)            url, inputs = self.parse_html_form('action=""{}""'.format(self.pyfile.url))            if inputs is not None:                if inputs[""do""] == ""captcha"":                    self.captcha.invalid()                    self.retry_captcha()",e5cc4a4d-0c7b-44de-932b-662fd9f2eff8
decrypters,CriptTo.py,handle_password,145,161,"def handle_password(self):        url, inputs = self.parse_html_form('action=""{}""'.format(self.pyfile.url))        if inputs is None:            return        elif inputs[""do""] == ""password"":            password = self.get_password()            if not password:                self.fail(self._(""Password required""))            inputs[""password""] = password            inputs[""submit""] = ""confirm""            self.data = self.load(url, post=inputs)            if ""That Password was incorrect"" in self.data:                self.fail(self._(""Wrong password""))",,"def handle_password(self):        url, inputs = self.parse_html_form('action=""{}""'.format(self.pyfile.url))        if inputs is None:            return        elif inputs[""do""] == ""password"":            password = self.get_password()            if not password:                self.fail(self._(""Password required""))            inputs[""password""] = password            inputs[""submit""] = ""confirm""            self.data = self.load(url, post=inputs)            if ""That Password was incorrect"" in self.data:                self.fail(self._(""Wrong password""))",6a4aa201-0c65-4e27-a549-eb96e6fecbe8
decrypters,CriptTo.py,handle_CNL,163,188,"def handle_CNL(self):        links = []        m = re.search(self.CNL_LINK_PATTERN, self.data)        if m is not None:            html = self.load(m.group(1))            _, inputs = parse_html_form(""/flash/"", html)            if inputs is not None:                #: Get key                key = bytes.fromhex(re.search(r""'(\w+)'"", inputs['jk']).group(1))                crypted = inputs[""crypted""]                #: Decrypt                #Key = key                #IV = key                cipher = Cipher(                    algorithms.AES(key), modes.CBC(key), backend=default_backend()                )                decryptor = cipher.decryptor()                text = decryptor.update(base64.b64decode(crypted)) + decryptor.finalize()                #: Extract links                text = to_str(text).replace(""\x00"", """")                links = [item for item in text.splitlines() if item]        return links",,"def handle_CNL(self):        links = []        m = re.search(self.CNL_LINK_PATTERN, self.data)        if m is not None:            html = self.load(m.group(1))            _, inputs = parse_html_form(""/flash/"", html)            if inputs is not None:                #: Get key                key = bytes.fromhex(re.search(r""'(\w+)'"", inputs['jk']).group(1))                crypted = inputs[""crypted""]                #: Decrypt                #Key = key                #IV = key                cipher = Cipher(                    algorithms.AES(key), modes.CBC(key), backend=default_backend()                )                decryptor = cipher.decryptor()                text = decryptor.update(base64.b64decode(crypted)) + decryptor.finalize()                #: Extract links                text = to_str(text).replace(""\x00"", """")                links = [item for item in text.splitlines() if item]        return links",e8cf8e93-717c-42fe-89ab-6278a43b5f92
decrypters,CriptTo.py,handle_weblinks,190,224,"def handle_weblinks(self):        links = []        weblinks = re.findall(self.WEB_LINK_PATTERN, self.data)        for weblink in weblinks:            html = self.load(weblink)            link = self.last_header[""url""]            if link == ""https://cript.to/bot"":                for _i in range(3):                    url, inputs = parse_html_form(""/bot"", html)                    if inputs is None or ""circlecaptcha"" not in html:                        continue                    captcha_url = ""https://cript.to/captcha/circlecaptcha""                    captcha_code = self.captcha.decrypt(captcha_url, input_type=""png"", output_type=""positional"")                    inputs[""button.x""] = captcha_code[0]                    inputs[""button.y""] = captcha_code[1]                    html = self.load(url, post=inputs)                    link = self.last_header[""url""]                    if not link.startswith(""https://cript.to""):                        self.captcha.correct()                        break                    else:                        self.captcha.invalid()                else:                        self.log_warning(self._(""Could not parse weblink (bot)""))                        links = []                        break            if link:                links.append(link)        return links",,"def handle_weblinks(self):        links = []        weblinks = re.findall(self.WEB_LINK_PATTERN, self.data)        for weblink in weblinks:            html = self.load(weblink)            link = self.last_header[""url""]            if link == ""https://cript.to/bot"":                for _i in range(3):                    url, inputs = parse_html_form(""/bot"", html)                    if inputs is None or ""circlecaptcha"" not in html:                        continue                    captcha_url = ""https://cript.to/captcha/circlecaptcha""                    captcha_code = self.captcha.decrypt(captcha_url, input_type=""png"", output_type=""positional"")                    inputs[""button.x""] = captcha_code[0]                    inputs[""button.y""] = captcha_code[1]                    html = self.load(url, post=inputs)                    link = self.last_header[""url""]                    if not link.startswith(""https://cript.to""):                        self.captcha.correct()                        break                    else:                        self.captcha.invalid()                else:                        self.log_warning(self._(""Could not parse weblink (bot)""))                        links = []                        break            if link:                links.append(link)        return links",44d44684-c0ac-4e71-af85-5f0feaa9cf4a
decrypters,CriptTo.py,handle_DLC,226,242,"def handle_DLC(self):        decrypter = DLCDecrypter(self)        dlc_urls = re.findall(self.DLC_LINK_PATTERN, self.data)        for dlc_url in dlc_urls:            dlc_data = self.load(dlc_url)            try:                packages = decrypter.decrypt(dlc_data)            except BadDLC:                self.log_warning(self._(""Container is corrupted""))                continue            self.packages.extend([(name or self.pyfile.name, links, name or self.pyfile.name)                                  for name, links in packages])        return []",,"def handle_DLC(self):        decrypter = DLCDecrypter(self)        dlc_urls = re.findall(self.DLC_LINK_PATTERN, self.data)        for dlc_url in dlc_urls:            dlc_data = self.load(dlc_url)            try:                packages = decrypter.decrypt(dlc_data)            except BadDLC:                self.log_warning(self._(""Container is corrupted""))                continue            self.packages.extend([(name or self.pyfile.name, links, name or self.pyfile.name)                                  for name, links in packages])        return []",251eedea-dcc8-4d94-bb0d-5ae2bfb2cd91
decrypters,CzshareComFolder.py,decrypt,33,40,"def decrypt(self, pyfile):        html = self.load(pyfile.url)        m = re.search(self.FOLDER_PATTERN, html, re.S)        if m is None:            self.error(self._(""FOLDER_PATTERN not found""))        self.links.extend(re.findall(self.LINK_PATTERN, m.group(1)))",,"def decrypt(self, pyfile):        html = self.load(pyfile.url)        m = re.search(self.FOLDER_PATTERN, html, re.S)        if m is None:            self.error(self._(""FOLDER_PATTERN not found""))        self.links.extend(re.findall(self.LINK_PATTERN, m.group(1)))",32bb5ef3-94f7-4878-a157-6fa441bf29a2
decrypters,DailymotionComFolder.py,api_request,32,35,"def api_request(self, ref, data=None):        url = urllib.parse.urljoin(""https://api.dailymotion.com/"", ref)        html = self.load(url, get=data)        return json.loads(html)",,"def api_request(self, ref, data=None):        url = urllib.parse.urljoin(""https://api.dailymotion.com/"", ref)        html = self.load(url, get=data)        return json.loads(html)",6a6513fd-2021-4604-8fb3-34039ebaf9ae
decrypters,DailymotionComFolder.py,get_playlist_info,37,47,"def get_playlist_info(self, id):        ref = ""playlist/"" + id        data = {""fields"": ""name,owner.screenname""}        playlist = self.api_request(ref, data)        if ""error"" in playlist:            return        name = playlist[""name""]        owner = playlist[""owner.screenname""]        return name, owner",,"def get_playlist_info(self, id):        ref = ""playlist/"" + id        data = {""fields"": ""name,owner.screenname""}        playlist = self.api_request(ref, data)        if ""error"" in playlist:            return        name = playlist[""name""]        owner = playlist[""owner.screenname""]        return name, owner",16fad854-7c33-448f-b7dd-a69c51d36318
decrypters,DailymotionComFolder.py,_get_playlists,49,62,"def _get_playlists(self, user_id, page=1):        ref = ""user/{}/playlists"".format(user_id)        data = {""fields"": ""id"", ""page"": page, ""limit"": 100}        user = self.api_request(ref, data)        if ""error"" in user:            return        for playlist in user[""list""]:            yield playlist[""id""]        if user[""has_more""]:            for item in self._get_playlists(user_id, page + 1):                yield item",,"def _get_playlists(self, user_id, page=1):        ref = ""user/{}/playlists"".format(user_id)        data = {""fields"": ""id"", ""page"": page, ""limit"": 100}        user = self.api_request(ref, data)        if ""error"" in user:            return        for playlist in user[""list""]:            yield playlist[""id""]        if user[""has_more""]:            for item in self._get_playlists(user_id, page + 1):                yield item",f4392c7d-14cd-4786-a41e-b25e3ea1801e
decrypters,DailymotionComFolder.py,get_playlists,64,67,"def get_playlists(self, user_id):        return [            (id,) + self.get_playlist_info(id) for id in self._get_playlists(user_id)        ]",,"def get_playlists(self, user_id):        return [            (id,) + self.get_playlist_info(id) for id in self._get_playlists(user_id)        ]",ae3695fb-e18f-4d5c-9ce9-53851a89b903
decrypters,DailymotionComFolder.py,_get_videos,69,82,"def _get_videos(self, id, page=1):        ref = ""playlist/{}/videos"".format(id)        data = {""fields"": ""url"", ""page"": page, ""limit"": 100}        playlist = self.api_request(ref, data)        if ""error"" in playlist:            return        for video in playlist[""list""]:            yield video[""url""]        if playlist[""has_more""]:            for item in self._get_videos(id, page + 1):                yield item",,"def _get_videos(self, id, page=1):        ref = ""playlist/{}/videos"".format(id)        data = {""fields"": ""url"", ""page"": page, ""limit"": 100}        playlist = self.api_request(ref, data)        if ""error"" in playlist:            return        for video in playlist[""list""]:            yield video[""url""]        if playlist[""has_more""]:            for item in self._get_videos(id, page + 1):                yield item",7a692e22-89ae-41b0-925c-6e89ee18e564
decrypters,DailymotionComFolder.py,get_videos,84,85,"def get_videos(self, playlist_id):        return list(self._get_videos(playlist_id))[::-1]",,"def get_videos(self, playlist_id):        return list(self._get_videos(playlist_id))[::-1]",ad695f10-9531-4407-a781-2dcc67796bbe
decrypters,DailymotionComFolder.py,decrypt,87,113,"def decrypt(self, pyfile):        m_id = self.info[""pattern""][""ID""]        m_type = self.info[""pattern""][""TYPE""]        if m_type == ""playlist"":            self.log_debug(""Url recognized as Playlist"")            p_info = self.get_playlist_info(m_id)            playlists = [(m_id,) + p_info] if p_info else None        else:            self.log_debug(""Url recognized as Channel"")            playlists = self.get_playlists(m_id)            self.log_debug(                r'{} playlist\s found on channel ""{}""'.format(len(playlists), m_id)            )        if not playlists:            self.fail(self._(""No playlist available""))        for p_id, p_name, p_owner in playlists:            p_videos = self.get_videos(p_id)            p_folder = os.path.join(                self.pyload.config.get(""general"", ""storage_folder""), p_owner, p_name            )            self.log_debug(                r'{} video\s found on playlist ""{}""'.format(len(p_videos), p_name))            # NOTE: Folder is NOT recognized by pyload 0.5.0!            self.packages.append((p_name, p_videos, p_folder))",,"def decrypt(self, pyfile):        m_id = self.info[""pattern""][""ID""]        m_type = self.info[""pattern""][""TYPE""]        if m_type == ""playlist"":            self.log_debug(""Url recognized as Playlist"")            p_info = self.get_playlist_info(m_id)            playlists = [(m_id,) + p_info] if p_info else None        else:            self.log_debug(""Url recognized as Channel"")            playlists = self.get_playlists(m_id)            self.log_debug(                r'{} playlist\s found on channel ""{}""'.format(len(playlists), m_id)            )        if not playlists:            self.fail(self._(""No playlist available""))        for p_id, p_name, p_owner in playlists:            p_videos = self.get_videos(p_id)            p_folder = os.path.join(                self.pyload.config.get(""general"", ""storage_folder""), p_owner, p_name            )            self.log_debug(                r'{} video\s found on playlist ""{}""'.format(len(p_videos), p_name))            # NOTE: Folder is NOT recognized by pyload 0.5.0!            self.packages.append((p_name, p_videos, p_folder))",9cdf2e0e-19e7-498b-900c-0bd5b2525e20
decrypters,DataHuFolder.py,_prepare,33,48,"def _prepare(self):        SimpleDecrypter._prepare(self)        if ""K\xe9rlek add meg a jelsz\xf3t"" in self.data:  #: Password protected            password = self.get_password()            if not password:                self.fail(self._(""Password required""))            self.log_debug(                ""The folder is password protected', 'Using password: "" + password            )            self.data = self.load(self.pyfile.url, post={""mappa_pass"": password})            if ""Hib\xe1s jelsz\xf3"" in self.data:  #: Wrong password                self.fail(self._(""Wrong password""))",,"def _prepare(self):        SimpleDecrypter._prepare(self)        if ""K\xe9rlek add meg a jelsz\xf3t"" in self.data:  #: Password protected            password = self.get_password()            if not password:                self.fail(self._(""Password required""))            self.log_debug(                ""The folder is password protected', 'Using password: "" + password            )            self.data = self.load(self.pyfile.url, post={""mappa_pass"": password})            if ""Hib\xe1s jelsz\xf3"" in self.data:  #: Wrong password                self.fail(self._(""Wrong password""))",469e6580-9de5-4b9f-bfb3-e0380a054969
decrypters,DebridlinkFrTorrent.py,api_request,44,56,"def api_request(self, method, get={}, post={}, multipart=False):        self.req.http.c.setopt(            pycurl.HTTPHEADER, [""Authorization: Bearer "" + self.api_token]        )        self.req.http.c.setopt(            pycurl.USERAGENT, ""pyLoad/{}"".format(self.pyload.version)        )        try:            json_data = self.load(self.API_URL + method, get=get, post=post, multipart=multipart)        except BadHeader as exc:            json_data = exc.content        return json.loads(json_data)",,"def api_request(self, method, get={}, post={}, multipart=False):        self.req.http.c.setopt(            pycurl.HTTPHEADER, [""Authorization: Bearer "" + self.api_token]        )        self.req.http.c.setopt(            pycurl.USERAGENT, ""pyLoad/{}"".format(self.pyload.version)        )        try:            json_data = self.load(self.API_URL + method, get=get, post=post, multipart=multipart)        except BadHeader as exc:            json_data = exc.content        return json.loads(json_data)",ed254e71-2e03-4128-b3c2-d06339d49ece
decrypters,DebridlinkFrTorrent.py,api_request_safe,58,80,"def api_request_safe(self, method, get={}, post={}, multipart=False):        for _i in range(2):            api_data = self.api_request(method, get=get, post=post, multipart=multipart)            if ""error"" in api_data:                if (                    api_data[""error""] == ""badToken""                ):  #: token expired, refresh the token and retry                    self.account.relogin()                    if not self.account.info[""login""][""valid""]:                        return api_data                    else:                        self.api_token = self.account.accounts[                            list(self.account.accounts.keys())[0]                        ][""api_token""]                        continue                else:                    return api_data            else:                return api_data",,"def api_request_safe(self, method, get={}, post={}, multipart=False):        for _i in range(2):            api_data = self.api_request(method, get=get, post=post, multipart=multipart)            if ""error"" in api_data:                if (                    api_data[""error""] == ""badToken""                ):  #: token expired, refresh the token and retry                    self.account.relogin()                    if not self.account.info[""login""][""valid""]:                        return api_data                    else:                        self.api_token = self.account.accounts[                            list(self.account.accounts.keys())[0]                        ][""api_token""]                        continue                else:                    return api_data            else:                return api_data",0e918083-a2cc-4608-b959-77a32e95ecf4
decrypters,DebridlinkFrTorrent.py,sleep,82,86,"def sleep(self, sec):        for _i in range(sec):            if self.pyfile.abort:                break            time.sleep(1)",,"def sleep(self, sec):        for _i in range(sec):            if self.pyfile.abort:                break            time.sleep(1)",0204cb99-444d-4027-9a4b-ae13b17bd109
decrypters,DebridlinkFrTorrent.py,exit_error,88,92,"def exit_error(self, msg):        if self.tmp_file:            os.remove(self.tmp_file)        self.fail(msg)",,"def exit_error(self, msg):        if self.tmp_file:            os.remove(self.tmp_file)        self.fail(msg)",5f0e8a09-b9a1-4f83-8463-ef7162614041
decrypters,DebridlinkFrTorrent.py,send_request_to_server,94,258,"def send_request_to_server(self):                if self.pyfile.url.endswith("".torrent""):            #: torrent URL            if self.pyfile.url.startswith(""http""):                #: remote URL, send to the server                api_data = self.api_request_safe(                    ""v2/seedbox/add"",                    post={                        ""url"": self.pyfile.url,                        ""wait"": True,                        ""async"": True,                    },                )            else:                #: URL is local torrent file (uploaded container)                torrent_filename = urllib.request.url2pathname(                    self.pyfile.url[7:]                )  #: trim the starting `file://`                if not exists(torrent_filename):                    self.fail(self._(""Torrent file does not exist""))                self.tmp_file = torrent_filename                #: Check if the torrent file path is inside pyLoad's temp directory                if os.path.abspath(torrent_filename).startswith(                    self.pyload.tempdir + os.sep                ):                    #: send the torrent content to the server                    api_data = self.api_request_safe(                        ""v2/seedbox/add"",                        post={                            ""file"": FormFile(                                torrent_filename, mimetype=""application/x-bittorrent""                            ),                            ""wait"": True,                            ""async"": True,                        },                        multipart=True,                    )                else:                    self.exit_error(                        self._(""Illegal URL"")                    )  #: We don't allow files outside pyLoad's config directory        else:            #: magnet URL, send to the server            api_data = self.api_request_safe(                ""v2/seedbox/add"",                post={""url"": self.pyfile.url, ""wait"": True, ""async"": True},            )        if not api_data[""success""]:            self.exit_error(                ""{} (code: {})"".format(                    api_data.get(                        ""error_description"", error_description(api_data[""error""])                    ),                    api_data[""error""],                )            )        torrent_id = api_data[""value""][""id""]        self.pyfile.set_custom_status(""metadata"")        self.pyfile.set_progress(0)        #: Get the file list of the torrent        page = 0        files = []        while True:            api_data = self.api_request_safe(                ""v2/seedbox/list"", get={""ids"": torrent_id, ""page"": page, ""perPage"": 50}            )            if not api_data[""success""]:                self.exit_error(                    ""{} (code: {})"".format(                        api_data.get(                            ""error_description"", error_description(api_data[""error""])                        ),                        api_data[""error""],                    )                )            api_files = api_data[""value""][0][""files""]            if api_files:                files.extend(                    [                        {                            ""id"": _file[""id""],                            ""name"": _file[""name""],                            ""size"": _file[""size""],                            ""url"": _file[""downloadUrl""],                        }                        for _file in api_files                    ]                )                page = api_data[""pagination""][""next""]                if page == -1:                    break            self.sleep(5)        self.pyfile.name = api_data[""value""][0][""name""]        #: Filter and select files for downloading        exclude_filters = self.config.get(""exclude_filter"").split("";"")        excluded_ids = []        for _filter in exclude_filters:            excluded_ids.extend(                [                    _file[""id""]                    for _file in files                    if fnmatch.fnmatch(_file[""name""], _filter)                ]            )        excluded_ids = uniquify(excluded_ids)        include_filters = self.config.get(""include_filter"").split("";"")        included_ids = []        for _filter in include_filters:            included_ids.extend(                [                    _file[""id""]                    for _file in files                    if fnmatch.fnmatch(_file[""name""], _filter)                ]            )        included_ids = uniquify(included_ids)        selected_ids = [_id for _id in included_ids if _id not in excluded_ids]        unwanted_ids = [            _file[""id""] for _file in files if _file[""id""] not in selected_ids        ]        self.pyfile.size = sum(            [_file[""size""] for _file in files if _file[""id""] in selected_ids]        )        api_data = self.api_request_safe(            ""v2/seedbox/{}/config"".format(torrent_id),            post={""files-unwanted"": json.dumps(unwanted_ids)},        )        if not api_data[""success""]:            self.exit_error(                ""{} (code: {})"".format(                    api_data.get(                        ""error_description"", error_description(api_data[""error""])                    ),                    api_data[""error""],                )            )        return torrent_id, [            _file[""url""] for _file in files if _file[""id""] in selected_ids        ]",Send torrent/magnet to the server ,"def send_request_to_server(self):        """""" Send torrent/magnet to the server """"""        if self.pyfile.url.endswith("".torrent""):            #: torrent URL            if self.pyfile.url.startswith(""http""):                #: remote URL, send to the server                api_data = self.api_request_safe(                    ""v2/seedbox/add"",                    post={                        ""url"": self.pyfile.url,                        ""wait"": True,                        ""async"": True,                    },                )            else:                #: URL is local torrent file (uploaded container)                torrent_filename = urllib.request.url2pathname(                    self.pyfile.url[7:]                )  #: trim the starting `file://`                if not exists(torrent_filename):                    self.fail(self._(""Torrent file does not exist""))                self.tmp_file = torrent_filename                #: Check if the torrent file path is inside pyLoad's temp directory                if os.path.abspath(torrent_filename).startswith(                    self.pyload.tempdir + os.sep                ):                    #: send the torrent content to the server                    api_data = self.api_request_safe(                        ""v2/seedbox/add"",                        post={                            ""file"": FormFile(                                torrent_filename, mimetype=""application/x-bittorrent""                            ),                            ""wait"": True,                            ""async"": True,                        },                        multipart=True,                    )                else:                    self.exit_error(                        self._(""Illegal URL"")                    )  #: We don't allow files outside pyLoad's config directory        else:            #: magnet URL, send to the server            api_data = self.api_request_safe(                ""v2/seedbox/add"",                post={""url"": self.pyfile.url, ""wait"": True, ""async"": True},            )        if not api_data[""success""]:            self.exit_error(                ""{} (code: {})"".format(                    api_data.get(                        ""error_description"", error_description(api_data[""error""])                    ),                    api_data[""error""],                )            )        torrent_id = api_data[""value""][""id""]        self.pyfile.set_custom_status(""metadata"")        self.pyfile.set_progress(0)        #: Get the file list of the torrent        page = 0        files = []        while True:            api_data = self.api_request_safe(                ""v2/seedbox/list"", get={""ids"": torrent_id, ""page"": page, ""perPage"": 50}            )            if not api_data[""success""]:                self.exit_error(                    ""{} (code: {})"".format(                        api_data.get(                            ""error_description"", error_description(api_data[""error""])                        ),                        api_data[""error""],                    )                )            api_files = api_data[""value""][0][""files""]            if api_files:                files.extend(                    [                        {                            ""id"": _file[""id""],                            ""name"": _file[""name""],                            ""size"": _file[""size""],                            ""url"": _file[""downloadUrl""],                        }                        for _file in api_files                    ]                )                page = api_data[""pagination""][""next""]                if page == -1:                    break            self.sleep(5)        self.pyfile.name = api_data[""value""][0][""name""]        #: Filter and select files for downloading        exclude_filters = self.config.get(""exclude_filter"").split("";"")        excluded_ids = []        for _filter in exclude_filters:            excluded_ids.extend(                [                    _file[""id""]                    for _file in files                    if fnmatch.fnmatch(_file[""name""], _filter)                ]            )        excluded_ids = uniquify(excluded_ids)        include_filters = self.config.get(""include_filter"").split("";"")        included_ids = []        for _filter in include_filters:            included_ids.extend(                [                    _file[""id""]                    for _file in files                    if fnmatch.fnmatch(_file[""name""], _filter)                ]            )        included_ids = uniquify(included_ids)        selected_ids = [_id for _id in included_ids if _id not in excluded_ids]        unwanted_ids = [            _file[""id""] for _file in files if _file[""id""] not in selected_ids        ]        self.pyfile.size = sum(            [_file[""size""] for _file in files if _file[""id""] in selected_ids]        )        api_data = self.api_request_safe(            ""v2/seedbox/{}/config"".format(torrent_id),            post={""files-unwanted"": json.dumps(unwanted_ids)},        )        if not api_data[""success""]:            self.exit_error(                ""{} (code: {})"".format(                    api_data.get(                        ""error_description"", error_description(api_data[""error""])                    ),                    api_data[""error""],                )            )        return torrent_id, [            _file[""url""] for _file in files if _file[""id""] in selected_ids        ]

Send torrent/magnet to the server ",f63b2d2a-3652-46be-939a-95f93cb4bb87
decrypters,DebridlinkFrTorrent.py,wait_for_server_dl,260,293,"def wait_for_server_dl(self, torrent_id):                self.pyfile.set_custom_status(""torrent"")        self.pyfile.set_progress(0)        while True:            api_data = self.api_request_safe(""v2/seedbox/activity"", get={""ids"": torrent_id})            if not api_data[""success""]:                self.fail(                    ""{} (code: {})"".format(                        api_data.get(                            ""error_description"",                            api_data.get(                                ""error_description"", error_description(api_data[""error""])                            ),                        ),                        api_data[""error""],                    )                )            if not api_data[""value""]:                self.fail(""Torrent deleted from server"")            progress = int(api_data[""value""][torrent_id][""downloadPercent""])            self.pyfile.set_progress(progress)            if progress == 100:                break            self.sleep(5)        self.pyfile.set_progress(100)",Show progress while the server does the download ,"def wait_for_server_dl(self, torrent_id):        """""" Show progress while the server does the download """"""        self.pyfile.set_custom_status(""torrent"")        self.pyfile.set_progress(0)        while True:            api_data = self.api_request_safe(""v2/seedbox/activity"", get={""ids"": torrent_id})            if not api_data[""success""]:                self.fail(                    ""{} (code: {})"".format(                        api_data.get(                            ""error_description"",                            api_data.get(                                ""error_description"", error_description(api_data[""error""])                            ),                        ),                        api_data[""error""],                    )                )            if not api_data[""value""]:                self.fail(""Torrent deleted from server"")            progress = int(api_data[""value""][torrent_id][""downloadPercent""])            self.pyfile.set_progress(progress)            if progress == 100:                break            self.sleep(5)        self.pyfile.set_progress(100)

Show progress while the server does the download ",d0122804-5471-451d-8509-17db816424ea
decrypters,DebridlinkFrTorrent.py,delete_torrent_from_server,295,320,"def delete_torrent_from_server(self, torrent_id):                url = ""{}v2/seedbox/{}/remove"".format(self.API_URL, torrent_id)        self.log_debug(""DELETE URL {}"".format(url))        c = pycurl.Curl()        c.setopt(pycurl.URL, url)        c.setopt(pycurl.SSL_VERIFYPEER, 0)        c.setopt(pycurl.USERAGENT, ""pyLoad/{}"".format(self.pyload.version))        c.setopt(            pycurl.HTTPHEADER,            [                ""Authorization: Bearer "" + self.api_token,                ""Accept: */*"",                ""Accept-Language: en-US,en"",                ""Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.7"",                ""Connection: keep-alive"",                ""Keep-Alive: 300"",                ""Expect:"",            ],        )        c.setopt(pycurl.CUSTOMREQUEST, ""DELETE"")        c.perform()        code = c.getinfo(pycurl.RESPONSE_CODE)        c.close()        return code",Remove the torrent from the server ,"def delete_torrent_from_server(self, torrent_id):        """""" Remove the torrent from the server """"""        url = ""{}v2/seedbox/{}/remove"".format(self.API_URL, torrent_id)        self.log_debug(""DELETE URL {}"".format(url))        c = pycurl.Curl()        c.setopt(pycurl.URL, url)        c.setopt(pycurl.SSL_VERIFYPEER, 0)        c.setopt(pycurl.USERAGENT, ""pyLoad/{}"".format(self.pyload.version))        c.setopt(            pycurl.HTTPHEADER,            [                ""Authorization: Bearer "" + self.api_token,                ""Accept: */*"",                ""Accept-Language: en-US,en"",                ""Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.7"",                ""Connection: keep-alive"",                ""Keep-Alive: 300"",                ""Expect:"",            ],        )        c.setopt(pycurl.CUSTOMREQUEST, ""DELETE"")        c.perform()        code = c.getinfo(pycurl.RESPONSE_CODE)        c.close()        return code

Remove the torrent from the server ",214e0148-6488-4eb8-a201-ad595178720a
decrypters,DebridlinkFrTorrent.py,decrypt,322,341,"def decrypt(self, pyfile):        self.tmp_file = None        if ""DebridlinkFr"" not in self.pyload.account_manager.plugins:            self.fail(self._(""This plugin requires an active Debrid-slink.fr account""))        self.account = self.pyload.account_manager.get_account_plugin(""DebridlinkFr"")        if len(self.account.accounts) == 0:            self.fail(self._(""This plugin requires an active Debrid-slink.fr account""))        self.api_token = self.account.accounts[list(self.account.accounts.keys())[0]][            ""api_token""        ]        torrent_id, torrent_urls = self.send_request_to_server()        self.wait_for_server_dl(torrent_id)        self.packages = [(pyfile.package().name, torrent_urls, pyfile.package().name)]        if self.tmp_file:            os.remove(self.tmp_file)",,"def decrypt(self, pyfile):        self.tmp_file = None        if ""DebridlinkFr"" not in self.pyload.account_manager.plugins:            self.fail(self._(""This plugin requires an active Debrid-slink.fr account""))        self.account = self.pyload.account_manager.get_account_plugin(""DebridlinkFr"")        if len(self.account.accounts) == 0:            self.fail(self._(""This plugin requires an active Debrid-slink.fr account""))        self.api_token = self.account.accounts[list(self.account.accounts.keys())[0]][            ""api_token""        ]        torrent_id, torrent_urls = self.send_request_to_server()        self.wait_for_server_dl(torrent_id)        self.packages = [(pyfile.package().name, torrent_urls, pyfile.package().name)]        if self.tmp_file:            os.remove(self.tmp_file)",887b1ea8-5f9a-4917-afac-0b8e02621186
decrypters,Dereferer.py,_log,36,38,"def _log(self, level, plugintype, pluginname, args, kwargs):        args = (self.PLUGIN_NAME,) + args        return super()._log(level, plugintype, pluginname, args, kwargs)",,"def _log(self, level, plugintype, pluginname, args, kwargs):        args = (self.PLUGIN_NAME,) + args        return super()._log(level, plugintype, pluginname, args, kwargs)",e5ba3241-f501-4863-92bc-23c02bf91553
decrypters,Dereferer.py,init,40,52,"def init(self):        self.__pattern__ = self.pyload.plugin_manager.decrypter_plugins[self.classname][            ""pattern""        ]  # TODO: Recheck in 0.6.x        self.PLUGIN_DOMAIN = (            re.match(self.__pattern__, self.pyfile.url).group(""DOMAIN"").lower()        )        self.PLUGIN_NAME = """".join(            part.capitalize()            for part in re.split(r""\.|\d+|-"", self.PLUGIN_DOMAIN)            if part != "".""        )",,"def init(self):        self.__pattern__ = self.pyload.plugin_manager.decrypter_plugins[self.classname][            ""pattern""        ]  # TODO: Recheck in 0.6.x        self.PLUGIN_DOMAIN = (            re.match(self.__pattern__, self.pyfile.url).group(""DOMAIN"").lower()        )        self.PLUGIN_NAME = """".join(            part.capitalize()            for part in re.split(r""\.|\d+|-"", self.PLUGIN_DOMAIN)            if part != "".""        )",6e8023f2-0403-4f2e-bb5b-b92ea1b74cf3
decrypters,Dereferer.py,get_links,54,55,"def get_links(self):        return [self.info[""pattern""][""LINK""]]",,"def get_links(self):        return [self.info[""pattern""][""LINK""]]",e1b351b6-da3b-437f-8bf0-3310aed615d9
decrypters,DevhostStFolder.py,check_name_size,44,79,"def check_name_size(self, getinfo=True):        if not self.info or getinfo:            self.log_debug(f""File info (BEFORE): {self.info}"")            self.info.update(self.get_info(self.pyfile.url, self.data))            self.log_debug(f""File info (AFTER): {self.info}"")        try:            if self.info[""pattern""][""ID""] == ""0"":                raise Exception            p = r'href=""(.+?)"">Back to \w+<'            m = re.search(p, self.data)            html = self.load(                urllib.parse.urljoin(""http://d-h.st/"", m.group(1)), cookies=False            )            p = r'\?fld_id={}.*?"">(.+?)<'.format(self.info[""pattern""][""ID""])            m = re.search(p, html)            self.pyfile.name = m.group(1)        except Exception as exc:            self.log_debug(                exc, exc_info=self.pyload.debug > 1, stack_info=self.pyload.debug > 2            )            self.pyfile.name = self.info[""pattern""][""USER""]        try:            folder = self.info[""folder""] = self.pyfile.name        except Exception:            pass        self.log_debug(            ""File name: {}"".format(self.pyfile.name),            ""File folder: {}"".format(self.pyfile.name),        )",,"def check_name_size(self, getinfo=True):        if not self.info or getinfo:            self.log_debug(f""File info (BEFORE): {self.info}"")            self.info.update(self.get_info(self.pyfile.url, self.data))            self.log_debug(f""File info (AFTER): {self.info}"")        try:            if self.info[""pattern""][""ID""] == ""0"":                raise Exception            p = r'href=""(.+?)"">Back to \w+<'            m = re.search(p, self.data)            html = self.load(                urllib.parse.urljoin(""http://d-h.st/"", m.group(1)), cookies=False            )            p = r'\?fld_id={}.*?"">(.+?)<'.format(self.info[""pattern""][""ID""])            m = re.search(p, html)            self.pyfile.name = m.group(1)        except Exception as exc:            self.log_debug(                exc, exc_info=self.pyload.debug > 1, stack_info=self.pyload.debug > 2            )            self.pyfile.name = self.info[""pattern""][""USER""]        try:            folder = self.info[""folder""] = self.pyfile.name        except Exception:            pass        self.log_debug(            ""File name: {}"".format(self.pyfile.name),            ""File folder: {}"".format(self.pyfile.name),        )",9af850e6-22b5-4e2c-a560-debe72b2a75a
decrypters,EmbeduploadCom.py,decrypt,41,62,"def decrypt(self, pyfile):        self.data = self.load(pyfile.url)        tmp_links = []        m = re.findall(self.LINK_PATTERN, self.data)        if m is not None:            prefered_set = set(self.config.get(""preferedHoster"").split(""|""))            prefered_set = [s.lower().split(""."")[0] for s in prefered_set]            self.log_debug(f""PF: {prefered_set}"")            tmp_links.extend(x[1] for x in m if x[0] in prefered_set)            self.links = self.get_location(tmp_links)            if not self.links:                ignored_set = set(self.config.get(""ignoredHoster"").split(""|""))                ignored_set = [s.lower().split(""."")[0] for s in ignored_set]                self.log_debug(f""IG: {ignored_set}"")                tmp_links.extend(x[1] for x in m if x[0] not in ignored_set)                self.links = self.get_location(tmp_links)",,"def decrypt(self, pyfile):        self.data = self.load(pyfile.url)        tmp_links = []        m = re.findall(self.LINK_PATTERN, self.data)        if m is not None:            prefered_set = set(self.config.get(""preferedHoster"").split(""|""))            prefered_set = [s.lower().split(""."")[0] for s in prefered_set]            self.log_debug(f""PF: {prefered_set}"")            tmp_links.extend(x[1] for x in m if x[0] in prefered_set)            self.links = self.get_location(tmp_links)            if not self.links:                ignored_set = set(self.config.get(""ignoredHoster"").split(""|""))                ignored_set = [s.lower().split(""."")[0] for s in ignored_set]                self.log_debug(f""IG: {ignored_set}"")                tmp_links.extend(x[1] for x in m if x[0] not in ignored_set)                self.links = self.get_location(tmp_links)",7b86e9cf-1f2c-45dd-a15e-6c7daf58bf55
decrypters,EmbeduploadCom.py,get_location,64,73,"def get_location(self, tmp_links):        new_links = []        for link in tmp_links:            try:                header = self.load(link, just_header=True)                if ""location"" in header:                    new_links.append(header.get(""location""))            except BadHeader:                pass        return new_links",,"def get_location(self, tmp_links):        new_links = []        for link in tmp_links:            try:                header = self.load(link, just_header=True)                if ""location"" in header:                    new_links.append(header.get(""location""))            except BadHeader:                pass        return new_links",d056a91e-0d62-447c-90cb-a6d625fdab9f
decrypters,FilecryptCc.py,setup,57,69,"def setup(self):        self.urls = []        try:            self.req.http.close()        except Exception:            pass        self.req.http = HTTPRequest(            cookies=self.req.cj,            options=self.pyload.request_factory.get_options(),            limit=2_000_000,        )",,"def setup(self):        self.urls = []        try:            self.req.http.close()        except Exception:            pass        self.req.http = HTTPRequest(            cookies=self.req.cj,            options=self.pyload.request_factory.get_options(),            limit=2_000_000,        )",0dac4f4e-c61d-4583-9f0d-45a5b8b9fd82
decrypters,FilecryptCc.py,decrypt,71,105,"def decrypt(self, pyfile):        pyfile.url = replace_patterns(pyfile.url, self.URL_REPLACEMENTS)        self.data = self._filecrypt_load_url(pyfile.url)        # @NOTE: ""content notfound"" is NOT a typo        if (            ""content notfound"" in self.data            or "">File <strong>not</strong> found<"" in self.data        ):            self.offline()        self.handle_password_protection()        self.site_with_links = self.handle_captcha(pyfile.url)        if self.site_with_links is None:            self.retry_captcha()        elif self.site_with_links == """":            self.retry()        if self.config.get(""handle_mirror_pages""):            self.handle_mirror_pages()        for handle in (            self.handle_CNL,            self.handle_weblinks,            self.handle_dlc_container,        ):            handle()            if self.urls:                self.packages = [                    (pyfile.package().name, self.urls, pyfile.package().name)                ]                return",,"def decrypt(self, pyfile):        pyfile.url = replace_patterns(pyfile.url, self.URL_REPLACEMENTS)        self.data = self._filecrypt_load_url(pyfile.url)        # @NOTE: ""content notfound"" is NOT a typo        if (            ""content notfound"" in self.data            or "">File <strong>not</strong> found<"" in self.data        ):            self.offline()        self.handle_password_protection()        self.site_with_links = self.handle_captcha(pyfile.url)        if self.site_with_links is None:            self.retry_captcha()        elif self.site_with_links == """":            self.retry()        if self.config.get(""handle_mirror_pages""):            self.handle_mirror_pages()        for handle in (            self.handle_CNL,            self.handle_weblinks,            self.handle_dlc_container,        ):            handle()            if self.urls:                self.packages = [                    (pyfile.package().name, self.urls, pyfile.package().name)                ]                return",6df8de80-2d01-4d4f-99f1-ea00baad4cad
decrypters,FilecryptCc.py,handle_mirror_pages,107,116,"def handle_mirror_pages(self):        if ""mirror="" not in self.site_with_links:            return        mirror = re.findall(self.MIRROR_PAGE_PATTERN, self.site_with_links)        self.log_info(self._(""Found {} mirrors"").format(len(mirror)))        for i in mirror[1:]:            self.site_with_links = self.site_with_links + self._filecrypt_load_url(i)",,"def handle_mirror_pages(self):        if ""mirror="" not in self.site_with_links:            return        mirror = re.findall(self.MIRROR_PAGE_PATTERN, self.site_with_links)        self.log_info(self._(""Found {} mirrors"").format(len(mirror)))        for i in mirror[1:]:            self.site_with_links = self.site_with_links + self._filecrypt_load_url(i)",caf0bf72-3697-44bf-9061-3c1e84d78465
decrypters,FilecryptCc.py,handle_password_protection,118,139,"def handle_password_protection(self):        if (            re.search(                r'div class=""input"">\s*<input type=""text"" name=""password"" id=""p4assw0rt""',                self.data,            )            is None        ):            return        self.log_info(self._(""Folder is password protected""))        password = self.get_password()        if not password:            self.fail(                self._(""Please enter the password in package section and try again"")            )        self.data = self._filecrypt_load_url(            self.pyfile.url, post={""password"": password}        )",,"def handle_password_protection(self):        if (            re.search(                r'div class=""input"">\s*<input type=""text"" name=""password"" id=""p4assw0rt""',                self.data,            )            is None        ):            return        self.log_info(self._(""Folder is password protected""))        password = self.get_password()        if not password:            self.fail(                self._(""Please enter the password in package section and try again"")            )        self.data = self._filecrypt_load_url(            self.pyfile.url, post={""password"": password}        )",a59c9e97-af96-499c-bce0-af7bab29b1b5
decrypters,FilecryptCc.py,handle_captcha,141,171,"def handle_captcha(self, submit_url):        if re.search(self.CAPTCHA_PATTERN, self.data):            for handle in (                self._handle_internal_captcha,                self._handle_circle_captcha,                self._handle_solvemedia_captcha,                self._handle_keycaptcha_captcha,                self._handle_coinhive_captcha,                self._handle_recaptcha_captcha,            ):                res = handle(submit_url)                if res is None:                    continue                elif res == """":                    return res                if re.search(self.CAPTCHA_PATTERN, res):                    return None                else:                    return res            else:                self.log_warning(self._(""Unknown captcha found, retrying""))                return """"        else:            self.log_info(self._(""No captcha found""))            return self.data",,"def handle_captcha(self, submit_url):        if re.search(self.CAPTCHA_PATTERN, self.data):            for handle in (                self._handle_internal_captcha,                self._handle_circle_captcha,                self._handle_solvemedia_captcha,                self._handle_keycaptcha_captcha,                self._handle_coinhive_captcha,                self._handle_recaptcha_captcha,            ):                res = handle(submit_url)                if res is None:                    continue                elif res == """":                    return res                if re.search(self.CAPTCHA_PATTERN, res):                    return None                else:                    return res            else:                self.log_warning(self._(""Unknown captcha found, retrying""))                return """"        else:            self.log_info(self._(""No captcha found""))            return self.data",a9521fff-94f1-4d3b-bf65-1535a6d2d41c
decrypters,FilecryptCc.py,_handle_internal_captcha,173,187,"def _handle_internal_captcha(self, url):        m = re.search(self.INTERNAL_CAPTCHA_PATTERN, self.data)        if m is not None:            captcha_url = urllib.parse.urljoin(self.pyfile.url, m.group(1))            self.log_debug(f""Internal Captcha URL: {captcha_url}"")            captcha_code = self.captcha.decrypt(captcha_url, input_type=""gif"")            return self._filecrypt_load_url(                url, post={""recaptcha_response_field"": captcha_code}            )        else:            return None",,"def _handle_internal_captcha(self, url):        m = re.search(self.INTERNAL_CAPTCHA_PATTERN, self.data)        if m is not None:            captcha_url = urllib.parse.urljoin(self.pyfile.url, m.group(1))            self.log_debug(f""Internal Captcha URL: {captcha_url}"")            captcha_code = self.captcha.decrypt(captcha_url, input_type=""gif"")            return self._filecrypt_load_url(                url, post={""recaptcha_response_field"": captcha_code}            )        else:            return None",ff11a3ea-f9e7-48a8-9142-94b67cb92364
decrypters,FilecryptCc.py,_handle_circle_captcha,189,211,"def _handle_circle_captcha(self, url):        m = re.search(self.CIRCLE_CAPTCHA_PATTERN, self.data)        if m is not None:            self.log_debug(                ""Circle Captcha URL: {}"".format(                    urllib.parse.urljoin(self.pyfile.url, m.group(1))                )            )            captcha_url = urllib.parse.urljoin(self.pyfile.url, m.group(1))            self.log_debug(f""Circle Captcha URL: {captcha_url}"")            captcha_code = self.captcha.decrypt(                captcha_url, input_type=""png"", output_type=""positional""            )            return self._filecrypt_load_url(                url, post={""button.x"": captcha_code[0], ""button.y"": captcha_code[1]}            )        else:            return None",,"def _handle_circle_captcha(self, url):        m = re.search(self.CIRCLE_CAPTCHA_PATTERN, self.data)        if m is not None:            self.log_debug(                ""Circle Captcha URL: {}"".format(                    urllib.parse.urljoin(self.pyfile.url, m.group(1))                )            )            captcha_url = urllib.parse.urljoin(self.pyfile.url, m.group(1))            self.log_debug(f""Circle Captcha URL: {captcha_url}"")            captcha_code = self.captcha.decrypt(                captcha_url, input_type=""png"", output_type=""positional""            )            return self._filecrypt_load_url(                url, post={""button.x"": captcha_code[0], ""button.y"": captcha_code[1]}            )        else:            return None",563f3101-e29d-4e94-8f70-287fae3f184c
decrypters,FilecryptCc.py,_handle_solvemedia_captcha,213,235,"def _handle_solvemedia_captcha(self, url):        m = re.search(self.SOLVEMEDIA_CAPTCHA_PATTERN, self.data)        if m is not None:            self.log_debug(                ""Solvemedia Captcha URL: {}"".format(                    urllib.parse.urljoin(self.pyfile.url, m.group(1))                )            )            solvemedia = SolveMedia(self.pyfile)            captcha_key = solvemedia.detect_key()            if captcha_key:                self.captcha = solvemedia                response, challenge = solvemedia.challenge(captcha_key)                return self._filecrypt_load_url(                    url,                    post={""adcopy_response"": response, ""adcopy_challenge"": challenge},                )        else:            return None",,"def _handle_solvemedia_captcha(self, url):        m = re.search(self.SOLVEMEDIA_CAPTCHA_PATTERN, self.data)        if m is not None:            self.log_debug(                ""Solvemedia Captcha URL: {}"".format(                    urllib.parse.urljoin(self.pyfile.url, m.group(1))                )            )            solvemedia = SolveMedia(self.pyfile)            captcha_key = solvemedia.detect_key()            if captcha_key:                self.captcha = solvemedia                response, challenge = solvemedia.challenge(captcha_key)                return self._filecrypt_load_url(                    url,                    post={""adcopy_response"": response, ""adcopy_challenge"": challenge},                )        else:            return None",ac6bb9ac-0dc8-4f5c-b043-a96d060dfe4d
decrypters,FilecryptCc.py,_handle_keycaptcha_captcha,237,246,"def _handle_keycaptcha_captcha(self, url):        m = re.search(self.KEY_CAPTCHA_PATTERN, self.data)        if m is not None:            self.log_debug(                ""Keycaptcha Captcha URL: {} unsupported, retrying"".format(m.group(1))            )            return """"        else:            return None",,"def _handle_keycaptcha_captcha(self, url):        m = re.search(self.KEY_CAPTCHA_PATTERN, self.data)        if m is not None:            self.log_debug(                ""Keycaptcha Captcha URL: {} unsupported, retrying"".format(m.group(1))            )            return """"        else:            return None",e8fa4158-271d-464a-bacc-54a2ce99b00b
decrypters,FilecryptCc.py,_handle_coinhive_captcha,248,259,"def _handle_coinhive_captcha(self, url):        coinhive = CoinHive(self.pyfile)        coinhive_key = coinhive.detect_key()        if coinhive_key:            self.captcha = coinhive            token = coinhive.challenge(coinhive_key)            return self._filecrypt_load_url(url, post={""coinhive-captcha-token"": token})        else:            return None",,"def _handle_coinhive_captcha(self, url):        coinhive = CoinHive(self.pyfile)        coinhive_key = coinhive.detect_key()        if coinhive_key:            self.captcha = coinhive            token = coinhive.challenge(coinhive_key)            return self._filecrypt_load_url(url, post={""coinhive-captcha-token"": token})        else:            return None",ae4db1d3-c46b-4a2e-a4ea-97c650c6f0ba
decrypters,FilecryptCc.py,_handle_recaptcha_captcha,261,274,"def _handle_recaptcha_captcha(self, url):        recaptcha = ReCaptcha(self.pyfile)        captcha_key = recaptcha.detect_key()        if captcha_key:            self.captcha = recaptcha            response = recaptcha.challenge(captcha_key)            return self._filecrypt_load_url(                url, post={""g-recaptcha-response"": response}            )        else:            return None",,"def _handle_recaptcha_captcha(self, url):        recaptcha = ReCaptcha(self.pyfile)        captcha_key = recaptcha.detect_key()        if captcha_key:            self.captcha = recaptcha            response = recaptcha.challenge(captcha_key)            return self._filecrypt_load_url(                url, post={""g-recaptcha-response"": response}            )        else:            return None",926dd043-b6f5-4e2c-a491-a6a02b1f5e81
decrypters,FilecryptCc.py,handle_dlc_container,276,288,"def handle_dlc_container(self):        m = re.search(r""const (\w+) = DownloadDLC;"", self.site_with_links)        if m is not None:            self.site_with_links = self.site_with_links.replace(m.group(1), ""DownloadDLC"")        dlcs = re.findall(self.DLC_LINK_PATTERN, self.site_with_links)        if not dlcs:            return        for dlc in dlcs:            self.urls.append(                urllib.parse.urljoin(self.pyfile.url, ""/DLC/{}.dlc"".format(dlc))            )",,"def handle_dlc_container(self):        m = re.search(r""const (\w+) = DownloadDLC;"", self.site_with_links)        if m is not None:            self.site_with_links = self.site_with_links.replace(m.group(1), ""DownloadDLC"")        dlcs = re.findall(self.DLC_LINK_PATTERN, self.site_with_links)        if not dlcs:            return        for dlc in dlcs:            self.urls.append(                urllib.parse.urljoin(self.pyfile.url, ""/DLC/{}.dlc"".format(dlc))            )",d64a3595-cb79-4568-ac29-6c0e7f4dbe81
decrypters,FilecryptCc.py,handle_weblinks,290,308,"def handle_weblinks(self):        try:            links = re.findall(self.WEBLINK_PATTERN, self.site_with_links)            for link in links:                link = ""https://filecrypt.cc/Link/{}.html"".format(link)                for i in range(5):                    self.data = self._filecrypt_load_url(link)                    m = re.search(r'https://filecrypt\.cc/index\.php\?Action=Go&id=\w+', self.data)                    if m is not None:                        headers = self._filecrypt_load_url(m.group(0), just_header=True)                        self.urls.append(headers[""location""])                        break                else:                    self.log_error(self._(""Weblink could not be found""))        except Exception as exc:            self.log_debug(f""Error decrypting weblinks: {exc}"")",,"def handle_weblinks(self):        try:            links = re.findall(self.WEBLINK_PATTERN, self.site_with_links)            for link in links:                link = ""https://filecrypt.cc/Link/{}.html"".format(link)                for i in range(5):                    self.data = self._filecrypt_load_url(link)                    m = re.search(r'https://filecrypt\.cc/index\.php\?Action=Go&id=\w+', self.data)                    if m is not None:                        headers = self._filecrypt_load_url(m.group(0), just_header=True)                        self.urls.append(headers[""location""])                        break                else:                    self.log_error(self._(""Weblink could not be found""))        except Exception as exc:            self.log_debug(f""Error decrypting weblinks: {exc}"")",67d35d98-9aea-4e00-bf34-342c15844ecf
decrypters,FilecryptCc.py,handle_CNL,310,324,"def handle_CNL(self):        try:            m = re.search(r""const (\w+) = CNLPOP;"", self.site_with_links)            if m is not None:                self.site_with_links = self.site_with_links.replace(m.group(1), ""CNLPOP"")            CNLdata = re.findall(                r'onsubmit=""CNLPOP\(\'(.*)\', \'(.*)\', \'(.*)\', \'(.*)\'\);',                self.site_with_links,            )            for index in CNLdata:                self.urls.extend(self._get_links(index[2], index[1]))        except Exception as exc:            self.log_debug(f""Error decrypting CNL: {exc}"")",,"def handle_CNL(self):        try:            m = re.search(r""const (\w+) = CNLPOP;"", self.site_with_links)            if m is not None:                self.site_with_links = self.site_with_links.replace(m.group(1), ""CNLPOP"")            CNLdata = re.findall(                r'onsubmit=""CNLPOP\(\'(.*)\', \'(.*)\', \'(.*)\', \'(.*)\'\);',                self.site_with_links,            )            for index in CNLdata:                self.urls.extend(self._get_links(index[2], index[1]))        except Exception as exc:            self.log_debug(f""Error decrypting CNL: {exc}"")",c2dc81dc-4bff-4a6f-93e0-761fa77ff000
decrypters,FilecryptCc.py,_get_links,326,341,"def _get_links(self, crypted, jk):        #: Get key and iv        key = iv = bytes.fromhex(jk)        #: Decrypt        cipher = Cipher(algorithms.AES(key), modes.CBC(iv), backend=default_backend())        decryptor = cipher.decryptor()        text = to_str(            decryptor.update(base64.b64decode(crypted)) + decryptor.finalize()        )        #: Extract links        text = text.replace(""\x00"", """").replace(""\r"", """")        links = [link for link in text.split(""\n"") if link]        return links",,"def _get_links(self, crypted, jk):        #: Get key and iv        key = iv = bytes.fromhex(jk)        #: Decrypt        cipher = Cipher(algorithms.AES(key), modes.CBC(iv), backend=default_backend())        decryptor = cipher.decryptor()        text = to_str(            decryptor.update(base64.b64decode(crypted)) + decryptor.finalize()        )        #: Extract links        text = text.replace(""\x00"", """").replace(""\r"", """")        links = [link for link in text.split(""\n"") if link]        return links",3b575e9d-7cfe-4b54-9fbf-bebe8cb76e66
decrypters,FilecryptCc.py,_filecrypt_load_url,343,350,"def _filecrypt_load_url(self, *args, **kwargs):        try:            return self.load(*args, **kwargs)        except BadHeader as exc:            if exc.code == 500:                return exc.content            else:                raise",,"def _filecrypt_load_url(self, *args, **kwargs):        try:            return self.load(*args, **kwargs)        except BadHeader as exc:            if exc.code == 500:                return exc.content            else:                raise",abef6f4e-9ab8-4549-81f1-74b97ef73ed6
decrypters,FilefactoryComFolder.py,load_page,35,36,"def load_page(self, page_n):        return self.load(self.pyfile.url, get={""page"": page_n, ""show"": 100})",,"def load_page(self, page_n):        return self.load(self.pyfile.url, get={""page"": page_n, ""show"": 100})",e628d993-3970-4385-a871-45d4dc5d4d1c
decrypters,FourChanOrg.py,decrypt,35,38,"def decrypt(self, pyfile):        pagehtml = self.load(pyfile.url)        images = set(re.findall(r'(images\.4chan\.org/[^/]*/src/[^""<]+)', pagehtml))        self.links = [urllib.parse.urljoin(""http://"", image) for image in images]",,"def decrypt(self, pyfile):        pagehtml = self.load(pyfile.url)        images = set(re.findall(r'(images\.4chan\.org/[^/]*/src/[^""<]+)', pagehtml))        self.links = [urllib.parse.urljoin(""http://"", image) for image in images]",e112d657-8f3c-4135-927e-14c92a7c75df
decrypters,FreakhareComFolder.py,load_page,35,53,"def load_page(self, page_n):        if not hasattr(self, ""f_id"") and not hasattr(self, ""f_md5""):            m = re.search(                r""http://freakshare.com/\?x=folder&f_id=(\d+)&f_md5=(\w+)"", self.data            )            if m is not None:                self.f_id = m.group(1)                self.f_md5 = m.group(2)        return self.load(            ""http://freakshare.com/"",            get={                ""x"": ""folder"",                ""f_id"": self.f_id,                ""f_md5"": self.f_md5,                ""entrys"": ""20"",                ""page"": page_n - 1,                ""order"": """",            },        )",,"def load_page(self, page_n):        if not hasattr(self, ""f_id"") and not hasattr(self, ""f_md5""):            m = re.search(                r""http://freakshare.com/\?x=folder&f_id=(\d+)&f_md5=(\w+)"", self.data            )            if m is not None:                self.f_id = m.group(1)                self.f_md5 = m.group(2)        return self.load(            ""http://freakshare.com/"",            get={                ""x"": ""folder"",                ""f_id"": self.f_id,                ""f_md5"": self.f_md5,                ""entrys"": ""20"",                ""page"": page_n - 1,                ""order"": """",            },        )",2d3b109b-d431-4e49-98c1-9096fa71c59e
decrypters,FreetexthostCom.py,get_links,30,37,"def get_links(self):        m = re.search(            r'<div id=""contentsinner"">\s*(.+)<div class=""viewcount"">', self.data, re.S        )        if m is None:            self.error(self._(""Unable to extract links""))        links = m.group(1)        return links.strip().split(""<br />\r\n"")",,"def get_links(self):        m = re.search(            r'<div id=""contentsinner"">\s*(.+)<div class=""viewcount"">', self.data, re.S        )        if m is None:            self.error(self._(""Unable to extract links""))        links = m.group(1)        return links.strip().split(""<br />\r\n"")",ff7e8d00-74ee-451c-a9eb-fe9e010387e6
decrypters,FshareVnFolder.py,enum_folder,45,92,"def enum_folder(self, folder_id):        links = []        self.req.http.c.setopt(            pycurl.HTTPHEADER, [""Accept: application/json, text/plain, */*""]        )        self.data = self.load(            ""https://www.fshare.vn/api/v3/files/folder"", get={""linkcode"": folder_id}        )        json_data = json.loads(self.data)        current_page = 1        last_page = int(            re.search(r""&page=(\d+)"", json_data[""_links""].get(""last"", ""&page=1"")).group(                1            )        )        while True:            folder_items = json_data[""items""]            for item in folder_items:                if item[""type""] == 1:                    links.append(""https://www.fshare.vn/file/"" + item[""linkcode""])                else:                    if self.config.get(""dl_subfolders""):                        if self.config.get(""package_subfolder""):                            links.append(                                ""https://www.fshare.vn/folder/"" + item[""linkcode""]                            )                        else:                            links.extend(self.enum_folder(item[""linkcode""]))            current_page += 1            if current_page > last_page:                break            self.req.http.c.setopt(                pycurl.HTTPHEADER, [""Accept: application/json, text/plain, */*""]            )            self.data = self.load(                ""https://www.fshare.vn/api/v3/files/folder"",                get={""linkcode"": folder_id, ""page"": current_page},            )            json_data = json.loads(self.data)        return links",,"def enum_folder(self, folder_id):        links = []        self.req.http.c.setopt(            pycurl.HTTPHEADER, [""Accept: application/json, text/plain, */*""]        )        self.data = self.load(            ""https://www.fshare.vn/api/v3/files/folder"", get={""linkcode"": folder_id}        )        json_data = json.loads(self.data)        current_page = 1        last_page = int(            re.search(r""&page=(\d+)"", json_data[""_links""].get(""last"", ""&page=1"")).group(                1            )        )        while True:            folder_items = json_data[""items""]            for item in folder_items:                if item[""type""] == 1:                    links.append(""https://www.fshare.vn/file/"" + item[""linkcode""])                else:                    if self.config.get(""dl_subfolders""):                        if self.config.get(""package_subfolder""):                            links.append(                                ""https://www.fshare.vn/folder/"" + item[""linkcode""]                            )                        else:                            links.extend(self.enum_folder(item[""linkcode""]))            current_page += 1            if current_page > last_page:                break            self.req.http.c.setopt(                pycurl.HTTPHEADER, [""Accept: application/json, text/plain, */*""]            )            self.data = self.load(                ""https://www.fshare.vn/api/v3/files/folder"",                get={""linkcode"": folder_id, ""page"": current_page},            )            json_data = json.loads(self.data)        return links",72f44c33-cf49-42a7-b148-377da288b9ab
decrypters,FshareVnFolder.py,decrypt,94,107,"def decrypt(self, pyfile):        pyfile.url = replace_patterns(pyfile.url, self.URL_REPLACEMENTS)        self.data = self.load(pyfile.url)        if re.search(self.OFFLINE_PATTERN, self.data):            self.offline()        m = re.search(self.NAME_PATTERN, self.data)        pack_name = m.group(1) if m is not None else pyfile.package().name        links = self.enum_folder(self.info[""pattern""][""ID""])        if links:            self.packages = [(pack_name, links, pack_name)]",,"def decrypt(self, pyfile):        pyfile.url = replace_patterns(pyfile.url, self.URL_REPLACEMENTS)        self.data = self.load(pyfile.url)        if re.search(self.OFFLINE_PATTERN, self.data):            self.offline()        m = re.search(self.NAME_PATTERN, self.data)        pack_name = m.group(1) if m is not None else pyfile.package().name        links = self.enum_folder(self.info[""pattern""][""ID""])        if links:            self.packages = [(pack_name, links, pack_name)]",a87e4df4-7d97-438a-8762-b04aa6409826
decrypters,Go4UpCom.py,get_links,42,61,"def get_links(self):        links = []        preference = self.config.get(""preferred_hoster"")        hosterslink_re = re.search(r'(/download/gethosts/.+?)""', self.data)        if hosterslink_re:            hosters = self.load(                urllib.parse.urljoin(""http://go4up.com/"", hosterslink_re.group(1))            )            for hoster in json.loads(hosters):                if preference not in (0, int(hoster[""hostId""])):                    continue                pagelink_re = re.search(self.LINK_PATTERN, hoster[""link""])                if pagelink_re:                    page = self.load(pagelink_re.group(1))                    link_re = re.search(r'<b><a href=""(.+?)""', page)                    if link_re:                        links.append(link_re.group(1))        return links",,"def get_links(self):        links = []        preference = self.config.get(""preferred_hoster"")        hosterslink_re = re.search(r'(/download/gethosts/.+?)""', self.data)        if hosterslink_re:            hosters = self.load(                urllib.parse.urljoin(""http://go4up.com/"", hosterslink_re.group(1))            )            for hoster in json.loads(hosters):                if preference not in (0, int(hoster[""hostId""])):                    continue                pagelink_re = re.search(self.LINK_PATTERN, hoster[""link""])                if pagelink_re:                    page = self.load(pagelink_re.group(1))                    link_re = re.search(r'<b><a href=""(.+?)""', page)                    if link_re:                        links.append(link_re.group(1))        return links",5e9b4c36-8c72-4af7-9dfb-a0c6ecd5924f
decrypters,GofileIoFolder.py,api_request,39,49,"def api_request(self, method, token=None, get={}, post={}):        if token is not None:            self.req.http.c.setopt(                pycurl.HTTPHEADER, [""Authorization: Bearer "" + token]            )        try:            json_data = self.load(self.API_URL + method, get=get, post=post)        except BadHeader as exc:            json_data = exc.content        return json.loads(json_data)",,"def api_request(self, method, token=None, get={}, post={}):        if token is not None:            self.req.http.c.setopt(                pycurl.HTTPHEADER, [""Authorization: Bearer "" + token]            )        try:            json_data = self.load(self.API_URL + method, get=get, post=post)        except BadHeader as exc:            json_data = exc.content        return json.loads(json_data)",1ceb7a31-c5bd-4866-8b6b-373f12972363
decrypters,GofileIoFolder.py,decrypt,51,99,"def decrypt(self, pyfile):        api_data = self.api_request(""accounts"", post=True)        if api_data[""status""] != ""ok"":            self.fail(                self._(""accounts API failed | {}"").format(api_data[""status""])            )        token = api_data[""data""][""token""]        api_data = self.api_request(            ""contents/{}"".format(self.info[""pattern""][""ID""]),            token=token,            get={""wt"": ""4fd6sg89d7s6""}        )        status = api_data[""status""]        if status == ""ok"":            pack_links = [                ""https://gofile.io/dl?q={}"".format(                    base64.b64encode(                        json.dumps(                            {                                ""t"": token,                                ""u"": file_data[""link""],                                ""n"": file_data[""name""],                                ""s"": file_data[""size""],                                ""m"": file_data[""md5""],                            }                        ).encode(""utf-8"")                    ).decode(""utf-8"")                )                for file_data in api_data[""data""][""children""].values()                if file_data[""type""] == ""file""            ]            if pack_links:                self.packages.append(                    (pyfile.package().name, pack_links, pyfile.package().folder)                )            else:                self.offline()        elif status == ""error-notFound"":            self.offline()        elif status == ""error-notPremium"":            self.fail(self._(""File can be downloaded by premium users only""))        else:            self.fail(self._(""getContent API failed | {}"").format(status))",,"def decrypt(self, pyfile):        api_data = self.api_request(""accounts"", post=True)        if api_data[""status""] != ""ok"":            self.fail(                self._(""accounts API failed | {}"").format(api_data[""status""])            )        token = api_data[""data""][""token""]        api_data = self.api_request(            ""contents/{}"".format(self.info[""pattern""][""ID""]),            token=token,            get={""wt"": ""4fd6sg89d7s6""}        )        status = api_data[""status""]        if status == ""ok"":            pack_links = [                ""https://gofile.io/dl?q={}"".format(                    base64.b64encode(                        json.dumps(                            {                                ""t"": token,                                ""u"": file_data[""link""],                                ""n"": file_data[""name""],                                ""s"": file_data[""size""],                                ""m"": file_data[""md5""],                            }                        ).encode(""utf-8"")                    ).decode(""utf-8"")                )                for file_data in api_data[""data""][""children""].values()                if file_data[""type""] == ""file""            ]            if pack_links:                self.packages.append(                    (pyfile.package().name, pack_links, pyfile.package().folder)                )            else:                self.offline()        elif status == ""error-notFound"":            self.offline()        elif status == ""error-notPremium"":            self.fail(self._(""File can be downloaded by premium users only""))        else:            self.fail(self._(""getContent API failed | {}"").format(status))",30fe57c5-f50f-492d-a82b-db06aee4f50a
decrypters,GooGl.py,api_request,38,44,"def api_request(self, cmd, **kwargs):        kwargs[""key""] = self.API_KEY        json_data = json.loads(self.load(""{}{}"".format(self.API_URL, cmd),                                         get=kwargs))        self.log_debug(""API response: {}"".format(json_data))        return json_data",,"def api_request(self, cmd, **kwargs):        kwargs[""key""] = self.API_KEY        json_data = json.loads(self.load(""{}{}"".format(self.API_URL, cmd),                                         get=kwargs))        self.log_debug(""API response: {}"".format(json_data))        return json_data",721eddcf-faf7-4ab7-9973-3f7bd06de5c6
decrypters,GooGl.py,decrypt,46,52,"def decrypt(self, pyfile):        res = self.api_request(""url"", shortUrl=self.pyfile.url)        if  res['status'] != ""OK"":            self.offline()        self.packages.append((pyfile.package().name, [res[""longUrl""]], pyfile.package().folder))",,"def decrypt(self, pyfile):        res = self.api_request(""url"", shortUrl=self.pyfile.url)        if  res['status'] != ""OK"":            self.offline()        self.packages.append((pyfile.package().name, [res[""longUrl""]], pyfile.package().folder))",b802553b-3eed-44df-ae55-0fd52f7e14f6
decrypters,GoogledriveComDereferer.py,api_request,42,68,"def api_request(self, cmd, **kwargs):        kwargs[""key""] = self.API_KEY        try:            json_data = json.loads(                self.load(""{}{}"".format(self.API_URL, cmd), get=kwargs)            )            self.log_debug(f""API response: {json_data}"")            return json_data        except BadHeader as exc:            try:                json_data = json.loads(exc.content)                self.log_error(                    ""API Error: {}"".format(cmd),                    json_data[""error""][""message""],                    ""ID: {}"".format(self.info[""pattern""][""ID""]),                    ""Error code: {}"".format(exc.code),                )            except ValueError:                self.log_error(                    ""API Error: {}"".format(cmd),                    exc,                    ""ID: {}"".format(self.info[""pattern""][""ID""]),                    ""Error code: {}"".format(exc.code),                )            return None",,"def api_request(self, cmd, **kwargs):        kwargs[""key""] = self.API_KEY        try:            json_data = json.loads(                self.load(""{}{}"".format(self.API_URL, cmd), get=kwargs)            )            self.log_debug(f""API response: {json_data}"")            return json_data        except BadHeader as exc:            try:                json_data = json.loads(exc.content)                self.log_error(                    ""API Error: {}"".format(cmd),                    json_data[""error""][""message""],                    ""ID: {}"".format(self.info[""pattern""][""ID""]),                    ""Error code: {}"".format(exc.code),                )            except ValueError:                self.log_error(                    ""API Error: {}"".format(cmd),                    exc,                    ""ID: {}"".format(self.info[""pattern""][""ID""]),                    ""Error code: {}"".format(exc.code),                )            return None",c8c0c441-436f-4865-a4b6-58082f33aa5e
decrypters,GoogledriveComDereferer.py,decrypt,70,91,"def decrypt(self, pyfile):        json_data = self.api_request(""files/{}"".format(self.info[""pattern""][""ID""]))        if json_data is None:            self.fail(""API error"")        if ""error"" in json_data:            if json_data[""error""][""code""] == 404:                self.offline()            else:                self.fail(json_data[""error""][""message""])        link = ""https://drive.google.com/{}/{}"".format(            (                ""file/d""                if json_data[""mimeType""] != ""application/vnd.google-apps.folder""                else ""drive/folders""            ),            self.info[""pattern""][""ID""],        )        self.packages = [(pyfile.package().folder, [link], pyfile.package().name)]",,"def decrypt(self, pyfile):        json_data = self.api_request(""files/{}"".format(self.info[""pattern""][""ID""]))        if json_data is None:            self.fail(""API error"")        if ""error"" in json_data:            if json_data[""error""][""code""] == 404:                self.offline()            else:                self.fail(json_data[""error""][""message""])        link = ""https://drive.google.com/{}/{}"".format(            (                ""file/d""                if json_data[""mimeType""] != ""application/vnd.google-apps.folder""                else ""drive/folders""            ),            self.info[""pattern""][""ID""],        )        self.packages = [(pyfile.package().folder, [link], pyfile.package().name)]",80b99dc8-389c-42e7-b3e1-08b2dcdda893
decrypters,GoogledriveComFolder.py,api_request,44,70,"def api_request(self, cmd, **kwargs):        kwargs[""key""] = self.API_KEY        try:            json_data = json.loads(                self.load(""{}{}"".format(self.API_URL, cmd), get=kwargs)            )            self.log_debug(f""API response: {json_data}"")            return json_data        except BadHeader as exc:            try:                json_data = json.loads(exc.content)                self.log_error(                    ""API Error: {}"".format(cmd),                    json_data[""error""][""message""],                    ""ID: {}"".format(self.info[""pattern""][""ID""]),                    ""Error code: {}"".format(exc.code),                )            except ValueError:                self.log_error(                    ""API Error: {}"".format(cmd),                    exc,                    ""ID: {}"".format(self.info[""pattern""][""ID""]),                    ""Error code: {}"".format(exc.code),                )            return None",,"def api_request(self, cmd, **kwargs):        kwargs[""key""] = self.API_KEY        try:            json_data = json.loads(                self.load(""{}{}"".format(self.API_URL, cmd), get=kwargs)            )            self.log_debug(f""API response: {json_data}"")            return json_data        except BadHeader as exc:            try:                json_data = json.loads(exc.content)                self.log_error(                    ""API Error: {}"".format(cmd),                    json_data[""error""][""message""],                    ""ID: {}"".format(self.info[""pattern""][""ID""]),                    ""Error code: {}"".format(exc.code),                )            except ValueError:                self.log_error(                    ""API Error: {}"".format(cmd),                    exc,                    ""ID: {}"".format(self.info[""pattern""][""ID""]),                    ""Error code: {}"".format(exc.code),                )            return None",6734777a-655e-445e-b3b6-1a55febd5519
decrypters,GoogledriveComFolder.py,enum_folder,72,133,"def enum_folder(self, folder_id):        links = []        json_data = self.api_request(            ""files"",            q=""'{}' in parents"".format(folder_id),            pageSize=100,            fields=""files/id,files/mimeType,nextPageToken"",            supportsAllDrives=""true"",            includeItemsFromAllDrives=""true"",        )        if json_data is None:            self.fail(""API error"")        if ""error"" in json_data:            self.fail(json_data[""error""][""message""])        for f in json_data.get(""files"", []):            if f[""mimeType""] != ""application/vnd.google-apps.folder"":                links.append(""https://drive.google.com/file/d/"" + f[""id""])            elif self.config.get(""dl_subfolders""):                if self.config.get(""package_subfolder""):                    links.append(""https://drive.google.com/drive/folders/"" + f[""id""])                else:                    links.extend(self.enum_folder(f[""id""]))        next_page = json_data.get(""nextPageToken"", None)        while next_page:            json_data = self.api_request(                ""files"",                q=""'{}' in parents"".format(folder_id),                pageToken=next_page,                pageSize=100,                fields=""files/id,files/mimeType,nextPageToken"",                supportsAllDrives=""true"",                includeItemsFromAllDrives=""true"",            )            if json_data is None:                self.fail(""API error"")            if ""error"" in json_data:                self.fail(json_data[""error""][""message""])            for f in json_data.get(""files"", []):                if f[""mimeType""] != ""application/vnd.google-apps.folder"":                    links.append(""https://drive.google.com/file/d/"" + f[""id""])                elif self.config.get(""dl_subfolders""):                    if self.config.get(""package_subfolder""):                        links.append(                            ""https://drive.google.com/drive/folders/"" + f[""id""]                        )                    else:                        links.extend(self.enum_folder(f[""id""]))            next_page = json_data.get(""nextPageToken"", None)        return links",,"def enum_folder(self, folder_id):        links = []        json_data = self.api_request(            ""files"",            q=""'{}' in parents"".format(folder_id),            pageSize=100,            fields=""files/id,files/mimeType,nextPageToken"",            supportsAllDrives=""true"",            includeItemsFromAllDrives=""true"",        )        if json_data is None:            self.fail(""API error"")        if ""error"" in json_data:            self.fail(json_data[""error""][""message""])        for f in json_data.get(""files"", []):            if f[""mimeType""] != ""application/vnd.google-apps.folder"":                links.append(""https://drive.google.com/file/d/"" + f[""id""])            elif self.config.get(""dl_subfolders""):                if self.config.get(""package_subfolder""):                    links.append(""https://drive.google.com/drive/folders/"" + f[""id""])                else:                    links.extend(self.enum_folder(f[""id""]))        next_page = json_data.get(""nextPageToken"", None)        while next_page:            json_data = self.api_request(                ""files"",                q=""'{}' in parents"".format(folder_id),                pageToken=next_page,                pageSize=100,                fields=""files/id,files/mimeType,nextPageToken"",                supportsAllDrives=""true"",                includeItemsFromAllDrives=""true"",            )            if json_data is None:                self.fail(""API error"")            if ""error"" in json_data:                self.fail(json_data[""error""][""message""])            for f in json_data.get(""files"", []):                if f[""mimeType""] != ""application/vnd.google-apps.folder"":                    links.append(""https://drive.google.com/file/d/"" + f[""id""])                elif self.config.get(""dl_subfolders""):                    if self.config.get(""package_subfolder""):                        links.append(                            ""https://drive.google.com/drive/folders/"" + f[""id""]                        )                    else:                        links.extend(self.enum_folder(f[""id""]))            next_page = json_data.get(""nextPageToken"", None)        return links",b83fa3c2-5ce7-4b3a-b3af-ff145d2a09ea
decrypters,GoogledriveComFolder.py,decrypt,135,157,"def decrypt(self, pyfile):        links = []        json_data = self.api_request(            ""files/{}"".format(self.info[""pattern""][""ID""]),            supportsAllDrives=""true"",        )        if json_data is None:            self.fail(""API error"")        if ""error"" in json_data:            if json_data[""error""][""code""] == 404:                self.offline()            else:                self.fail(json_data[""error""][""message""])        pack_name = json_data.get(""name"", pyfile.package().name)        links = self.enum_folder(self.info[""pattern""][""ID""])        if links:            self.packages = [(pack_name, links, pack_name)]",,"def decrypt(self, pyfile):        links = []        json_data = self.api_request(            ""files/{}"".format(self.info[""pattern""][""ID""]),            supportsAllDrives=""true"",        )        if json_data is None:            self.fail(""API error"")        if ""error"" in json_data:            if json_data[""error""][""code""] == 404:                self.offline()            else:                self.fail(json_data[""error""][""message""])        pack_name = json_data.get(""name"", pyfile.package().name)        links = self.enum_folder(self.info[""pattern""][""ID""])        if links:            self.packages = [(pack_name, links, pack_name)]",04c2c4b8-4a01-4b81-b1b6-884c77f0b930
decrypters,HearthisAtFolder.py,decrypt,33,60,"def decrypt(self, pyfile):        self.data = self.load(pyfile.url)        m = re.search(r""intTrackId = (\d+);"", self.data)        if m is not None:            #: Single track            self.packages = [                (pyfile.package().name, pyfile.url + ""#pyload"", pyfile.package().folder)            ]        else:            #: Playlist            m = re.search(r""intInternalId = (\d+);"", self.data)            if m is None:                self.fail(self._(""Internal Id not found""))            self.data = self.load(                ""https://hearthis.at/user_ajax_more.php"",                post={""user"": m.group(1), ""min"": 0, ""max"": 200},            )            links = [                urllib.parse.urljoin(pyfile.url, x) + ""#pyload""                for x in re.findall(                    r'<a class=""player-link"".+?href=""(.+?)"".+?</a>', self.data, re.S                )            ]            self.packages = [(pyfile.package().name, links, pyfile.package().folder)]",,"def decrypt(self, pyfile):        self.data = self.load(pyfile.url)        m = re.search(r""intTrackId = (\d+);"", self.data)        if m is not None:            #: Single track            self.packages = [                (pyfile.package().name, pyfile.url + ""#pyload"", pyfile.package().folder)            ]        else:            #: Playlist            m = re.search(r""intInternalId = (\d+);"", self.data)            if m is None:                self.fail(self._(""Internal Id not found""))            self.data = self.load(                ""https://hearthis.at/user_ajax_more.php"",                post={""user"": m.group(1), ""min"": 0, ""max"": 200},            )            links = [                urllib.parse.urljoin(pyfile.url, x) + ""#pyload""                for x in re.findall(                    r'<a class=""player-link"".+?href=""(.+?)"".+?</a>', self.data, re.S                )            ]            self.packages = [(pyfile.package().name, links, pyfile.package().folder)]",ba07d267-b89e-4662-b382-51a717c153e8
decrypters,HflixIn.py,decrypt,20,30,"def decrypt(self, pyfile):        headers = self.load(pyfile.url, just_header=True)        if ""refresh"" in headers and headers[""refresh""]:            m = re.search(r""\d+;url=(.+)"", headers[""refresh""])            if m and ""http://hflix.in/admin"" not in m.group(1):                self.packages.append(                    (pyfile.package().name, [m.group(1)], pyfile.package().name)                )            else:                self.offline()",,"def decrypt(self, pyfile):        headers = self.load(pyfile.url, just_header=True)        if ""refresh"" in headers and headers[""refresh""]:            m = re.search(r""\d+;url=(.+)"", headers[""refresh""])            if m and ""http://hflix.in/admin"" not in m.group(1):                self.packages.append(                    (pyfile.package().name, [m.group(1)], pyfile.package().name)                )            else:                self.offline()",5e69f20a-e4a6-4b86-8755-aeec882e9724
decrypters,HoerbuchIn.py,decrypt,38,54,"def decrypt(self, pyfile):        self.pyfile = pyfile        if self.article.match(pyfile.url):            html = self.load(pyfile.url)            soup = BeautifulSoup(                html, 'html.parser'            )            links = []            for a in soup.findAll(""a"", attrs={""href"": self.hoster_links}):                for decrypted_link in self.decrypt_folder(a.get(""href"")):                    links.append(decrypted_link)            self.packages.append((pyfile.name, links, pyfile.name))        else:            self.links = self.decrypt_folder(pyfile.url)",,"def decrypt(self, pyfile):        self.pyfile = pyfile        if self.article.match(pyfile.url):            html = self.load(pyfile.url)            soup = BeautifulSoup(                html, 'html.parser'            )            links = []            for a in soup.findAll(""a"", attrs={""href"": self.hoster_links}):                for decrypted_link in self.decrypt_folder(a.get(""href"")):                    links.append(decrypted_link)            self.packages.append((pyfile.name, links, pyfile.name))        else:            self.links = self.decrypt_folder(pyfile.url)",277f82fe-b033-4d56-93ae-da29a5e7c6ce
decrypters,HoerbuchIn.py,decrypt_folder,56,87,"def decrypt_folder(self, url):        m = self.hoster_links.search(url) or self.protection.search(url)        if m is None:            self.fail(self._(""Bad URL""))        url = m.group(0)        if self.hoster_links.match(url):            self.load(url)            url = self.req.last_effective_url        html = self.load(url, post={""viewed"": ""adpg""})        self.pyfile.url = url        links = []        soup = BeautifulSoup(            html, 'html.parser'        )        for container in soup.findAll(""div"", attrs={""class"": ""container""}):            href = container.a.get(""href"")            uploaded = self.uploaded.search(href)            if uploaded is not None:                href = ""http://uploaded.net/file/{}"".format(uploaded.group(1))            links.append(href)        return links",,"def decrypt_folder(self, url):        m = self.hoster_links.search(url) or self.protection.search(url)        if m is None:            self.fail(self._(""Bad URL""))        url = m.group(0)        if self.hoster_links.match(url):            self.load(url)            url = self.req.last_effective_url        html = self.load(url, post={""viewed"": ""adpg""})        self.pyfile.url = url        links = []        soup = BeautifulSoup(            html, 'html.parser'        )        for container in soup.findAll(""div"", attrs={""class"": ""container""}):            href = container.a.get(""href"")            uploaded = self.uploaded.search(href)            if uploaded is not None:                href = ""http://uploaded.net/file/{}"".format(uploaded.group(1))            links.append(href)        return links",b2b97e82-2ceb-4cfd-9edb-4244679df775
decrypters,ImgurCom.py,sanitize,43,53,"def sanitize(self, name):                keepcharacters = ("" "", ""\t"", ""."", ""_"")        replacecharacters = ("" "", ""\t"")        return """".join(            c if c not in replacecharacters else ""_""            for c in name.strip()            if c.isalnum() or c in keepcharacters        ).strip(""_"")",Turn Imgur Gallery title into a safe Package and Folder name.,"def sanitize(self, name):        """"""        Turn Imgur Gallery title into a safe Package and Folder name.        """"""        keepcharacters = ("" "", ""\t"", ""."", ""_"")        replacecharacters = ("" "", ""\t"")        return """".join(            c if c not in replacecharacters else ""_""            for c in name.strip()            if c.isalnum() or c in keepcharacters        ).strip(""_"")

Turn Imgur Gallery title into a safe Package and Folder name.",31b0db12-0fce-45ea-889d-9ae73de353c3
decrypters,ImgurCom.py,get_ids_from_json,55,110,"def get_ids_from_json(self):                # Greedy re should match the closing bracket of json assuming JSON data        # is placed on a single line        m = re.search(r""\simage\s+:\s+({.*})"", self.data)        if m is not None:            embedded_json = json.loads(m.group(1))            # Extract some metadata (ID, Title, NumImages)            gallery_id = embedded_json[""hash""]            self.gallery_name = self.sanitize(                self._(""{}_{}"").format(gallery_id, embedded_json[""title""])            )            self.total_num_images = int(embedded_json[""num_images""])            # Extract images            images = {                e[""hash""]: e[""ext""] for e in embedded_json[""album_images""][""images""]            }            self.log_debug(                ""Found {} of {} expected links in embedded JSON"".format(                    len(images), self.total_num_images                )            )            # Depeding on the gallery, the embedded JSON may not contain all image information, then we also try the external JSON            # If this doesn't help either (which is possible),... TODO: Find            # out what to do            if len(images) < self.total_num_images:                external_json = json.loads(                    self.load(self.GALLERY_JSON.format(gallery_id))                )                try:                    images = {                        e[""hash""]: e[""ext""] for e in external_json[""data""][""images""]                    }                    self.log_debug(                        ""Found {} of {} expected links in external JSON"".format(                            len(images), self.total_num_images                        )                    )                except (KeyError, TypeError):                    self.log_debug(""Could not extract links from external JSON"")                    # It is possible that the returned JSON contains an empty                    # 'data' section. We ignore it then.            return images        self.log_debug(""Could not find embedded JSON"")        return {}",Check the embedded JSON and if needed the external JSON for more images.,"def get_ids_from_json(self):        """"""        Check the embedded JSON and if needed the external JSON for more images.        """"""        # Greedy re should match the closing bracket of json assuming JSON data        # is placed on a single line        m = re.search(r""\simage\s+:\s+({.*})"", self.data)        if m is not None:            embedded_json = json.loads(m.group(1))            # Extract some metadata (ID, Title, NumImages)            gallery_id = embedded_json[""hash""]            self.gallery_name = self.sanitize(                self._(""{}_{}"").format(gallery_id, embedded_json[""title""])            )            self.total_num_images = int(embedded_json[""num_images""])            # Extract images            images = {                e[""hash""]: e[""ext""] for e in embedded_json[""album_images""][""images""]            }            self.log_debug(                ""Found {} of {} expected links in embedded JSON"".format(                    len(images), self.total_num_images                )            )            # Depeding on the gallery, the embedded JSON may not contain all image information, then we also try the external JSON            # If this doesn't help either (which is possible),... TODO: Find            # out what to do            if len(images) < self.total_num_images:                external_json = json.loads(                    self.load(self.GALLERY_JSON.format(gallery_id))                )                try:                    images = {                        e[""hash""]: e[""ext""] for e in external_json[""data""][""images""]                    }                    self.log_debug(                        ""Found {} of {} expected links in external JSON"".format(                            len(images), self.total_num_images                        )                    )                except (KeyError, TypeError):                    self.log_debug(""Could not extract links from external JSON"")                    # It is possible that the returned JSON contains an empty                    # 'data' section. We ignore it then.            return images        self.log_debug(""Could not find embedded JSON"")        return {}

Check the embedded JSON and if needed the external JSON for more images.",0ea93bc0-c89d-49b1-8508-1937deecf377
decrypters,ImgurCom.py,get_indirect_links,112,132,"def get_indirect_links(self, links_direct):                # Extract IDs of known direct links        ids_direct = set(            l for link in links_direct for l in re.findall(r""(\w{7})"", link)        )        # Get filename extensions for new IDs        ids_json = self.get_ids_from_json()        ids_indirect = [id for id in ids_json.keys() if id not in ids_direct]        # No additional images found        if len(ids_indirect) == 0:            return []        # Translate new IDs to Direct-URLs        return [            ""http://i.imgur.com/{}{}"".format(id, ids_json[id]) for id in ids_indirect        ]",Try to find a list of all images and add those we didn't find already.,"def get_indirect_links(self, links_direct):        """"""        Try to find a list of all images and add those we didn't find already.        """"""        # Extract IDs of known direct links        ids_direct = set(            l for link in links_direct for l in re.findall(r""(\w{7})"", link)        )        # Get filename extensions for new IDs        ids_json = self.get_ids_from_json()        ids_indirect = [id for id in ids_json.keys() if id not in ids_direct]        # No additional images found        if len(ids_indirect) == 0:            return []        # Translate new IDs to Direct-URLs        return [            ""http://i.imgur.com/{}{}"".format(id, ids_json[id]) for id in ids_indirect        ]

Try to find a list of all images and add those we didn't find already.",f4a32b5d-1489-4848-bbeb-b2ac90269ac8
decrypters,ImgurCom.py,setup,134,136,def setup(self):        self.gallery_name = None        self.total_num_images = 0,,def setup(self):        self.gallery_name = None        self.total_num_images = 0,69fde9a9-e22c-4e02-94b7-088509478ea4
decrypters,ImgurCom.py,get_links,138,181,"def get_links(self):                def f(url):            return ""http://"" + re.sub(r""(\w{7})s\."", r""\1."", url)        direct_links = uniquify(f(x) for x in re.findall(self.LINK_PATTERN, self.data))        # Imgur Galleryies may contain more images than initially shown. Find        # the rest now!        try:            indirect_links = self.get_indirect_links(direct_links)            self.log_debug(f""Found {len(indirect_links)} additional links"")        except (TypeError, KeyError, ValueError) as exc:            # Fail gracefull as we already had some success            self.log_error(                self._(""Processing of additional links unsuccessful - {}: {}"").format(                    type(exc).__name__, exc                )            )            indirect_links = []        # Check if all images were found and inform the user        num_images_found = len(direct_links) + len(indirect_links)        if num_images_found < self.total_num_images:            self.log_error(                self._(""Could not save all images of this gallery: {}/{}"").format(                    num_images_found, self.total_num_images                )            )        # If we could extract a name, use this to create a specific package        if self.gallery_name:            self.packages.append(                (self.gallery_name, direct_links + indirect_links, self.gallery_name)            )            return []        else:            return direct_links + indirect_links","Extract embedded links from HTML // then check if there are further images which
will be lazy-loaded.","def get_links(self):        """"""        Extract embedded links from HTML // then check if there are further images which        will be lazy-loaded.        """"""        def f(url):            return ""http://"" + re.sub(r""(\w{7})s\."", r""\1."", url)        direct_links = uniquify(f(x) for x in re.findall(self.LINK_PATTERN, self.data))        # Imgur Galleryies may contain more images than initially shown. Find        # the rest now!        try:            indirect_links = self.get_indirect_links(direct_links)            self.log_debug(f""Found {len(indirect_links)} additional links"")        except (TypeError, KeyError, ValueError) as exc:            # Fail gracefull as we already had some success            self.log_error(                self._(""Processing of additional links unsuccessful - {}: {}"").format(                    type(exc).__name__, exc                )            )            indirect_links = []        # Check if all images were found and inform the user        num_images_found = len(direct_links) + len(indirect_links)        if num_images_found < self.total_num_images:            self.log_error(                self._(""Could not save all images of this gallery: {}/{}"").format(                    num_images_found, self.total_num_images                )            )        # If we could extract a name, use this to create a specific package        if self.gallery_name:            self.packages.append(                (self.gallery_name, direct_links + indirect_links, self.gallery_name)            )            return []        else:            return direct_links + indirect_links

Extract embedded links from HTML // then check if there are further images which
will be lazy-loaded.",03f67a79-b9b2-414a-b055-9bb0c5658262
decrypters,JDlist.py,decrypt,30,31,"def decrypt(self, pyfile):        self.links.extend(base64.b64decode(self.info[""pattern""][""LIST""]).split("",""))",,"def decrypt(self, pyfile):        self.links.extend(base64.b64decode(self.info[""pattern""][""LIST""]).split("",""))",e30c92ea-5eb0-40b2-b073-85d03e537771
decrypters,LixIn.py,decrypt,34,70,"def decrypt(self, pyfile):        url = pyfile.url        m = re.match(self.__pattern__, url)        if m is None:            self.error(self._(""Unable to identify file ID""))        id = m.group(""ID"")        self.log_debug(f""File id is {id}"")        self.data = self.load(url)        m = re.search(self.SUBMIT_PATTERN, self.data)        if m is None:            self.error(self._(""Link doesn't seem valid""))        m = re.search(self.CAPTCHA_PATTERN, self.data)        if m is not None:            captcharesult = self.captcha.decrypt(                urllib.parse.urljoin(""http://lix.in/"", m.group(1))            )            self.data = self.load(                url, post={""capt"": captcharesult, ""submit"": ""submit"", ""tiny"": id}            )            if re.search(self.CAPTCHA_PATTERN, self.data):                self.fail(self._(""No captcha solved""))        else:            self.data = self.load(url, post={""submit"": ""submit"", ""tiny"": id})        m = re.search(self.LINK_PATTERN, self.data)        if m is None:            self.error(self._(""Unable to find destination url""))        else:            self.links = [m.group(1)]            self.log_debug(f""Found link {self.links[0]}, adding to package"")",,"def decrypt(self, pyfile):        url = pyfile.url        m = re.match(self.__pattern__, url)        if m is None:            self.error(self._(""Unable to identify file ID""))        id = m.group(""ID"")        self.log_debug(f""File id is {id}"")        self.data = self.load(url)        m = re.search(self.SUBMIT_PATTERN, self.data)        if m is None:            self.error(self._(""Link doesn't seem valid""))        m = re.search(self.CAPTCHA_PATTERN, self.data)        if m is not None:            captcharesult = self.captcha.decrypt(                urllib.parse.urljoin(""http://lix.in/"", m.group(1))            )            self.data = self.load(                url, post={""capt"": captcharesult, ""submit"": ""submit"", ""tiny"": id}            )            if re.search(self.CAPTCHA_PATTERN, self.data):                self.fail(self._(""No captcha solved""))        else:            self.data = self.load(url, post={""submit"": ""submit"", ""tiny"": id})        m = re.search(self.LINK_PATTERN, self.data)        if m is None:            self.error(self._(""Unable to find destination url""))        else:            self.links = [m.group(1)]            self.log_debug(f""Found link {self.links[0]}, adding to package"")",134bc1d6-6c5f-4593-92ad-a6fa5c9801fe
decrypters,MediafireComFolder.py,api_request,36,44,"def api_request(self, method, **kwargs):        kwargs[""response_format""] = ""json""        json_data = self.load(self.API_URL + method + "".php"", get=kwargs)        res = json.loads(json_data)        if res[""response""][""result""] != ""Success"":            self.fail(res[""response""][""message""])        return res",,"def api_request(self, method, **kwargs):        kwargs[""response_format""] = ""json""        json_data = self.load(self.API_URL + method + "".php"", get=kwargs)        res = json.loads(json_data)        if res[""response""][""result""] != ""Success"":            self.fail(res[""response""][""message""])        return res",8b8f9e1a-cf6f-4111-86b8-7b5b5a5bc97b
decrypters,MediafireComFolder.py,decrypt,46,66,"def decrypt(self, pyfile):        api_data = self.api_request(            ""folder/get_info"", folder_key=self.info[""pattern""][""ID""]        )        pack_name = (            api_data[""response""][""folder_info""].get(""name"")            or self.pyfile.package().name        )        api_data = self.api_request(            ""folder/get_content"",            folder_key=self.info[""pattern""][""ID""],            content_type=""files"",        )        pack_links = [            ""http://www.mediafire.com/file/{}"".format(f[""quickkey""])            for f in api_data[""response""][""folder_content""][""files""]        ]        if pack_links:            self.packages.append((pack_name, pack_links, pack_name))",,"def decrypt(self, pyfile):        api_data = self.api_request(            ""folder/get_info"", folder_key=self.info[""pattern""][""ID""]        )        pack_name = (            api_data[""response""][""folder_info""].get(""name"")            or self.pyfile.package().name        )        api_data = self.api_request(            ""folder/get_content"",            folder_key=self.info[""pattern""][""ID""],            content_type=""files"",        )        pack_links = [            ""http://www.mediafire.com/file/{}"".format(f[""quickkey""])            for f in api_data[""response""][""folder_content""][""files""]        ]        if pack_links:            self.packages.append((pack_name, pack_links, pack_name))",366a1726-d5a0-451a-9264-52006582c092
decrypters,MegaCoNzFolder.py,setup,34,44,"def setup(self):        try:            self.req.http.close()        except Exception:            pass        self.req.http = HTTPRequest(            cookies=self.req.cj,            options=self.pyload.request_factory.get_options(),            limit=10_000_000,        )",,"def setup(self):        try:            self.req.http.close()        except Exception:            pass        self.req.http = HTTPRequest(            cookies=self.req.cj,            options=self.pyload.request_factory.get_options(),            limit=10_000_000,        )",b809c786-c6f5-407a-81cd-82abac060926
decrypters,MegaCoNzFolder.py,decrypt,46,72,"def decrypt(self, pyfile):        id = self.info[""pattern""][""ID""]        master_key = self.info[""pattern""][""KEY""]        subdir = self.info[""pattern""][""SUBDIR""]        self.log_debug(            ""ID: {}"".format(id), ""Key: {}"".format(master_key), ""Type: public folder""        )        mega = MegaClient(self, id)        #: F is for requesting folder listing (kind like a `ls` command)        res = mega.api_request(a=""f"", c=1, r=1, ca=1, ssl=1)        if isinstance(res, int):            mega.check_error(res)        elif ""e"" in res:            mega.check_error(res[""e""])        urls = [            ""https://mega.co.nz/folder/{}#{}/file/{}"".format(id, master_key, node[""h""])            for node in res[""f""]            if node[""t""] == 0 and "":"" in node[""k""]            if subdir is None or node[""p""] == subdir        ]        if urls:            self.packages = [(pyfile.package().folder, urls, pyfile.package().name)]",,"def decrypt(self, pyfile):        id = self.info[""pattern""][""ID""]        master_key = self.info[""pattern""][""KEY""]        subdir = self.info[""pattern""][""SUBDIR""]        self.log_debug(            ""ID: {}"".format(id), ""Key: {}"".format(master_key), ""Type: public folder""        )        mega = MegaClient(self, id)        #: F is for requesting folder listing (kind like a `ls` command)        res = mega.api_request(a=""f"", c=1, r=1, ca=1, ssl=1)        if isinstance(res, int):            mega.check_error(res)        elif ""e"" in res:            mega.check_error(res[""e""])        urls = [            ""https://mega.co.nz/folder/{}#{}/file/{}"".format(id, master_key, node[""h""])            for node in res[""f""]            if node[""t""] == 0 and "":"" in node[""k""]            if subdir is None or node[""p""] == subdir        ]        if urls:            self.packages = [(pyfile.package().folder, urls, pyfile.package().name)]",5b7d4e3b-243c-4848-9486-74e98c1dc926
decrypters,MegadyskPlFolder.py,xor_decrypt,11,18,"def xor_decrypt(data, key):    data = base64.b64decode(data)    return """".join(        [            chr(ord(x[1]) ^ ord(key[x[0].format(len(key))]))            for x in [(i, c) for i, c in enumerate(data)]        ]    )",,"def xor_decrypt(data, key):    data = base64.b64decode(data)    return """".join(        [            chr(ord(x[1]) ^ ord(key[x[0].format(len(key))]))            for x in [(i, c) for i, c in enumerate(data)]        ]    )",c5545e36-75dc-4503-8dd1-b2ada79a2156
decrypters,MegadyskPlFolder.py,api_info,44,79,"def api_info(self, url):        html = self.load(url)        info = {}        m = re.search(r""window\['.*?'\]\s*=\s*\""(.*?)\"""", html)        if m is None:            info[""status""] = 8            info[""error""] = ""Encrypted info pattern not found""            return info        encrypted_info = m.group(1)        html = self.load(""https://megadysk.pl/dist/index.js"")        m = re.search(r't.ISK\s*=\s*""(\w+)""', html)        if m is None:            info[""status""] = 8            info[""error""] = ""Encryption key pattern not found""            return info        key = m.group(1)        res = xor_decrypt(encrypted_info, key)        json_data = json.loads(urllib.parse.unquote(res))        if json_data[""app""][""maintenance""]:            info[""status""] = 6            return info        if json_data[""app""][""folderView""][""notFound""]:            info[""status""] = 1            return info        info[""entities""] = json_data[""app""][""folderView""][""entities""]        return info",,"def api_info(self, url):        html = self.load(url)        info = {}        m = re.search(r""window\['.*?'\]\s*=\s*\""(.*?)\"""", html)        if m is None:            info[""status""] = 8            info[""error""] = ""Encrypted info pattern not found""            return info        encrypted_info = m.group(1)        html = self.load(""https://megadysk.pl/dist/index.js"")        m = re.search(r't.ISK\s*=\s*""(\w+)""', html)        if m is None:            info[""status""] = 8            info[""error""] = ""Encryption key pattern not found""            return info        key = m.group(1)        res = xor_decrypt(encrypted_info, key)        json_data = json.loads(urllib.parse.unquote(res))        if json_data[""app""][""maintenance""]:            info[""status""] = 6            return info        if json_data[""app""][""folderView""][""notFound""]:            info[""status""] = 1            return info        info[""entities""] = json_data[""app""][""folderView""][""entities""]        return info",7d1279a9-04be-49f4-938e-771d15cda3aa
decrypters,MegadyskPlFolder.py,decrypt,81,94,"def decrypt(self, pyfile):        if ""entities"" not in self.info:            self.error(self._(""Missing JSON data""))        pack_links = [            self.fixurl(l[""downloadUrl""])            for l in self.info[""entities""]            if l[""downloadUrl""].startswith(""/dl/"")        ]        if pack_links:            self.packages.append(                (pyfile.package().name, pack_links, pyfile.package().folder)            )",,"def decrypt(self, pyfile):        if ""entities"" not in self.info:            self.error(self._(""Missing JSON data""))        pack_links = [            self.fixurl(l[""downloadUrl""])            for l in self.info[""entities""]            if l[""downloadUrl""].startswith(""/dl/"")        ]        if pack_links:            self.packages.append(                (pyfile.package().name, pack_links, pyfile.package().folder)            )",dbf3fdc4-011a-4e4c-9888-14221bbb376d
decrypters,MirrorcreatorCom.py,decrypt,35,92,"def decrypt(self, pyfile):        pyfile.url = replace_patterns(pyfile.url, self.URL_REPLACEMENTS)        hosters_priority = [            h for h in self.config.get(""hosters_priority"").split(""|"") if h        ]        ignored_hosters = [            h for h in self.config.get(""ignored_hosters"").split(""|"") if h        ]        self.data = self.load(pyfile.url)        m = re.search(self.OFFLINE_PATTERN, self.data)        if m is not None:            self.offline()        pack_name, pack_folder = self.get_package_info()        uid = self.info[""pattern""][""ID""]        m = re.search(rf'""(/mstat\.php\?uid={uid}.+?)""', self.data)        if m is None:            self.fail(""mstat URL not found"")        self.data = self.load(self.fixurl(m.group(1)))        hosters_data = {}        for tr in re.findall(r""<tr>(.+?)</tr>"", self.data, re.S):            uid = self.info[""pattern""][""ID""]            m = re.search(                rf'<a href=""(/showlink\.php\?uid={uid}.+?)"".*&hname=(\w+)', tr, re.S            )            if m is not None:                hosters_data[m.group(2)] = m.group(1)        choosen_hosters = []        # priority hosters goes first        for h in hosters_priority:            if h in hosters_data and h not in ignored_hosters:                self.log_debug(f""Adding '{h}' link"")                choosen_hosters.append(h)                if not self.config.get(""grab_all""):                    break        # Now the rest of the hosters        if self.config.get(""grab_all"") or (            not self.config.get(""grab_all"") and not choosen_hosters        ):            for h in hosters_data:                if h not in ignored_hosters and h not in choosen_hosters:                    self.log_debug(f""Adding '{h}' link"")                    choosen_hosters.append(h)                    if not self.config.get(""grab_all""):                        break        pack_links = [self.resolve_hoster(hosters_data[h]) for h in choosen_hosters]        if pack_links:            self.packages.append((pack_name, pack_links, pack_folder))",,"def decrypt(self, pyfile):        pyfile.url = replace_patterns(pyfile.url, self.URL_REPLACEMENTS)        hosters_priority = [            h for h in self.config.get(""hosters_priority"").split(""|"") if h        ]        ignored_hosters = [            h for h in self.config.get(""ignored_hosters"").split(""|"") if h        ]        self.data = self.load(pyfile.url)        m = re.search(self.OFFLINE_PATTERN, self.data)        if m is not None:            self.offline()        pack_name, pack_folder = self.get_package_info()        uid = self.info[""pattern""][""ID""]        m = re.search(rf'""(/mstat\.php\?uid={uid}.+?)""', self.data)        if m is None:            self.fail(""mstat URL not found"")        self.data = self.load(self.fixurl(m.group(1)))        hosters_data = {}        for tr in re.findall(r""<tr>(.+?)</tr>"", self.data, re.S):            uid = self.info[""pattern""][""ID""]            m = re.search(                rf'<a href=""(/showlink\.php\?uid={uid}.+?)"".*&hname=(\w+)', tr, re.S            )            if m is not None:                hosters_data[m.group(2)] = m.group(1)        choosen_hosters = []        # priority hosters goes first        for h in hosters_priority:            if h in hosters_data and h not in ignored_hosters:                self.log_debug(f""Adding '{h}' link"")                choosen_hosters.append(h)                if not self.config.get(""grab_all""):                    break        # Now the rest of the hosters        if self.config.get(""grab_all"") or (            not self.config.get(""grab_all"") and not choosen_hosters        ):            for h in hosters_data:                if h not in ignored_hosters and h not in choosen_hosters:                    self.log_debug(f""Adding '{h}' link"")                    choosen_hosters.append(h)                    if not self.config.get(""grab_all""):                        break        pack_links = [self.resolve_hoster(hosters_data[h]) for h in choosen_hosters]        if pack_links:            self.packages.append((pack_name, pack_links, pack_folder))",8d0402f8-5812-49ce-8522-968ee545a955
decrypters,MirrorcreatorCom.py,resolve_hoster,94,101,"def resolve_hoster(self, link):        self.data = self.load(self.fixurl(link))        m = re.search(self.LINK_PATTERN, self.data)        if m is None:            self.fail(""Link pattern not found"")        return m.group(1)",,"def resolve_hoster(self, link):        self.data = self.load(self.fixurl(link))        m = re.search(self.LINK_PATTERN, self.data)        if m is None:            self.fail(""Link pattern not found"")        return m.group(1)",291b70f8-2f44-4cfb-a6a5-78ea5ce0ca3d
decrypters,MirrorcreatorCom.py,get_package_info,103,118,"def get_package_info(self):        m = re.search(r""<title>Download links for ([^<]+) - Mirrorcreator"", self.data)        if m is not None:            pack_name = m.group(1)            # We remove file extension from package name            while True:                pack_name, ext = os.path.splitext(pack_name)                if ext == """":                    break            return pack_name, pack_name        else:  #: Fallback to defaults            pack = self.pyfile.package()            return pack.name, pack.folder",,"def get_package_info(self):        m = re.search(r""<title>Download links for ([^<]+) - Mirrorcreator"", self.data)        if m is not None:            pack_name = m.group(1)            # We remove file extension from package name            while True:                pack_name, ext = os.path.splitext(pack_name)                if ext == """":                    break            return pack_name, pack_name        else:  #: Fallback to defaults            pack = self.pyfile.package()            return pack.name, pack.folder",a6aa3bbd-d4c7-44c2-a955-2b5ab17fb2a4
decrypters,MultiloadCz.py,decrypt,33,48,"def decrypt(self, pyfile):        self.data = self.load(pyfile.url)        if re.match(self.__pattern__, pyfile.url).group(1) == ""slozka"":            m = re.search(self.FOLDER_PATTERN, self.data)            if m is not None:                self.links.extend(m.group(1).split())        else:            m = re.findall(self.LINK_PATTERN, self.data)            if m is not None:                prefered_set = set(self.config.get(""usedHoster"").split(""|""))                self.links.extend(x[1] for x in m if x[0] in prefered_set)                if not self.links:                    ignored_set = set(self.config.get(""ignoredHoster"").split(""|""))                    self.links.extend(x[1] for x in m if x[0] not in ignored_set)",,"def decrypt(self, pyfile):        self.data = self.load(pyfile.url)        if re.match(self.__pattern__, pyfile.url).group(1) == ""slozka"":            m = re.search(self.FOLDER_PATTERN, self.data)            if m is not None:                self.links.extend(m.group(1).split())        else:            m = re.findall(self.LINK_PATTERN, self.data)            if m is not None:                prefered_set = set(self.config.get(""usedHoster"").split(""|""))                self.links.extend(x[1] for x in m if x[0] in prefered_set)                if not self.links:                    ignored_set = set(self.config.get(""ignoredHoster"").split(""|""))                    self.links.extend(x[1] for x in m if x[0] not in ignored_set)",b7d7f81b-04f8-4f2e-bd4c-b9c19d8a232f
decrypters,MultiUpOrg.py,decrypt,52,57,"def decrypt(self, pyfile):        self._prepare()        self._preload()        links = self.get_links()        self.packages = [(pyfile.package().name, links, pyfile.package().folder)]",,"def decrypt(self, pyfile):        self._prepare()        self._preload()        links = self.get_links()        self.packages = [(pyfile.package().name, links, pyfile.package().folder)]",450d3eb8-a217-4729-9301-077710603377
decrypters,MultiUpOrg.py,get_links,59,109,"def get_links(self):        m_type = self.info[""pattern""][""TYPE""]        hosts_priority = [            _h for _h in self.config.get(""hosts_priority"").split(""|"") if _h        ]        ignored_hosts = [_h for _h in self.config.get(""ignored_hosts"").split(""|"") if _h]        grab_all = self.config.get(""grab_all"")        if m_type == ""project"":            return re.findall(                r""(https?://www\.multiup\.org/(?:en/|fr/)?download/.*)"", self.data            )        elif m_type in (""download"", None):            url, inputs = self.parse_html_form()            if inputs is not None:                self.data = self.load(                    urllib.parse.urljoin(""https://www.multiup.org/"", url), post=inputs                )        hosts_data = {}        for _a in re.findall(            r'<button (.+?) class=""host btn btn-md btn-default btn-block btn-3d hvr-bounce-to-right"">',            self.data,            re.M,        ):            validity = re.search(r'validity=""(\w+)""', _a).group(1)            if validity in (""valid"", ""unknown""):                host = re.search(r'namehost=""(.+?)""', _a).group(1)                url = re.search(r'link=""(.+?)""', _a).group(1)                hosts_data[host] = url        chosen_hosts = []        # priority hosts goes first        for _h in hosts_priority:            if _h in hosts_data and _h not in ignored_hosts:                self.log_debug(f""Adding '{_h}' link"")                chosen_hosts.append(_h)                if not grab_all:                    break        # Now the rest of the hosts        if grab_all or (not grab_all and not chosen_hosts):            for _h in hosts_data:                if _h not in ignored_hosts and _h not in chosen_hosts:                    self.log_debug(f""Adding '{_h}' link"")                    chosen_hosts.append(_h)                    if not grab_all:                        break        return [hosts_data[_h] for _h in chosen_hosts]",,"def get_links(self):        m_type = self.info[""pattern""][""TYPE""]        hosts_priority = [            _h for _h in self.config.get(""hosts_priority"").split(""|"") if _h        ]        ignored_hosts = [_h for _h in self.config.get(""ignored_hosts"").split(""|"") if _h]        grab_all = self.config.get(""grab_all"")        if m_type == ""project"":            return re.findall(                r""(https?://www\.multiup\.org/(?:en/|fr/)?download/.*)"", self.data            )        elif m_type in (""download"", None):            url, inputs = self.parse_html_form()            if inputs is not None:                self.data = self.load(                    urllib.parse.urljoin(""https://www.multiup.org/"", url), post=inputs                )        hosts_data = {}        for _a in re.findall(            r'<button (.+?) class=""host btn btn-md btn-default btn-block btn-3d hvr-bounce-to-right"">',            self.data,            re.M,        ):            validity = re.search(r'validity=""(\w+)""', _a).group(1)            if validity in (""valid"", ""unknown""):                host = re.search(r'namehost=""(.+?)""', _a).group(1)                url = re.search(r'link=""(.+?)""', _a).group(1)                hosts_data[host] = url        chosen_hosts = []        # priority hosts goes first        for _h in hosts_priority:            if _h in hosts_data and _h not in ignored_hosts:                self.log_debug(f""Adding '{_h}' link"")                chosen_hosts.append(_h)                if not grab_all:                    break        # Now the rest of the hosts        if grab_all or (not grab_all and not chosen_hosts):            for _h in hosts_data:                if _h not in ignored_hosts and _h not in chosen_hosts:                    self.log_debug(f""Adding '{_h}' link"")                    chosen_hosts.append(_h)                    if not grab_all:                        break        return [hosts_data[_h] for _h in chosen_hosts]",ee5b14ad-265a-4497-b397-4828693a8c41
decrypters,NitroflareComFolder.py,get_links,31,47,"def get_links(self):        html = self.load(            ""http://nitroflare.com/ajax/folder.php"",            post={                ""userId"": self.info[""pattern""][""USER""],                ""folder"": self.info[""pattern""][""ID""],                ""page"": 1,                ""perPage"": 10000,            },        )        res = json.loads(html)        if res[""name""]:            self.pyfile.name = res[""name""]        else:            self.offline()        return [link[""url""] for link in res[""files""]] if ""files"" in res else None",,"def get_links(self):        html = self.load(            ""http://nitroflare.com/ajax/folder.php"",            post={                ""userId"": self.info[""pattern""][""USER""],                ""folder"": self.info[""pattern""][""ID""],                ""page"": 1,                ""perPage"": 10000,            },        )        res = json.loads(html)        if res[""name""]:            self.pyfile.name = res[""name""]        else:            self.offline()        return [link[""url""] for link in res[""files""]] if ""files"" in res else None",cdbbcded-40c5-4069-a5bf-10775fba9d6d
decrypters,PastedCo.py,decrypt,27,44,"def decrypt(self, pyfile):        package = pyfile.package()        pack_name = package.name        pack_folder = package.folder        html = self.load(pyfile.url, decode=True).splitlines()        fs_url = None        FS_URL_RE = re.compile(rf""{pyfile.url}/fullscreen\.php\?hash=[0-9a-f]*"")        for line in html:            match = FS_URL_RE.search(line)            if match:                fs_url = match.group()                break        if not fs_url:            raise Exception(""Could not find pasted.co fullscreen URL!"")        urls = self.load(fs_url, decode=True)        urls = urls[urls.find(PastedCo.FS_URL_PREFIX) + len(PastedCo.FS_URL_PREFIX) :]        urls = urls[: urls.find(PastedCo.FS_URL_SUFFIX)].splitlines()        self.packages.append((pack_name, urls, pack_folder))",,"def decrypt(self, pyfile):        package = pyfile.package()        pack_name = package.name        pack_folder = package.folder        html = self.load(pyfile.url, decode=True).splitlines()        fs_url = None        FS_URL_RE = re.compile(rf""{pyfile.url}/fullscreen\.php\?hash=[0-9a-f]*"")        for line in html:            match = FS_URL_RE.search(line)            if match:                fs_url = match.group()                break        if not fs_url:            raise Exception(""Could not find pasted.co fullscreen URL!"")        urls = self.load(fs_url, decode=True)        urls = urls[urls.find(PastedCo.FS_URL_PREFIX) + len(PastedCo.FS_URL_PREFIX) :]        urls = urls[: urls.find(PastedCo.FS_URL_SUFFIX)].splitlines()        self.packages.append((pack_name, urls, pack_folder))",9fcceb74-eb64-46aa-8ee9-b9e8dc372b96
decrypters,QuickshareCzFolder.py,decrypt,32,38,"def decrypt(self, pyfile):        html = self.load(pyfile.url)        m = re.search(self.FOLDER_PATTERN, html, re.S)        if m is None:            self.error(self._(""FOLDER_PATTERN not found""))        self.links.extend(re.findall(self.LINK_PATTERN, m.group(1)))",,"def decrypt(self, pyfile):        html = self.load(pyfile.url)        m = re.search(self.FOLDER_PATTERN, html, re.S)        if m is None:            self.error(self._(""FOLDER_PATTERN not found""))        self.links.extend(re.findall(self.LINK_PATTERN, m.group(1)))",a084202e-dca5-4c0a-89e9-51838dc55976
decrypters,RealdebridComTorrent.py,api_request,42,72,"def api_request(self, method, get={}, post={}):        self.req.http.c.setopt(pycurl.USERAGENT, ""pyLoad/{}"".format(self.pyload.version))        for _i in range(2):            try:                json_data = self.load(self.API_URL + method, get=get, post=post)            except BadHeader as e:                json_data = e.content            res = json.loads(json_data) if len(json_data) > 0 else {}            if ""error_code"" in res:                if res[""error_code""] == 8:  #: token expired, refresh the token and retry                    self.account.relogin()                    if not self.account.info[""login""][""valid""]:                        return res                    else:                        self.api_token = self.account.accounts[list(self.account.accounts.keys())[0]][""api_token""]                        get[""auth_token""] = self.api_token                        continue                else:                    error_msg = res[""error""]                    self.fail(error_msg)            return res        else:            self.fail(self._(""Refresh token has failed""))",,"def api_request(self, method, get={}, post={}):        self.req.http.c.setopt(pycurl.USERAGENT, ""pyLoad/{}"".format(self.pyload.version))        for _i in range(2):            try:                json_data = self.load(self.API_URL + method, get=get, post=post)            except BadHeader as e:                json_data = e.content            res = json.loads(json_data) if len(json_data) > 0 else {}            if ""error_code"" in res:                if res[""error_code""] == 8:  #: token expired, refresh the token and retry                    self.account.relogin()                    if not self.account.info[""login""][""valid""]:                        return res                    else:                        self.api_token = self.account.accounts[list(self.account.accounts.keys())[0]][""api_token""]                        get[""auth_token""] = self.api_token                        continue                else:                    error_msg = res[""error""]                    self.fail(error_msg)            return res        else:            self.fail(self._(""Refresh token has failed""))",82579210-6305-4b9d-8842-83bdf181c87c
decrypters,RealdebridComTorrent.py,sleep,74,78,"def sleep(self, sec):        for _i in range(sec):            if self.pyfile.abort:                break            time.sleep(1)",,"def sleep(self, sec):        for _i in range(sec):            if self.pyfile.abort:                break            time.sleep(1)",4adbd435-bca7-4884-9285-2d807f6f5306
decrypters,RealdebridComTorrent.py,exit_error,80,84,"def exit_error(self, msg):        if self.tmp_file:            os.remove(self.tmp_file)        self.fail(msg)",,"def exit_error(self, msg):        if self.tmp_file:            os.remove(self.tmp_file)        self.fail(msg)",d962bc9d-0eb8-4e78-9b31-02ca50194618
decrypters,RealdebridComTorrent.py,send_request_to_server,86,181,"def send_request_to_server(self):                if self.pyfile.url.endswith("".torrent""):            #: torrent URL            if self.pyfile.url.startswith(""http""):                #: remote URL, download the torrent to tmp directory                torrent_content = self.load(self.pyfile.url, decode=False)                torrent_filename = safejoin(self.pyload.tempdir, ""tmp_{}.torrent"".format(self.pyfile.package().name))                with open(torrent_filename, ""wb"") as f:                    f.write(torrent_content)            else:                #: URL is local torrent file (uploaded container)                torrent_filename = urllib.request.url2pathname(self.pyfile.url[7:])  #: trim the starting `file://`                if not exists(torrent_filename):                    self.fail(self._(""Torrent file does not exist""))            self.tmp_file = torrent_filename            #: Check if the torrent file path is inside pyLoad's temp directory            if os.path.abspath(torrent_filename).startswith(self.pyload.tempdir + os.sep):                for _i in range(2):                    try:                        #: send the torrent content to the server                        json_data = self.upload(torrent_filename,                                                self.API_URL + ""/torrents/addTorrent"",                                                get={'auth_token': self.api_token})                    except BadHeader as exc:                        json_data = exc.content                    api_data = json.loads(json_data) if len(json_data) > 0 else {}                    if ""error_code"" in api_data:                        if api_data[""error_code""] == 8:  #: token expired, refresh the token and retry                            self.account.relogin()                            if not self.account.info[""login""][""valid""]:                                self.exit_error(_(""Token refresh has failed""))                            else:                                self.api_token = self.account.accounts[list(self.account.accounts.keys())[0]][""api_token""]                        else:                            error_msg = api_data[""error""]                            self.exit_error(error_msg)                    else:                        break                else:                    self.exit_error(self._(""Token refresh has failed""))            else:                self.exit_error(self._(""Illegal URL""))  #: We don't allow files outside pyLoad's config directory        else:            #: magnet URL, send to the server            api_data = self.api_request(""/torrents/addMagnet"",                                          get={""auth_token"": self.api_token},                                          post={""magnet"": self.pyfile.url})        torrent_id = api_data[""id""]        torrent_info = self.api_request(""/torrents/info/"" + torrent_id,                                         get={'auth_token': self.api_token})        if ""error"" in torrent_info:            self.exit_error(""{} (code: {})"".format(torrent_info[""error""], torrent_info.get(""error_code"", -1)))        #: Filter and select files for downloading        exclude_filters = self.config.get(""exclude_filter"").split(';')        excluded_ids = []        for _filter in exclude_filters:            excluded_ids.extend([_file[""id""] for _file in torrent_info[""files""]                                 if fnmatch.fnmatch(os.path.basename(_file[""path""]), _filter)])        excluded_ids = uniquify(excluded_ids)        include_filters = self.config.get(""include_filter"").split("";"")        included_ids = []        for _filter in include_filters:            included_ids.extend([_file[""id""] for _file in torrent_info[""files""]                                 if fnmatch.fnmatch(os.path.basename(_file[""path""]), _filter)])        included_ids = uniquify(included_ids)        selected_ids = "","".join([str(_id) for _id in included_ids                                 if _id not in excluded_ids])        self.api_request(""/torrents/selectFiles/"" + torrent_id,                          get={""auth_token"": self.api_token},                          post={""files"": selected_ids})        if self.tmp_file:            os.remove(self.tmp_file)        return torrent_id",Send torrent/magnet to the server ,"def send_request_to_server(self):        """""" Send torrent/magnet to the server """"""        if self.pyfile.url.endswith("".torrent""):            #: torrent URL            if self.pyfile.url.startswith(""http""):                #: remote URL, download the torrent to tmp directory                torrent_content = self.load(self.pyfile.url, decode=False)                torrent_filename = safejoin(self.pyload.tempdir, ""tmp_{}.torrent"".format(self.pyfile.package().name))                with open(torrent_filename, ""wb"") as f:                    f.write(torrent_content)            else:                #: URL is local torrent file (uploaded container)                torrent_filename = urllib.request.url2pathname(self.pyfile.url[7:])  #: trim the starting `file://`                if not exists(torrent_filename):                    self.fail(self._(""Torrent file does not exist""))            self.tmp_file = torrent_filename            #: Check if the torrent file path is inside pyLoad's temp directory            if os.path.abspath(torrent_filename).startswith(self.pyload.tempdir + os.sep):                for _i in range(2):                    try:                        #: send the torrent content to the server                        json_data = self.upload(torrent_filename,                                                self.API_URL + ""/torrents/addTorrent"",                                                get={'auth_token': self.api_token})                    except BadHeader as exc:                        json_data = exc.content                    api_data = json.loads(json_data) if len(json_data) > 0 else {}                    if ""error_code"" in api_data:                        if api_data[""error_code""] == 8:  #: token expired, refresh the token and retry                            self.account.relogin()                            if not self.account.info[""login""][""valid""]:                                self.exit_error(_(""Token refresh has failed""))                            else:                                self.api_token = self.account.accounts[list(self.account.accounts.keys())[0]][""api_token""]                        else:                            error_msg = api_data[""error""]                            self.exit_error(error_msg)                    else:                        break                else:                    self.exit_error(self._(""Token refresh has failed""))            else:                self.exit_error(self._(""Illegal URL""))  #: We don't allow files outside pyLoad's config directory        else:            #: magnet URL, send to the server            api_data = self.api_request(""/torrents/addMagnet"",                                          get={""auth_token"": self.api_token},                                          post={""magnet"": self.pyfile.url})        torrent_id = api_data[""id""]        torrent_info = self.api_request(""/torrents/info/"" + torrent_id,                                         get={'auth_token': self.api_token})        if ""error"" in torrent_info:            self.exit_error(""{} (code: {})"".format(torrent_info[""error""], torrent_info.get(""error_code"", -1)))        #: Filter and select files for downloading        exclude_filters = self.config.get(""exclude_filter"").split(';')        excluded_ids = []        for _filter in exclude_filters:            excluded_ids.extend([_file[""id""] for _file in torrent_info[""files""]                                 if fnmatch.fnmatch(os.path.basename(_file[""path""]), _filter)])        excluded_ids = uniquify(excluded_ids)        include_filters = self.config.get(""include_filter"").split("";"")        included_ids = []        for _filter in include_filters:            included_ids.extend([_file[""id""] for _file in torrent_info[""files""]                                 if fnmatch.fnmatch(os.path.basename(_file[""path""]), _filter)])        included_ids = uniquify(included_ids)        selected_ids = "","".join([str(_id) for _id in included_ids                                 if _id not in excluded_ids])        self.api_request(""/torrents/selectFiles/"" + torrent_id,                          get={""auth_token"": self.api_token},                          post={""files"": selected_ids})        if self.tmp_file:            os.remove(self.tmp_file)        return torrent_id

Send torrent/magnet to the server ",ecbba97d-440f-4c2f-8671-5b26724c58ba
decrypters,RealdebridComTorrent.py,wait_for_server_dl,183,211,"def wait_for_server_dl(self, torrent_id):                torrent_info = self.api_request(""/torrents/info/"" + torrent_id,                                         get={""auth_token"": self.api_token})        if ""error"" in torrent_info:            self.fail(""{} (code: {})"".format(torrent_info[""error""], torrent_info.get(""error_code"", -1)))        self.pyfile.name = torrent_info[""original_filename""]        self.pyfile.size = torrent_info[""original_bytes""]        self.pyfile.set_custom_status(""torrent"")        self.pyfile.set_progress(0)        while torrent_info[""status""] != ""downloaded"" or torrent_info[""progress""] != 100:            progress = int(torrent_info[""progress""])            self.pyfile.set_progress(progress)            self.sleep(5)            torrent_info = self.api_request(""/torrents/info/"" + torrent_id,                                             get={""auth_token"": self.api_token})            if ""error"" in torrent_info:                self.fail(""{} (code: {})"".format(torrent_info[""error""], torrent_info.get(""error_code"", -1)))        self.pyfile.set_progress(100)        return torrent_info[""links""]",Show progress while the server does the download ,"def wait_for_server_dl(self, torrent_id):        """""" Show progress while the server does the download """"""        torrent_info = self.api_request(""/torrents/info/"" + torrent_id,                                         get={""auth_token"": self.api_token})        if ""error"" in torrent_info:            self.fail(""{} (code: {})"".format(torrent_info[""error""], torrent_info.get(""error_code"", -1)))        self.pyfile.name = torrent_info[""original_filename""]        self.pyfile.size = torrent_info[""original_bytes""]        self.pyfile.set_custom_status(""torrent"")        self.pyfile.set_progress(0)        while torrent_info[""status""] != ""downloaded"" or torrent_info[""progress""] != 100:            progress = int(torrent_info[""progress""])            self.pyfile.set_progress(progress)            self.sleep(5)            torrent_info = self.api_request(""/torrents/info/"" + torrent_id,                                             get={""auth_token"": self.api_token})            if ""error"" in torrent_info:                self.fail(""{} (code: {})"".format(torrent_info[""error""], torrent_info.get(""error_code"", -1)))        self.pyfile.set_progress(100)        return torrent_info[""links""]

Show progress while the server does the download ",eb001f19-29c4-42f5-90d8-ba4bc0263ba7
decrypters,RealdebridComTorrent.py,delete_torrent_from_server,213,232,"def delete_torrent_from_server(self, torrent_id):                url = ""{}/torrents/delete/{}?auth_token={}"".format(self.API_URL, torrent_id, self.api_token)        self.log_debug(""DELETE URL {}"".format(url))        c = pycurl.Curl()        c.setopt(pycurl.URL, url)        c.setopt(pycurl.SSL_VERIFYPEER, 0)        c.setopt(pycurl.USERAGENT, ""pyLoad/{}"".format(self.pyload.version))        c.setopt(pycurl.HTTPHEADER, [""Accept: */*"",                                     ""Accept-Language: en-US,en"",                                     ""Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.7"",                                     ""Connection: keep-alive"",                                     ""Keep-Alive: 300"",                                     ""Expect:""])        c.setopt(pycurl.CUSTOMREQUEST, ""DELETE"")        c.perform()        code = c.getinfo(pycurl.RESPONSE_CODE)        c.close()        return code",Remove the torrent from the server ,"def delete_torrent_from_server(self, torrent_id):        """""" Remove the torrent from the server """"""        url = ""{}/torrents/delete/{}?auth_token={}"".format(self.API_URL, torrent_id, self.api_token)        self.log_debug(""DELETE URL {}"".format(url))        c = pycurl.Curl()        c.setopt(pycurl.URL, url)        c.setopt(pycurl.SSL_VERIFYPEER, 0)        c.setopt(pycurl.USERAGENT, ""pyLoad/{}"".format(self.pyload.version))        c.setopt(pycurl.HTTPHEADER, [""Accept: */*"",                                     ""Accept-Language: en-US,en"",                                     ""Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.7"",                                     ""Connection: keep-alive"",                                     ""Keep-Alive: 300"",                                     ""Expect:""])        c.setopt(pycurl.CUSTOMREQUEST, ""DELETE"")        c.perform()        code = c.getinfo(pycurl.RESPONSE_CODE)        c.close()        return code

Remove the torrent from the server ",e53ddae5-6f29-4637-b51d-defcaca5eaa2
decrypters,RealdebridComTorrent.py,decrypt,234,254,"def decrypt(self, pyfile):        self.tmp_file = None        torrent_id = 0        if ""RealdebridCom"" not in self.pyload.account_manager.plugins:            self.fail(self._(""This plugin requires an active Realdebrid.com account""))        self.account = self.pyload.account_manager.get_account_plugin(""RealdebridCom"")        if len(self.account.accounts) == 0:            self.fail(self._(""This plugin requires an active Realdebrid.com account""))        self.api_token = self.account.accounts[list(self.account.accounts.keys())[0]][""api_token""]        try:            torrent_id = self.send_request_to_server()            torrent_urls = self.wait_for_server_dl(torrent_id)            self.packages = [(pyfile.package().name, torrent_urls, pyfile.package().name)]        finally:            if torrent_id and self.config.get(""del_finished""):                self.delete_torrent_from_server(torrent_id)",,"def decrypt(self, pyfile):        self.tmp_file = None        torrent_id = 0        if ""RealdebridCom"" not in self.pyload.account_manager.plugins:            self.fail(self._(""This plugin requires an active Realdebrid.com account""))        self.account = self.pyload.account_manager.get_account_plugin(""RealdebridCom"")        if len(self.account.accounts) == 0:            self.fail(self._(""This plugin requires an active Realdebrid.com account""))        self.api_token = self.account.accounts[list(self.account.accounts.keys())[0]][""api_token""]        try:            torrent_id = self.send_request_to_server()            torrent_urls = self.wait_for_server_dl(torrent_id)            self.packages = [(pyfile.package().name, torrent_urls, pyfile.package().name)]        finally:            if torrent_id and self.config.get(""del_finished""):                self.delete_torrent_from_server(torrent_id)",f61edc45-67d4-4a7f-9194-cf46447f2472
decrypters,SafelinkingNet.py,api_request,40,69,"def api_request(self, url, post_data):        self.req.http.c.setopt(            pycurl.HTTPHEADER,            [                ""Accept: application/json, text/plain, */*"",                ""Content-Type: application/json"",            ],        )        try:            res = json.loads(self.load(url, post=json.dumps(post_data)))        except (BadHeader, ValueError) as exc:            self.log_error(exc)            self.fail(exc)        # Headers back to normal        self.req.http.c.setopt(            pycurl.HTTPHEADER,            [                ""Accept: */*"",                ""Accept-Language: en-US,en"",                ""Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.7"",                ""Connection: keep-alive"",                ""Keep-Alive: 300"",                ""Expect:"",            ],        )        return res",,"def api_request(self, url, post_data):        self.req.http.c.setopt(            pycurl.HTTPHEADER,            [                ""Accept: application/json, text/plain, */*"",                ""Content-Type: application/json"",            ],        )        try:            res = json.loads(self.load(url, post=json.dumps(post_data)))        except (BadHeader, ValueError) as exc:            self.log_error(exc)            self.fail(exc)        # Headers back to normal        self.req.http.c.setopt(            pycurl.HTTPHEADER,            [                ""Accept: */*"",                ""Accept-Language: en-US,en"",                ""Accept-Charset: ISO-8859-1,utf-8;q=0.7,*;q=0.7"",                ""Connection: keep-alive"",                ""Keep-Alive: 300"",                ""Expect:"",            ],        )        return res",356a3824-e843-4a07-be21-8749a535bf14
decrypters,SafelinkingNet.py,decrypt,71,146,"def decrypt(self, pyfile):        # Process direct links        if self.info[""pattern""][""TYPE""] == ""d/"":            header = self.load(pyfile.url, just_header=True)            if ""location"" in header:                self.links = [header.get(""location"")]            else:                self.error(self._(""Couldn't find forwarded Link""))        else:  #: Process protected links            self.package_password = self.get_password()            post_data = {""hash"": self.info[""pattern""][""ID""]}            link_info = self.api_request(                ""http://safelinking.net/v1/protected"", post_data            )            if ""messsage"" in link_info:                self.log_error(link_info[""messsage""])                self.fail(link_info[""messsage""])            # Response: Links            elif ""links"" in link_info:                for link in link_info[""links""]:                    self.links.append(link[""url""])                    return            if link_info[""security""].get(""usePassword"", False):                if self.package_password:                    self.log_debug(""Using package password"")                    post_data[""password""] = self.package_password                else:                    self.fail(self._(""Password required""))            if link_info[""security""].get(""useCaptcha"", False):                self.captcha = SolveMedia(pyfile)                response, challenge = self.captcha.challenge(self.SOLVEMEDIA_KEY)                post_data[""answer""] = response                post_data[""challengeId""] = challenge                post_data[""type""] = ""0""            json_res = self.api_request(                ""https://safelinking.net/v1/captcha"", post_data            )            # Evaluate response            if json_res is None:                self.fail(self._(""Invalid JSON response""))            # Response: Wrong password            elif ""passwordFail"" in json_res:                self.log_error(                    self._('Wrong password: ""{}""').format(self.package_password)                )                self.fail(self._(""Wrong password""))            elif ""captchaFail"" in json_res:                self.retry_captcha()            # Response: Error message            elif ""message"" in json_res:                self.log_error(self._(""Site error: {}"").format(json_res[""message""]))                self.retry(wait=60, msg=json_res[""message""])            # Response: Links            elif ""links"" in json_res:                for link in json_res[""links""]:                    self.links.append(link[""url""])            else:                self.fail(self._(""Unexpected JSON response""))",,"def decrypt(self, pyfile):        # Process direct links        if self.info[""pattern""][""TYPE""] == ""d/"":            header = self.load(pyfile.url, just_header=True)            if ""location"" in header:                self.links = [header.get(""location"")]            else:                self.error(self._(""Couldn't find forwarded Link""))        else:  #: Process protected links            self.package_password = self.get_password()            post_data = {""hash"": self.info[""pattern""][""ID""]}            link_info = self.api_request(                ""http://safelinking.net/v1/protected"", post_data            )            if ""messsage"" in link_info:                self.log_error(link_info[""messsage""])                self.fail(link_info[""messsage""])            # Response: Links            elif ""links"" in link_info:                for link in link_info[""links""]:                    self.links.append(link[""url""])                    return            if link_info[""security""].get(""usePassword"", False):                if self.package_password:                    self.log_debug(""Using package password"")                    post_data[""password""] = self.package_password                else:                    self.fail(self._(""Password required""))            if link_info[""security""].get(""useCaptcha"", False):                self.captcha = SolveMedia(pyfile)                response, challenge = self.captcha.challenge(self.SOLVEMEDIA_KEY)                post_data[""answer""] = response                post_data[""challengeId""] = challenge                post_data[""type""] = ""0""            json_res = self.api_request(                ""https://safelinking.net/v1/captcha"", post_data            )            # Evaluate response            if json_res is None:                self.fail(self._(""Invalid JSON response""))            # Response: Wrong password            elif ""passwordFail"" in json_res:                self.log_error(                    self._('Wrong password: ""{}""').format(self.package_password)                )                self.fail(self._(""Wrong password""))            elif ""captchaFail"" in json_res:                self.retry_captcha()            # Response: Error message            elif ""message"" in json_res:                self.log_error(self._(""Site error: {}"").format(json_res[""message""]))                self.retry(wait=60, msg=json_res[""message""])            # Response: Links            elif ""links"" in json_res:                for link in json_res[""links""]:                    self.links.append(link[""url""])            else:                self.fail(self._(""Unexpected JSON response""))",bbedc9ef-94a9-4411-92e4-317641278f0f
decrypters,SexuriaCom.py,decrypt,47,58,"def decrypt(self, pyfile):        #: Init        self.pyfile = pyfile        self.package = pyfile.package()        #: Decrypt and add links        pack_name, self.urls, folder_name, pack_pwd = self.decrypt_links(            self.pyfile.url        )        if pack_pwd:            self.pyfile.package().password = pack_pwd        self.packages = [(pack_name, self.urls, folder_name)]",,"def decrypt(self, pyfile):        #: Init        self.pyfile = pyfile        self.package = pyfile.package()        #: Decrypt and add links        pack_name, self.urls, folder_name, pack_pwd = self.decrypt_links(            self.pyfile.url        )        if pack_pwd:            self.pyfile.package().password = pack_pwd        self.packages = [(pack_name, self.urls, folder_name)]",fb488e97-6781-49df-9740-7be828b03d31
decrypters,SexuriaCom.py,decrypt_links,60,136,"def decrypt_links(self, url):        linklist = []        name = self.package.name        folder = self.package.folder        password = None        if re.match(self.PATTERN_SUPPORTED_MAIN, url, re.I):            #: Processing main page            html = self.load(url)            links = re.findall(self.PATTERN_DL_LINK_PAGE, html, re.I)            for link in links:                linklist.append(""http://sexuria.com/v1/"" + link)        elif re.match(self.PATTERN_SUPPORTED_REDIRECT, url, re.I):            #: Processing direct redirect link (out.php), redirecting to main page            id = re.search(self.PATTERN_SUPPORTED_REDIRECT, url, re.I).group(""ID"")            if id:                linklist.append(                    ""http://sexuria.com/v1/Pornos_Kostenlos_liebe_{}.html"".format(id)                )        elif re.match(self.PATTERN_SUPPORTED_CRYPT, url, re.I):            #: Extract info from main file            id = re.search(self.PATTERN_SUPPORTED_CRYPT, url, re.I).group(""ID"")            html = self.load(                ""http://sexuria.com/v1/Pornos_Kostenlos_info_{}.html"".format(id)            )            #: Webpage title / Package name            titledata = re.search(self.PATTERN_TITLE, html, re.I)            if not titledata:                self.log_warning(""No title data found, has site changed?"")            else:                title = titledata.group(""TITLE"").strip()                if title:                    name = folder = title                    self.log_debug(                        ""Package info found, name [{}] and folder [{}]"".format(                            name, folder                        )                    )            #: Password            pwddata = re.search(self.PATTERN_PASSWORD, html, re.I | re.S)            if not pwddata:                self.log_warning(""No password data found, has site changed?"")            else:                pwd = pwddata.group(""PWD"").strip()                if pwd and pwd not in self.LIST_PWDIGNORE:                    password = pwd                    self.log_debug(f""Package info found, password [{password}]"")            #: Process links (dl_link)            html = self.load(url)            links = re.findall(self.PATTERN_REDIRECT_LINKS, html, re.I)            if not links:                self.log_error(self._(""Broken for link: {}"").format(link))            else:                for link in links:                    link = link.replace(                        ""http://sexuria.com/"", ""http://www.sexuria.com/""                    )                    finallink = self.load(link, just_header=True)[""url""]                    if not finallink or ""sexuria.com/"" in finallink:                        self.log_error(self._(""Broken for link: {}"").format(link))                    else:                        linklist.append(finallink)        #: Log result        if not linklist:            self.fail(self._(""Unable to extract links (maybe plugin out of date?)""))        else:            for i, link in enumerate(linklist):                self.log_debug(                    ""Supported link {}/{}: {}"".format(i + 1, len(linklist), link)                )        #: All done, return to caller        return name, linklist, folder, password",,"def decrypt_links(self, url):        linklist = []        name = self.package.name        folder = self.package.folder        password = None        if re.match(self.PATTERN_SUPPORTED_MAIN, url, re.I):            #: Processing main page            html = self.load(url)            links = re.findall(self.PATTERN_DL_LINK_PAGE, html, re.I)            for link in links:                linklist.append(""http://sexuria.com/v1/"" + link)        elif re.match(self.PATTERN_SUPPORTED_REDIRECT, url, re.I):            #: Processing direct redirect link (out.php), redirecting to main page            id = re.search(self.PATTERN_SUPPORTED_REDIRECT, url, re.I).group(""ID"")            if id:                linklist.append(                    ""http://sexuria.com/v1/Pornos_Kostenlos_liebe_{}.html"".format(id)                )        elif re.match(self.PATTERN_SUPPORTED_CRYPT, url, re.I):            #: Extract info from main file            id = re.search(self.PATTERN_SUPPORTED_CRYPT, url, re.I).group(""ID"")            html = self.load(                ""http://sexuria.com/v1/Pornos_Kostenlos_info_{}.html"".format(id)            )            #: Webpage title / Package name            titledata = re.search(self.PATTERN_TITLE, html, re.I)            if not titledata:                self.log_warning(""No title data found, has site changed?"")            else:                title = titledata.group(""TITLE"").strip()                if title:                    name = folder = title                    self.log_debug(                        ""Package info found, name [{}] and folder [{}]"".format(                            name, folder                        )                    )            #: Password            pwddata = re.search(self.PATTERN_PASSWORD, html, re.I | re.S)            if not pwddata:                self.log_warning(""No password data found, has site changed?"")            else:                pwd = pwddata.group(""PWD"").strip()                if pwd and pwd not in self.LIST_PWDIGNORE:                    password = pwd                    self.log_debug(f""Package info found, password [{password}]"")            #: Process links (dl_link)            html = self.load(url)            links = re.findall(self.PATTERN_REDIRECT_LINKS, html, re.I)            if not links:                self.log_error(self._(""Broken for link: {}"").format(link))            else:                for link in links:                    link = link.replace(                        ""http://sexuria.com/"", ""http://www.sexuria.com/""                    )                    finallink = self.load(link, just_header=True)[""url""]                    if not finallink or ""sexuria.com/"" in finallink:                        self.log_error(self._(""Broken for link: {}"").format(link))                    else:                        linklist.append(finallink)        #: Log result        if not linklist:            self.fail(self._(""Unable to extract links (maybe plugin out of date?)""))        else:            for i, link in enumerate(linklist):                self.log_debug(                    ""Supported link {}/{}: {}"".format(i + 1, len(linklist), link)                )        #: All done, return to caller        return name, linklist, folder, password",13c30a4f-3a99-4be0-bd40-d574773e0948
decrypters,ShSt.py,decrypt,23,29,"def decrypt(self, pyfile):        #: If we use curl as a user agent, we will get a straight redirect (no waiting!)        self.req.http.c.setopt(pycurl.USERAGENT, ""curl/7.42.1"")        #: Fetch the target URL        header = self.load(self.pyfile.url, just_header=True, decode=False)        target_url = header.get(""location"")        self.links.append(target_url)",,"def decrypt(self, pyfile):        #: If we use curl as a user agent, we will get a straight redirect (no waiting!)        self.req.http.c.setopt(pycurl.USERAGENT, ""curl/7.42.1"")        #: Fetch the target URL        header = self.load(self.pyfile.url, just_header=True, decode=False)        target_url = header.get(""location"")        self.links.append(target_url)",100ce34e-74cf-4166-9783-dfa21b7e33e0
decrypters,SwisstransferComFolder.py,api_request,38,46,"def api_request(self, method, auth=None, **kwargs):        headers = [""Content-Type: application/json""]        if auth:            headers.append(f""Authorization: {auth}"")        self.req.http.c.setopt(pycurl.HTTPHEADER, headers)        json_data = self.load(self.API_URL + method,                              post=json.dumps(kwargs) if kwargs else {})        return json.loads(json_data)",,"def api_request(self, method, auth=None, **kwargs):        headers = [""Content-Type: application/json""]        if auth:            headers.append(f""Authorization: {auth}"")        self.req.http.c.setopt(pycurl.HTTPHEADER, headers)        json_data = self.load(self.API_URL + method,                              post=json.dumps(kwargs) if kwargs else {})        return json.loads(json_data)",4ef3b2bb-9fe3-4651-9530-e5b38c719d1a
decrypters,SwisstransferComFolder.py,decrypt,48,85,"def decrypt(self, pyfile):        folder_id = self.info[""pattern""][""ID""]        api_data = self.api_request(f""links/{folder_id}"")        if api_data.get(""result"") == ""success"":            if api_data[""data""].get(""type"") == ""expired"":                self.fail(self._(""Download expired""))            has_password = api_data[""data""].get(""type"") == ""need_password""            if has_password:                password = self.get_password()                if password:                    auth = to_str(base64.b64encode(to_bytes(urllib.parse.quote(password), ""ascii"")))                    api_data = self.api_request(f""links/{folder_id}"", auth=auth)                    if api_data[""data""].get(""type"") == ""wrong_password"":                        self.fail(self._(""Wrong password""))                else:                    self.fail(self._(""Download is password protected""))            if api_data[""data""][""downloadCounterCredit""] == 0:                self.fail(self._(""Authorized number of downloads has been reached.""))            download_host = api_data[""data""][""downloadHost""]            pack_links = []            for file in api_data[""data""][""container""][""files""]:                link = f'https://{download_host}/api/download/{folder_id}/{file[""UUID""]}'                if has_password:                    download_token = self.api_request(                        ""generateDownloadToken"",                        containerUUID=file[""containerUUID""],                        fileUUID=file[""UUID""],                        password=password                    )                    link += f""?token={download_token}""                pack_links.append(link)            if pack_links:                self.packages.append((pyfile.package().name, pack_links, pyfile.package().name))",,"def decrypt(self, pyfile):        folder_id = self.info[""pattern""][""ID""]        api_data = self.api_request(f""links/{folder_id}"")        if api_data.get(""result"") == ""success"":            if api_data[""data""].get(""type"") == ""expired"":                self.fail(self._(""Download expired""))            has_password = api_data[""data""].get(""type"") == ""need_password""            if has_password:                password = self.get_password()                if password:                    auth = to_str(base64.b64encode(to_bytes(urllib.parse.quote(password), ""ascii"")))                    api_data = self.api_request(f""links/{folder_id}"", auth=auth)                    if api_data[""data""].get(""type"") == ""wrong_password"":                        self.fail(self._(""Wrong password""))                else:                    self.fail(self._(""Download is password protected""))            if api_data[""data""][""downloadCounterCredit""] == 0:                self.fail(self._(""Authorized number of downloads has been reached.""))            download_host = api_data[""data""][""downloadHost""]            pack_links = []            for file in api_data[""data""][""container""][""files""]:                link = f'https://{download_host}/api/download/{folder_id}/{file[""UUID""]}'                if has_password:                    download_token = self.api_request(                        ""generateDownloadToken"",                        containerUUID=file[""containerUUID""],                        fileUUID=file[""UUID""],                        password=password                    )                    link += f""?token={download_token}""                pack_links.append(link)            if pack_links:                self.packages.append((pyfile.package().name, pack_links, pyfile.package().name))",a5327420-dc90-472c-92da-76edb72e0055
decrypters,TenluaVnFolder.py,api_request,33,35,"def api_request(self, method, **kwargs):        kwargs[""a""] = method        return json.loads(self.load(self.API_URL, post=json.dumps([kwargs])))",,"def api_request(self, method, **kwargs):        kwargs[""a""] = method        return json.loads(self.load(self.API_URL, post=json.dumps([kwargs])))",89c0e5f9-d8ca-46bc-b243-937ae8c8d0fd
decrypters,TenluaVnFolder.py,decrypt,37,50,"def decrypt(self, pyfile):        folder_info = self.api_request(            ""filemanager_gettree"", p=self.info[""pattern""][""ID""], download=1        )        pack_links = [            ""https://www.tenlua.vn/download/{}/{}"".format(x[""h""], x[""ns""])            for x in folder_info[0][""f""]            if ""h"" in x and ""ns"" in x        ]        pack_name = folder_info[0][""f""][0].get(""n"") or self.pyfile.package().name        if pack_links:            self.packages.append((pack_name, pack_links, pack_name))",,"def decrypt(self, pyfile):        folder_info = self.api_request(            ""filemanager_gettree"", p=self.info[""pattern""][""ID""], download=1        )        pack_links = [            ""https://www.tenlua.vn/download/{}/{}"".format(x[""h""], x[""ns""])            for x in folder_info[0][""f""]            if ""h"" in x and ""ns"" in x        ]        pack_name = folder_info[0][""f""][0].get(""n"") or self.pyfile.package().name        if pack_links:            self.packages.append((pack_name, pack_links, pack_name))",b9aa7ff3-e6c8-4da2-9866-43eebf07d0bb
decrypters,TNTVillageScambioeticoOrg.py,get_links,34,39,def get_links(self):        for p in self.LINK_PATTERNS:            self.LINK_PATTERN = p            links = SimpleDecrypter.get_links(self)            if links:                return links,,def get_links(self):        for p in self.LINK_PATTERNS:            self.LINK_PATTERN = p            links = SimpleDecrypter.get_links(self)            if links:                return links,20437e1e-9e7c-425f-8e9d-34fdcc56bb63
decrypters,TnyCz.py,get_links,33,35,"def get_links(self):        m = re.search(r'<a id=\'save_paste\' href=""(.+save\.php\?hash=.+)"">', self.data)        return re.findall("".+"", self.load(m.group(1))) if m else None",,"def get_links(self):        m = re.search(r'<a id=\'save_paste\' href=""(.+save\.php\?hash=.+)"">', self.data)        return re.findall("".+"", self.load(m.group(1))) if m else None",9bf8d85f-a4ec-4f0d-aaeb-72421660e83b
decrypters,TurbobitNetFolder.py,_get_links,36,49,"def _get_links(self, id, page=1):        gridFile = self.load(            ""http://turbobit.net/downloadfolder/gridFile"",            get={""rootId"": id, ""rows"": 200, ""page"": page},        )        grid = json.loads(gridFile)        if grid[""rows""]:            for i in grid[""rows""]:                yield i[""id""]            for id in self._get_links(id, page + 1):                yield id        else:            return",,"def _get_links(self, id, page=1):        gridFile = self.load(            ""http://turbobit.net/downloadfolder/gridFile"",            get={""rootId"": id, ""rows"": 200, ""page"": page},        )        grid = json.loads(gridFile)        if grid[""rows""]:            for i in grid[""rows""]:                yield i[""id""]            for id in self._get_links(id, page + 1):                yield id        else:            return",fd211608-1c95-4fe5-b255-6419c2874c96
decrypters,TurbobitNetFolder.py,get_links,51,55,"def get_links(self):        return [            f""http://turbobit.net/{id}.html""            for id in self._get_links(self.info[""pattern""][""ID""])        ]",,"def get_links(self):        return [            f""http://turbobit.net/{id}.html""            for id in self._get_links(self.info[""pattern""][""ID""])        ]",36661d76-fc5f-4ef0-9b77-23e48d2e551d
decrypters,TusfilesNetFolder.py,load_page,41,42,"def load_page(self, page_n):        return self.load(urllib.parse.urljoin(self.pyfile.url, str(page_n)))",,"def load_page(self, page_n):        return self.load(urllib.parse.urljoin(self.pyfile.url, str(page_n)))",afbe655c-bdbc-4aa7-b88e-6826ef529cc8
decrypters,TusfilesNetFolder.py,handle_pages,44,56,"def handle_pages(self, pyfile):        pages = re.search(self.PAGES_PATTERN, self.data)        if not pages:            return        pages = math.ceil(int(pages.group(""pages""))) // 25        links = self.links        for p in range(2, pages + 1):            self.data = self.load_page(p)            links.append(self.get_links())        self.links = links",,"def handle_pages(self, pyfile):        pages = re.search(self.PAGES_PATTERN, self.data)        if not pages:            return        pages = math.ceil(int(pages.group(""pages""))) // 25        links = self.links        for p in range(2, pages + 1):            self.data = self.load_page(p)            links.append(self.get_links())        self.links = links",b4ca1998-3d32-4a76-9a3c-b3ca805e15cd
decrypters,UlozToFolder.py,decrypt,34,54,"def decrypt(self, pyfile):        html = self.load(pyfile.url)        new_links = []        for i in range(1, 100):            self.log_info(self._(""Fetching links from page {}"").format(i))            m = re.search(self.FOLDER_PATTERN, html, re.S)            if m is None:                self.error(self._(""FOLDER_PATTERN not found""))            new_links.extend(re.findall(self.LINK_PATTERN, m.group(1)))            m = re.search(self.NEXT_PAGE_PATTERN, html)            if m is not None:                html = self.load(""http://ulozto.net/"" + m.group(1))            else:                break        else:            self.log_info(self._(""Limit of 99 pages reached, aborting""))        if new_links:            self.links = [[""http://ulozto.net/{}"".format(s) for s in new_links]]",,"def decrypt(self, pyfile):        html = self.load(pyfile.url)        new_links = []        for i in range(1, 100):            self.log_info(self._(""Fetching links from page {}"").format(i))            m = re.search(self.FOLDER_PATTERN, html, re.S)            if m is None:                self.error(self._(""FOLDER_PATTERN not found""))            new_links.extend(re.findall(self.LINK_PATTERN, m.group(1)))            m = re.search(self.NEXT_PAGE_PATTERN, html)            if m is not None:                html = self.load(""http://ulozto.net/"" + m.group(1))            else:                break        else:            self.log_info(self._(""Limit of 99 pages reached, aborting""))        if new_links:            self.links = [[""http://ulozto.net/{}"".format(s) for s in new_links]]",09402608-9fcd-47dd-80d8-53e73f148d33
decrypters,WetransferComDereferer.py,decrypt,29,33,"def decrypt(self, pyfile):        headers = self.load(pyfile.url, just_header=True)        link = headers.get(""location"")        if link is not None:            self.packages = [(pyfile.package().folder, [link], pyfile.package().name)]",,"def decrypt(self, pyfile):        headers = self.load(pyfile.url, just_header=True)        link = headers.get(""location"")        if link is not None:            self.packages = [(pyfile.package().folder, [link], pyfile.package().name)]",edc605bb-b23e-4689-84b6-0273d44c7b8a
decrypters,WorkuploadComFolder.py,decrypt,34,44,"def decrypt(self, pyfile):        html = self.load(pyfile.url)        links = uniquify(re.findall(self.LINK_PATTERN, html))        if links:            self.packages = [                (                    pyfile.package().folder,                    [""https://workupload.com"" + link for link in links],                    pyfile.package().name,                )            ]",,"def decrypt(self, pyfile):        html = self.load(pyfile.url)        links = uniquify(re.findall(self.LINK_PATTERN, html))        if links:            self.packages = [                (                    pyfile.package().folder,                    [""https://workupload.com"" + link for link in links],                    pyfile.package().name,                )            ]",8bfa77c0-4e38-47a7-976e-627f107d9d18
decrypters,XFileSharingFolder.py,_log,31,33,"def _log(self, level, plugintype, pluginname, args, kwargs):        args = (self.PLUGIN_NAME,) + args        return super()._log(level, plugintype, pluginname, args, kwargs)",,"def _log(self, level, plugintype, pluginname, args, kwargs):        args = (self.PLUGIN_NAME,) + args        return super()._log(level, plugintype, pluginname, args, kwargs)",cd660b06-efc8-4957-942f-c52919ece810
decrypters,XFileSharingFolder.py,init,35,47,"def init(self):        self.__pattern__ = self.pyload.plugin_manager.decrypter_plugins[self.classname][            ""pattern""        ]        self.PLUGIN_DOMAIN = (            re.match(self.__pattern__, self.pyfile.url).group(""DOMAIN"").lower()        )        self.PLUGIN_NAME = """".join(            part.capitalize()            for part in re.split(r""\.|\d+|-"", self.PLUGIN_DOMAIN)            if part != "".""        )",,"def init(self):        self.__pattern__ = self.pyload.plugin_manager.decrypter_plugins[self.classname][            ""pattern""        ]        self.PLUGIN_DOMAIN = (            re.match(self.__pattern__, self.pyfile.url).group(""DOMAIN"").lower()        )        self.PLUGIN_NAME = """".join(            part.capitalize()            for part in re.split(r""\.|\d+|-"", self.PLUGIN_DOMAIN)            if part != "".""        )",2df7a4d9-d5ec-40ab-9d3f-c9812b3ef25a
decrypters,XFileSharingFolder.py,setup_base,50,61,"def setup_base(self):        super().setup_base()        if self.account:            self.req = self.pyload.request_factory.get_request(                self.PLUGIN_NAME, self.account.user            )            # NOTE: Don't call get_info here to reduce overhead            self.premium = self.account.info[""data""][""premium""]        else:            self.req = self.pyload.request_factory.get_request(self.classname)            self.premium = False",,"def setup_base(self):        super().setup_base()        if self.account:            self.req = self.pyload.request_factory.get_request(                self.PLUGIN_NAME, self.account.user            )            # NOTE: Don't call get_info here to reduce overhead            self.premium = self.account.info[""data""][""premium""]        else:            self.req = self.pyload.request_factory.get_request(self.classname)            self.premium = False",8e65faca-990b-4912-9aa7-07b996b95afe
decrypters,XFileSharingFolder.py,load_account,64,68,def load_account(self):        class_name = self.classname        self.__class__.__name__ = str(self.PLUGIN_NAME)        super().load_account()        self.__class__.__name__ = class_name,,def load_account(self):        class_name = self.classname        self.__class__.__name__ = str(self.PLUGIN_NAME)        super().load_account()        self.__class__.__name__ = class_name,a6b66749-629d-4a34-a0d8-7001b9cdc680
decrypters,XupPl.py,decrypt,29,34,"def decrypt(self, pyfile):        header = self.load(pyfile.url, just_header=True)        if ""location"" in header:            self.links = [header.get(""location"")]        else:            self.fail(self._(""Unable to find link""))",,"def decrypt(self, pyfile):        header = self.load(pyfile.url, just_header=True)        if ""location"" in header:            self.links = [header.get(""location"")]        else:            self.fail(self._(""Unable to find link""))",987e05ff-96d0-4000-8349-98e89ddb094f
decrypters,YoutubeComFolder.py,api_request,35,38,"def api_request(self, method, **kwargs):        kwargs['key'] = self.API_KEY        json_data = self.load(""https://www.googleapis.com/youtube/v3/"" + method, get=kwargs)        return json.loads(json_data)",,"def api_request(self, method, **kwargs):        kwargs['key'] = self.API_KEY        json_data = self.load(""https://www.googleapis.com/youtube/v3/"" + method, get=kwargs)        return json.loads(json_data)",932c3bef-8ded-45fc-abb0-77bbe28a2165
decrypters,YoutubeComFolder.py,get_channel,40,50,"def get_channel(self, user):        channels = self.api_request(""channels"",                                     part=""id,snippet,contentDetails"",                                     forUsername=user,                                     maxResults=50)        if channels['items']:            channel = channels['items'][0]            return {'id': channel['id'],                    'title': channel['snippet']['title'],                    'relatedPlaylists': channel['contentDetails']['relatedPlaylists'],                    'user': user}",,"def get_channel(self, user):        channels = self.api_request(""channels"",                                     part=""id,snippet,contentDetails"",                                     forUsername=user,                                     maxResults=50)        if channels['items']:            channel = channels['items'][0]            return {'id': channel['id'],                    'title': channel['snippet']['title'],                    'relatedPlaylists': channel['contentDetails']['relatedPlaylists'],                    'user': user}",9f39024d-61a5-402d-9976-7d73b7ae6906
decrypters,YoutubeComFolder.py,get_playlist,52,61,"def get_playlist(self, playlist_id):        playlists = self.api_request(""playlists"",                                      part=""snippet"",                                      id=playlist_id)        if playlists['items']:            playlist = playlists['items'][0]            return {'id': playlist_id,                    'title': playlist['snippet']['title'],                    'channelId': playlist['snippet']['channelId'],                    'channelTitle': playlist['snippet']['channelTitle']}",,"def get_playlist(self, playlist_id):        playlists = self.api_request(""playlists"",                                      part=""snippet"",                                      id=playlist_id)        if playlists['items']:            playlist = playlists['items'][0]            return {'id': playlist_id,                    'title': playlist['snippet']['title'],                    'channelId': playlist['snippet']['channelId'],                    'channelTitle': playlist['snippet']['channelTitle']}",edb7591a-4b16-4051-86e6-7def0c6d54b9
decrypters,YoutubeComFolder.py,_get_playlists,63,81,"def _get_playlists(self, playlist_id, token=None):        if token:            playlists = self.api_request(""playlists"",                                          part=""id"",                                          maxResults=50,                                          channelId=playlist_id,                                          pageToken=token)        else:            playlists = self.api_request(""playlists"",                                          part=""id"",                                          maxResults=50,                                          channelId=playlist_id)        for playlist in playlists['items']:            yield playlist['id']        if ""nextPageToken"" in playlists:            for item in self._get_playlists(playlist_id, playlists['nextPageToken']):                yield item",,"def _get_playlists(self, playlist_id, token=None):        if token:            playlists = self.api_request(""playlists"",                                          part=""id"",                                          maxResults=50,                                          channelId=playlist_id,                                          pageToken=token)        else:            playlists = self.api_request(""playlists"",                                          part=""id"",                                          maxResults=50,                                          channelId=playlist_id)        for playlist in playlists['items']:            yield playlist['id']        if ""nextPageToken"" in playlists:            for item in self._get_playlists(playlist_id, playlists['nextPageToken']):                yield item",38903170-e772-48b1-87db-f9357ec36064
decrypters,YoutubeComFolder.py,get_playlists,83,84,"def get_playlists(self, ch_id):        return [self.get_playlist(p_id) for p_id in self._get_playlists(ch_id)]",,"def get_playlists(self, ch_id):        return [self.get_playlist(p_id) for p_id in self._get_playlists(ch_id)]",65a6305b-01fe-45a4-b3fc-50d0a452225b
decrypters,YoutubeComFolder.py,_get_videos_id,86,104,"def _get_videos_id(self, playlist_id, token=None):        if token:            playlist = self.api_request(""playlistItems"",                                         part=""contentDetails"",                                         maxResults=50,                                         playlistId=playlist_id,                                         pageToken=token)        else:            playlist = self.api_request(""playlistItems"",                                          part=""contentDetails"",                                          maxResults=50,                                          playlistId=playlist_id)        for item in playlist[""items""]:            yield item[""contentDetails""][""videoId""]        if ""nextPageToken"" in playlist:            for item in self._get_videos_id(playlist_id, playlist[""nextPageToken""]):                yield item",,"def _get_videos_id(self, playlist_id, token=None):        if token:            playlist = self.api_request(""playlistItems"",                                         part=""contentDetails"",                                         maxResults=50,                                         playlistId=playlist_id,                                         pageToken=token)        else:            playlist = self.api_request(""playlistItems"",                                          part=""contentDetails"",                                          maxResults=50,                                          playlistId=playlist_id)        for item in playlist[""items""]:            yield item[""contentDetails""][""videoId""]        if ""nextPageToken"" in playlist:            for item in self._get_videos_id(playlist_id, playlist[""nextPageToken""]):                yield item",614ed6ac-d4c9-4859-bdde-b35f27601e86
decrypters,YoutubeComFolder.py,get_videos_id,106,107,"def get_videos_id(self, p_id):        return list(self._get_videos_id(p_id))",,"def get_videos_id(self, p_id):        return list(self._get_videos_id(p_id))",d31da36f-7531-4862-a54e-43f79931f94c
decrypters,YoutubeComFolder.py,decrypt,109,178,"def decrypt(self, pyfile):        if self.info[""pattern""][""TYPE""] == ""user"":            self.log_debug(""Url recognized as Channel"")            channel = self.get_channel(self.info[""pattern""][""ID""])            if channel:                playlists = self.get_playlists(channel[""id""])                self.log_debug(                    r'{} playlists found on channel ""{}""'.format(                        len(playlists), channel[""title""]                    )                )                related_playlist = {                    p_name: self.get_playlist(p_id)                    for p_name, p_id in channel[""relatedPlaylists""].items()                }                self.log_debug(                    ""Channel's related playlists found = {}"".format(                        list(related_playlist.keys())                    )                )                related_playlist[""uploads""][""title""] = ""Unplaylisted videos""                related_playlist[""uploads""][""checkDups""] = True  #: checkDups flag                for p_name, p_data in related_playlist.items():                    if self.config.get(p_name):                        p_data[""title""] += "" of "" + channel[""user""]                        playlists.append(p_data)            else:                playlists = []        else:            self.log_debug(""Url recognized as Playlist"")            playlists = [self.get_playlist(self.info[""pattern""][""ID""])]        if not playlists:            self.fail(self._(""No playlist available""))        added_videos = []        urlize = lambda x: ""https://www.youtube.com/watch?v="" + x        for p in playlists:            p_name = p[""title""]            p_videos = self.get_videos_id(p[""id""])            self.log_debug(                r'{} videos found on playlist ""{}""'.format(len(p_videos), p_name)            )            if not p_videos:                continue            elif ""checkDups"" in p:                p_urls = [urlize(v_id) for v_id in p_videos if v_id not in added_videos]                self.log_debug(                    r'{} videos available on playlist ""{}"" after duplicates cleanup'.format(                        len(p_urls), p_name                    )                )            else:                p_urls = [urlize(url) for url in p_videos]            #: Folder is NOT recognized by pyload 0.5.0!            self.packages.append((p_name, p_urls, p_name))            added_videos.extend(p_videos)",,"def decrypt(self, pyfile):        if self.info[""pattern""][""TYPE""] == ""user"":            self.log_debug(""Url recognized as Channel"")            channel = self.get_channel(self.info[""pattern""][""ID""])            if channel:                playlists = self.get_playlists(channel[""id""])                self.log_debug(                    r'{} playlists found on channel ""{}""'.format(                        len(playlists), channel[""title""]                    )                )                related_playlist = {                    p_name: self.get_playlist(p_id)                    for p_name, p_id in channel[""relatedPlaylists""].items()                }                self.log_debug(                    ""Channel's related playlists found = {}"".format(                        list(related_playlist.keys())                    )                )                related_playlist[""uploads""][""title""] = ""Unplaylisted videos""                related_playlist[""uploads""][""checkDups""] = True  #: checkDups flag                for p_name, p_data in related_playlist.items():                    if self.config.get(p_name):                        p_data[""title""] += "" of "" + channel[""user""]                        playlists.append(p_data)            else:                playlists = []        else:            self.log_debug(""Url recognized as Playlist"")            playlists = [self.get_playlist(self.info[""pattern""][""ID""])]        if not playlists:            self.fail(self._(""No playlist available""))        added_videos = []        urlize = lambda x: ""https://www.youtube.com/watch?v="" + x        for p in playlists:            p_name = p[""title""]            p_videos = self.get_videos_id(p[""id""])            self.log_debug(                r'{} videos found on playlist ""{}""'.format(len(p_videos), p_name)            )            if not p_videos:                continue            elif ""checkDups"" in p:                p_urls = [urlize(v_id) for v_id in p_videos if v_id not in added_videos]                self.log_debug(                    r'{} videos available on playlist ""{}"" after duplicates cleanup'.format(                        len(p_urls), p_name                    )                )            else:                p_urls = [urlize(url) for url in p_videos]            #: Folder is NOT recognized by pyload 0.5.0!            self.packages.append((p_name, p_urls, p_name))            added_videos.extend(p_videos)",0b899cc6-c2e3-4c53-8163-8e5400dd66e1
downloaders,AccioDebridCom.py,args,11,12,def args(**kwargs):    return kwargs,,def args(**kwargs):    return kwargs,9155e025-310c-4d1a-a2f8-090567a42e27
downloaders,AccioDebridCom.py,api_response,35,43,"def api_response(self, action, get={}, post={}):        get['action'] = action        # Better use pyLoad User-Agent so we don't get blocked        self.req.http.c.setopt(pycurl.USERAGENT, ""pyLoad/%s"" % self.pyload.version)        json_data = self.load(self.API_URL, get=get, post=post)        return json.loads(json_data)",,"def api_response(self, action, get={}, post={}):        get['action'] = action        # Better use pyLoad User-Agent so we don't get blocked        self.req.http.c.setopt(pycurl.USERAGENT, ""pyLoad/%s"" % self.pyload.version)        json_data = self.load(self.API_URL, get=get, post=post)        return json.loads(json_data)",56d4c937-16bf-490c-9e89-f1f05077bcfd
downloaders,AccioDebridCom.py,handle_premium,45,70,"def handle_premium(self, pyfile):        try:            res = self.api_response(""getLink"",                                    get=args(token=self.account.info['data']['cache_info'][self.account.user]['token']),                                    post=args(link=pyfile.url))        except BadHeader as exc:            if exc.code == 405:                self.fail(self._(""Banned IP""))            else:                raise        if res['response_code'] == ""ok"":            self.link = res['debridLink']        elif res['response_code'] == ""UNKNOWN_ACCOUNT_TOKEN"":            self.account.relogin()            self.retry()        elif res['response_code'] == ""UNALLOWED_IP"":            self.fail(self._(""Banned IP""))        else:            self.log_error(res['response_text'])            self.fail(res['response_text'])",,"def handle_premium(self, pyfile):        try:            res = self.api_response(""getLink"",                                    get=args(token=self.account.info['data']['cache_info'][self.account.user]['token']),                                    post=args(link=pyfile.url))        except BadHeader as exc:            if exc.code == 405:                self.fail(self._(""Banned IP""))            else:                raise        if res['response_code'] == ""ok"":            self.link = res['debridLink']        elif res['response_code'] == ""UNKNOWN_ACCOUNT_TOKEN"":            self.account.relogin()            self.retry()        elif res['response_code'] == ""UNALLOWED_IP"":            self.fail(self._(""Banned IP""))        else:            self.log_error(res['response_text'])            self.fail(res['response_text'])",baee067e-ada2-4842-af0b-134150cf7ae1
downloaders,AlfafileNet.py,handle_free,43,90,"def handle_free(self, pyfile):        json_data = self.load(            self.fixurl(""/download/start_timer/"" + self.info[""pattern""][""ID""])        )        json_data = json.loads(json_data)        if json_data[""show_timer""]:            self.wait(json_data[""timer""])            redirect_url = self.fixurl(json_data[""redirect_url""])            self.data = self.load(redirect_url)            solvemedia = SolveMedia(self.pyfile)            captcha_key = solvemedia.detect_key()            if captcha_key:                self.captcha = solvemedia                response, challenge = solvemedia.challenge(captcha_key)                self.data = self.load(                    redirect_url,                    post={""adcopy_response"": response, ""adcopy_challenge"": challenge},                )            else:                recaptcha = ReCaptcha(self.pyfile)                captcha_key = recaptcha.detect_key()                if captcha_key:                    self.captcha = recaptcha                    response = recaptcha.challenge(captcha_key)                    self.data = self.load(redirect_url,                                          post={'g-recaptcha-response': response})                else:                    self.error(self._(""Captcha pattern not found""))            if ""Invalid captcha"" in self.data:                self.retry_captcha()            else:                self.captcha.correct()                m = re.search(self.LINK_PATTERN, self.data)                if m is not None:                    self.link = m.group(1)        else:            self.data = json_data[""html""]            self.check_errors()",,"def handle_free(self, pyfile):        json_data = self.load(            self.fixurl(""/download/start_timer/"" + self.info[""pattern""][""ID""])        )        json_data = json.loads(json_data)        if json_data[""show_timer""]:            self.wait(json_data[""timer""])            redirect_url = self.fixurl(json_data[""redirect_url""])            self.data = self.load(redirect_url)            solvemedia = SolveMedia(self.pyfile)            captcha_key = solvemedia.detect_key()            if captcha_key:                self.captcha = solvemedia                response, challenge = solvemedia.challenge(captcha_key)                self.data = self.load(                    redirect_url,                    post={""adcopy_response"": response, ""adcopy_challenge"": challenge},                )            else:                recaptcha = ReCaptcha(self.pyfile)                captcha_key = recaptcha.detect_key()                if captcha_key:                    self.captcha = recaptcha                    response = recaptcha.challenge(captcha_key)                    self.data = self.load(redirect_url,                                          post={'g-recaptcha-response': response})                else:                    self.error(self._(""Captcha pattern not found""))            if ""Invalid captcha"" in self.data:                self.retry_captcha()            else:                self.captcha.correct()                m = re.search(self.LINK_PATTERN, self.data)                if m is not None:                    self.link = m.group(1)        else:            self.data = json_data[""html""]            self.check_errors()",05ec3364-8d96-4a92-b008-e870cd845f64
downloaders,AlfafileNet.py,check_errors,92,107,"def check_errors(self):        super().check_errors()        if re.search(r""You can't download not more than \d+ file at a time"", self.data):            self.retry(                wait=20 * 60,                msg=self._(""Too many max simultaneous downloads""),                msgfail=self._(""Too many max simultaneous downloads""),            )        if ""You have reached your daily downloads limit"" in self.data:            self.retry(                wait=seconds.to_midnight(),                msg=self._(""Daily download limit reached""),                msgfail=self._(""Daily download limit reached""),            )",,"def check_errors(self):        super().check_errors()        if re.search(r""You can't download not more than \d+ file at a time"", self.data):            self.retry(                wait=20 * 60,                msg=self._(""Too many max simultaneous downloads""),                msgfail=self._(""Too many max simultaneous downloads""),            )        if ""You have reached your daily downloads limit"" in self.data:            self.retry(                wait=seconds.to_midnight(),                msg=self._(""Daily download limit reached""),                msgfail=self._(""Daily download limit reached""),            )",9a9b1c8d-55c4-4718-ac91-858824971a9f
downloaders,AlldebridCom.py,api_request,56,64,"def api_request(self, method, get={}, post={}, multipart=False):        get.update({""agent"": ""pyLoad"", ""version"": self.pyload.version})        json_data = json.loads(            self.load(self.API_URL + method, get=get, post=post, multipart=multipart)        )        if json_data[""status""] == ""success"":            return json_data[""data""]        else:            return json_data",,"def api_request(self, method, get={}, post={}, multipart=False):        get.update({""agent"": ""pyLoad"", ""version"": self.pyload.version})        json_data = json.loads(            self.load(self.API_URL + method, get=get, post=post, multipart=multipart)        )        if json_data[""status""] == ""success"":            return json_data[""data""]        else:            return json_data",605ec059-c230-4fd8-ae21-97dcbb66a007
downloaders,AlldebridCom.py,sleep,66,70,"def sleep(self, sec):        for _i in range(sec):            if self.pyfile.abort:                break            time.sleep(1)",,"def sleep(self, sec):        for _i in range(sec):            if self.pyfile.abort:                break            time.sleep(1)",564c0953-f5e6-42ab-a671-7c11865081ae
downloaders,AlldebridCom.py,setup,72,73,def setup(self):        self.chunk_limit = 16,,def setup(self):        self.chunk_limit = 16,100f59c1-25fa-4583-888b-21f92e646fdc
downloaders,AlldebridCom.py,handle_premium,75,162,"def handle_premium(self, pyfile):        api_data = self.api_request(            ""link/unlock"",            get={                ""link"": pyfile.url,                ""password"": self.get_password(),                ""apikey"": self.account.info[""login""][""password""],            },        )        if api_data.get(""error"", False):            if api_data[""error""][""code""] == ""LINK_DOWN"":                self.offline()            else:                self.log_error(api_data[""error""][""message""])                self.temp_offline()        else:            if api_data[""link""] == """" and ""streams"" in api_data:                unlock_id = api_data[""id""]                streams = dict(                    [                        (                            _s[""quality""],                            {                                ""ext"": _s[""ext""],                                ""filesize"": _s[""filesize""],                                ""id"": _s[""id""],                            },                        )                        for _s in api_data[""streams""]                        if type(_s[""quality""]) == int                    ]                )                qualities = sorted(streams.keys())                self.log_debug(""AVAILABLE STREAMS: {}"".format(qualities))                desired_quality = self.config.get(""stream_quality"")                if desired_quality == ""Lowest"":                    chosen_quality = qualities[0]                elif desired_quality == ""Highest"":                    chosen_quality = qualities[-1]                else:                    desired_quality = int(re.search(r""\d+"", desired_quality).group(0))                    chosen_quality = min(qualities, key=lambda x: abs(x - desired_quality))                self.log_debug(""CHOSEN STREAM: {}"".format(chosen_quality))                stream_id = streams[chosen_quality][""id""]                stream_name = (                    api_data[""filename""] + ""."" + streams[chosen_quality][""ext""]                )                stream_size = streams[chosen_quality][""filesize""]                api_data = self.api_request(                    ""link/streaming"",                    get={                        ""apikey"": self.account.info[""login""][""password""],                        ""id"": unlock_id,                        ""stream"": stream_id,                    },                )                if api_data.get(""error"", False):                    self.log_error(api_data[""error""][""message""])                    self.temp_offline()                delayed_id = api_data.get(""delayed"")                if delayed_id:                    pyfile.set_custom_status(""delayed stream"")                    while True:                        api_data = self.api_request(                            ""link/delayed"",                            get={                                ""apikey"": self.account.info[""login""][""password""],                                ""id"": delayed_id,                            },                        )                        if ""link"" in api_data:                            pyfile.name = stream_name                            pyfile.size = stream_size                            self.chunk_limit = api_data.get(""max_chunks"", 16)                            self.link = api_data[""link""]                            return                        self.sleep(5)            pyfile.name = api_data[""filename""]            pyfile.size = api_data[""filesize""]            self.chunk_limit = api_data.get(""max_chunks"", 16)            self.link = api_data[""link""]",,"def handle_premium(self, pyfile):        api_data = self.api_request(            ""link/unlock"",            get={                ""link"": pyfile.url,                ""password"": self.get_password(),                ""apikey"": self.account.info[""login""][""password""],            },        )        if api_data.get(""error"", False):            if api_data[""error""][""code""] == ""LINK_DOWN"":                self.offline()            else:                self.log_error(api_data[""error""][""message""])                self.temp_offline()        else:            if api_data[""link""] == """" and ""streams"" in api_data:                unlock_id = api_data[""id""]                streams = dict(                    [                        (                            _s[""quality""],                            {                                ""ext"": _s[""ext""],                                ""filesize"": _s[""filesize""],                                ""id"": _s[""id""],                            },                        )                        for _s in api_data[""streams""]                        if type(_s[""quality""]) == int                    ]                )                qualities = sorted(streams.keys())                self.log_debug(""AVAILABLE STREAMS: {}"".format(qualities))                desired_quality = self.config.get(""stream_quality"")                if desired_quality == ""Lowest"":                    chosen_quality = qualities[0]                elif desired_quality == ""Highest"":                    chosen_quality = qualities[-1]                else:                    desired_quality = int(re.search(r""\d+"", desired_quality).group(0))                    chosen_quality = min(qualities, key=lambda x: abs(x - desired_quality))                self.log_debug(""CHOSEN STREAM: {}"".format(chosen_quality))                stream_id = streams[chosen_quality][""id""]                stream_name = (                    api_data[""filename""] + ""."" + streams[chosen_quality][""ext""]                )                stream_size = streams[chosen_quality][""filesize""]                api_data = self.api_request(                    ""link/streaming"",                    get={                        ""apikey"": self.account.info[""login""][""password""],                        ""id"": unlock_id,                        ""stream"": stream_id,                    },                )                if api_data.get(""error"", False):                    self.log_error(api_data[""error""][""message""])                    self.temp_offline()                delayed_id = api_data.get(""delayed"")                if delayed_id:                    pyfile.set_custom_status(""delayed stream"")                    while True:                        api_data = self.api_request(                            ""link/delayed"",                            get={                                ""apikey"": self.account.info[""login""][""password""],                                ""id"": delayed_id,                            },                        )                        if ""link"" in api_data:                            pyfile.name = stream_name                            pyfile.size = stream_size                            self.chunk_limit = api_data.get(""max_chunks"", 16)                            self.link = api_data[""link""]                            return                        self.sleep(5)            pyfile.name = api_data[""filename""]            pyfile.size = api_data[""filesize""]            self.chunk_limit = api_data.get(""max_chunks"", 16)            self.link = api_data[""link""]",429caf46-a328-476f-91a2-6aa20508d3b0
downloaders,AndroidfilehostCom.py,setup,38,41,def setup(self):        self.multi_dl = True        self.resume_download = True        self.chunk_limit = 1,,def setup(self):        self.multi_dl = True        self.resume_download = True        self.chunk_limit = 1,460ed63d-fe95-4d38-8b8f-f01b755ad281
downloaders,AndroidfilehostCom.py,handle_free,43,67,"def handle_free(self, pyfile):        wait = re.search(self.WAIT_PATTERN, self.data)        if wait is not None:            self.log_debug(f""Waiting time: {wait.group(1)} seconds"")        fid = re.search(r'id=""fid"" value=""(\d+)"" />', self.data).group(1)        self.log_debug(f""FID: {fid}"")        self.req.http.c.setopt(pycurl.HTTPHEADER, [""X-MOD-SBB-CTYPE: xhr""])        html = self.load(            ""https://androidfilehost.com/libs/otf/mirrors.otf.php"",            post={""submit"": ""submit"", ""action"": ""getdownloadmirrors"", ""fid"": fid},        )        self.req.http.c.setopt(pycurl.HTTPHEADER, [""X-MOD-SBB-CTYPE:""])        self.link = re.findall('""url"":""(.*?)""', html)[0].replace(""\\"", """")        mirror_host = self.link.split(""/"")[2]        self.log_debug(f""Mirror Host: {mirror_host}"")        html = self.load(            ""https://androidfilehost.com/libs/otf/stats.otf.php"",            get={""fid"": fid, ""w"": ""download"", ""mirror"": mirror_host},        )",,"def handle_free(self, pyfile):        wait = re.search(self.WAIT_PATTERN, self.data)        if wait is not None:            self.log_debug(f""Waiting time: {wait.group(1)} seconds"")        fid = re.search(r'id=""fid"" value=""(\d+)"" />', self.data).group(1)        self.log_debug(f""FID: {fid}"")        self.req.http.c.setopt(pycurl.HTTPHEADER, [""X-MOD-SBB-CTYPE: xhr""])        html = self.load(            ""https://androidfilehost.com/libs/otf/mirrors.otf.php"",            post={""submit"": ""submit"", ""action"": ""getdownloadmirrors"", ""fid"": fid},        )        self.req.http.c.setopt(pycurl.HTTPHEADER, [""X-MOD-SBB-CTYPE:""])        self.link = re.findall('""url"":""(.*?)""', html)[0].replace(""\\"", """")        mirror_host = self.link.split(""/"")[2]        self.log_debug(f""Mirror Host: {mirror_host}"")        html = self.load(            ""https://androidfilehost.com/libs/otf/stats.otf.php"",            get={""fid"": fid, ""w"": ""download"", ""mirror"": mirror_host},        )",48633370-abbe-47bc-9a04-61e7e1b5dc34
downloaders,AnonfilesCom.py,setup,32,35,def setup(self):        self.multi_dl = True        self.resume_download = True        self.chunk_limit = -1,,def setup(self):        self.multi_dl = True        self.resume_download = True        self.chunk_limit = -1,962f8014-79e1-4f67-96cb-a3f880deaffb
downloaders,ArchiveOrg.py,setup,25,28,def setup(self):        self.multi_dl = True        self.resume_download = True        self.chunk_limit = -1,,def setup(self):        self.multi_dl = True        self.resume_download = True        self.chunk_limit = -1,9293d49d-17dd-40c9-bd88-64a9801d94d7
downloaders,BasketbuildCom.py,setup,36,39,def setup(self):        self.multi_dl = True        self.resume_download = True        self.chunk_limit = 1,,def setup(self):        self.multi_dl = True        self.resume_download = True        self.chunk_limit = 1,0e873530-4881-4b0d-83e7-fb45f13bb101
downloaders,BasketbuildCom.py,handle_free,41,64,"def handle_free(self, pyfile):        try:            link1 = re.search(r'href=""(.+dlgate/.+)""', self.data).group(1)            self.data = self.load(link1)        except AttributeError:            self.error(self._(""Hop #1 not found""))        else:            self.log_debug(f""Next hop: {link1}"")        try:            wait = re.search(r""var sec = (\d+)"", self.data).group(1)            self.log_debug(f""Wait {wait} seconds"")            self.wait(wait)        except AttributeError:            self.log_debug(""No wait time found"")        try:            self.link = re.search(r'id=""dlLink"">\s*<a href=""(.+?)""', self.data).group(1)        except AttributeError:            self.error(self._(""DL-Link not found""))",,"def handle_free(self, pyfile):        try:            link1 = re.search(r'href=""(.+dlgate/.+)""', self.data).group(1)            self.data = self.load(link1)        except AttributeError:            self.error(self._(""Hop #1 not found""))        else:            self.log_debug(f""Next hop: {link1}"")        try:            wait = re.search(r""var sec = (\d+)"", self.data).group(1)            self.log_debug(f""Wait {wait} seconds"")            self.wait(wait)        except AttributeError:            self.log_debug(""No wait time found"")        try:            self.link = re.search(r'id=""dlLink"">\s*<a href=""(.+?)""', self.data).group(1)        except AttributeError:            self.error(self._(""DL-Link not found""))",3881efa5-a833-46a1-bf47-1ab05cdcb970
downloaders,BayfilesCom.py,api_info,32,51,"def api_info(self, url):        info = {}        file_id = re.match(self.__pattern__, url).group(""ID"")        json_data = self.load(f""https://api.bayfiles.com/v2/file/{file_id}/info"")        api_data = json.loads(json_data)        if api_data[""status""] is True:            info[""status""] = 2            info[""name""] = api_data[""data""][""file""][""metadata""][""name""]            info[""size""] = api_data[""data""][""file""][""metadata""][""size""][""bytes""]        else:            if api_data[""error""][""type""] in (""FILE_NOT_FOUND"", ""ERROR_FILE_BANNED""):                info[""status""] = 1            else:                info[""error""] = api_data[""error""][""message""]                info[""status""] = 8        return info",,"def api_info(self, url):        info = {}        file_id = re.match(self.__pattern__, url).group(""ID"")        json_data = self.load(f""https://api.bayfiles.com/v2/file/{file_id}/info"")        api_data = json.loads(json_data)        if api_data[""status""] is True:            info[""status""] = 2            info[""name""] = api_data[""data""][""file""][""metadata""][""name""]            info[""size""] = api_data[""data""][""file""][""metadata""][""size""][""bytes""]        else:            if api_data[""error""][""type""] in (""FILE_NOT_FOUND"", ""ERROR_FILE_BANNED""):                info[""status""] = 1            else:                info[""error""] = api_data[""error""][""message""]                info[""status""] = 8        return info",7713c1b2-972c-4c92-a93f-b16c4576bf18
